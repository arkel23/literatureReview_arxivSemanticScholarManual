authors,paperId,title,venue,year,no_citations,abstract
"Peng Xu, Chaitanya K. Joshi, X. Bresson",29c2b6c72b41583206bb7c2694824ca7723d2dcc,Multi-Graph Transformer for Free-Hand Sketch Recognition,IEEE transactions on neural networks and learning systems,2021.0,19,"Learning meaningful representations of free-hand sketches remains a challenging task given the signal sparsity and the high-level abstraction of sketches. Existing techniques have focused on exploiting either the static nature of sketches with convolutional neural networks (CNNs) or the temporal sequential property with recurrent neural networks (RNNs). In this work, we propose a new representation of sketches as multiple sparsely connected graphs. We design a novel graph neural network (GNN), the multigraph transformer (MGT), for learning representations of sketches from multiple graphs, which simultaneously capture global and local geometric stroke structures as well as temporal information. We report extensive numerical experiments on a sketch recognition task to demonstrate the performance of the proposed approach. Particularly, MGT applied on 414k sketches from Google QuickDraw: 1) achieves a small recognition gap to the CNN-based performance upper bound (72.80% versus 74.22%) and infers faster than the CNN competitors and 2) outperforms all RNN-based models by a significant margin. To the best of our knowledge, this is the first work proposing to represent sketches as graphs and apply GNNs for sketch recognition. Code and trained models are available at https://github.com/PengBoXiangShang/multigraph_transformer."
"Bingchen Liu, Yizhe Zhu, Kunpeng Song, A. Elgammal",6c4fe31504d47b8547e47267c0cb4efa464f022b,Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis,ICLR,2021.0,6,"Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on 1024 × 1024 resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains 1, we show our model’s superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited."
"Yuefan Shen, Changgeng Zhang, Hongbo Fu, Kun Zhou, Youyi Zheng",ca0e4d793052f65f2a38771bce81406c101c4230,DeepSketchHair: Deep Sketch-Based 3D Hair Modeling,IEEE Transactions on Visualization and Computer Graphics,2021.0,5,"We present DeepSketchHair, a deep learning based tool for modeling of 3D hair from 2D sketches. Given a 3D bust model as reference, our sketching system takes as input a user-drawn sketch (consisting of hair contour and a few strokes indicating the hair growing direction within a hair region), and automatically generates a 3D hair model, matching the input sketch. The key enablers of our system are three carefully designed neural networks, namely, S2ONet, which converts an input sketch to a dense 2D hair orientation field; O2VNet, which maps the 2D orientation field to a 3D vector field; and V2VNet, which updates the 3D vector field with respect to the new sketches, enabling hair editing with additional sketches in new views. All the three networks are trained with synthetic data generated from a 3D hairstyle database. We demonstrate the effectiveness and expressiveness of our tool using a variety of hairstyles and also compare our method with prior art."
"Peng Xu, Zeyu Song, Qiyue Yin, Yi-Zhe Song, Liang Wang",092a640603e1e5bea677f4182a067cc45a5fcc32,Deep Self-Supervised Representation Learning for Free-Hand Sketch,IEEE Transactions on Circuits and Systems for Video Technology,2021.0,5,"In this paper, we tackle for the first time, the problem of self-supervised representation learning for free-hand sketches. This importantly addresses a common problem faced by the sketch community – that annotated supervisory data are difficult to obtain. This problem is very challenging in which sketches are highly abstract and subject to different drawing styles, making existing solutions tailored for photos unsuitable. Key for the success of our self-supervised learning paradigm lies with our sketch-specific designs: (i) we propose a set of pretext tasks specifically designed for sketches that mimic different drawing styles, and (ii) we further exploit the use of the textual convolution network (TCN) together with the convolutional neural network (CNN) in a dual-branch architecture for sketch feature learning, as means to accommodate the sequential stroke nature of sketches. We demonstrate the superiority of our sketch-specific designs through two sketch-related applications (retrieval and recognition) on a million-scale sketch dataset, and show that the proposed approach outperforms the state-of-the-art unsupervised representation learning methods, and significantly narrows the performance gap between with supervised representation learning.11PyTorch code of this work is available at https://github.com/zzz1515151/self-supervised_learning_sketch."
"Mohammad Keshavarzi, Clayton Hutson, Chin-Yi Cheng, M. Nourbakhsh, M. Bergin, M. R. Asl",dab15e14d224b74490111c2c60d4f1e1a4a3ee7c,SketchOpt: Sketch-based Parametric Model Retrieval for Generative Design,CHI Extended Abstracts,2021.0,4,"Developing fully parametric building models for performance-based generative design tasks often requires proficiency in many advanced 3D modeling and visual programming software, limiting its use for many building designers. Moreover, iterations of such models can be time-consuming tasks and sometimes limiting depending on the the design stage, as major changes in the layout design may result in remodeling the entire parametric definition. To address these challenges, we introduce a novel automated generative design system, which takes a basic floor plan sketch as an input and provides a parametric model prepared for multi-objective building optimization as output. In addition, the user-designer can assign various design variables for its desired building elements by using simple annotations in the drawing. We take advantage of a asymmetric convolutional module combined with a parametrizer to allow real-time parametric sketch-retrieval for a performance-based generative workflow. The system would recognize the corresponding element and define variable constraints to prepare for a multi-objective optimization problem. We illustrate the the use case of our proposed system by running a real-time structural optimization form-finding study. Our findings indicate the system can be utilized as a promising generative design tool for novice users."
"Hao Su, J. Niu, X. Liu, Qingfeng Li, Jiahe Cui, J. Wan",55f45f009bdf4f8ec0bbf5c1c0da6db0e39508da,Unpaired Photo-to-manga Translation Based on The Methodology of Manga Drawing,AAAI,2021.0,4,"Manga is a world popular comic form originated in Japan, which typically employs black-and-white stroke lines and geometric exaggeration to describe humans' appearances, poses, and actions. In this paper, we propose MangaGAN, the first method based on Generative Adversarial Network (GAN) for unpaired photo-to-manga translation. Inspired by how experienced manga artists draw manga, MangaGAN generates the geometric features of manga face by a designed GAN model and delicately translates each facial region into the manga domain by a tailored multi-GANs architecture. For training MangaGAN, we construct a new dataset collected from a popular manga work, containing manga facial features, landmarks, bodies, and so on. Moreover, to produce high-quality manga faces, we further propose a structural smoothing loss to smooth stroke-lines and avoid noisy pixels, and a similarity preserving module to improve the similarity between domains of photo and manga. Extensive experiments show that MangaGAN can produce high-quality manga faces which preserve both the facial similarity and a popular manga style, and outperforms other related state-of-the-art methods."
"Jialu Huang, Jing Liao, S. Kwong",b34f49ca5955c19fc1b5f82a356c259d129fdb05,Semantic Example Guided Image-to-Image Translation,IEEE Transactions on Multimedia,2021.0,4,"Many image-to-image (I2I) translation problems are in nature of high diversity that a single input may have various counterparts. The multi-modal network that can build a many-to-many mapping between two visual domains has been proposed in prior works. However, most of them are guided by sampled noises. Some others encode the reference image into a latent vector, which would eliminate the semantic information of the reference image. In this work, we aim to provide a solution to control the output based on references semantically. Given a reference image and an input in another domain, we first perform semantic matching between the two visual content and generate an auxiliary image, which explicitly encourages the semantic characteristic to be preserved. A deep network then is used for I2I translation and the final outputs are expected to be semantically similar to both the input and the reference. However, few paired data can satisfy that dual-similarity in a supervised fashion, and so we build up a self-supervised framework in the training stage. We improve the quality and diversity of the outputs by employing non-local blocks and a multi-task architecture. We assess the proposed method through extensive qualitative and quantitative evaluations and also present comparisons with several state-of-the-art models."
"Aneeshan Sain, A. Bhunia, Yongxin Yang, Tao Xiang, Yi-Zhe Song",52bffd428b3f0c14509d6e68699ece7c46f7cf0b,StyleMeUp: Towards Style-Agnostic Sketch-Based Image Retrieval,ArXiv,2021.0,3,"Sketch-based image retrieval (SBIR) is a cross-modal matching problem which is typically solved by learning a joint embedding space where the semantic content shared between photo and sketch modalities are preserved. However, a fundamental challenge in SBIR has been largely ignored so far, that is, sketches are drawn by humans and considerable style variations exist amongst different users. An effective SBIR model needs to explicitly account for this style diversity, crucially, to generalise to unseen user styles. To this end, a novel style-agnostic SBIR model is proposed. Different from existing models, a cross-modal variational autoencoder (VAE) is employed to explicitly disentangle each sketch into a semantic content part shared with the corresponding photo, and a style part unique to the sketcher. Importantly, to make our model dynamically adaptable to any unseen user styles, we propose to metatrain our cross-modal VAE by adding two style-adaptive components: a set of feature transformation layers to its encoder and a regulariser to the disentangled semantic content latent code. With this meta-learning framework, our model can not only disentangle the cross-modal shared semantic content for SBIR, but can adapt the disentanglement to any unseen user style as well, making the SBIR model truly style-agnostic. Extensive experiments show that our style-agnostic model yields state-of-the-art performance for both category-level and instance-level SBIR."
"A. Bhunia, Pinaki Nath Chowdhury, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",a122250dddb137f41ffbb534878794f46f740e00,Vectorization and Rasterization: Self-Supervised Learning for Sketch and Handwriting,ArXiv,2021.0,3,"Self-supervised learning has gained prominence due to its efficacy at learning powerful representations from unlabelled data that achieve excellent performance on many challenging downstream tasks. However, supervision-free pre-text tasks are challenging to design and usually modality specific. Although there is a rich literature of selfsupervised methods for either spatial (such as images) or temporal data (sound or text) modalities, a common pretext task that benefits both modalities is largely missing. In this paper, we are interested in defining a self-supervised pre-text task for sketches and handwriting data. This data is uniquely characterised by its existence in dual modalities of rasterized images and vector coordinate sequences. We address and exploit this dual representation by proposing two novel cross-modal translation pre-text tasks for selfsupervised feature learning: Vectorization and Rasterization. Vectorization learns to map image space to vector coordinates and rasterization maps vector coordinates to image space. We show that our learned encoder modules benefit both raster-based and vector-based downstream approaches to analysing hand-drawn data. Empirical evidence shows that our novel pre-text tasks surpass existing single and multi-modal self-supervision methods."
"Michael P. Sheehan, J. Tachella, M. Davies",f820b189b7444957ecb74b64243c37bdf8c8af17,A Sketching Framework for Reduced Data Transfer in Photon Counting Lidar,,2021.0,2,"Single-photon lidar has become a prominent tool for depth imaging in recent years. At the core of the technique, the depth of a target is measured by constructing a histogram of time delays between emitted light pulses and detected photon arrivals. A major data processing bottleneck arises on the device when either the number of photons per pixel is large or the resolution of the time stamp is fine, as both the space requirement and the complexity of the image reconstruction algorithms scale with these parameters. We solve this limiting bottleneck of existing lidar techniques by sampling the characteristic function of the time of flight (ToF) model to build a compressive statistic, a socalled sketch of the time delay distribution, which is sufficient to infer the spatial distance and intensity of the object. The size of the sketch scales with the degrees of freedom of the ToF model (number of objects) and not, fundamentally, with the number of photons or the time stamp resolution. Moreover, the sketch is highly amenable for on-chip online processing. We show theoretically that the loss of information for compression is controlled and the mean squared error of the inference quickly converges towards the optimal Cramér-Rao bound (i.e. no loss of information) for modest sketch sizes. The proposed compressed single-photon lidar framework is tested and evaluated on real life datasets of complex scenes where it is shown that a compression rate of up-to 1/150 is achievable in practice without sacrificing the overall resolution of the reconstructed image."
"A. Bhunia, Pinaki Nath Chowdhury, Aneeshan Sain, Yongxin Yang, Tao Xiang, Yi-Zhe Song",ee3ec7893003ba55175a183b13baad845e5375e1,More Photos are All You Need: Semi-Supervised Learning for Fine-Grained Sketch Based Image Retrieval,ArXiv,2021.0,2,"A fundamental challenge faced by existing Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) models is the data scarcity – model performances are largely bottlenecked by the lack of sketch-photo pairs. Whilst the number of photos can be easily scaled, each corresponding sketch still needs to be individually produced. In this paper, we aim to mitigate such an upper-bound on sketch data, and study whether unlabelled photos alone (of which they are many) can be cultivated for performance gain. In particular, we introduce a novel semi-supervised framework for cross-modal retrieval that can additionally leverage large-scale unlabelled photos to account for data scarcity. At the center of our semi-supervision design is a sequential photo-to-sketch generation model that aims to generate paired sketches for unlabelled photos. Importantly, we further introduce a discriminator-guided mechanism to guide against unfaithful generation, together with a distillation loss-based regularizer to provide tolerance against noisy training samples. Last but not least, we treat generation and retrieval as two conjugate problems, where a joint learning procedure is devised for each module to mutually benefit from each other. Extensive experiments show that our semi-supervised model yields a significant performance boost over the state-of-theart supervised alternatives, as well as existing methods that can exploit unlabelled photos for FG-SBIR."
"Bingchen Liu, Yizhe Zhu, Kunpeng Song, A. Elgammal",e5956dc1c3e93a37d80aeb908b8a7e76c2185856,Self-Supervised Sketch-to-Image Synthesis,AAAI,2021.0,2,"Imagining a colored realistic image from an arbitrarily drawn sketch is one of the human capabilities that we eager machines to mimic. Unlike previous methods that either requires the sketch-image pairs or utilize low-quantity detected edges as sketches, we study the exemplar-based sketch-to-image (s2i) synthesis task in a self-supervised learning manner, eliminating the necessity of the paired sketch data. To this end, we first propose an unsupervised method to efficiently synthesize line-sketches for general RGB-only datasets. With the synthetic paired-data, we then present a self-supervised Auto-Encoder (AE) to decouple the content/style features from sketches and RGB-images, and synthesize images that are both content-faithful to the sketches and style-consistent to the RGB-images. While prior works employ either the cycle-consistence loss or dedicated attentional modules to enforce the content/style fidelity, we show AE's superior performance with pure self-supervisions. To further improve the synthesis quality in high resolution, we also leverage an adversarial network to refine the details of synthetic images. Extensive experiments on 1024*1024 resolution demonstrate a new state-of-art-art performance of the proposed model on CelebA-HQ and Wiki-Art datasets. Moreover, with the proposed sketch generator, the model shows a promising performance on style mixing and style transfer, which require synthesized images to be both style-consistent and semantically meaningful. Our code is available on this https URL, and please visit this https URL for an online demo of our model."
"Peng Xu, K. Liu, Tao Xiang, Timothy M. Hospedales, Zhanyu Ma, Jun Guo, Yi-Zhe Song",b5c8c79a9a943ababce9bd6892da97d297d0b3e1,Fine-Grained Instance-Level Sketch-Based Video Retrieval,IEEE Transactions on Circuits and Systems for Video Technology,2021.0,2,"Existing sketch-analysis work studies sketches depicting static objects or scenes. In this work, we propose a novel cross-modal retrieval problem of fine-grained instance-level sketch-based video retrieval (FG-SBVR), where a sketch sequence is used as a query to retrieve a specific target video instance. Compared with sketch-based still image retrieval, and coarse-grained category-level video retrieval, this is more challenging as both visual appearance and motion need to be simultaneously matched at a fine-grained level. We contribute the first FG-SBVR dataset with rich annotations. We then introduce a novel multi-stream multi-modality deep network to perform FG-SBVR under both strong and weakly supervised settings. The key component of the network is a relation module, designed to prevent model overfitting given scarce training data. We show that this model significantly outperforms a number of existing state-of-the-art models designed for video analysis."
"Deng Yu, Lei Li, Youyi Zheng, M. Lau, Yi-Zhe Song, C. Tai, Hongbo Fu",4ac408cd2c4eab610de34a0fc37a6d68f07115e9,SketchDesc: Learning Local Sketch Descriptors for Multi-View Correspondence,IEEE Transactions on Circuits and Systems for Video Technology,2021.0,2,"In this article, we study the problem of multi-view sketch correspondence, where we take as input multiple freehand sketches with different views of the same object and predict as output the semantic correspondence among the sketches. This problem is challenging since the visual features of corresponding points at different views can be very different. To this end, we take a deep learning approach and learn a novel local sketch descriptor from data. We contribute a training dataset by generating the pixel-level correspondence for the multi-view line drawings synthesized from 3D shapes. To handle the sparsity and ambiguity of sketches, we design a novel multi-branch neural network that integrates a patch-based representation and a multi-scale strategy to learn the pixel-level correspondence among multi-view sketches. We demonstrate the effectiveness of our proposed approach with extensive experiments on hand-drawn sketches and multi-view line drawings rendered from multiple 3D shape datasets."
"Pablo E. Navarro, J. Orlando, C. Delrieux, Emmanuel Iarussi",049d7356d18f7fed9b11720e895b35f103f62828,SketchZooms: Deep Multi‐view Descriptors for Matching Line Drawings,Comput. Graph. Forum,2021.0,2,"Finding point‐wise correspondences between images is a long‐standing problem in image analysis. This becomes particularly challenging for sketch images, due to the varying nature of human drawing style, projection distortions and viewport changes. In this paper, we present the first attempt to obtain a learned descriptor for dense registration in line drawings. Based on recent deep learning techniques for corresponding photographs, we designed descriptors to locally match image pairs where the object of interest belongs to the same semantic category, yet still differ drastically in shape, form, and projection angle. To this end, we have specifically crafted a data set of synthetic sketches using non‐photorealistic rendering over a large collection of part‐based registered 3D models. After training, a neural network generates descriptors for every pixel in an input image, which are shown togeneralize correctly in unseen sketches hand‐drawn by humans. We evaluate our method against a baseline of correspondences data collected from expert designers, in addition to comparisons with other descriptors that have been proven effective in sketches. Code, data and further resources will be publicly released by the time of publication."
"Dries Van Daele, Nicholas Decleyre, Herman Dubois, Wannes Meert",4274358c42000073c1e1181c8dd78ff18b92400a,An Automated Engineering Assistant: Learning Parsers for Technical Drawings,AAAI,2021.0,2,"From a set of technical drawings and expert knowledge, we automatically learn a parser to interpret such a drawing. This enables automatic reasoning and learning on top of a large database of technical drawings. In this work, we develop a similarity based search algorithm to help engineers and designers find or complete designs more easily and flexibly. This is part of an ongoing effort to build an automated engineering assistant. The proposed methods make use of both neural methods to learn to interpret images, and symbolic methods to learn to interpret the structure in the technical drawing and incorporate expert knowledge."
"Yu Tian, Jian Ren, Menglei Chai, Kyle Olszewski, Xi Peng, Dimitris N. Metaxas, S. Tulyakov",3618e503068e5f0e4f17ad1557a9bd6692daea79,A Good Image Generator Is What You Need for High-Resolution Video Synthesis,ICLR,2021.0,2,"Image and video synthesis are closely related areas aiming at generating content from noise. While rapid progress has been demonstrated in improving imagebased models to handle large resolutions, high-quality renderings, and wide variations in image content, achieving comparable video generation results remains problematic. We present a framework that leverages contemporary image generators to render high-resolution videos. We frame the video synthesis problem as discovering a trajectory in the latent space of a pre-trained and fixed image generator. Not only does such a framework render high-resolution videos, but it also is an order of magnitude more computationally efficient. We introduce a motion generator that discovers the desired trajectory, in which content and motion are disentangled. With such a representation, our framework allows for a broad range of applications, including content and motion manipulation. Furthermore, we introduce a new task, which we call cross-domain video synthesis, in which the image and motion generators are trained on disjoint datasets belonging to different domains. This allows for generating moving objects for which the desired video data is not available. Extensive experiments on various datasets demonstrate the advantages of our methods over existing video generation techniques. Code will be released at https://github.com/snap-research/MoCoGAN-HD."
"Manuel Rebol, C. Gütl, K. Pietroszek",24977653dc0868968b6f6523682070d8eebb57c8,Passing a Non-verbal Turing Test: Evaluatina Gesture Animations Generated from Speech,2021 IEEE Virtual Reality and 3D User Interfaces (VR),2021.0,1,"In real life, people communicate using both speech and non-verbal signals such as gestures, face expression or body pose. Non-verbal signals impact the meaning of the spoken utterance in an abundance of ways. An absence of non-verbal signals impoverishes the process of communication. Yet, when users are represented as avatars, it is difficult to translate non-verbal signals along with the speech into the virtual world without specialized motion-capture hardware. In this paper, we propose a novel, data-driven technique for generating gestures directly from speech. Our approach is based on the application of Generative Adversarial Neural Networks (GANs) to model the correlation rather than causation between speech and gestures. This approach approximates neuroscience findings on how non-verbal communication and speech are correlated. We create a large dataset which consists of speech and corresponding gestures in a 3D human pose format from which our model learns the speaker-specific correlation. We evaluate the proposed technique in a user study that is inspired by the Turing test. For the study, we animate the generated gestures on a virtual character. We find that users are not able to distinguish between the generated and the recorded gestures. Moreover, users are able to identify our synthesized gestures as related or not related to a given utterance."
"Shuchao Duan, Zhenxue Chen, Q. M. Wu, Lei Cai, Dan Lu",77684f515090c2c818b9a83565ecec6cebb8a919,Multi-Scale Gradients Self-Attention Residual Learning for Face Photo-Sketch Transformation,IEEE Transactions on Information Forensics and Security,2021.0,1,"Face sketch synthesis, as a key technique for solving face sketch recognition, has made considerable progress in recent years. Due to the difference of modality between face photo and face sketch, traditional exemplar-based methods often lead to missed texture details and deformation while synthesizing sketches. And limited to the local receptive field, Convolutional Neural Networks-based methods cannot deal with the interdependence between features well, which makes the constraint of facial features insufficient; as such, it cannot retain some details in the synthetic image. Moreover, the deeper the network layer is, the more obvious the problems of gradient disappearance and explosion will be, which will lead to instability in the training process. Therefore, in this paper, we propose a multi-scale gradients self-attention residual learning framework for face photo-sketch transformation that embeds a self-attention mechanism in the residual block, making full use of the relationship between features to selectively enhance the characteristics of specific information through self-attention distribution. Simultaneously, residual learning can keep the characteristics of the original features from being destroyed. In addition, the problem of instability in GAN training is alleviated by allowing discriminator to become a function of multi-scale outputs of the generator in the training process. Based on cycle framework, the matching between the target domain image and the source domain image can be constrained while the mapping relationship between the two domains is established so that the tasks of face photo-to-sketch synthesis (FP2S) and face sketch-to-photo synthesis (FS2P) can be achieved simultaneously. Both Image Quality Assessment (IQA) and experiments related to face recognition show that our method can achieve state-of-the-art performance on the public benchmarks, whether using FP2S or FS2P."
"Karl D. D. Willis, P. Jayaraman, J. Lambourne, Hang Chu, Yewen Pu",2b4d1d2108d708830899e31fd0eae553b0bf1713,Engineering Sketch Generation for Computer-Aided Design,ArXiv,2021.0,1,"Engineering sketches form the 2D basis of parametric Computer-Aided Design (CAD), the foremost modeling paradigm for manufactured objects. In this paper we tackle the problem of learning based engineering sketch generation as a first step towards synthesis and composition of parametric CAD models. We propose two generative models, CurveGen and TurtleGen, for engineering sketch generation. Both models generate curve primitives without the need for a sketch constraint solver and explicitly consider topology for downstream use with constraints and 3D CAD modeling operations. We find in our perceptual evaluation using human subjects that both CurveGen and TurtleGen produce more realistic engineering sketches when compared with the current state-of-the-art for engineering sketch generation."
"Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",6f4490cfc05763b420ee2eb961a64f041e2c53c2,Cloud2Curve: Generation and Vectorization of Parametric Sketches,ArXiv,2021.0,1,"Analysis of human sketches in deep learning has advanced immensely through the use of waypoint-sequences rather than raster-graphic representations. We further aim to model sketches as a sequence of low-dimensional parametric curves. To this end, we propose an inverse graphics framework capable of approximating a raster or waypoint based stroke encoded as a point-cloud with a variable-degree Bézier curve. Building on this module, we present Cloud2Curve, a generative model for scalable high-resolution vector sketches that can be trained end-toend using point-cloud data alone. As a consequence, our model is also capable of deterministic vectorization which can map novel raster or waypoint based sketches to their corresponding high-resolution scalable Bézier equivalent. We evaluate the generation and vectorization capabilities of our model on Quick, Draw! and K-MNIST datasets."
"Yi He, Haoran Xie, Chao Zhang, Xi Yang, K. Miyata",cad37c4cde604c9262b3dd3d94283277dfaf44ec,Sketch-based normal map generation with geometric sampling,Other Conferences,2021.0,1,Normal map is an important and efficient way to represent complex 3D models. A designer may benefit from the auto-generation of high quality and accurate normal maps from freehand sketches in 3d content creation. This paper proposes a deep generative model for generating normal maps from users’ sketch with geometric sampling. Our generative model is based on conditional generative adversarial network with the curvature-sensitive points sampling of conditional masks. This sampling process can help eliminate the ambiguity of generation results as network input. It is verified that the proposed framework can generate more accurate normal maps.
"R. Sarmiento, M. Huertas-Company, J. Knapen, S. S'anchez, H. D. S'anchez, N. Drory, J. Falc'on-Barroso",a0e1f630e87abb84afcecfa0d9b086ccf9a643ca,Capturing the physics of MaNGA galaxies with self-supervised Machine Learning,,2021.0,1,"As available data sets grow in size and complexity, advanced visualization tools enabling their exploration and analysis become more important. In modern astronomy, integral field spectroscopic galaxy surveys are a clear example of increasing dimensionality and complexity of datasets, which challenge the traditional methods used to extract the physical information they contain. We present the use of a novel self-supervised Machine Learning method to visualize the multi-dimensional information on stellar population and kinematics in the MaNGA survey in a two dimensional plane. Our framework is insensitive to non-physical properties such as the size of integral field unit (IFU) and is therefore able to order galaxies according to their resolved physical properties. Using the extracted representations, we show that galaxies naturally cluster into three well-known categories from a purely data driven perspective: rotating main-sequence disks, massive slow rotators and lowmass rotation-dominated quenched galaxies. The framework for data exploration is publicly released with this publication, ready to be used with the MaNGA or other integral field data sets."
"A. Bhunia, Pinaki Nath Chowdhury, Aneeshan Sain, Yongxin Yang, Tao Xiang, Yi-Zhe Song",eda0e5a0073cdf818234338e26c1c95eaa3ecc7b,Supplementary material for More Photos are All You Need: Semi-Supervised Learning for Fine-Grained Sketch Based Image Retrieval,,2021.0,1,"We are mostly inspired by recent image generation works [8, 3] that use the discriminator scores to iteratively improve generation quality. We also did an ablative study to investigate further (see L768-785 and Fig. 4(a)). We found that synthetic sketch-photo pairs having higher discriminator score, tend to have much better quality, and vice-versa. We will add some qualitative examples to further illustrate this correlation in supplementary materials. Defining a hard threshold (optimised) to eliminate bad generated sketches is an option – new experiments show acc@1 lags by around 2% compared to ours on Shoe-V2."
"B. Li, Yuanlue Zhu, Yitong Wang, Chia-Wen Lin, Bernard Ghanem, Linlin Shen",15af12d267303ff665b3afc96463ba647e9a7b1a,AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation,ArXiv,2021.0,1,"In this paper, we propose a novel framework to translate a portrait photo-face into an anime appearance. Our aim is to synthesize anime-faces which are style-consistent with a given reference anime-face. However, unlike typical translation tasks, such anime-face translation is challenging due to complex variations of appearances among anime-faces. Existing methods often fail to transfer the styles of reference anime-faces, or introduce noticeable artifacts/distortions in the local shapes of their generated faces. We propose AniGAN, a novel GAN-based translator that synthesizes highquality anime-faces. Specifically, a new generator architecture is proposed to simultaneously transfer color/texture styles and transform local facial shapes into anime-like counterparts based on the style of a reference anime-face, while preserving the global structure of the source photoface. We propose a double-branch discriminator to learn both domain-specific distributions and domain-shared distributions, helping generate visually pleasing anime-faces and effectively mitigate artifacts. Extensive experiments qualitatively and quantitatively demonstrate the superiority of our method over state-of-the-art methods."
"Apoorva Sharma, Navid Azizan, M. Pavone",5166ddb378cf28817cf34ceccd7a9ed17ba9a008,Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks,ArXiv,2021.0,1,"In order to safely deploy Deep Neural Networks (DNNs) within the perception pipelines of realtime decision making systems, there is a need for safeguards that can detect out-of-trainingdistribution (OoD) inputs both efficiently and accurately. Building on recent work leveraging the local curvature of DNNs to reason about epistemic uncertainty, we propose Sketching Curvature for OoD Detection (SCOD), an architecture-agnostic framework for equipping any trained DNN with a task-relevant epistemic uncertainty estimate. Offline, given a trained model and its training data, SCOD employs tools from matrix sketching to tractably compute a low-rank approximation of the Fisher information matrix, which characterizes which directions in the weight space are most influential on the predictions over the training data. Online, we estimate uncertainty by measuring how much perturbations orthogonal to these directions can alter predictions at a new test input. We apply SCOD to pre-trained networks of varying architectures on several tasks, ranging from regression to classification. We demonstrate that SCOD achieves comparable or better OoD detection performance with lower computational burden relative to existing baselines."
"Osman Tursun, S. Denman, S. Sridharan, Ethan Goan, C. Fookes",a319032aa65d55022127c1c9c0b0cdf269b8453c,An Efficient Framework for Zero-Shot Sketch-Based Image Retrieval,ArXiv,2021.0,1,"Recently, Zero-shot Sketch-based Image Retrieval (ZS-SBIR) has attracted the attention of the computer vision community due to it’s real-world applications, and the more realistic and challenging setting than found in SBIR. ZS-SBIR inherits the main challenges of multiple computer vision problems including contentbased Image Retrieval (CBIR), zero-shot learning and domain adaptation. The majority of previous studies using deep neural networks have achieved improved results through either projecting sketch and images into a common low-dimensional space or transferring knowledge from seen to unseen classes. However, those approaches are trained with complex frameworks composed of multiple deep convolutional neural networks (CNNs) and are dependent on category-level word labels. This increases the requirements on training resources and datasets. In comparison, we propose a simple and efficient framework that does not require high computational training resources, and can be trained on datasets without semantic categorical labels. Furthermore, at training and inference stages our method only uses a single CNN. In this work, a pre-trained ImageNet CNN (i.e.ResNet50) is fine-tuned with three proposed learning objects: domain-aware quadruplet loss, semantic classification loss, and semantic knowledge preservation loss. The domain-aware quadruplet and semantic classification losses are introduced to learn discriminative, semantic and domain invariant features through considering ZS-SBIR as a object detection and verification problem. To preserve semantic knowledge learned with ImageNet and utilise it on unseen categories, the semantic knowledge preservation loss is proposed. To reduce computational cost and increase the accuracy of the semantic knowledge distillation process, ground-truth semantic knowledge is prepared in a class-oriented fashion prior to training. Extensive experiments are conducted on three challenging ZS-SBIR datasets, Sketchy Extended, TU-Berlin Extended and QuickDraw Extended. The proposed method achieves state-of-the-art results, and outperforms the majority of related works by a large margin."
"Songwei Ge, Vedanuj Goswami, C. L. Zitnick, Devi Parikh",9cc1c31cf4c399d7749815037479844b9d8b151c,Creative Sketch Generation,ICLR,2021.0,1,"Sketching or doodling is a popular creative activity that people engage in. However, most existing work in automatic sketch understanding or generation has focused on sketches that are quite mundane. In this work, we introduce two datasets of creative sketches -- Creative Birds and Creative Creatures -- containing 10k sketches each along with part annotations. We propose DoodlerGAN -- a part-based Generative Adversarial Network (GAN) -- to generate unseen compositions of novel part appearances. Quantitative evaluations as well as human studies demonstrate that sketches generated by our approach are more creative and of higher quality than existing approaches. In fact, in Creative Birds, subjects prefer sketches generated by DoodlerGAN over those drawn by humans! Our code can be found at this https URL and a demo can be found at this http URL."
"Xingqun Qi, Muyi Sun, Weining Wang, Xiaoxiao Dong, Qi Li, Caifeng Shan",e9606141a651c0c22820895ae76b60e69a1dd7d2,Face Sketch Synthesis via Semantic-Driven Generative Adversarial Network,ArXiv,2021.0,0,"Face sketch synthesis has made significant progress with the development of deep neural networks in these years. The delicate depiction of sketch portraits facilitates a wide range of applications like digital entertainment and law enforcement. However, accurate and realistic face sketch generation is still a challenging task due to the illumination variations and complex backgrounds in the real scenes. To tackle these challenges, we propose a novel Semantic-Driven Generative Adversarial Network (SDGAN) which embeds global structure-level style injection and local class-level knowledge re-weighting. Specifically, we conduct facial saliency detection on the input face photos to provide overall facial texture structure, which could be used as a global type of prior information. In addition, we exploit face parsing layouts as the semantic-level spatial prior to enforce globally structural style injection in the generator of SDGAN. Furthermore, to enhance the realistic effect of the details, we propose a novel Adaptive Re-weighting Loss (ARLoss) which dedicates to balance the contributions of different semantic classes. Experimentally, our extensive experiments on CUFS and CUFSF datasets show that our proposed algorithm achieves state-of-the-art performance."
"Kevin Frans, L. B. Soros, O. Witkowski",b1a5e147f8b4d4f750f8224ea2dcb0fdebb3ff73,CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders,ArXiv,2021.0,0,"This work presents CLIPDraw, an algorithm that synthesizes novel drawings based on natural language input. CLIPDraw does not require any training; rather a pre-trained CLIP languageimage encoder is used as a metric for maximizing similarity between the given description and a generated drawing. Crucially, CLIPDraw operates over vector strokes rather than pixel images, a constraint that biases drawings towards simpler human-recognizable shapes. Results compare between CLIPDraw and other synthesis-throughoptimization methods, as well as highlight various interesting behaviors of CLIPDraw, such as satisfying ambiguous text in multiple ways, reliably producing drawings in diverse artistic styles, and scaling from simple to complex visual representations as stroke count is increased. Code for experimenting with the method is available at: https://colab.research.google.com/github/ kvfrans/clipdraw/blob/main/clipdraw.ipynb"
"Wenchao Li, Yun Wang, He Huang, Weiwei Cui, Haidong Zhang, Huamin Qu, Dongmei Zhang",5fdb7a1c59c4a1f85ae2ae9f3b280710b3c6ecaa,AniVis: Generating Animated Transitions Between Statistical Charts with a Tree Model,ArXiv,2021.0,0,"Animated transitions help viewers understand changes between related visualizations. To clearly present the underlying relations between statistical charts, animation authors need to have a high level of expertise and a considerable amount of time to describe the relations with reasonable animation stages. We present AniVis, an automated approach for generating animated transitions to demonstrate the changes between two statistical charts. AniVis models each statistical chart on the basis of a tree-based structure. Given an input chart pair, the differences of data and visual properties of the chart pair are formalized as atomic transition units. Through this approach, the animated transition between two charts is expressed as a series of transition units. Then, we conduct a preliminary study to understand people’s preferences for animation sequences. Based on the study, we propose a set of principles and a sequence composition algorithm to compose the transition units into a meaningful animation sequence. Finally, we synthesize these units together to deliver a smooth and intuitive animated transition between charts. To evaluate our workflow, we implement a web-based system and demonstrate its generated results to illustrate the usage of our approach. We perform a comparative study with the latest method to assess the animated transitions automatically generated by our system. We further collect feedback from experts to evaluate the usability of our method."
"Xiaoqi Wang, Kevin Yen, Yifan Hu, Han-Wei Shen",4f58d052a8c4b4891e06fac41807863c1452185e,DeepGD: A Deep Learning Framework for Graph Drawing Using GNN,ArXiv,2021.0,0,"In the past decades, many graph drawing techniques have been proposed for generating aesthetically pleasing graph layouts. However, it remains a challenging task since different layout methods tend to highlight different characteristics of the graphs. Recently, studies on deep learning based graph drawing algorithm have emerged but they are often not generalizable to arbitrary graphs without re-training. In this paper, we propose a Convolutional Graph Neural Network based deep learning framework, DeepGD, which can draw arbitrary graphs once trained. It attempts to generate layouts by compromising among multiple pre-specified aesthetics considering a good graph layout usually complies with multiple aesthetics simultaneously. In order to balance the trade-off, we propose two adaptive training strategies which adjust the weight factor of each aesthetic dynamically during training. The quantitative and qualitative assessment of DeepGD demonstrates that it is capable of drawing arbitrary graphs effectively, while being flexible at accommodating different aesthetic criteria."
"B. Soni, Debangan Thakuria, Nilutpal Nath, Navarun Das, Bhaskarananda Boro",e7bd20152f4d9b196ae1e0651b9dac7c2310c9ce,RikoNet: A Novel Anime Recommendation Engine,ArXiv,2021.0,0,"Anime is quite well-received today, especially among the younger generations. With many genres of available shows, more and more people are increasingly getting attracted to this niche section of the entertainment industry. As anime has recently garnered mainstream attention, we have insufficient information regarding users’ penchant and watching habits. Therefore, it is an uphill task to build a recommendation engine for this relatively obscure entertainment medium. In this attempt, we have built a novel hybrid recommendation system that could act both as a recommendation system and as a means of exploring new anime genres and titles. We have analyzed the general trends in this field and the users’ watching habits for coming up with our efficacious solution. Our solution employs deep autoencoders for the tasks of predicting ratings and generating embeddings. Following this, we formed clusters using the embeddings of the anime titles. These clusters form the search space for animewith similarities and are used to find anime similar to the ones liked and disliked by the user. This method, combined with the predicted ratings, forms the novel hybrid filter. In this article, we have demonstrated this idea and compared the performance of our implemented model with the existing state-of-the-art techniques. Badal Soni National Institute of Technology Silchar, India E-mail: badal@cse.nits.ac.in Debangan Thakuria National Institute of Technology Silchar, India E-mail: debanganthakuria44@gmail.com Nilutpal Nath National Institute of Technology Silchar, India E-mail: nilutpalnath555@gmail.com Navarun Das National Institute of Technology Silchar, India E-mail: dasnavarun06@gmail.com Bhaskar Boro National Institute of Technology Silchar, India E-mail: boro123bhaskar@gmail.com ar X iv :2 10 6. 12 97 0v 1 [ cs .I R ] 2 4 Ju n 20 21"
"Zhipeng Wang, Hao Wang, Jiexi Yan, Aming Wu, Cheng Deng",174fee8db0ef28e7aa52933e05983da885164e07,Domain-Smoothing Network for Zero-Shot Sketch-Based Image Retrieval,ArXiv,2021.0,0,"Zero-Shot Sketch-Based Image Retrieval (ZSSBIR) is a novel cross-modal retrieval task, where abstract sketches are used as queries to retrieve natural images under zero-shot scenario. Most existing methods regard ZS-SBIR as a traditional classification problem and employ a cross-entropy or triplet-based loss to achieve retrieval, which neglect the problems of the domain gap between sketches and natural images and the large intra-class diversity in sketches. Toward this end, we propose a novel Domain-Smoothing Network (DSN) for ZS-SBIR. Specifically, a cross-modal contrastive method is proposed to learn generalized representations to smooth the domain gap by mining relations with additional augmented samples. Furthermore, a category-specific memory bank with sketch features is explored to reduce intra-class diversity in the sketch domain. Extensive experiments demonstrate that our approach notably outperforms the state-of-the-art methods in both Sketchy and TU-Berlin datasets. Our source code is publicly available at https://github.com/ haowang1992/DSN."
Jihye Back,6430eb5f5c42d0d8e70f164ec02b270aa8ff9b98,Fine-Tuning StyleGAN2 For Cartoon Face Generation,ArXiv,2021.0,0,"Recent studies have shown remarkable success in the unsupervised image to image (I2I) translation. However, due to the imbalance in the data, learning joint distribution for various domains is still very challenging. Although existing models can generate realistic target images, it’s difficult to maintain the structure of the source image. In addition, training a generative model on large data in multiple domains requires a lot of time and computer resources. To address these limitations, we propose a novel image-to-image translation method that generates images of the target domain by finetuning a stylegan2 pretrained model. The stylegan2 model is suitable for unsupervised I2I translation on unbalanced datasets; it is highly stable, produces realistic images, and even learns properly from limited data when applied with simple fine-tuning techniques. Thus, in this paper, we propose new methods to preserve the structure of the source images and generate realistic images in the target domain. The code and results are available at https://github.com/happy-jihye/Cartoon-StyleGan2"
"Daya Guo, Alexey Svyatkovskiy, Jian Yin, Nan Duan, Marc Brockschmidt, Miltiadis Allamanis",f82f1c722831bc3def1853ac65497d6a4fea01b9,Learning to Generate Code Sketches,ArXiv,2021.0,0,"Traditional generative models are limited to predicting sequences of terminal tokens. However, ambiguities in the generation task may lead to incorrect outputs. Towards addressing this, we introduce GRAMMFORMERs, transformer-based grammarguided models that learn (without explicit supervision) to generate sketches — sequences of tokens with holes. Through reinforcement learning, GRAMMFORMERs learn to introduce holes avoiding the generation of incorrect tokens where there is ambiguity in the target task. We train GRAMMFORMERs for statement-level source code completion, i.e. the generation of code snippets given an ambiguous user intent, such as a partial code context. We evaluate GRAMMFORMERs on code completion for C# and Python and show that it generates 10-50% more accurate sketches compared to traditional generative models and 37-50% longer sketches compared to sketch-generating baselines trained with similar techniques."
"Spyridon Chavlis, P. Poirazi",0c756b201c0b8151daf1acb873228a65ed6b8ddf,Drawing inspiration from biological dendrites to empower artificial neural networks,Current Opinion in Neurobiology,2021.0,0,"This article highlights specific features of biological neurons and their dendritic trees, whose adoption may help advance artificial neural networks used in various machine learning applications. Advancements could take the form of increased computational capabilities and/or reduced power consumption. Proposed features include dendritic anatomy, dendritic nonlinearities, and compartmentalized plasticity rules, all of which shape learning and information processing in biological networks. We discuss the computational benefits provided by these features in biological neurons and suggest ways to adopt them in artificial neurons in order to exploit the respective benefits in machine learning."
"Zeqiu Wu, Michel Galley, Chris Brockett, Yizhe Zhang, Bill Dolan",c86f268c3f37749595baad4f2474edf668645756,Automatic Document Sketching: Generating Drafts from Analogous Texts,ArXiv,2021.0,0,"The advent of large pre-trained language models has made it possible to make high-quality predictions on how to add or change a sentence in a document. However, the high branching factor inherent to text generation impedes the ability of even the strongest language models to offer useful editing suggestions at a more global or document level. We introduce a new task, DOCUMENT SKETCHING, which involves generating entire draft documents for the writer to review and revise. These drafts are built from sets of documents that overlap in form – sharing large segments of potentially reusable text – while diverging in content. To support this task, we introduce a Wikipediabased dataset of analogous documents and investigate the application of weakly supervised methods, including use of a transformer-based mixture of experts, together with reinforcement learning. We report experiments using automated and human evaluation methods and discuss relative merits of these models."
"Siddharth Bhatia, Mohit Wadhwa, P. Yu, Bryan Hooi",89ad0eb31b690adcb358f584adae1e90d3b493e3,Sketch-Based Streaming Anomaly Detection in Dynamic Graphs,ArXiv,2021.0,0,"Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges and subgraphs in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? For example, in intrusion detection, existing work seeks to detect either anomalous edges or anomalous subgraphs, but not both. In this paper, we first extend the count-min sketch data structure to a higher-order sketch. This higher-order sketch has the useful property of preserving the dense subgraph structure (dense subgraphs in the input turn into dense submatrices in the data structure). We then propose four online algorithms that utilize this enhanced data structure, which (a) detect both edge and graph anomalies; (b) process each edge and graph in constant memory and constant update time per newly arriving edge, and; (c) outperform state-of-the-art baselines on four real-world datasets. Our method is the first streaming approach that incorporates dense subgraph search to detect graph anomalies in constant memory and time."
"W. Para, S. Bhat, Paul Guerrero, Tom Kelly, N. Mitra, L. Guibas, Peter Wonka",adfce546ad940c724b25e6c0023c5d5bc7362272,SketchGen: Generating Constrained CAD Sketches,ArXiv,2021.0,0,"Computer-aided design (CAD) is the most widely used modeling approach for technical design. The typical starting point in these designs is 2D sketches which can later be extruded and combined to obtain complex three-dimensional assemblies. Such sketches are typically composed of parametric primitives, such as points, lines, and circular arcs, augmented with geometric constraints linking the primitives, such as coincidence, parallelism, or orthogonality. Sketches can be represented as graphs, with the primitives as nodes and the constraints as edges. Training a model to automatically generate CAD sketches can enable several novel workflows, but is challenging due to the complexity of the graphs and the heterogeneity of the primitives and constraints. In particular, each type of primitive and constraint may require a record of different size and parameter types. We propose SketchGen as a generative model based on a transformer architecture to address the heterogeneity problem by carefully designing a sequential language for the primitives and constraints that allows distinguishing between different primitive or constraint types and their parameters, while encouraging our model to re-use information across related parameters, encoding shared structure. A particular highlight of our work is the ability to produce primitives linked via constraints that enables the final output to be further regularized via a constraint solver. We evaluate our model by demonstrating constraint prediction for given sets of primitives and full sketch generation from scratch, showing that our approach significantly out performs the state-of-the-art in CAD sketch generation."
"Daniela Mihai, Jonathon S. Hare",7d245e6119ca3b83857bfacdd6824284a598ee75,Learning to Draw: Emergent Communication through Sketching,ArXiv,2021.0,0,"Evidence that visual communication preceded written language and provided a basis for it goes back to prehistory, in forms such as cave and rock paintings depicting traces of our distant ancestors. Emergent communication research has sought to explore how agents can learn to communicate in order to collaboratively solve tasks. Existing research has focused on language, with a learned communication channel transmitting sequences of discrete tokens between the agents. In this work, we explore a visual communication channel between agents that are allowed to draw with simple strokes. Our agents are parameterised by deep neural networks, and the drawing procedure is differentiable, allowing for end-to-end training. In the framework of a referential communication game, we demonstrate that agents can not only successfully learn to communicate by drawing, but with appropriate inductive biases, can do so in a fashion that humans can interpret. We hope to encourage future research to consider visual communication as a more flexible and directly interpretable alternative of training collaborative agents."
"Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang, Jingren Zhou, Hongxia Yang",c4d0df5f7a700f8c999bb2fa5a7a9df0b2d2dd97,Sketch and Refine: Towards Faithful and Informative Table-to-Text Generation,ArXiv,2021.0,0,"Table-to-text generation refers to generating a descriptive text from a key-value table. Traditional autoregressive methods, though can generate text with high fluency, suffer from low coverage and poor faithfulness problems. To mitigate these problems, we propose a novel Skeleton-based two-stage method that combines both Autoregressive and NonAutoregressive generation (SANA). Our approach includes: (1) skeleton generation with an autoregressive pointer network to select key tokens from the source table; (2) edit-based non-autoregressive generation model to produce texts via iterative insertion and deletion operations. By integrating hard constraints from the skeleton, the non-autoregressive model improves the generation’s coverage over the source table and thus enhances its faithfulness. We conduct experiments on both the WikiPerson and WikiBio datasets. Experimental results demonstrate that our method outperforms the previous state-of-the-art methods in both automatic and human evaluation, especially on coverage and faithfulness. In particular, we achieve PARENT-T recall of 99.47 in WikiPerson, improving over the existing best results by more than 10 points."
"Yuri Sato, K. Mineshima, K. Ueda",17b2ded066f94513b0998cfc2ff645e9caf1ed53,Visual representation of negation: Real world data analysis on comic image design,ArXiv,2021.0,0,"There has been a widely held view that visual representations (e.g., photographs and illustrations) do not depict negation, for example, one that can be expressed by a sentence “the train is not coming”. This view is empirically challenged by analyzing the real-world visual representations of comic (manga) illustrations. In the experiment using image captioning tasks, we gave people comic illustrations and asked them to explain what they could read from them. The collected data showed that some comic illustrations could depict negation without any aid of sequences (multiple panels) or conventional devices (special symbols). This type of comic illustrations was subjected to further experiments, classifying images into those containing negation and those not containing negation. While this image classification was easy for humans, it was difficult for data-driven machines, i.e., deep learning models (CNN), to achieve the same high performance. Given the findings, we argue that some comic illustrations evoke background knowledge and thus can depict negation with purely visual elements."
"Tavi Halperin, Hanit Hakim, O. Vantzos, Gershon Hochman, Netai Benaim, Lior Sassy, Michael Kupchik, Ofir Bibi, Ohad Fried",9b20ecfe7a0f5e7e0cb681d71099e34f1d9a7c03,Endless Loops: Detecting and Animating Periodic Patterns in Still Images,ArXiv,2021.0,0,"Fig. 1. Creating a cinemagraph from a still image. We look for self-similarities in the user-selected area of interest, solve for a displacement field, and use it to warp the image into a seamlessly looping animation; in this case each window smoothly sliding into the next one along the face of the building, a surreal yet aesthetically pleasing visual effect. Please open in Acrobat Reader to see embedded videos. Image credit: © Gal Nachmana"
"Conghui Hu, Yongxin Yang, Yunpeng Li, Timothy M. Hospedales, Yi-Zhe Song",a0bcbba2b688ab647cd42d8da0782cd0044749ac,Towards Unsupervised Sketch-based Image Retrieval,ArXiv,2021.0,0,"Current supervised sketch-based image retrieval (SBIR) methods achieve excellent performance. However, the cost of data collection and labeling imposes an intractable barrier to practical deployment of real applications. In this paper, we present the first attempt at unsupervised SBIR to remove the labeling cost (category annotations and sketchphoto pairings) that is conventionally needed for training. Existing single-domain unsupervised representation learning methods perform poorly in this application, due to the unique cross-domain (sketch and photo) nature of the problem. We therefore introduce a novel framework that simultaneously performs unsupervised representation learning and sketch-photo domain alignment. Technically this is underpinned by exploiting joint distribution optimal transport (JDOT) to align data from different domains during representation learning, which we extend with trainable cluster prototypes and feature memory banks to further improve scalability and efficacy. Extensive experiments show that our framework achieves excellent performance in the new unsupervised setting, and performs comparably or better than state-of-the-art in the zero-shot setting."
"T. Biedl, G. Liotta, J. Lynch, Fabrizio Montecchiani",552e4170cebafb5584259c522ad0728df5b8113d,Generalized LR-drawings of trees,ArXiv,2021.0,0,"The LR-drawing-method is a method of drawing an ordered rooted binary tree based on drawing one root-to-leaf path on a vertical line and attaching recursively obtained drawings of the subtrees on the left and right. In this paper, we study how to generalize this drawing-method to trees of higher arity. We first prove that (with some careful modifications) the proof of existence of a special root-to-leaf path transfers to trees of higher arity. Then we use such paths to obtain generalized LR-drawings of trees of arbitrary arity."
"Michael P. Sheehan, J. Tachella, M. Davies",3ff3531d256fe8d1e925ff02d12f085a8b73039b,Surface Detection for Sketched Single Photon Lidar,,2021.0,0,"Single-photon lidar devices are able to collect an ever-increasing amount of time-stamped photons in small time periods due to increasingly larger arrays, generating a memory and computational bottleneck on the data processing side. Recently, a sketching technique was introduced to overcome this bottleneck which compresses the amount of information to be stored and processed. The size of the sketch scales with the number of underlying parameters of the time delay distribution and not, fundamentally, with either the number of detected photons or the time-stamp resolution. In this paper, we propose a detection algorithm based solely on a small sketch that determines if there are surfaces or objects in the scene or not. If a surface is detected, the depth and intensity of a single object can be computed in closed-form directly from the sketch. The computational load of the proposed detection algorithm depends solely on the size of the sketch, in contrast to previous algorithms that depend at least linearly in the number of collected photons or histogram bins, paving the way for fast, accurate and memory efficient lidar estimation. Our experiments demonstrate the memory and statistical efficiency of the proposed algorithm both on synthetic and real lidar datasets."
"Nilesh Pandey, A. Savakis",b8f46108160b98799f8ae85777999e5249be677f,Extreme Face Inpainting with Sketch-Guided Conditional GAN,ArXiv,2021.0,0,"Recovering badly damaged face images is a useful yet challenging task, especially in extreme cases where the masked or damaged region is very large. One of the major challenges is the ability of the system to generalize on faces outside the training dataset. We propose to tackle this extreme inpainting task with a conditional Generative Adversarial Network (GAN) that utilizes structural information, such as edges, as a prior condition. Edge information can be obtained from the partially masked image and a structurally similar image or a hand drawing. In our proposed conditional GAN, we pass the conditional input in every layer of the encoder while maintaining consistency in the distributions between the learned weights and the incoming conditional input. We demonstrate the effectiveness of our method with badly damaged face examples. Introduction Image inpainting is a popular and challenging problem in computer vision with applications in image editing and restoring of damaged image regions [1], [2], [3], [4], [5], [6]. The damaged image regions may range from rectangular patches of various sizes to irregular regions or entire objects. In image editing, some regions are tactically damaged so that they can be inpainted with different content. In this paper we deal with the problem of extreme inpainting, where large regions of faces have been damaged with the application of an irregular mask. Initial works dealt with small square patches, while more recent approaches take on the more challenging problem of inpainting large irregular regions [3], [4]. Our face inpainting method, called FIpoly-GAN, is based on the Poly-GAN conditional Generative Adversarial Network (GAN) architecture [7], that was initially proposed for fashion synthesis and is suitable for various tasks, e.g. geometric transformations, image stitching and inpainting. To recover the facial structure that is lost after significant image regions have been masked, we utilize an edge sketch as a condition that guides the inpainting process by providing structure in the damaged regions. The proposed FIpoly-GAN has shown ability to generalize on faces obtained in the wild from various sources unrelated to the training data. A representative result is shown in in Fig. 1. The main contributions of this paper can be summarized as follows: • We propose FIpoly-GAN, a conditional GAN architecture that leverages edge information for extreme face inpainting. • Our FIpoly-GAN architecture uses the edge map, from a sketch or a similar image, as a condition that is fed at various levels of the network to learn the structure of the image for inpainting color and texture in the missing region. • FIpoly-GAN achieves state of the art results on standard face datasets and outperforms other methods on images that are unrelated to the training dataset. Figure 1. Example of sketch-conditioned face inpainting with the proposed FIpoly-GAN network. From left to right: original, damaged image with large irregular mask, hand-drawn sketch, inpainted result. Related Work Early inpainting methods operated under the assumption that the damaged region is a standard shape, i.e. square or rectangle. Free form inpainting, where the damaged regions are large and irregular, poses a challenge to many methods due to lack of relevant information that can be used from nearby regions. A popular approach is the Patch-based image inpainting network [1], which progressively learns to associate nearby image contect to the missing region. However, this approach is not as effective in the case of free form inpainting. Image Inpainting using Partial Convolution [2] is one of the first methods to tackle free form inpainting on images with irregular damage. It utilizes a neural network with a partial convolution layer and performs an automatic update on the binary mask. Given a binary mask, the partial convolution utilizes nondamaged information near damaged region to estimate missing content. The next step in the method is to update the binary mask according to the output of the partial convolution, so that if the output is positive for the damaged region then the mask is updated accordingly. Free-form image inpainting with Gated Convolution (SNpatchGAN) [3] is a state-of-the-art method for inpainting images with irregular damage. This method introduces a new convolution layer named gated convolution. The input features in the model are first used to compute the gating value, g = sigmoid(Wg ∗ x), where x denotes the input features. The final output of the layer is multiplication of learned features and gating values, y = φ(W ∗ x) g. The architecture includes a contextual attention module with the refinement network, with both having a gated convolution layer. Gated Convolution has inspired several other methods for image inpainting. Image inpainting via Generative Multi-column Convolutional Neural Networks (GMCNN) [4] The GMCNN network consists of three sub-networks, one generator, one global and one local discriminator for adversarial training. Only the generator is deployed when testing on a new image. SC-FEGAN [5] and Face-Shop [6] are state-of-the-art image inpainting methods based on image editing. They work by providing the network a simple sketch of the face. Both methods use a similar approach to generate sketch images of the face, which can be edited and passed to the model as conditional input. The Edgear X iv :2 10 5. 06 03 3v 1 [ cs .C V ] 1 3 M ay 2 02 1"
"Tim Fuchs, D. Gross, F. Krahmer, R. Kueng, Dustin G. Mixon",243fa85eecb1be9a5d9c2abe995ef173eb02ddb7,Sketching with Kerdock's crayons: Fast sparsifying transforms for arbitrary linear maps,ArXiv,2021.0,0,"Given an arbitrary matrix A ∈ Rn×n, we consider the fundamental problem of computing Ax for any x ∈ Rn such that Ax is s-sparse. While fast algorithms exist for particular choices of A, such as the discrete Fourier transform, there is currently no o(n2) algorithm that treats the unstructured case. In this paper, we devise a randomized approach to tackle the unstructured case. Our method relies on a representation of A in terms of certain real-valued mutually unbiased bases derived from Kerdock sets. In the preprocessing phase of our algorithm, we compute this representation of A in O(n3 log n) operations. Next, given any unit vector x ∈ Rn such that Ax is s-sparse, our randomized fast transform uses this representation of A to compute the entrywise -hard threshold of Ax with high probability in only O(sn + ‖A‖2→∞n log n) operations. In addition to a performance guarantee, we provide numerical results that demonstrate the plausibility of real-world implementation of our algorithm."
"Barbara Rychalska, Mikolaj Wieczorek, Jacek Dabrowski",3a957999b638c8c12c0fa755e0f3da74be421f8f,T-EMDE: Sketching-based global similarity for cross-modal retrieval,ArXiv,2021.0,0,"The key challenge in cross-modal retrieval is to find similarities between objects represented with different modalities, such as image and text. However, each modality embeddings stem from nonrelated feature spaces, which causes the notorious ’heterogeneity gap’. Currently, many cross-modal systems try to bridge the gap with self-attention. However, self-attention has been widely criticized for its quadratic complexity, which prevents many real-life applications. In response to this, we propose T-EMDE a neural density estimator inspired by the recently introduced Efficient Manifold Density Estimator (EMDE) from the area of recommender systems. EMDE operates on sketches representations especially suitable for multimodal operations. However, EMDE is non-differentiable and ingests precomputed, static embeddings. With T-EMDE we introduce a trainable version of EMDE which allows full end-to-end training. In contrast to self-attention, the complexity of our solution is linear to the number of tokens/segments. As such, T-EMDE is a drop-in replacement for the self-attention module, with beneficial influence on both speed and metric performance in cross-modal settings. It facilitates communication between modalities, as each global text/image representation is expressed with a standardized sketch histogram which represents the same manifold structures irrespective of the underlying modality. We evaluate T-EMDE by introducing it into two recent cross-modal SOTAmodels and achieving new state-of-the-art results on multiple datasets and decreasing model latency by up to 20%."
"D. Giunchi, A. Sztrajman, Stuart James, A. Steed",8f42d66ff12791928392590be81d6ac3deab6ecd,Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality,IMX,2021.0,0,"Sketch and speech are intuitive interaction methods that convey complementary information and have been independently used for 3D model retrieval in virtual environments. While sketch has been shown to be an effective retrieval method, not all collections are easily navigable using this modality alone. We design a new challenging database for sketch comprised of 3D chairs where each of the components (arms, legs, seat, back) are independently colored. To overcome this, we implement a multimodal interface for querying 3D model databases within a virtual environment. We base the sketch on the state-of-the-art for 3D Sketch Retrieval, and use a Wizard-of-Oz style experiment to process the voice input. In this way, we avoid the complexities of natural language processing which frequently requires fine-tuning to be robust. We conduct two user studies and show that hybrid search strategies emerge from the combination of interactions, fostering the advantages provided by both modalities."
"Alessio Schiavo, Filippo Minutella, Mattia Daole, Marsha Gomez Gomez",d0ed22ce118de142325b9db1974537c71e0e25f5,Sketches image analysis: Web image search engine usingLSH index and DNN InceptionV3,ArXiv,2021.0,0,"The adoption of an appropriate approximate similarity search method is an essential prerequisite for developing a fast and efficient CBIR system, especially when dealing with large amount of data. In this study we implement a web image search engine on top of a Locality Sensitive Hashing (LSH) Index to allow fast similarity search on deep features. Specifically, we exploit transfer learning for deep features extraction from images. Firstly, we adopt InceptionV3 pretrained on ImageNet as features extractor, secondly, we try out several CNNs built on top of InceptionV3 as convolutional base fine-tuned on our dataset. In both of the previous cases we index the features extracted within our LSH index implementation so as to compare the retrieval performances with and without fine-tuning. In our approach we try out two different LSH implementations: the first one working with real number feature vectors and the second one with the binary transposed version of those vectors. Interestingly, we obtain the best performances when using the binary LSH, reaching almost the same result, in terms of mean average precision, obtained by performing sequential scan of the features, thus avoiding the bias introduced by the LSH index. Lastly, we carry out a performance analysis class by class in terms of recall against mAP highlighting, as expected, a strong positive correlation between the two."
"Anibal Fuentes, J. M. Saavedra",92cb6e04e28f2099dae2e5a311505e78ec23bda9,Sketch-QNet: A Quadruplet ConvNet for Color Sketch-based Image Retrieval,ArXiv,2021.0,0,"Architectures based on siamese networks with triplet loss have shown outstanding performance on the image-based similarity search problem. This approach attempts to discriminate between positive (relevant) and negative (irrelevant) items. However, it undergoes a critical weakness. Given a query, it cannot discriminate weakly relevant items, for instance, items of the same type but different color or texture as the given query, which could be a serious limitation for many real-world search applications. Therefore, in this work, we present a quadruplet-based architecture that overcomes the aforementioned weakness. Moreover, we present an instance of this quadruplet network, which we call Sketch-QNet, to deal with the color sketch-based image retrieval (CSBIR) problem, achieving new state-ofthe-art results."
"Pablo Torres, J. M. Saavedra",8f4829ee339ced9a1fa2896f72d82f452472c7c0,Compact and Effective Representations for Sketch-based Image Retrieval,ArXiv,2021.0,0,"Sketch-based image retrieval (SBIR) has undergone an increasing interest in the community of computer vision bringing high impact in real applications. For instance, SBIR brings an increased benefit to eCommerce search engines because it allows users to formulate a query just by drawing what they need to buy. However, current methods showing high precision in retrieval work in a high dimensional space, which negatively affects aspects like memory consumption and time processing. Although some authors have also proposed compact representations, these drastically degrade the performance in a low dimension. Therefore in this work, we present different results of evaluating methods for producing compact embeddings in the context of sketch-based image retrieval. Our main interest is in strategies aiming to keep the local structure of the original space. The recent unsupervised local-topology preserving dimension reduction method UMAP fits our requirements and shows outstanding performance, improving even the precision achieved by SOTA methods. We evaluate six methods in two different datasets. We use Flickr15K and eCommerce datasets; the latter is another contribution of this work. We show that UMAP allows us to have feature vectors of 16 bytes improving precision by more than 35%."
"Vincent Schellekens, L. Jacques",b473c1c072673f39dd60561ec698c0bbda9e7edb,Asymmetric compressive learning guarantees with applications to quantized sketches,ArXiv,2021.0,0,"The compressive learning framework reduces the computational cost of training on large-scale datasets. In a sketching phase, the data is first compressed to a lightweight sketch vector, obtained by mapping the data samples through a well-chosen feature map, and averaging those contributions. In a learning phase, the desired model parameters are then extracted from this sketch by solving an optimization problem, which also involves a feature map. When the feature map is identical during the sketching and learning phases, formal statistical guarantees (excess risk bounds) have been proven. However, the desirable properties of the feature map are different during sketching and learning (e.g., quantized outputs, and differentiability, respectively). We thus study the relaxation where this map is allowed to be different for each phase. First, we prove that the existing guarantees carry over to this asymmetric scheme, up to a controlled error term, provided some Limited Projected Distortion (LPD) property holds. We then instantiate this framework to the setting of quantized sketches, by proving that the LPD indeed holds for binary sketch contributions. Finally, we further validate the approach with numerical simulations, including a large-scale application in audio event classification."
"Haoran Li, Aditya Krishnan, Jingfeng Wu, S. Kolouri, Praveen K. Pilly, Vladimir Braverman",0d21dedce9542de8d80355dfd930d968fc8299cc,Lifelong Learning with Sketched Structural Regularization,ArXiv,2021.0,0,"Preventing catastrophic forgetting while continually learning new tasks is an essential problem in lifelong learning. Structural regularization (SR) refers to a family of algorithms that mitigate catastrophic forgetting by penalizing the network for changing its “critical parameters” from previous tasks while learning a new one. The penalty is often induced via a quadratic regularizer defined by an importance matrix, e.g., the (empirical) Fisher information matrix in the Elastic Weight Consolidation framework. In practice and due to computational constraints, most SR methods crudely approximate the importance matrix by its diagonal. In this paper, we propose Sketched Structural Regularization (Sketched SR) as an alternative approach to compress the importance matrices used for regularizing in SR methods. Specifically, we apply linear sketching methods to better approximate the importance matrices in SR algorithms. We show that sketched SR: (i) is computationally efficient and straightforward to implement, (ii) provides an approximation error that is justified in theory, and (iii) is method oblivious by construction and can be adapted to any method that belongs to the structural regularization class. We show that our proposed approach consistently improves various SR algorithms’ performance on both synthetic experiments and benchmark continual learning tasks, including permuted-MNIST and CIFAR-100."
"Vihanga Gamage, Cathy Ennis, Robert Ross",de481cc10b02be6ad9db5f53ee8f4f9eb1cfb50e,Data-Driven Reinforcement Learning for Virtual Character Animation Control,ArXiv,2021.0,0,"Virtual character animation control is a problem for which Reinforcement Learning (RL) is a viable approach. While current work have applied RL effectively to portray physics-based skills, social behaviours are challenging to design reward functions for, due to their lack of physical interaction with the world. On the other hand, data-driven implementations for these skills have been limited to supervised learning methods which require extensive training data and carry constraints on generalisability. In this paper, we propose RLAnimate, a novel data-driven deep RL approach to address this challenge, where we combine the strengths of RL together with an ability to learn from a motion dataset when creating agents. We formalise a mathematical structure for training agents by refining the conceptual roles of elements such as agents, environments, states and actions, in a way that leverages attributes of the character animation domain and model-based RL. An agent trained using our approach learns versatile animation dynamics to portray multiple behaviours, using an iterative RL training process, which becomes aware of valid behaviours via representations learnt from motion capture clips. We demonstrate, by training agents that portray realistic pointing and waving behaviours, that our approach requires a significantly lower training time, and substantially fewer sample episodes to be generated during training relative to state-of-the-art physics-based RL methods. Also, compared to existing supervised learning-based animation agents, RLAnimate needs a limited dataset of motion clips to generate representations of valid behaviours during training."
"Xiaoyu Xiang, Ding Liu, Xiao Yang, Yiheng Zhu, Xiaohui Shen, J. Allebach",43b743c0b456e5bf0918ff6850f6a5243acf8ac4,Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis,ArXiv,2021.0,0,"In this paper, we explore the open-domain sketch-tophoto translation, which aims to synthesize a realistic photo from a freehand sketch with its class label, even if the sketches of that class are missing in the training data. It is challenging due to the lack of training supervision and the large geometry distortion between the freehand sketch and photo domains. To synthesize the absent freehand sketches from photos, we propose a framework that jointly learns sketch-to-photo and photo-to-sketch generation. However, the generator trained from fake sketches might lead to unsatisfying results when dealing with sketches of missing classes, due to the domain gap between synthesized sketches and real ones. To alleviate this issue, we further propose a simple yet effective open-domain sampling and optimization strategy to “fool” the generator into treating fake sketches as real ones. Our method takes advantage of the learned sketch-to-photo and photo-to-sketch mapping of in-domain data and generalizes them to the open-domain classes. We validate our method on the Scribble and SketchyCOCO datasets. Compared with the recent competing methods, our approach shows impressive results in synthesizing realistic color, texture, and maintaining the geometric composition for various categories of open-domain sketches."
"Nicolae-Teodor Pavel, Traian Rebedea",1868a5ca323b82c42f1456995d8809f248458770,A Sketch-Based Neural Model for Generating Commit Messages from Diffs,ArXiv,2021.0,0,"Commit messages have an important impact in software development, especially when working in large teams. Multiple developers who have a different style of writing may often be involved in the same project. For this reason, it may be difficult to maintain a strict pattern of writing informative commit messages, with the most frequent issue being that these messages are not descriptive enough. In this paper we apply neural machine translation (NMT) techniques to convert code diffs into commit messages and we present an improved sketchbased encoder for this task. We split the approach into three parts. Firstly, we focus on finding a more suitable NMT baseline for this problem. Secondly, we show that the performance of the NMT models can be improved by training on examples containing a specific file type. Lastly, we introduce a novel sketch-based neural model inspired by recent approaches used for code generation and we show that the sketch-based encoder significantly outperforms existing state of the art solutions. The results highlight that this improvement is relevant especially for Java source code files, by examining two different datasets introduced in recent years for this task."
"Siyao Li, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, D. Metaxas, Chen Change Loy, Ziwei Liu",701c56592f6b4132f5869f175a46c88df12a3340,Deep Animation Video Interpolation in the Wild,ArXiv,2021.0,0,"In the animation industry, cartoon videos are usually produced at low frame rate since hand drawing of such frames is costly and time-consuming. Therefore, it is desirable to develop computational models that can automatically interpolate the in-between animation frames. However, existing video interpolation methods fail to produce satisfying results on animation data. Compared to natural videos, animation videos possess two unique characteristics that make frame interpolation difficult: 1) cartoons comprise lines and smooth color pieces. The smooth areas lack textures and make it difficult to estimate accurate motions on animation videos. 2) cartoons express stories via exaggeration. Some of the motions are non-linear and extremely large. In this work, we formally define and study the animation video interpolation problem for the first time. To address the aforementioned challenges, we propose an effective framework, AnimeInterp, with two dedicated modules in a coarse-to-fine manner. Specifically, 1) Segment-Guided Matching resolves the “lack of textures” challenge by exploiting global matching among color pieces that are piecewise coherent. 2) Recurrent Flow Refinement resolves the “non-linear and extremely large motion” challenge by recurrent predictions using a transformer-like architecture. To facilitate comprehensive training and evaluations, we build a large-scale animation triplet dataset, ATD-12K, which comprises 12,000 triplets with rich annotations. Extensive experiments demonstrate that our approach outperforms ex∗Equal contributions; Corresponding author. isting state-of-the-art interpolation methods for animation videos. Notably, AnimeInterp shows favorable perceptual quality and robustness for animation scenarios in the wild. The proposed dataset and code are available at https: //github.com/lisiyao21/AnimeInterp/."
"Changying Hao, Liang Pang, Yanyan Lan, Yan Wang, Jiafeng Guo, Xueqi Cheng",9e329bc6d33fa31a8f51563ee632e3962d3f624b,Sketch and Customize: A Counterfactual Story Generator,AAAI,2021.0,0,"Recent text generation models are easy to generate relevant and fluent text for the given text, while lack of causal reasoning ability when we change some parts of the given text. Counterfactual story rewriting is a recently proposed task to test the causal reasoning ability for text generation models, which requires a model to predict the corresponding story ending when the condition is modified to a counterfactual one. Previous works have shown that the traditional sequence-tosequence model cannot well handle this problem, as it often captures some spurious correlations between the original and counterfactual endings, instead of the causal relations between conditions and endings. To address this issue, we propose a sketch-and-customize generation model guided by the causality implicated in the conditions and endings. In the sketch stage, a skeleton is extracted by removing words which are conflict to the counterfactual condition, from the original ending. In the customize stage, a generation model is used to fill proper words in the skeleton under the guidance of the counterfactual condition. In this way, the obtained counterfactual ending is both relevant to the original ending and consistent with the counterfactual condition. Experimental results show that the proposed model generates much better endings, as compared with the traditional sequence-to-sequence model."
"Chenjie Cao, Yanwei Fu",a3f75bc7b11423e4561f8844cb6981d1f9b7c5a3,Learning a Sketch Tensor Space for Image Inpainting of Man-made Scenes,ArXiv,2021.0,0,"This paper studies the task of inpainting man-made scenes. It is very challenging due to the difficulty in preserving the visual patterns of images, such as edges, lines, and junctions. Especially, most previous works are failed to restore the object/building structures for images of man-made scenes. To this end, this paper proposes learning a Sketch Tensor (ST) space for inpainting man-made scenes. Such a space is learned to restore the edges, lines, and junctions in images, and thus makes reliable predictions of the holistic image structures. To facilitate the structure refinement, we propose a Multi-scale Sketch Tensor inpainting (MST) network, with a novel encoder-decoder structure. The encoder extracts lines and edges from the input images to project them into an ST space . From this space, the decoder is learned to restore the input images. Extensive experiments validate the efficacy of our model. Furthermore, our model can also achieve competitive performance in inpainting general nature images over the competitors. The project page is https://ewrfcas.github.io/MST_inpainting. 1 ar X iv :2 10 3. 15 08 7v 1 [ cs .C V ] 2 8 M ar 2 02 1"
"Z. Jian, M. Xie",f4324b44df0d034522c1de8846785fc0cc7bc958,Realistic face animation generation from videos,ArXiv,2021.0,0,"3D face reconstruction and face alignment are two fundamental and highly related topics in computer vision. Recently, some works start to use deep learning models to estimate the 3DMM coefficients to reconstruct 3D face geometry. However, the performance is restricted due to the limitation of the pre-defined face templates. To address this problem, some end-to-end methods, which can completely bypass the calculation of 3DMM coefficients, are proposed and attract much attention. In this report, we introduce and analyse three state-of-the-art methods in 3D face reconstruction and face alignment. Some potential improvement on PRN are proposed to further enhance its accuracy and speed."
"Anindita Ghosh, N. Cheema, Cennet Oguz, C. Theobalt, P. Slusallek",4684e687f2f2a7b53c25ac07d8d9a2e6210e9c18,Synthesis of Compositional Animations from Textual Descriptions,ArXiv,2021.0,0,"“How can we animate 3D-characters from a movie script or move robots by simply telling them what we would like them to do?” “How unstructured and complex can we make a sentence and still generate plausible movements from it?” These are questions that need to be answered in the long-run, as the field is still in its infancy. Inspired by these problems, we present a new technique for generating compositional actions, which handles complex input sentences. Our output is a 3D pose sequence depicting the actions in the input sentence. We propose a hierarchical two-stream sequential model to explore a finer jointlevel mapping between natural language sentences and 3D pose sequences corresponding to the given motion. We learn two manifold representations of the motion – one each for the upper body and the lower body movements. Our model can generate plausible pose sequences for short sentences describing single actions as well as long compositional sentences describing multiple sequential and superimposed actions. We evaluate our proposed model on the publicly available KIT Motion-Language Dataset containing 3D pose data with human-annotated sentences. Experimental results show that our model advances the state-ofthe-art on text-based motion synthesis in objective evaluations by a margin of 50%. Qualitative evaluations based on a user study indicate that our synthesized motions are perceived to be the closest to the ground-truth motion captures for both short and compositional sentences."
"Daniel Baul'e, C. V. Wangenheim, A. V. Wangenheim, J. C. Hauck, Edson C. Vargas J'unior",cc0a01510a21023c4061479d453eea2fd31ac23a,Automatic code generation from sketches of mobile applications in end-user development using Deep Learning,ArXiv,2021.0,0,"A common need for mobile application development by end-users or in computing education is to transform a sketch of a user interface into wireframe code using App Inventor, a popular block-based programming environment. As this task is challenging and time-consuming, we present the Sketch2aia approach that automates this process. Sketch2aia employs deep learning to detect the most frequent user interface components and their position on a hand-drawn sketch creating an intermediate representation of the user interface and then automatically generates the App Inventor code of the wireframe. The approach achieves an average user interface component classification accuracy of 87,72% and results of a preliminary user evaluation indicate that it generates wireframes that closely mirror the sketches in terms of visual similarity. The approach has been implemented as a web tool and can be used to support the end-user development of mobile applications effectively and efficiently as well as the teaching of user interface design in K-12."
"Y. Li, Honghao Lin, David P. Woodruff",6ee6f05be7d5cca3a656cd659baa5bbc064e7563,Learning-Augmented Sketches for Hessians,ArXiv,2021.0,0,"Sketching is a dimensionality reduction technique where one compresses a matrix by linear combinations that are typically chosen at random. A line of work has shown how to sketch the Hessian to speed up each iteration in a second order method, but such sketches usually depend only on the matrix at hand, and in a number of cases are even oblivious to the input matrix. One could instead hope to learn a distribution on sketching matrices that is optimized for the specific distribution of input matrices. We show how to design learned sketches for the Hessian in the context of second order methods, where we learn potentially different sketches for the different iterations of an optimization procedure. We show empirically that learned sketches, compared with their “non-learned” counterparts, improve the approximation accuracy for important problems, including LASSO, SVM, and matrix estimation with nuclear norm constraints. Several of our schemes can be proven to perform no worse than their unlearned counterparts. Additionally, we show that a smaller sketching dimension of the column space of a tall matrix is possible, assuming an oracle for predicting rows which have a large leverage score."
Xavier Ignacio Gonz'alez,d020fa2236740c2b6db56c984c6b1eb8c919ab0d,The FaCells. An Exploratory Study about LSTM Layers on Face Sketches Classifiers,ArXiv,2021.0,0,"Lines are human mental abstractions. A bunch of lines may form a drawing. A set of drawings can feed an LSTM network input layer, considering each draw as a list of lines and a line a list of points. This paper proposes the pointless motive to classify the gender of celebrities' portraits as an excuse for exploration in a broad, more artistic sense. Investigation results drove compelling ideas here discussed. The experiments compared different ways to represent draws to be input in a network and showed that an absolute format of coordinates (x, y) was a better performer than a relative one (Dx, Dy) with respect to prior points, most frequent in the reviewed literature. Experiments also showed that, due to the recurrent nature of LSTMs, the order of lines forming a drawing is a relevant factor for input in an LSTM classifier not studied before. A minimum 'pencil' traveled length criteria for line ordering proved suitable, possible by reducing it to a TSP particular instance. The best configuration for gender classification appears with an LSTM layer that returns the hidden state value for each input point step, followed by a global average layer along the sequence, before the output dense layer. That result guided the idea of removing the average in the network pipeline and return a per-point attribute score just by adjusting tensors dimensions. With this trick, the model detects an attribute in a drawing and also recognizes the points linked to it. Moreover, by overlapping filtered lines of portraits, an attribute's visual essence is depicted. Meet the FaCells."
"Neeraj Kumar, Srishti Goel, Ankur Narang, B. Lall, H. Mujtaba, Pranshu Agarwal, Dipankar Sarkar",43bb7b47521b6f2be80b76f94ae9700653cad1ca,One Shot Audio to Animated Video Generation,ArXiv,2021.0,0,"We consider the challenging problem of audio to animated video generation. We propose a novel method OneShotAu2AV to generate an animated video of arbitrary length using an audio clip and a single unseen image of a person as an input. The proposed method consists of two stages. In the first stage, OneShotAu2AV generates the talking-head video in the human domain given an audio and a person′s image. In the second stage, the talking-head video from the human domain is converted to the animated domain. The model architecture of the first stage consists of spatially adaptive normalization based multi-level generator and multiple multilevel discriminators along with multiple adversarial and non-adversarial losses. The second stage leverages attention based normalization driven GAN architecture along with temporal predictor based recycle loss and blink loss coupled with lipsync loss, for unsupervised generation of animated video. In our approach, the input audio clip is not restricted to any specific language, which gives the method multilingual applicability. OneShotAu2AV can generate animated videos that have: (a) lip movements that are in sync with the audio, (b) natural facial expressions such as blinks and eyebrow movements, (c) head movements. Experimental evaluation demonstrates superior performance of OneShotAu2AV as compared to U-GAT-IT and RecycleGan on multiple quantitative metrics including KID(Kernel Inception Distance), Word error rate, blinks/sec."
"Samet Hicsonmez, Nermin Samet, Emre Akbas, P. Duygulu",b400f12e36e4489fdefa4d2188b59d35a9923259,Adversarial Segmentation Loss for Sketch Colorization,ArXiv,2021.0,0,"We introduce a new method for generating color images from sketches or edge maps. Current methods either require some form of additional user-guidance or are limited to the “paired” translation approach. We argue that segmentation information could provide valuable guidance for sketch colorization. To this end, we propose to leverage semantic image segmentation, as provided by a general purpose pantoptic segmentation network, to create an additional adversarial loss function. Our loss function can be integrated to any baseline GAN model. Our method is not limited to datasets that contain segmentation labels, and it can be trained for “unpaired” translation tasks. We show the effectiveness of our method on four different datasets spanning scene level indoor, outdoor, and children book illustration images using qualitative, quantitative and user study analysis. Our model improves its baseline up to 35 points on the FID metric. Our code and pretrained models can be found at https://github.com/giddyyupp/AdvSegLoss."
"Emanuele Dolera, S. Favaro, Stefano Peluchetti",c704884cd9d899a1ece976f23b48881f73bdec86,Learning-augmented count-min sketches via Bayesian nonparametrics,ArXiv,2021.0,0,"The count-min sketch (CMS) is a time and memory efficient randomized data structure that provides estimates of tokens’ frequencies in a data stream, i.e. point queries, based on random hashed data. Learning-augmented CMSs improve the CMS by learning models that allow to better exploit data properties. In this paper, we focus on the learning-augmented CMS of Cai, Mitzenmacher and Adams (NeurIPS 2018), which relies on Bayesian nonparametric (BNP) modeling of a data stream via Dirichlet process (DP) priors. This is referred to as the CMS-DP, and it leads to BNP estimates of a point query as posterior means of the point query given the hashed data. While BNPs is proved to be a powerful tool for developing robust learning-augmented CMSs, ideas and methods behind the CMS-DP are tailored to point queries under DP priors, and they can not be used for other priors or more general queries. In this paper, we present an alternative, and more flexible, derivation of the CMS-DP such that: i) it allows to make use of the Pitman-Yor process (PYP) prior, which is arguably the most popular generalization of the DP prior; ii) it can be readily applied to the more general problem of estimating range queries. This leads to develop a novel learning-augmented CMS under powerlaw data streams, referred to as the CMS-PYP, which relies on BNP modeling of the stream via PYP priors. Applications to synthetic and real data show that the CMS-PYP outperforms the CMS and the CMS-DP in the estimation of low-frequency tokens; this known to be a critical feature in natural language processing, where it is indeed common to encounter power-law data streams."
"X. Yang, Zongliang Ma, Letian Yu, Ying Cao, Baocai Yin, Xiaopeng Wei, Q. Zhang, Rynson W. H. Lau",c22325b8c8c321b3591092dfda1c2cf409eb3881,Automatic Comic Generation with Stylistic Multi-page Layouts and Emotion-driven Text Balloon Generation,ACM Trans. Multim. Comput. Commun. Appl.,2021.0,0,"In this article, we propose a fully automatic system for generating comic books from videos without any human intervention. Given an input video along with its subtitles, our approach first extracts informative keyframes by analyzing the subtitles and stylizes keyframes into comic-style images. Then, we propose a novel automatic multi-page layout framework that can allocate the images across multiple pages and synthesize visually interesting layouts based on the rich semantics of the images (e.g., importance and inter-image relation). Finally, as opposed to using the same type of balloon as in previous works, we propose an emotion-aware balloon generation method to create different types of word balloons by analyzing the emotion of subtitles and audio. Our method is able to vary balloon shapes and word sizes in balloons in response to different emotions, leading to more enriched reading experience. Once the balloons are generated, they are placed adjacent to their corresponding speakers via speaker detection. Our results show that our method, without requiring any user inputs, can generate high-quality comic pages with visually rich layouts and balloons. Our user studies also demonstrate that users prefer our generated results over those by state-of-the-art comic generation systems."
"Danny Vainstein, Vaggos Chatziafratis, Gui Citovsky, Anand Rajagopalan, Mohammad Mahdian, Y. Azar",c7892d8a02606911542f042cf858a74719c81838,Hierarchical Clustering via Sketches and Hierarchical Correlation Clustering,AISTATS,2021.0,0,"Recently, Hierarchical Clustering (HC) has been considered through the lens of optimization. In particular, two maximization objectives have been defined. Moseley and Wang defined the Revenue objective to handle similarity information given by a weighted graph on the data points (w.l.o.g., [0, 1] weights), while Cohen-Addad et al. defined the Dissimilarity objective to handle dissimilarity information. In this paper, we prove structural lemmas for both objectives allowing us to convert any HC tree to a tree with constant number of internal nodes while incurring an arbitrarily small loss in each objective. Although the best-known approximations are 0.585 and 0.667 respectively, using our lemmas we obtain approximations arbitrarily close to 1, if not all weights are small (i.e., there exist constants , δ such that the fraction of weights smaller than δ, is at most 1 − ); such instances encompass many metric-based similarity instances, thereby improving upon prior work. Finally, we introduce Hierarchical Correlation Clustering (HCC) to handle instances that contain similarity and dissimilarity information simultaneously. For HCC, we provide an approximation of 0.4767 and for complementary similarity/dissimilarity weights (analogous to +/− correlation clustering), we again present nearly-optimal approximations. Proceedings of the 24 International Conference on Artificial Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR: Volume 130. Copyright 2021 by the author(s)."
"Edwin Arkel Rios, Wen-Huang Cheng, Bo-Cheng Lai",9992e634f17ed379e2e89092c388c51f1b2b2e70,"DAF: re: A Challenging, Crowd-Sourced, Large-Scale, Long-Tailed Dataset For Anime Character Recognition",ArXiv,2021.0,0,"In this work we tackle the challenging problem of anime character recognition. Anime, referring to animation produced within Japan and work derived or inspired from it. For this purpose we present DAF:re (DanbooruAnimeFaces:revamped), a large-scale, crowd-sourced, long-tailed dataset with almost 500 K images spread across more than 3000 classes. Additionally, we conduct experiments on DAF:re and similar datasets using a variety of classification models, including CNN based ResNets and self-attention based Vision Transformer (ViT). Our results give new insights into the generalization and transfer learning properties of ViT models on substantially different domain datasets from those used for the upstream pre-training, including the influence of batch and image size in their training. Additionally, we share our dataset, source-code, pre-trained checkpoints and results, as Animesion, the first end-toend framework for large-scale anime character recognition: https://github.com/arkel23/animesion."
"Riku Arakawa, Hiromu Yakura",d297510d8486aefdf938062679f5a6679948c67b,Mindless Attractor: A False-Positive Resistant Intervention for Drawing Attention Using Auditory Perturbation,CHI,2021.0,0,"Explicitly alerting users is not always an optimal intervention, especially when they are not motivated to obey. For example, in video-based learning, learners who are distracted from the video would not follow an alert asking them to pay attention. Inspired by the concept of Mindless Computing, we propose a novel intervention approach, Mindless Attractor, that leverages the nature of human speech communication to help learners refocus their attention without relying on their motivation. Specifically, it perturbs the voice in the video to direct their attention without consuming their conscious awareness. Our experiments not only confirmed the validity of the proposed approach but also emphasized its advantages in combination with a machine learning-based sensing module. Namely, it would not frustrate users even though the intervention is activated by false-positive detection of their attentive state. Our intervention approach can be a reliable way to induce behavioral change in human–AI symbiosis."
"Nikos Papasarantopoulos, Shay B. Cohen",0131c9e6b277b9334b2d806c8f0483cae677113d,Narration Generation for Cartoon Videos,ArXiv,2021.0,0,"Research on text generation from multimodal inputs has largely focused on static images, and less on video data. In this paper, we propose a new task, narration generation, that is complementing videos with narration texts that are to be interjected in several places. The narrations are part of the video and contribute to the storyline unfolding in it. Moreover, they are context-informed, since they include information appropriate for the timeframe of video they cover, and also, do not need to include every detail shown in input scenes, as a caption would. We collect a new dataset from the animated television series Peppa Pig. Furthermore, we formalize the task of narration generation as including two separate tasks, timing and content generation, and present a set of models on the new task.1"
"Jin-ye Peng, Jiaxin Wang, J. Wang, Erlei Zhang, Qunxi Zhang, Yongqin Zhang, Xianlin Peng, Kai Yu",ddcb714beb7c414dd11135aa52b0e65df25f82f8,A relic sketch extraction framework based on detail-aware hierarchical deep network,Signal Process.,2021.0,0,"As the first step of the restoration process of painted relics, sketch extraction plays an important role in cultural research. However, sketch extraction suffers from serious disease corrosion, which results in broken lines and noise. To overcome these problems, we propose a deep learning-based hierarchical sketch extraction framework for painted cultural relics. We design the sketch extraction process into two stages: coarse extraction and fine extraction. In the coarse extraction stage, we develop a novel detail-aware bi-directional cascade network that integrates flow-based difference-of-Gaussians (FDoG) edge detection and a bi-directional cascade network (BDCN) under a transfer learning framework. It not only uses the pre-trained strategy to extenuate the requirements of large datasets for deep network training but also guides the network to learn the detail characteristics by the prior knowledge from FDoG. For the fine extraction stage, we design a new multiscale U-Net (MSU-Net) to effectively remove disease noise and refine the sketch. Specifically, all the features extracted from multiple intermediate layers in the decoder of MSU-Net are fused for sketch predication. Experimental results showed that the proposed method outperforms the other seven state-of-the-art methods in terms of visual and quantitative metrics and can also deal with complex backgrounds."
"Ting Han, Sina Zarrieß",5e1f3aea257d09d75101f489b88ae4253c9182c6,Enabling Robots to Draw and Tell: Towards Visually Grounded Multimodal Description Generation,ArXiv,2021.0,0,"Socially competent robots should be equippedwith the ability to perceive the world that surrounds them and communicate about it in a human-like manner. Representative skills that exhibit such ability include generating image descriptions and visually grounded referring expressions. In the NLG community, these generation tasks are largely investigated in non-interactive and language-only settings. However, in face-to-face interaction, humans often deploy multiple modalities to communicate, forming seamless integration of natural language, hand gestures and other modalities like sketches. To enable robots to describe what they perceive with speech and sketches/gestures, we propose to model the task of generating natural language together with free-hand sketches/hand gestures to describe visual scenes and reallife objects, namely, visually-grounded multimodal description generation. In this paper, we discuss the challenges and evaluation metrics of the task, and how the task can benefit from progress recently made in the natural language processing and computer vision realms, where related topics such as visually grounded NLG, distributional semantics, and photo-based sketch generation have been extensively studied."
"Ryota Hinami, Shonosuke Ishiwatari, Kazuhiko Yasuda, Yusuke Matsui",a8302a61f49bbf1e702d417c4122dfbc729a4985,Towards Fully Automated Manga Translation,AAAI,2021.0,0,"We tackle the problem of machine translation (MT) of manga, Japanese comics. Manga translation involves two important problems in MT: context-aware and multimodal translation. Since text and images are mixed up in an unstructured fashion in manga, obtaining context from the image is essential for its translation. However, it is still an open problem how to extract context from images and integrate into MT models. In addition, corpus and benchmarks to train and evaluate such models are currently unavailable. In this paper, we make the following four contributions that establish the foundation of manga translation research. First, we propose a multimodal context-aware translation framework. We are the first to incorporate context information obtained from manga images. It enables us to translate texts in speech bubbles that cannot be translated without using context information (e.g., texts in other speech bubbles, gender of speakers, etc.). Second, for training the model, we propose the approach to automatic corpus construction from pairs of original manga and their translations, by which a large parallel corpus can be constructed without any manual labeling. Third, we created a new benchmark to evaluate manga translation. Finally, on top of our proposed methods, we devised a first comprehensive system for fully automated manga translation."
"Zhengyan Tong, Xuanhong Chen, Bingbing Ni, Xiaohan Wang",5f8cc52cdd8859963a9f074cf461f2132a38d346,Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale,AAAI,2021.0,0,"We propose a novel image-to-pencil translation method that could not only generate high-quality pencil sketches but also offer the drawing process. Existing pencil sketch algorithms are based on texture rendering rather than the direct imitation of strokes, making them unable to show the drawing process but only a final result. To address this challenge, we first establish a pencil stroke imitation mechanism. Next, we develop a framework with three branches to guide stroke drawing: the first branch guides the direction of the strokes, the second branch determines the shade of the strokes, and the third branch enhances the details further. Under this framework's guidance, we can produce a pencil sketch by drawing one stroke every time. Our method is fully interpretable. Comparison with existing pencil drawing algorithms shows that our method is superior to others in terms of texture quality, style, and user evaluation."
"Yuhe Ding, Xin Ma, Mandi Luo, A. Zheng, Ran He",54fb1e19c138c9617c0c23d32a88dc9594980d72,Unsupervised Contrastive Photo-to-Caricature Translation based on Auto-distortion,2020 25th International Conference on Pattern Recognition (ICPR),2021.0,0,"Photo-to-caricature translation aims to synthesize the caricature as a rendered image exaggerating the features through sketching, pencil strokes, or other artistic drawings. Style rendering and geometry deformation are the most important aspects in photo-to-caricature translation task. To take both into consideration, we propose an unsupervised contrastive photo-to-caricature translation architecture. Considering the intuitive artifacts in the existing methods, we propose a contrastive style loss for style rendering to enforce the similarity between the style of rendered photo and the caricature, and simultaneously enhance its discrepancy to the photos. To obtain an exaggerating deformation in an unpaired/unsupervised fashion, we propose a Distortion Prediction Module (DPM) to predict a set of displacements vectors for each input image while fixing some controlling points, followed by the thin plate spline interpolation for warping. The model is trained on unpaired photo and caricature while can offer bidirectional synthesizing via inputting either a photo or a caricature. Extensive experiments demonstrate that the proposed model is effective to generate hand-drawn like caricatures compared with existing competitors."
"Qinchen Cao, Weilin Zhang, Yonghua Zhu",fd1aaaf5ad5e41560ff99c7bcc00a485a2a4a070,"Deep learning-based classification of the polar emotions of ""moe""-style cartoon pictures",,2021.0,0,"The cartoon animation industry has developed into a huge industrial chain with a large potential market involving games, digital entertainment, and other industries. However, due to the coarse-grained classification of cartoon materials, cartoon animators can hardly find relevant materials during the process of creation. The polar emotions of cartoon materials are an important reference for creators as they can help them easily obtain the pictures they need. Some methods for obtaining the emotions of cartoon pictures have been proposed, but most of these focus on expression recognition. Meanwhile, other emotion recognition methods are not ideal for use as cartoon materials. We propose a deep learning-based method to classify the polar emotions of the cartoon pictures of the ""Moe"" drawing style. According to the expression feature of the cartoon characters of this drawing style, we recognize the facial expressions of cartoon characters and extract the scene and facial features of the cartoon images. Then, we correct the emotions of the pictures obtained by the expression recognition according to the scene features. Finally, we can obtain the polar emotions of corresponding picture. We designed a dataset and performed verification tests on it, achieving 81.9% experimental accuracy. The experimental results prove that our method is competitive."
"Yuki Endo, Yoshihiro Kanamori",3f05ab16f8797c6858d53a498862bb6b278f11d8,Few-shot Semantic Image Synthesis Using StyleGAN Prior,ArXiv,2021.0,0,"This paper tackles a challenging problem of generating photorealistic images from semantic layouts in few-shot scenarios where annotated training pairs are hardly available but pixel-wise annotation is quite costly. We present a training strategy that performs pseudo labeling of semantic masks using the StyleGAN prior. Our key idea is to construct a simple mapping between the StyleGAN feature and each semantic class from a few examples of semantic masks. With such mappings, we can generate an unlimited number of pseudo semantic masks from random noise to train an encoder for controlling a pre-trained StyleGAN generator. Although the pseudo semantic masks might be too coarse for previous approaches that require pixel-aligned masks, our framework can synthesize high-quality images from not only dense semantic masks but also sparse inputs such as landmarks and scribbles. Qualitative and quantitative results with various datasets demonstrate improvement over previous approaches with respect to layout fidelity and visual quality in as few as oneor five-shot settings."
"Tzu-Ting Fang, Duc Minh Vo, A. Sugimoto, S. Lai",ec35e52df54a26688e8f096415c9838d153915e9,Stylized-Colorization for Line Arts,2020 25th International Conference on Pattern Recognition (ICPR),2021.0,0,"We address a novel problem of stylized-colorization which colorizes a given line art using a given coloring style in text. This problem can be stated as multi-domain image translation and is more challenging than the current colorization problem because it requires not only capturing the illustration distribution but also satisfying the required coloring styles specific to anime such as lightness, shading, or saturation. We propose a GAN-based end-to-end model for stylized-colorization where the model has one generator and two discriminators. Our generator is based on the U-Net architecture and receives a pair of a line art and a coloring style in text as its input to produce a stylized-colorization image of the line art. Two discriminators, on the other hand, share weights at early layers to judge the stylized-colorization image in two different aspects: one for color and one for style. One generator and two discriminators are jointly trained in an adversarial and end-to-end manner. Extensive experiments demonstrate the effectiveness of our proposed model."
"Can Wang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao",69e1da852c06ef47aa9c7d130805b8f03c761ac8,Cross-Domain and Disentangled Face Manipulation with 3D Guidance,ArXiv,2021.0,0,"Face imagemanipulation via three-dimensional guidance has been widely applied in various interactive scenarios due to its semantically-meaningful understanding and user-friendly controllability. However, existing 3D-morphablemodel-based manipulation methods are not directly applicable to out-ofdomain faces, such as non-photorealistic paintings, cartoon portraits, or even animals, mainly due to the formidable difficulties in building the model for each specific face domain. To overcome this challenge, we propose, as far as we know, the first method to manipulate faces in arbitrary domains using human 3DMM. This is achieved through two major steps: 1) disentangled mapping from 3DMM parameters to the latent space embedding of a pre-trained StyleGAN2 [Karras et al. 2020] that guarantees disentangled and precise controls for each semantic attribute; and 2) cross-domain adaptation that bridges domain discrepancies and makes human 3DMM applicable to out-of-domain faces by enforcing a consistent latent space embedding. Experiments and comparisons demonstrate the superiority of our high-quality semantic manipulation method on a variety of face domains with all major 3D facial attributes controllable – pose, expression, shape, albedo, and illumination. Moreover, we develop an intuitive editing interface to support user-friendly control and instant feedback. Our project page is https://cassiepython.github.io/sigasia/cddfm3d.html."
"Zhenliang He, Meina Kan, S. Shan",21e348d81033f419199764a040f247ceff81718f,EigenGAN: Layer-Wise Eigen-Learning for GANs,ArXiv,2021.0,0,"Recent studies on Generative Adversarial Network (GAN) reveal that different layers of a generative CNN hold different semantics of the synthesized images. However, few GAN models have explicit dimensions to control the semantic attributes represented in a specific layer. This paper proposes EigenGAN which is able to unsupervisedly mine interpretable and controllable dimensions from different generator layers. Specifically, EigenGAN embeds one linear subspace with orthogonal basis into each generator layer. Via the adversarial training to learn a target distribution, these layer-wise subspaces automatically discover a set of “eigen-dimensions” at each layer corresponding to a set of semantic attributes or interpretable variations. By traversing the coefficient of a specific eigen-dimension, the generator can produce samples with continuous changes corresponding to a specific semantic attribute. Taking the human face for example, EigenGAN can discover controllable dimensions for high-level concepts such as pose and gender in the subspace of deep layers, as well as low-level concepts such as hue and color in the subspace of shallow layers. Moreover, under the linear circumstance, we theoretically prove that our algorithm derives the principal components as PCA does. Codes can be found in https://github. com/LynnHo/EigenGAN-Tensorflow ."
"Huiting Yang, Liangyu Chai, Q. Wen, Shuang Zhao, Zixun Sun, Shengfeng He",59b8a2a1b88ce8dc15a6603f135f7b4d04820a55,Discovering Interpretable Latent Space Directions of GANs Beyond Binary Attributes,,2021.0,0,"Generative adversarial networks (GANs) learn to map noise latent vectors to high-fidelity image outputs. It is found that the input latent space shows semantic correlations with the output image space. Recent works aim to interpret the latent space and discover meaningful directions that correspond to human interpretable image transformations. However, these methods either rely on explicit scores of attributes (e.g., memorability) or are restricted to binary ones (e.g., gender), which largely limits the applicability of editing tasks, especially for free-form artistic tasks like style/anime editing. In this paper, we propose an adversarial method, AdvStyle, for discovering interpretable directions in the absence of well-labeled scores or binary attributes. In particular, the proposed adversarial method simultaneously optimizes the discovered directions and the attribute assessor using the target attribute data as positive samples, while the generated ones being negative. In this way, arbitrary attributes can be edited by collecting positive data only, and the proposed method learns a controllable representation enabling manipulation *Corresponding author (hesfe@scut.edu.cn). of non-binary attributes like anime styles and facial characteristics. Moreover, the proposed learning strategy attenuates the entanglement between attributes, such that multiattribute manipulation can be easily achieved without any additional constraint. Furthermore, we reveal several interesting semantics with the involuntarily learned negative directions. Extensive experiments on 9 anime attributes and 7 human attributes demonstrate the effectiveness of our adversarial approach qualitatively and quantitatively. Code is available at https://github.com/BERYLSHEEP/AdvStyle."
"Eungyeup Kim, Sanghyeon Lee, Jeonghoon Park, Somi Choi, Choonghyun Seo, J. Choo",b51b3bc074cbb5aa75df66b7ab89892cc1807ee0,Deep Edge-Aware Interactive Colorization against Color-Bleeding Effects,,2021.0,0,"Deep image colorization networks often suffer from the color-bleeding artifact, a problematic color spreading near the boundaries between adjacent objects. The colorbleeding artifacts debase the reality of generated outputs, limiting the applicability of colorization models on a practical application. Although previous approaches have tackled this problem in an automatic manner, they often generate imperfect outputs because their enhancements are available only in limited cases, such as having a high contrast of gray-scale value in an input image. Instead, leveraging user interactions would be a promising approach, since it can help the edge correction in the desired regions. In this * indicates equal contribution paper, we propose a novel edge-enhancing framework for the regions of interest, by utilizing user scribbles that indicate where to enhance. Our method requires minimal user effort to obtain satisfactory enhancements. Experimental results on various datasets demonstrate that our interactive approach has outstanding performance in improving colorbleeding artifacts against the existing baselines."
"M. Xie, Menghan Xia, T. Wong",378f5305d7250e7290dd1cde87b319617d285d39,Exploiting Aliasing for Manga Restoration,ArXiv,2021.0,0,"As a popular entertainment art form, manga enriches the line drawings details with bitonal screentones. However, manga resources over the Internet usually show screentone artifacts because of inappropriate scanning/rescaling resolution. In this paper, we propose an innovative twostage method to restore quality bitonal manga from degraded ones. Our key observation is that the aliasing induced by downsampling bitonal screentones can be utilized as informative clues to infer the original resolution and screentones. First, we predict the target resolution from the degraded manga via the Scale Estimation Network (SENet) with spatial voting scheme. Then, at the target resolution, we restore the region-wise bitonal screentones via the Manga Restoration Network (MR-Net) discriminatively, depending on the degradation degree. Specifically, the original screentones are directly restored in pattern-identifiable regions, and visually plausible screentones are synthesized in pattern-agnostic regions. Quantitative evaluation on synthetic data and visual assessment on real-world cases illustrate the effectiveness of our method."
"Minjun Li, Yanghua Jin, Huachun Zhu",5f4c8a26d30b9a6a078c3f7433477f1c85cfb555,Surrogate Gradient Field for Latent Space Manipulation,ArXiv,2021.0,0,"Generative adversarial networks (GANs) can generate high-quality images from sampled latent codes. Recent works attempt to edit an image by manipulating its underlying latent code, but rarely go beyond the basic task of attribute adjustment. We propose the first method that enables manipulation with multidimensional condition such as keypoints and captions. Specifically, we design an algorithm that searches for a new latent code that satisfies the target condition based on the Surrogate Gradient Field (SGF) induced by an auxiliary mapping network. For quantitative comparison, we propose a metric to evaluate the disentanglement of manipulation methods. Thorough experimental *Equal contribution. analysis on the facial attribute adjustment task shows that our method outperforms state-of-the-art methods in disentanglement. We further apply our method to tasks of various condition modalities to demonstrate that our method can alter complex image properties such as keypoints and captions."
"Chang Wook Seo, Y. Seo",1d972f2474ffbf4151d4195009b4ed6171db6e28,Seg2pix: Few Shot Training Line Art Colorization with Segmented Image Data,,2021.0,0,
"Min Jin Chong, David Forsyth",c79b7d36351938301877a3fa6d5478f368ef0f3f,"GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",ArXiv,2021.0,0,"We show how to learn a map that takes a content code, derived from a face image, and a randomly chosen style code to an anime image. We derive an adversarial loss from our simple and effective definitions of style and content. This adversarial loss guarantees the map is diverse – a very wide range of anime can be produced from a single content code. Under plausible assumptions, the map is not just diverse, but also correctly represents the probability of an anime, conditioned on an input face. In contrast, current multimodal generation procedures cannot capture the complex styles that appear in anime. Extensive quantitative experiments support the idea the map is correct. Extensive qualitative results show that the method can generate a much more diverse range of styles than SOTA comparisons. Finally, we show that our formalization of content and style allows us to perform video to video translation without ever training on videos. Code can be found here https://github.com/mchong6/GANsNRoses."
"Xu Shao, Weidong Zhang",370211492b976f2b33e0b590abecf27905fc882f,SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation,ArXiv,2021.0,0,"For unsupervised image-to-image translation, we propose a discriminator architecture which focuses on the statistical features instead of individual patches. The network is stabilized by distribution matching of key statistical features at multiple scales. Unlike the existing methods which impose more and more constraints on the generator, our method facilitates the shape deformation and enhances the fine details with a greatly simplified framework. We show that the proposed method outperforms the existing state-ofthe-art models in various challenging applications including selfie-to-anime, male-to-female and glasses removal. The code will be made publicly available."
"Rawan Alghofaili, Matthew Fisher, Richard Zhang, M. Lukác",e11025c56dbc07293990731d8eb9cb4cef771cac,Exploring Sketch-based Character Design Guided by Automatic Colorization,,2021.0,0,"Character design is a lengthy process, requiring artists to iteratively alter their characters’ features and colorization schemes according to feedback from creative directors or peers. Artists experiment with multiple colorization schemes before deciding on the right color palette. This process may necessitate several tedious manual re-colorizations of the character. Any substantial changes to the character’s appearance may also require manual re-colorization. Such complications motivate a computational approach for visualizing characters and drafting solutions. We propose a character exploration tool that automatically colors a sketch based on a selected style. The tool employs a Generative Adversarial Network trained to automatically color sketches. The tool also allows a selection of faces to be used as a template for the character’s design. We validated our tool by comparing it with using Photoshop for character exploration in our pilot study. Finally, we conducted a study to evaluate our tool’s efficacy within the design pipeline."
"F. Gao, Meimei Shang, Xiang Li, Jingjie Zhu, Lingna Dai",f2477ab15c8d0a8d3b87bdb1e0d2edf8c352e723,Bridging Unpaired Facial Photos And Sketches By Line-drawings,ArXiv,2021.0,0,"In this paper, we propose a novel method to learn face sketch synthesis models by using unpaired data. Our main idea is bridging the photo domain X and the sketch domain Y by using the line-drawing domain Z . Specially, we map both photos and sketches to line-drawings by using a neural style transfer method, i.e. F : X/Y 7→ Z . Consequently, we obtain pseudo paired data (Z,Y), and can learn the mapping G : Z 7→ Y in a supervised learning manner. In the inference stage, given a facial photo, we can first transfer it to a line-drawing and then to a sketch by G ◦ F . Additionally, we propose a novel stroke loss for generating different types of strokes. Our method, termed sRender, accords well with human artists’ rendering process. Experimental results demonstrate that sRender can generate multi-style sketches, and significantly outperforms existing unpaired image-toimage translation methods."
"Junho Kim, M. Kim, Hyeonwoo Kang, KwangHee Lee",2f5cc15bee412176356ea6e068ff775140a02f8f,U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation,ICLR,2020.0,99,"We propose a novel method for unsupervised image-to-image translation, which incorporates a new attention module and a new learnable normalization function in an end-to-end manner. The attention module guides our model to focus on more important regions distinguishing between source and target domains based on the attention map obtained by the auxiliary classifier. Unlike previous attention-based method which cannot handle the geometric changes between domains, our model can translate both images requiring holistic changes and images requiring large shape changes. Moreover, our new AdaLIN (Adaptive Layer-Instance Normalization) function helps our attention-guided model to flexibly control the amount of change in shape and texture by learned parameters depending on datasets. Experimental results show the superiority of the proposed method compared to the existing state-of-the-art models with a fixed network architecture and hyper-parameters. Our code and datasets are available at this https URL or this https URL."
"Haoran You, Chaojian Li, P. Xu, Y. Fu, Yue Wang, Xiaohan Chen, Yingyan Lin, Zhangyang Wang, Richard Baraniuk",0cd14ff1b049f7461be40f53254a069bdfe847ff,Drawing early-bird tickets: Towards more efficient training of deep networks,ICLR,2020.0,59,"(Frankle & Carbin, 2019) shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve comparable accuracies to the latter in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, limiting their practical benefits. In this paper, we discover for the first time that the winning tickets can be identified at the very early training stage, which we term as early-bird (EB) tickets, via low-cost training schemes (e.g., early stopping and low-precision training) at large learning rates. Our finding of EB tickets is consistent with recently reported observations that the key connectivity patterns of neural networks emerge early. Furthermore, we propose a mask distance metric that can be used to identify EB tickets with low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, we leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low-cost schemes, and then continuing to train merely the EB tickets towards the target accuracy. Experiments based on various deep networks and datasets validate: 1) the existence of EB tickets, and the effectiveness of mask distance in efficiently identifying them; and 2) that the proposed efficient training via EB tickets can achieve up to 4.7x energy savings while maintaining comparable or even better accuracy, demonstrating a promising and easily adopted method for tackling cost-prohibitive deep network training."
"A. Voynov, Artem Babenko",7dc31d7fa8bf8caabed958173c3e220256c64af4,Unsupervised Discovery of Interpretable Directions in the GAN Latent Space,ICML,2020.0,50,"The latent spaces of GAN models often have semantically meaningful directions. Moving in these directions corresponds to human-interpretable image transformations, such as zooming or recoloring, enabling a more controllable generation process. However, the discovery of such directions is currently performed in a supervised manner, requiring human labels, pretrained models, or some form of self-supervision. These requirements severely restrict a range of directions existing approaches can discover. In this paper, we introduce an unsupervised method to identify interpretable directions in the latent space of a pretrained GAN model. By a simple model-agnostic procedure, we find directions corresponding to sensible semantic manipulations without any form of (self-)supervision. Furthermore, we reveal several non-trivial findings, which would be difficult to obtain by existing methods, e.g., a direction corresponding to background removal. As an immediate practical benefit of our work, we show how to exploit this finding to achieve competitive performance for weakly-supervised saliency detection."
"Yujun Shen, Bolei Zhou",dc0092d06ab76465431edfd51b08d823b7d1ff3f,Closed-Form Factorization of Latent Semantics in GANs,ArXiv,2020.0,42,"A rich set of semantic attributes has been shown to emerge in the latent space of the Generative Adversarial Networks (GANs) trained for synthesizing images. In order to identify such latent semantics for image manipulation, previous methods annotate a collection of synthesized samples and then train supervised classifiers in the latent space. However, they require a clear definition of the target attribute as well as the corresponding manual annotations, severely limiting their applications in practice. In this work, we examine the internal representation learned by GANs to reveal the underlying variation factors in an unsupervised manner. By studying the essential role of the fully-connected layer that takes the latent code into the generator of GANs, we propose a general closed-form factorization method for latent semantic discovery. The properties of the identified semantics are further analyzed both theoretically and empirically. With its fast and efficient implementation, our approach is capable of not only finding latent semantics as accurately as the state-of-the-art supervised methods, but also resulting in far more versatile semantic classes across multiple GAN models trained on a wide range of datasets."
"Yaxing Wang, Abel Gonzalez-Garcia, David Berga, Luis Herranz, F. Khan, Joost van de Weijer",80bf8b9598312d7897082057783da583b46f8ffb,MineGAN: Effective Knowledge Transfer From GANs to Target Domains With Few Images,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,26,"One of the attractive characteristics of deep neural networks is their ability to transfer knowledge obtained in one domain to other related domains. As a result, high-quality networks can be trained in domains with relatively little training data. This property has been extensively studied for discriminative networks but has received significantly less attention for generative models. Given the often enormous effort required to train GANs, both computationally as well as in the dataset collection, the re-use of pretrained GANs is a desirable objective. We propose a novel knowledge transfer method for generative models based on mining the knowledge that is most beneficial to a specific target domain, either from a single or multiple pretrained GANs. This is done using a miner network that identifies which part of the generative distribution of each pretrained GAN outputs samples closest to the target domain. Mining effectively steers GAN sampling towards suitable regions of the latent space, which facilitates the posterior finetuning and avoids pathologies of other methods such as mode collapse and lack of flexibility. We perform experiments on several complex datasets using various GAN architectures (BigGAN, Progressive GAN) and show that the proposed method, called MineGAN, effectively transfers knowledge to domains with few target images, outperforming existing methods. In addition, MineGAN can successfully transfer knowledge from multiple pretrained GANs. Our code is available at: \url{https://github.com/yaxingwang/MineGAN}."
"J. Yu, X. Xu, F. Gao, Shengjie Shi, Meng Wang, D. Tao, Qingming Huang",db7ad10a0481fa1c0ac041c9522c90e72ebe5163,Toward Realistic Face Photo-Sketch Synthesis via Composition-Aided GANs.,IEEE transactions on cybernetics,2020.0,23,"Face photo-sketch synthesis aims at generating a facial sketch/photo conditioned on a given photo/sketch. It covers wide applications including digital entertainment and law enforcement. Precisely depicting face photos/sketches remains challenging due to the restrictions on structural realism and textural consistency. While existing methods achieve compelling results, they mostly yield blurred effects and great deformation over various facial components, leading to the unrealistic feeling of synthesized images. To tackle this challenge, in this article, we propose using facial composition information to help the synthesis of face sketch/photo. Especially, we propose a novel composition-aided generative adversarial network (CA-GAN) for face photo-sketch synthesis. In CA-GAN, we utilize paired inputs, including a face photo/sketch and the corresponding pixelwise face labels for generating a sketch/photo. Next, to focus training on hard-generated components and delicate facial structures, we propose a compositional reconstruction loss. In addition, we employ a perceptual loss function to encourage the synthesized image and real image to be perceptually similar. Finally, we use stacked CA-GANs (SCA-GANs) to further rectify defects and add compelling details. The experimental results show that our method is capable of generating both visually comfortable and identity-preserving face sketches/photos over a wide range of challenging data. In addition, our method significantly decreases the best previous Fréchet inception distance (FID) from 36.2 to 26.2 for sketch synthesis, and from 60.9 to 30.5 for photo synthesis. Besides, we demonstrate that the proposed method is of considerable generalization ability."
"D. Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, I. Stoica, Vladimir Braverman, Joseph E. Gonzalez, R. Arora",06da2e6c52b9fc7abe1b421642c9385bd79b316f,FetchSGD: Communication-Efficient Federated Learning with Sketching,ICML,2020.0,23,"Existing approaches to federated learning suffer from a communication bottleneck as well as convergence issues due to sparse client participation. In this paper we introduce a novel algorithm, called FetchSGD, to overcome these challenges. FetchSGD compresses model updates using a Count Sketch, and then takes advantage of the mergeability of sketches to combine model updates from many workers. A key insight in the design of FetchSGD is that, because the Count Sketch is linear, momentum and error accumulation can both be carried out within the sketch. This allows the algorithm to move momentum and error accumulation from clients to the central aggregator, overcoming the challenges of sparse client participation while still achieving high compression rates and good convergence. We prove that FetchSGD has favorable convergence guarantees, and we demonstrate its empirical effectiveness by training two residual networks and a transformer model."
P. Xu,17ca0cd38e24231311ac21da9b9b36cfbe93d5f1,Deep Learning for Free-Hand Sketch: A Survey,ArXiv,2020.0,19,"Free-hand sketches are highly illustrative, and have been widely used by humans to depict objects or stories from ancient times to the present. The recent prevalence of touchscreen devices has made sketch creation a much easier task than ever and consequently made sketch-oriented applications increasingly popular. The progress of deep learning has immensely benefited free-hand sketch research and applications. This paper presents a comprehensive survey of the deep learning techniques oriented at free-hand sketch data, and the applications that they enable. The main contents of this survey include: (i) A discussion of the intrinsic traits and unique challenges of free-hand sketch, to highlight the essential differences between sketch data and other data modalities, e.g., natural photos. (ii) A review of the developments of free-hand sketch research in the deep learning era, by surveying existing datasets, research topics, and the state-of-the-art methods through a detailed taxonomy and experimental evaluation. (iii) Promotion of future work via a discussion of bottlenecks, open problems, and potential research directions for the community. Finally, to support future sketch research and applications, we contribute TorchSketch -- the first sketch-oriented open-source deep learning library, which is built on PyTorch and available at this https URL."
"Mingjin Zhang, Nannan Wang, Yunsong Li, Xinbo Gao",0a55ee667b7d6275712e7ec84cdff29401eafdc0,Neural Probabilistic Graphical Model for Face Sketch Synthesis,IEEE Transactions on Neural Networks and Learning Systems,2020.0,19,"Neural network learning for face sketch synthesis from photos has attracted substantial attention due to its favorable synthesis performance. However, most existing deep-learning-based face sketch synthesis models stacked only by multiple convolutional layers without structured regression often lose the common facial structures, limiting their flexibility in a wide range of practical applications, including intelligent security and digital entertainment. In this article, we introduce a neural network to a probabilistic graphical model and propose a novel face sketch synthesis framework based on the neural probabilistic graphical model (NPGM) composed of a specific structure and a common structure. In the specific structure, we investigate a neural network for mapping the direct relationship between training photos and sketches, yielding the specific information and characteristic features of a test photo. In the common structure, the fidelity between the sketch pixels generated by the specific structure and their candidates selected from the training data are considered, ensuring the preservation of the common facial structure. Experimental results on the Chinese University of Hong Kong face sketch database demonstrate, both qualitatively and quantitatively, that the proposed NPGM-based face sketch synthesis approach can more effectively capture specific features and recover common structures compared with the state-of-the-art methods. Extensive experiments in practical applications further illustrate that the proposed method achieves superior performance."
"X. Zhang, Yaping Huang, Qi Zou, Yanting Pei, Runsheng Zhang, Song Wang",e749523659b07533de693daff2e95658017981ad,A Hybrid convolutional neural network for sketch recognition,Pattern Recognit. Lett.,2020.0,18,"Abstract With the popularity of touch-screen devices, it is becoming increasingly important to understand users’ free-hand sketches in computer vision and human-computer interaction. Most of existing sketch recognition methods employ the similar strategies used in image recognition, relying on appearance information represented by hand-crafted features or deep features from convolutional neural networks. We believe that sketch recognition can benefit from learning both appearance and shape representation. In this paper, we propose a novel architecture, named Hybrid CNN, which is composed of A-Net and S-Net. They describe appearance information and shape information, respectively. Hybrid CNN is then comprehensively evaluated in the sketch classification and retrieval tasks on different datasets, including TU-Berlin, Sketchy and Flickr15k. Experimental results demonstrate that the Hybrid CNN achieves competitive accuracy compared with the state-of-the-art methods."
"Leo Sampaio Ferraz Ribeiro, Tu Bui, J. Collomosse, M. Ponti",42b3a039a666caab2881bfef244d3ce074b7f529,Sketchformer: Transformer-Based Representation for Sketched Structure,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,17,"Sketchformer is a novel transformer-based representation for encoding free-hand sketches input in a vector form, i.e. as a sequence of strokes. Sketchformer effectively addresses multiple tasks: sketch classification, sketch based image retrieval (SBIR), and the reconstruction and interpolation of sketches. We report several variants exploring continuous and tokenized input representations, and contrast their performance. Our learned embedding, driven by a dictionary learning tokenization scheme, yields state of the art performance in classification and image retrieval tasks, when compared against baseline representations driven by LSTM sequence to sequence architectures: SketchRNN and derivatives. We show that sketch reconstruction and interpolation are improved significantly by the Sketchformer embedding for complex sketches with longer stroke sequences."
"Ori Nizan, A. Tal",a5d6a87e42f3cb1f7bbc23450b1ad0c79f40450b,Breaking the Cycle – Colleagues Are All You Need,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,17,"This paper proposes a novel approach to performing image-to-image translation between unpaired domains. Rather than relying on a cycle constraint, our method takes advantage of collaboration between various GANs. This results in a multi modal method, in which multiple optional and diverse images are produced for a given image. Our model addresses some of the shortcomings of classical GANs: (1) It is able to remove large objects, such as glasses. (2) Since it does not need to support the cycle constraint, no irrelevant traces of the input are left on the generated image. (3) It manages to translate between domains that require large shape modifications. Our results are shown to outperform those generated by state-of-the-art methods for several challenging applications on commonly-used datasets, both qualitatively and quantitatively."
"Junsoo Lee, Eungyeup Kim, Yunsung Lee, Dongju Kim, Jaehyuk Chang, J. Choo",8c5aa40f3e7a804f1a6a644792deef9f8d810b83,Reference-Based Sketch Image Colorization Using Augmented-Self Reference and Dense Semantic Correspondence,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,16,"This paper tackles the automatic colorization task of a sketch image given an already-colored reference image. Colorizing a sketch image is in high demand in comics, animation, and other content creation applications, but it suffers from information scarcity of a sketch image. To address this, a reference image can render the colorization process in a reliable and user-driven manner. However, it is difficult to prepare for a training data set that has a sufficient amount of semantically meaningful pairs of images as well as the ground truth for a colored image reflecting a given reference (e.g., coloring a sketch of an originally blue car given a reference green car). To tackle this challenge, we propose to utilize the identical image with geometric distortion as a virtual reference, which makes it possible to secure the ground truth for a colored output image. Furthermore, it naturally provides the ground truth for dense semantic correspondence, which we utilize in our internal attention mechanism for color transfer from reference to sketch input. We demonstrate the effectiveness of our approach in various types of sketch image colorization via quantitative as well as qualitative evaluation against existing methods."
"Shu-Yu Chen, Wanchao Su, Lin Gao, Shi-hong Xia, Hongbo Fu",36dc0db687300c97a35ca8785e98ba0f5ccb1461,DeepFaceDrawing: deep generation of face images from sketches,ACM Trans. Graph.,2020.0,15,"SHU-YU CHEN†, Institute of Computing Technology, CAS and University of Chinese Academy of Sciences WANCHAO SU†, School of Creative Media, City University of Hong Kong LIN GAO∗, Institute of Computing Technology, CAS and University of Chinese Academy of Sciences SHIHONG XIA, Institute of Computing Technology, CAS and University of Chinese Academy of Sciences HONGBO FU, School of Creative Media, City University of Hong Kong"
"Wenbin Li, Wei Xiong, Haofu Liao, Jing Huo, Yang Gao, Jiebo Luo",8fc45e0d7056de2fbb34107e038842e5d5735205,CariGAN: Caricature Generation through Weakly Paired Adversarial Learning,Neural Networks,2020.0,15,"Caricature generation is an interesting yet challenging task. The primary goal is to generate a plausible caricature with reasonable exaggerations given a face image. Conventional caricature generation approaches mainly use low-level geometric transformations such as image warping to generate exaggerated images, which lack richness and diversity in terms of content and style. The recent progress in generative adversarial networks (GANs) makes it possible to learn an image-to-image transformation from data so as to generate diverse images. However, directly applying GAN-based models to this task leads to unsatisfactory results due to the large variance in the caricature distribution. Moreover, conventional models typically require pixel-wisely paired training data which largely limits their usage scenarios. In this paper, we model caricature generation as a weakly paired image-to-image translation task, and propose CariGAN to address these issues. Specifically, to enforce reasonable exaggeration and facial deformation, manually annotated caricature facial landmarks are used as an additional condition to constrain the generated image. Furthermore, an image fusion mechanism is designed to encourage our model to focus on the key facial parts so that more vivid details in these regions can be generated. Finally, a diversity loss is proposed to encourage the model to produce diverse results. Extensive experiments on a large-scale ""WebCaricature"" dataset show that the proposed CariGAN can generate more visually plausible caricatures with larger diversity compared with the state-of-the-art models."
"Kfir Aberman, Yijia Weng, Dani Lischinski, D. Cohen-Or, Baoquan Chen",786c28e88d100f37633e1bf311b4a96c85731c02,Unpaired motion style transfer from video to animation,ACM Trans. Graph.,2020.0,14,"Transferring the motion style from one animation clip to another, while preserving the motion content of the latter, has been a long-standing problem in character animation. Most existing data-driven approaches are supervised and rely on paired data, where motions with the same content are performed in different styles. In addition, these approaches are limited to transfer of styles that were seen during training. In this paper, we present a novel data-driven framework for motion style transfer, which learns from an unpaired collection of motions with style labels, and enables transferring motion styles not observed during training. Furthermore, our framework is able to extract motion styles directly from videos, bypassing 3D reconstruction, and apply them to the 3D input motion. Our style transfer network encodes motions into two latent codes, for content and for style, each of which plays a different role in the decoding (synthesis) process. While the content code is decoded into the output motion by several temporal convolutional layers, the style code modifies deep features via temporally invariant adaptive instance normalization (AdaIN). Moreover, while the content code is encoded from 3D joint rotations, we learn a common embedding for style from either 3D or 2D joint positions, enabling style extraction from videos. Our results are comparable to the state-of-the-art, despite not requiring paired training data, and outperform other methods when transferring previously unseen styles. To our knowledge, we are the first to demonstrate style transfer directly from videos to 3D animations - an ability which enables one to extend the set of style examples far beyond motions captured by MoCap systems."
"Yong Wang, Zhihua Jin, Qianwen Wang, Weiwei Cui, Tengfei Ma, Huamin Qu",4b8f10fdf59164be4c42c8edda0c9888774457f1,DeepDrawing: A Deep Learning Approach to Graph Drawing,IEEE Transactions on Visualization and Computer Graphics,2020.0,13,"Node-link diagrams are widely used to facilitate network explorations. However, when using a graph drawing technique to visualize networks, users often need to tune different algorithm-specific parameters iteratively by comparing the corresponding drawing results in order to achieve a desired visual effect. This trial and error process is often tedious and time-consuming, especially for non-expert users. Inspired by the powerful data modelling and prediction capabilities of deep learning techniques, we explore the possibility of applying deep learning techniques to graph drawing. Specifically, we propose using a graph-LSTM-based approach to directly map network structures to graph drawings. Given a set of layout examples as the training dataset, we train the proposed graph-LSTM-based model to capture their layout characteristics. Then, the trained model is used to generate graph drawings in a similar style for new networks. We evaluated the proposed approach on two special types of layouts (i.e., grid layouts and star layouts) and two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both qualitative and quantitative ways. The results provide support for the effectiveness of our approach. We also conducted a time cost assessment on the drawings of small graphs with 20 to 50 nodes. We further report the lessons we learned and discuss the limitations and future work."
"Lumin Yang, Jiajie Zhuang, Hongbo Fu, Kun Zhou, Youyi Zheng",2753e74b2bbf9bd71e0fe82d441f48454fb3c9ec,SketchGCN: Semantic Sketch Segmentation with Graph Convolutional Networks,ArXiv,2020.0,13,"We introduce SketchGCN, a graph convolutional neural network for semantic segmentation and labeling of free-hand sketches. We treat an input sketch as a 2D pointset, and encode the stroke structure information into graph node/edge representations. To predict the per-point labels, our SketchGCN uses graph convolution and a global-local branching network architecture to extract both intra-stroke and inter-stroke features. SketchGCN significantly improves the accuracy of the state-of-the-art methods for semantic sketch segmentation (by 11.4% in the pixel-basedmetric and 18.2% in the component-based metric over a large-scale challenging SPG dataset) and has magnitudes fewer parameters than both image-based and sequence-based methods."
"Yang Zhou, Dingzeyu Li, Xintong Han, E. Kalogerakis, E. Shechtman, Jose I. Echevarria",739497ec657d2c1e6ed7eb424951e0affe117be4,MakeItTalk: Speaker-Aware Talking Head Animation,ACM Trans. Graph.,2020.0,13,"We present a method that generates expressive talking heads from a single facial image with audio as the only input. In contrast to previous approaches that attempt to learn direct mappings from audio to raw pixels or points for creating talking faces, our method first disentangles the content and speaker information in the input audio signal. The audio content robustly controls the motion of lips and nearby facial regions, while the speaker information determines the specifics of facial expressions and the rest of the talking head dynamics. Another key component of our method is the prediction of facial landmarks reflecting speaker-aware dynamics. Based on this intermediate representation, our method is able to synthesize photorealistic videos of entire talking heads with full range of motion and also animate artistic paintings, sketches, 2D cartoon characters, Japanese mangas, stylized caricatures in a single unified framework. We present extensive quantitative and qualitative evaluation of our method, in addition to user studies, demonstrating generated talking heads of significantly higher quality compared to prior state-of-the-art."
"A. Bhunia, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",5b2781e76085f61783277de5862d45438ff3682c,Sketch Less for More: On-the-Fly Fine-Grained Sketch-Based Image Retrieval,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,11,"Fine-grained sketch-based image retrieval (FG-SBIR) addresses the problem of retrieving a particular photo instance given a user's query sketch. Its widespread applicability is however hindered by the fact that drawing a sketch takes time, and most people struggle to draw a complete and faithful sketch. In this paper, we reformulate the conventional FG-SBIR framework to tackle these challenges, with the ultimate goal of retrieving the target photo with the least number of strokes possible. We further propose an on-the-fly design that starts retrieving as soon as the user starts drawing. To accomplish this, we devise a reinforcement learning based cross-modal retrieval framework that directly optimizes rank of the ground-truth photo over a complete sketch drawing episode. Additionally, we introduce a novel reward scheme that circumvents the problems related to irrelevant sketch strokes, and thus provides us with a more consistent rank list during the retrieval. We achieve superior early-retrieval efficiency over state-of-the-art methods and alternative baselines on two publicly available fine-grained sketch retrieval datasets."
"Shuai Yang, Zhangyang Wang, Jiaying Liu, Zongming Guo",1bf19b9635bcbf3b1372a1edfc0bbdab5f9d34e6,Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches,ECCV,2020.0,11,"Sketch-based image editing aims to synthesize and modify photos based on the structural information provided by the human-drawn sketches. Since sketches are difficult to collect, previous methods mainly use edge maps instead of sketches to train models (referred to as edge-based models). However, sketches display great structural discrepancy with edge maps, thus failing edge-based models. Moreover, sketches often demonstrate huge variety among different users, demanding even higher generalizability and robustness for the editing model to work. In this paper, we propose Deep Plastic Surgery, a novel, robust and controllable image editing framework that allows users to interactively edit images using hand-drawn sketch inputs. We present a sketch refinement strategy, as inspired by the coarse-to-fine drawing process of the artists, which we show can help our model well adapt to casual and varied sketches without the need for real sketch training data. Our model further provides a refinement level control parameter that enables users to flexibly define how ""reliable"" the input sketch should be considered for the final output, balancing between sketch faithfulness and output verisimilitude (as the two goals might contradict if the input sketch is drawn poorly). To achieve the multi-level refinement, we introduce a style-based module for level conditioning, which allows adaptive feature representations for different levels in a singe network. Extensive experimental results demonstrate the superiority of our approach in improving the visual quality and user controllablity of image editing over the state-of-the-art methods."
"Xinrui Wang, Jinze Yu",0269b13ccbe3e3a81213e7ca2b049298d3a154f5,Learning to Cartoonize Using White-Box Cartoon Representations,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,11,"This paper presents an approach for image cartoonization. By observing the cartoon painting behavior and consulting artists, we propose to separately identify three white-box representations from images: the surface representation that contains smooth surface of cartoon images, the structure representation that refers to the sparse color-blocks and flatten global content in the celluloid style workflow, and the texture representation that reflects high-frequency texture, contours and details in cartoon images. A Generative Adversarial Network (GAN) framework is used to learn the extracted representations and to cartoonize images. The learning objectives of our method are separately based on each extracted representations, making our framework controllable and adjustable. This enables our approach to meet artists' requirements in different styles and diverse use cases. Qualitative comparisons and quantitative analyses, as well as user studies, have been conducted to validate the effectiveness of this approach, and our method outperforms previous methods in all comparisons. Finally, the ablation study demonstrates the influence of each component in our framework."
"Sam Snodgrass, Anurag Sarkar",5353511b577ef6dc8c5020c06a3bc0190601ab36,Multi-Domain Level Generation and Blending with Sketches via Example-Driven BSP and Variational Autoencoders,FDG,2020.0,10,"Procedural content generation via machine learning (PCGML) has demonstrated its usefulness as a content and game creation approach, and has been shown to be able to support human creativity. An important facet of creativity is combinational creativity or the recombination, adaptation, and reuse of ideas and concepts between and across domains. In this paper, we present a PCGML approach for level generation that is able to recombine, adapt, and reuse structural patterns from several domains to approximate unseen domains. We extend prior work involving example-driven Binary Space Partitioning for recombining and reusing patterns in multiple domains, and incorporate Variational Autoencoders (VAEs) for generating unseen structures. We evaluate our approach by blending across 7 domains and subsets of those domains. We show that our approach is able to blend domains together while retaining structural components. Additionally, by using different groups of training domains our approach is able to generate both 1) levels that reproduce and capture features of a target domain, and 2) levels that have vastly different properties from the input domain."
"Kuangxiao Gu, Yuqian Zhou, Thomas Huang",2f1e3211356260bcda348290c0863a91ab1bccaf,FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis,AAAI,2020.0,10,"Talking face synthesis has been widely studied in either appearance-based or warping-based methods. Previous works mostly utilize single face image as a source, and generate novel facial animations by merging other person's facial features. However, some facial regions like eyes or teeth, which may be hidden in the source image, can not be synthesized faithfully and stably. In this paper, We present a landmark driven two-stream network to generate faithful talking facial animation, in which more facial details are created, preserved and transferred from multiple source images instead of a single one. Specifically, we propose a network consisting of a learning and fetching stream. The fetching sub-net directly learns to attentively warp and merge facial regions from five source images of distinctive landmarks, while the learning pipeline renders facial organs from the training face space to compensate. Compared to baseline algorithms, extensive experiments demonstrate that the proposed method achieves a higher performance both quantitatively and qualitatively. Codes are at this https URL."
"Anubha Pandey, Ashish Mishra, V. Verma, Anurag Mittal, H. Murthy",b3ef9e6c2b794ee6ac2041ed49d3f16fd716eb83,Stacked Adversarial Network for Zero-Shot Sketch based Image Retrieval,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020.0,9,"Conventional approaches to Sketch-Based Image Retrieval (SBIR) assume that the data of all the classes are available during training. The assumption may not always be practical since the data of a few classes may be unavailable, or the classes may not appear at the time of training. Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) relaxes this constraint and allows the algorithm to handle previously unseen classes during the test. This paper proposes a generative approach based on the Stacked Adversarial Network (SAN) and the advantage of Siamese Network (SN) for ZS-SBIR. While SAN generates a high-quality sample, SN learns a better distance metric compared to that of the nearest neighbor search. The capability of the generative model to synthesize image features based on the sketch reduces the SBIR problem to that of an image-to-image retrieval problem. We evaluate the efficacy of our proposed approach on TU-Berlin, and Sketchy database in both standard ZSL and generalized ZSL setting. The proposed method yields a significant improvement in standard ZSL as well as in a more challenging generalized ZSL setting (GZSL) for SBIR."
"Chengying Gao, Qi Liu, Qi Xu, Jianzhuang Liu, Limin Wang, C. Zou",44c83649daf0b75ce8f036f79321be0dc36bfa8a,SketchyCOCO: Image Generation From Freehand Scene Sketches,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,9,"We introduce the first method for automatic image generation from scene-level freehand sketches. Our model allows for controllable image generation by specifying the synthesis goal via freehand sketches. The key contribution is an attribute vector bridged Generative Adversarial Network called EdgeGAN, which supports high visual-quality object-level image content generation without using freehand sketches as training data. We have built a large-scale composite dataset called SketchyCOCO to support and evaluate the solution. We validate our approach on the tasks of both object-level and scene-level image generation on SketchyCOCO. Through quantitative, qualitative results, human evaluation and ablation studies, we demonstrate the method's capacity to generate realistic complex scene-level images from various freehand sketches."
"Yuke Fang, Weihong Deng, Junping Du, Jiani Hu",f3fb6e4ea01fa29003ccaf4c6c50c46692e51eb0,Identity-aware CycleGAN for face photo-sketch synthesis and recognition,Pattern Recognit.,2020.0,9,"Abstract Face photo-sketch synthesis and recognition has many applications in digital entertainment and law enforcement. Recently, generative adversarial networks (GANs) based methods have significantly improved the quality of image synthesis, but they have not explicitly considered the purpose of recognition. In this paper, we first propose an Identity-Aware CycleGAN (IACycleGAN) model that applies a new perceptual loss to supervise the image generation network. It improves CycleGAN on photo-sketch synthesis by paying more attention to the synthesis of key facial regions, such as eyes and nose, which are important for identity recognition. Furthermore, we develop a mutual optimization procedure between the synthesis model and the recognition model, which iteratively synthesizes better images by IACycleGAN and enhances the recognition model by the triplet loss of the generated and real samples. Extensive experiments are performed on both photo-to-sketch and sketch-to-photo tasks using the widely used CUFS and CUFSF databases. The results show that the proposed method performs better than several state-of-the-art methods in terms of both synthetic image quality and photo-sketch recognition accuracy."
"Jianjun Lei, Y. Song, Bo Peng, Zhanyu Ma, L. Shao, Yi-Zhe Song",b4e31dde236698ee4085147832f5fecbe028df9d,Semi-Heterogeneous Three-Way Joint Embedding Network for Sketch-Based Image Retrieval,IEEE Transactions on Circuits and Systems for Video Technology,2020.0,9,"Sketch-based image retrieval (SBIR) is a challenging task due to the large cross-domain gap between sketches and natural images. How to align abstract sketches and natural images into a common high-level semantic space remains a key problem in SBIR. In this paper, we propose a novel semi-heterogeneous three-way joint embedding network (Semi3-Net), which integrates three branches (a sketch branch, a natural image branch, and an edgemap branch) to learn more discriminative cross-domain feature representations for the SBIR task. The key insight lies with how we cultivate the mutual and subtle relationships amongst the sketches, natural images, and edgemaps. A semi-heterogeneous feature mapping is designed to extract bottom features from each domain, where the sketch and edgemap branches are shared while the natural image branch is heterogeneous to the other branches. In addition, a joint semantic embedding is introduced to embed the features from different domains into a common high-level semantic space, where all of the three branches are shared. To further capture informative features common to both natural images and the corresponding edgemaps, a co-attention model is introduced to conduct common channel-wise feature recalibration between different domains. A hybrid-loss mechanism is designed to align the three branches, where an alignment loss and a sketch-edgemap contrastive loss are presented to encourage the network to learn invariant cross-domain representations. Experimental results on two widely used category-level datasets (Sketchy and TU-Berlin Extension) demonstrate that the proposed method outperforms state-of-the-art methods."
"Pegah Karimi, Jeba Rezwana, Safat Siddiqui, M. Maher, N. Dehbozorgi",61ea05a7a417a7dbfff00f261e1160cbaf9951e1,Creative sketching partner: an analysis of human-AI co-creativity,IUI,2020.0,9,"The creative sketching partner (CSP) is a proof of concept intelligent interface to inspire designers while sketching in response to a specified design task. With this interactive system we are studying the effect of an AI model of visual and conceptual similarity for selecting the Al's sketch response as an inspiration to the current state of the user's sketch. Specifically, we are interested in the user's behavior and response to an AI partner when engaged in a design task. By developing deep learning models of the sketches from a large-scale dataset, the user can control the amount of visual and conceptual similarity of the AI response when requesting inspiration from the CSP. We conducted a study with 50 design students to examine the participants' interaction behavior and their self reports. The participants' behavior maps into clusters that are co-related with three types of design creativity: combinatorial, exploratory, and transformational. Our findings demonstrate that the tool can facilitate ideation and overcome design fixation. In addition, analysis suggests that inspiration related to conceptual similarity is more associated with transformational creativity and inspiration related to visual similarity occurs more frequently during the detailed stages of design and is more prevalent with combinatorial creativity."
"Kaiyue Pang, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",910ad17250a239feac3983f806a82ae91d94816a,Solving Mixed-Modal Jigsaw Puzzle for Fine-Grained Sketch-Based Image Retrieval,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,8,"ImageNet pre-training has long been considered crucial by the fine-grained sketch-based image retrieval (FG-SBIR) community due to the lack of large sketch-photo paired datasets for FG-SBIR training. In this paper, we propose a self-supervised alternative for representation pre-training. Specifically, we consider the jigsaw puzzle game of recomposing images from shuffled parts. We identify two key facets of jigsaw task design that are required for effective FG-SBIR pre-training. The first is formulating the puzzle in a mixed-modality fashion. Second we show that framing the optimisation as permutation matrix inference via Sinkhorn iterations is more effective than the common classifier formulation of Jigsaw self-supervision. Experiments show that this self-supervised pre-training strategy significantly outperforms the standard ImageNet-based pipeline across all four product-level FG-SBIR benchmarks. Interestingly it also leads to improved cross-category generalisation across both pre-train/fine-tune and fine-tune/testing stages."
"Mingjin Zhang, Yunsong Li, Nannan Wang, Yuan Chi, Xinbo Gao",9791dfddb84abee536f6003d13fc1993e58b7693,Cascaded Face Sketch Synthesis Under Various Illuminations,IEEE Transactions on Image Processing,2020.0,8,"Face sketch synthesis from a photo is of significant importance in digital entertainment. An intelligent face sketch synthesis system requires a strong robustness to lighting variations. Under uncontrolled lighting conditions in real-world settings, such a system will perform consistently well and have little restriction on the lighting conditions. However, previous face sketch synthesis methods tend to synthesize sketches under well-controlled lighting conditions. These methods are sensitive to lighting variations and produce unsatisfactory results when the lighting condition varies. In this paper, we propose a novel cascaded face sketch synthesis framework composed of a multiple feature generator and a cascaded low-rank representation. The multiple feature generator not only produces a generated sketch feature consistent with an artist’s drawing style but also extracts a photo feature that is robust to various illuminations. Both features ensure that given a photo patch, the optimal sketch candidates can be selected from the database. The cascaded low-rank representation enables a gradual reduction in the gap between the synthesized face sketch and the corresponding artist-drawn sketch. Experimental results illustrate that the proposed cascaded framework generates realistic sketches on par with the current methods on the Chinese University of Hong Kong face sketch database under well-controlled illuminations. Moreover, this framework exhibits greatly improved performance compared to these methods on the extended Chinese University of Hong Kong face sketch database and Chinese celebrity face photos from the web under different illuminations. We argue that this framework paves a novel way for the implementation of computer-aided optical systems that are of essential importance in both face sketch synthesis and optical imaging."
"Alexandre Carlier, Martin Danelljan, Alexandre Alahi, R. Timofte",2c5dba61816bc607a91fa44da7407620561cd985,DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation,NeurIPS,2020.0,7,"Scalable Vector Graphics (SVG) are ubiquitous in modern 2D interfaces due to their ability to scale to different resolutions. However, despite the success of deep learning-based models applied to rasterized images, the problem of vector graphics representation learning and generation remains largely unexplored. In this work, we propose a novel hierarchical generative network, called DeepSVG, for complex SVG icons generation and interpolation. Our architecture effectively disentangles high-level shapes from the low-level commands that encode the shape itself. The network directly predicts a set of shapes in a non-autoregressive fashion. We introduce the task of complex SVG icons generation by releasing a new large-scale dataset along with an open-source library for SVG manipulation. We demonstrate that our network learns to accurately reconstruct diverse vector graphics, and can serve as a powerful animation tool by performing interpolations and other latent space operations. Our code is available at this https URL."
"Yanfei Wang, Fei Huang, Yuejie Zhang, Rui Feng, T. Zhang, Weiguo Fan",619b2281ea26875e8097291342672914b4061c30,Deep cascaded cross-modal correlation learning for fine-grained sketch-based image retrieval,Pattern Recognit.,2020.0,7,"Abstract Fine-grained Sketch-based Image Retrieval (FG-SBIR), which utilizes hand-drawn sketches to search the target object images, has recently drawn much attention. It is a challenging task because sketches and images belong to different modalities and sketches are highly abstract and ambiguous. Existing solutions to this problem either focus on visual comparisons between sketches and images and ignore the multimodal characteristics of annotated images, or treat the retrieval as a one-time process. In this paper, we formulate FG-SBIR as a coarse-to-fine process, and propose a Deep Cascaded Cross-modal Ranking Model (DCCRM) that can exploit all the beneficial multimodal information in sketches and annotated images and improve both the retrieval efficiency and the top-K ranked effectiveness. Our goal concentrates on constructing deep representations for sketches, images, and descriptions, and learning the optimized deep correlations across such different domains. Thus for a given query sketch, its relevant images with fine-grained instance-level similarities in a specific category can be returned, and the strict requirement of the instance-level retrieval for FG-SBIR is satisfied. Very positive results have been obtained in our experiments by using a large quantity of public data."
"Ayan Das, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",1c2a3b7e31f914c1482795bf1f6ebcd7741d06eb,BézierSketch: A generative model for scalable vector sketches,ECCV,2020.0,7,"The study of neural generative models of human sketches is a fascinating contemporary modeling problem due to the links between sketch image generation and the human drawing process. The landmark SketchRNN provided breakthrough by sequentially generating sketches as a sequence of waypoints. However this leads to low-resolution image generation, and failure to model long sketches. In this paper we present BezierSketch, a novel generative model for fully vector sketches that are automatically scalable and high-resolution. To this end, we first introduce a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit Bezier curve. This enables us to treat sketches as short sequences of paramaterized strokes and thus train a recurrent sketch generator with greater capacity for longer sketches, while producing scalable high-resolution results. We report qualitative and quantitative results on the Quick, Draw! benchmark."
"Fei Wang, Shujin Lin, H. Li, Hefeng Wu, Tie Cai, Xiaonan Luo, Ruomei Wang",50d16eca3a2368ce6da07f7e3d47ea20541a86bd,Multi-column point-CNN for sketch segmentation,Neurocomputing,2020.0,7,"Traditional sketch segmentation methods mainly rely on handcrafted features and complicate models, and their performance is far from satisfactory due to the abstract representation of sketches. Recent success of Deep Neural Networks (DNNs) in related tasks suggests DNNs could be a practical solution for this problem, yet the suitable datasets for learning and evaluating DNNs are limited. To this end, we introduce SketchSeg, a large dataset consisting of 10,000 pixel-wisely labeled sketches.Besides, due to the lack of colors and textures in sketches, conventional DNNs learned on natural images are not optimal for tackling our problem.Therefore, we further propose the Multi-column Point-CNN (MCPNet), which (1) directly takes sampled points as its input to reduce computational costs, and (2) adopts multiple columns with different filter sizes to better capture the structures of sketches. Extensive experiments validate that the MCPNet is superior to conventional DNNs like FCN. The SketchSeg dataset is publicly available on this https URL."
"Xing Di, V. Patel",d043bf8f03ada1f9f3504a8084a452c7579b84d8,Facial Synthesis From Visual Attributes via Sketch Using Multiscale Generators,"IEEE Transactions on Biometrics, Behavior, and Identity Science",2020.0,7,"Automatic synthesis of faces from visual attributes is an important problem in computer vision and has wide applications in law enforcement and entertainment. With the advent of deep generative convolutional neural networks (CNNs), attempts have been made to synthesize face images from attributes and text descriptions. In this paper, we take a different approach, where we formulate the original problem as a stage-wise learning problem. We first synthesize the facial sketch corresponding to the visual attributes and then we generate the face image based on the synthesized sketch. The proposed framework, is based on a combination of two different Generative Adversarial Networks (GANs) – (1) a sketch generator network which synthesizes realistic sketch from the input attributes, and (2) a face generator network which synthesizes facial images from the synthesized sketch images with the help of facial attributes. Extensive experiments and comparison with recent methods are performed to verify the effectiveness of the proposed attribute-based two-stage face synthesis method."
"Robin Rombach, Patrick Esser, B. Ommer",88ed54f0e52c7131ee6d3cc9efc3c12d730a7181,Network-to-Network Translation with Conditional Invertible Neural Networks,NeurIPS,2020.0,7,"Given the ever-increasing computational costs of modern machine learning models, we need to find new ways to reuse such expert models and thus tap into the resources that have been invested in their creation. Recent work suggests that the power of these massive models is captured by the representations they learn. Therefore, we seek a model that can relate between different existing representations and propose to solve this task with a conditionally invertible network. This network demonstrates its capability by (i) providing generic transfer between diverse domains, (ii) enabling controlled content synthesis by allowing modification in other domains, and (iii) facilitating diagnosis of existing representations by translating them into interpretable domains such as images. Our domain transfer network can translate between fixed representations without having to learn or finetune them. This allows users to utilize various existing domain-specific expert models from the literature that had been trained with extensive computational resources. Experiments on diverse conditional image synthesis tasks, competitive image modification results and experiments on image-to-image and text-to-image generation demonstrate the generic applicability of our approach. For example, we translate between BERT and BigGAN, state-of-the-art text and image models to provide text-to-image generation, which neither of both experts can perform on their own."
"Samet Hicsonmez, Nermin Samet, Emre Akbas, P. D. Sahin",d2159c0b74e5827e8a1a74bd3068dfe7d71fb93f,GANILLA: Generative Adversarial Networks for Image to Illustration Translation,Image Vis. Comput.,2020.0,7,"In this paper, we explore illustrations in children's books as a new domain in unpaired image-to-image translation. We show that although the current state-of-the-art image-to-image translation models successfully transfer either the style or the content, they fail to transfer both at the same time. We propose a new generator network to address this issue and show that the resulting network strikes a better balance between style and content. 
There are no well-defined or agreed-upon evaluation metrics for unpaired image-to-image translation. So far, the success of image translation models has been based on subjective, qualitative visual comparison on a limited number of images. To address this problem, we propose a new framework for the quantitative evaluation of image-to-illustration models, where both content and style are taken into account using separate classifiers. In this new evaluation framework, our proposed model performs better than the current state-of-the-art models on the illustrations dataset. Our code and pretrained models can be found at this https URL."
"Saeed Anwar, Muhammad Tahir, Chongyi Li, A. Mian, F. Khan, A. W. Muzaffar",4da589d5400e8abf219d1c6d3157e9f2e56b86b5,Image Colorization: A Survey and Dataset,ArXiv,2020.0,7,"Image colorization is an essential image processing and computer vision branch to colorize images and videos. Recently, deep learning techniques progressed notably for image colorization. This article presents a comprehensive survey of recent state-of-the-art colorization using deep learning algorithms, describing their fundamental block architectures in terms of skip connections, input etc. as well as optimizers, loss functions, training protocols, and training data etc. Generally, we can roughly categorize the existing colorization techniques into seven classes. Besides, we also provide some additional essential issues, such as benchmark datasets and evaluation metrics. We also introduce a new dataset specific to colorization and perform an experimental evaluation of the publicly available methods. In the last section, we discuss the limitations, possible solutions, and future research directions of the rapidly evolving topic of deep image colorization that the community should further address. Dataset and Codes for evaluation will be publicly available at this https URL"
"Vage Egiazarian, Oleg Voynov, A. Artemov, Denis Volkhonskiy, Aleksandr Safin, Maria Taktasheva, D. Zorin, Evgeny Burnaev",aea330277baa762026b98709d3a16e7028635cdb,Deep Vectorization of Technical Drawings,ECCV,2020.0,6,"We present a new method for vectorization of technical line drawings, such as floor plans, architectural drawings, and 2D CAD images. Our method includes (1) a deep learning-based cleaning stage to eliminate the background and imperfections in the image and fill in missing parts, (2) a transformer-based network to estimate vector primitives, and (3) optimization procedure to obtain the final primitive configurations. We train the networks on synthetic data, renderings of vector line drawings, and manually vectorized scans of line drawings. Our method quantitatively and qualitatively outperforms a number of existing techniques on a collection of representative technical drawings."
"R. Liu, Qian Yu, Stella X. Yu",c6a2a8fbe41109ff3c19a71b732efbac50d57ce2,Unsupervised Sketch to Photo Synthesis,ECCV,2020.0,6,"Humans can envision a realistic photo given a free-hand sketch that is not only spatially imprecise and geometrically distorted but also without colors and visual details. We study unsupervised sketch-to-photo synthesis for the first time, learning from unpaired sketch-photo data where the target photo for a sketch is unknown during training. Existing works only deal with style change or spatial deformation alone, synthesizing photos from edge-aligned line drawings or transforming shapes within the same modality, e.g., color images. Our key insight is to decompose unsupervised sketch-to-photo synthesis into a two-stage translation task: First shape translation from sketches to grayscale photos and then content enrichment from grayscale to color photos. We also incorporate a self-supervised denoising objective and an attention module to handle abstraction and style variations that are inherent and specific to sketches. Our synthesis is sketch-faithful and photo-realistic to enable sketch-based image retrieval in practice. An exciting corollary product is a universal and promising sketch generator that captures human visual perception beyond the edge map of a photo."
"Jonathan Lacotte, Sifan Liu, E. Dobriban, Mert Pilanci",99abf66e780992dc4caa73fc4b700dc3875dafd4,Limiting Spectrum of Randomized Hadamard Transform and Optimal Iterative Sketching Methods,ArXiv,2020.0,6,"We provide an exact analysis of the limiting spectrum of matrices randomly projected either with the subsampled randomized Hadamard transform, or truncated Haar matrices. We characterize this limiting distribution through its Stieltjes transform, a classical object in random matrix theory, and compute the first and second inverse moments. We leverage the limiting spectrum and asymptotic freeness of random matrices to obtain an exact analysis of iterative sketching methods for solving least squares problems. Our results also yield optimal step-sizes and convergence rates in terms of simple closed-form expressions. Moreover, we show that the convergence rate for Haar and randomized Hadamard matrices are identical, and uniformly improve upon Gaussian random projections. The developed techniques and formulas can be applied to a plethora of randomized algorithms that employ fast randomized Hadamard dimension reduction."
"Xi Ye, Qiaochu Chen, Xinyu Wang, Isil Dillig, Greg Durrett",1bb27a0180f0c5fdd66cf34864752dfb1d6d94d2,Sketch-Driven Regular Expression Generation from Natural Language and Examples,Transactions of the Association for Computational Linguistics,2020.0,6,"Abstract Recent systems for converting natural language descriptions into regular expressions (regexes) have achieved some success, but typically deal with short, formulaic text and can only produce simple regexes. Real-world regexes are complex, hard to describe with brief sentences, and sometimes require examples to fully convey the user’s intent. We present a framework for regex synthesis in this setting where both natural language (NL) and examples are available. First, a semantic parser (either grammar-based or neural) maps the natural language description into an intermediate sketch, which is an incomplete regex containing holes to denote missing components. Then a program synthesizer searches over the regex space defined by the sketch and finds a regex that is consistent with the given string examples. Our semantic parser can be trained purely from weak supervision based on correctness of the synthesized regex, or it can leverage heuristically derived sketches. We evaluate on two prior datasets (Kushman and Barzilay 2013; Locascio et al. 2016) and a real-world dataset from Stack Overflow. Our system achieves state-of-the-art performance on the prior datasets and solves 57% of the real-world dataset, which existing neural systems completely fail on.1"
Aaron Hertzmann,59e3f5e66a3cdf3bdfc814e3565b77d2cbc13b83,Why Do Line Drawings Work? A Realism Hypothesis,Perception,2020.0,6,"Why is it that we can recognize object identity and 3D shape from line drawings, even though they do not exist in the natural world? This article hypothesizes that the human visual system perceives line drawings as if they were approximately realistic images. Moreover, the techniques of line drawing are chosen to accurately convey shape to a human observer. Several implications and variants of this hypothesis are explored."
"Hui Ren, J. Li, Nan Gao",e27cdd0f144b9045608f7772b3ac4b6d7ba90b0f,Two-Stage Sketch Colorization With Color Parsing,IEEE Access,2020.0,6,"We implement high-quality sketch colorization using two-stage conditional generative adversarial network (GAN) training based on different intermediate features. The intermediate features used in autonomous colorization are the grayscale parsing and interval pixel-level color parsing. The autonomous colorization based on grayscale parsing feature can learn the spacial topology of pixels in the first stage to guide the colorization in the second stage. The autonomous colorization based on pixel-level color parsing feature can learn the color information of few feature points in the first stage to guide the colorization of all pixels in the second stage. Additionally, we use the intermediate feature of sampling points as constraint and achieve the color reconstruction using Laplacian mesh editing as a special second stage. Furthermore, the interactive colorization uses the superpixel color parsing as the intermediate feature. Specifically, we use the simple linear iterative cluster (SLIC) to obtain a palette that maintains the edges in the first stage to guide the colorization in the second stage. As for evaluation metrics, we propose a color-coded local binary pattern (CCLBP) score based on color distances from the first-order 8 pixels to the central pixel, to measure the degrees of color blurring and mess. We also propose a light-sensitivity (LS) score based on the reversed grayscale map, to measure the degrees of auto painting and overfitting of the color hint. According to the L1 distances between the original and generated color images based on these scores, compared with state-of-the-art methods including one stage approaches such as pix2pix and PaintsChainer and two-stage approaches such as Style2Paints and DeepColor, our model can achieve the highest-quality autonomous colorization. Moreover, compared with pix2pix, PaintsChainer and Style2Paints with color hints, according to the proposed objective evaluation as well as the user visual study, our model can achieve the highest-quality interactive colorization as well."
"Hung-Yu Tseng, Matthew Fisher, Jingwan Lu, Yijun Li, Vladimir G. Kim, Ming-Hsuan Yang",29cc6d8fab87a70d50b5b156c804e667f785e2a9,Modeling Artistic Workflows for Image Generation and Editing,ECCV,2020.0,6,"People often create art by following an artistic workflow involving multiple stages that inform the overall design. If an artist wishes to modify an earlier decision, significant work may be required to propagate this new decision forward to the final artwork. Motivated by the above observations, we propose a generative model that follows a given artistic workflow, enabling both multi-stage image generation as well as multi-stage image editing of an existing piece of art. Furthermore, for the editing scenario, we introduce an optimization process along with learning-based regularization to ensure the edited image produced by the model closely aligns with the originally provided image. Qualitative and quantitative results on three different artistic datasets demonstrate the effectiveness of the proposed framework on both image generation and editing tasks."
"Titir Dutta, Soma Biswas",d5142a6da6298a778ceb8dc797d00b999648a743,s-SBIR: Style Augmented Sketch based Image Retrieval,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020.0,5,"Sketch-based image retrieval (SBIR) is gaining increasing popularity because of its flexibility to search natural images using unrestricted hand-drawn sketch query. Here, we address a related, but relatively unexplored problem, where the users can also specify their preferred styles of the images they want to retrieve, e.g., color, shape, etc., as keywords, whose information is not present in the sketch. The contribution of this work is three-fold. First, we propose a deep network for the problem of style-augmented SBIR (or s-SBIR) having three main components - category module, style module and mixer module, which are trained in an end-to-end manner. Second, we propose a quintuplet loss, which takes into consideration both the category and style, while giving appropriate importance to the two components. Third, we propose a normalized composite evaluation metric or ncMAP which can quantitatively evaluate s-SBIR approaches. Extensive experiments on subsets of two benchmark image-sketch datasets, Sketchy and TU-Berlin show the effectiveness of the proposed approach."
"Chaitanya Ahuja, Dong Won Lee, Y. Nakano, Louis-Philippe Morency",6e78e32481218e9391a88e6d0e30c0062ae71bec,Style Transfer for Co-Speech Gesture Animation: A Multi-Speaker Conditional-Mixture Approach,ECCV,2020.0,5,"How can we teach robots or virtual assistants to gesture naturally? Can we go further and adapt the gesturing style to follow a specific speaker? Gestures that are naturally timed with corresponding speech during human communication are called co-speech gestures. A key challenge, called gesture style transfer, is to learn a model that generates these gestures for a speaking agent 'A' in the gesturing style of a target speaker 'B'. A secondary goal is to simultaneously learn to generate co-speech gestures for multiple speakers while remembering what is unique about each speaker. We call this challenge style preservation. In this paper, we propose a new model, named Mix-StAGE, which trains a single model for multiple speakers while learning unique style embeddings for each speaker's gestures in an end-to-end manner. A novelty of Mix-StAGE is to learn a mixture of generative models which allows for conditioning on the unique gesture style of each speaker. As Mix-StAGE disentangles style and content of gestures, gesturing styles for the same input speech can be altered by simply switching the style embeddings. Mix-StAGE also allows for style preservation when learning simultaneously from multiple speakers. We also introduce a new dataset, Pose-Audio-Transcript-Style (PATS), designed to study gesture generation and style transfer. Our proposed Mix-StAGE model significantly outperforms the previous state-of-the-art approach for gesture generation and provides a path towards performing gesture style transfer across multiple speakers. Link to code, data, and videos: this http URL"
"Ran Yi, Yongjin Liu, Yu-Kun Lai, Paul L. Rosin",e316d2b0463511089c9a7d6f703e1c3d3b85c0f5,Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,5,"Portrait drawing is a common form of art with high abstraction and expressiveness. Due to its unique characteristics, existing methods achieve decent results only with paired training data, which is costly and time-consuming to obtain.In this paper, we address the problem of automatic transfer from face photos to portrait drawings with unpaired training data. We observe that due to the significant imbalance of information richness between photos and drawings, existing unpaired transfer methods such as CycleGAN tends to embed invisible reconstruction information indiscriminately in the whole drawings, leading to important facial features partially missing in drawings. To address this problem, we propose a novel asymmetric cycle mapping that enforces the reconstruction information to be visible (by a truncation loss) and only embedded in selective facial regions (by a relaxed forward cycle-consistency loss). Along with localized discriminators for the eyes, nose and lips, our method well preserves all important facial features in the generated portrait drawings. By introducing a style classifier and taking the style vector into account, our method can learn to generate portrait drawings in multiple styles using a single network. Extensive experiments show that our model outperforms state-of-the-art methods."
"Jichao Zhang, Jingjing Chen, Hao Tang, Wei Wang, Yan Yan, E. Sangineto, N. Sebe",4ecba049e0671e29840bed7bf7e67b070abbb003,Dual In-painting Model for Unsupervised Gaze Correction and Animation in the Wild,ACM Multimedia,2020.0,5,"We address the problem of unsupervised gaze correction in the wild, presenting a solution that works without the need of precise annotations of the gaze angle and the head pose. We created a new dataset called CelebAGaze consisting of two domains X, Y, where the eyes are either staring at the camera or somewhere else. Our method consists of three novel modules: the Gaze Correction module(GCM), the Gaze Animation module(GAM), and the Pretrained Autoencoder module (PAM). Specifically, GCM and GAM separately train a dual in-painting network using data from the domain X for gaze correction and data from the domain Y for gaze animation. Additionally, a Synthesis-As-Training method is proposed when training GAM to encourage the features encoded from the eye region to be correlated with the angle information, resulting in gaze animation achieved by interpolation in the latent space. To further preserve the identity information e.g., eye shape, iris color, we propose the PAM with an Autoencoder, which is based on Self-Supervised mirror learning where the bottleneck features are angle-invariant and which works as an extra input to the dual in-painting models. Extensive experiments validate the effectiveness of the proposed method for gaze correction and gaze animation in the wild and demonstrate the superiority of our approach in producing more compelling results than state-of-the-art baselines. Our code, the pretrained models and supplementary results are available at:https://github.com/zhangqianhui/GazeAnimation."
"Wenbin Wang, Ruiping Wang, S. Shan, Xilin Chen",c450ead5da6783d93e20e718f27f4475b16c7dc9,Sketching Image Gist: Human-Mimetic Hierarchical Scene Graph Generation,ECCV,2020.0,5,"Scene graph aims to faithfully reveal humans' perception of image content. When humans analyze a scene, they usually prefer to describe image gist first, namely major objects and key relations in a scene graph. This humans' inherent perceptive habit implies that there exists a hierarchical structure about humans' preference during the scene parsing procedure. Therefore, we argue that a desirable scene graph should be also hierarchically constructed, and introduce a new scheme for modeling scene graph. Concretely, a scene is represented by a human-mimetic Hierarchical Entity Tree (HET) consisting of a series of image regions. To generate a scene graph based on HET, we parse HET with a Hybrid Long Short-Term Memory (Hybrid-LSTM) which specifically encodes hierarchy and siblings context to capture the structured information embedded in HET. To further prioritize key relations in the scene graph, we devise a Relation Ranking Module (RRM) to dynamically adjust their rankings by learning to capture humans' subjective perceptive habits from objective entity saliency and size. Experiments indicate that our method not only achieves state-of-the-art performances for scene graph generation, but also is expert in mining image-specific relations which play a great role in serving downstream tasks."
"Qingyuan Zheng, Zhuoru Li, Adam W. Bargteil",e21bf68bd69630c80d54c295c4b206aba2279eec,Learning to Shadow Hand-Drawn Sketches,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,5,"We present a fully automatic method to generate detailed and accurate artistic shadows from pairs of line drawing sketches and lighting directions. We also contribute a new dataset of one thousand examples of pairs of line drawings and shadows that are tagged with lighting directions. Remarkably, the generated shadows quickly communicate the underlying 3D structure of the sketched scene. Consequently, the shadows generated by our approach can be used directly or as an excellent starting point for artists. We demonstrate that the deep learning network we propose takes a hand-drawn sketch, builds a 3D model in latent space, and renders the resulting shadows. The generated shadows respect the hand-drawn lines and underlying 3D space and contain sophisticated and accurate details, such as self-shadowing effects. Moreover, the generated shadows contain artistic effects, such as rim lighting or halos appearing from backlighting, that would be achievable with traditional 3D rendering methods."
"Esther Robb, Wen-Sheng Chu, Abhishek Kumar, Jia-Bin Huang",4b8a11d7b2508d64a39e37968a3a00a2e80de187,Few-Shot Adaptation of Generative Adversarial Networks,ArXiv,2020.0,5,"Generative Adversarial Networks (GANs) have shown remarkable performance in image synthesis tasks, but typically require a large number of training samples to achieve high-quality synthesis. This paper proposes a simple and effective method, Few-Shot GAN (FSGAN), for adapting GANs in few-shot settings (less than 100 images). FSGAN repurposes component analysis techniques and learns to adapt the singular values of the pre-trained weights while freezing the corresponding singular vectors. This provides a highly expressive parameter space for adaptation while constraining changes to the pretrained weights. We validate our method in a challenging few-shot setting of 5-100 images in the target domain. We show that our method has significant visual quality gains compared with existing GAN adaptation methods. We report qualitative and quantitative results showing the effectiveness of our method. We additionally highlight a problem for few-shot synthesis in the standard quantitative metric used by data-efficient image synthesis works. Code and additional results are available at this http URL."
"Hanzhou Wu, Gen Liu, Y. Yao, Xinpeng Zhang",e7053f0d899702c1e70ccaf95b96706c1b287671,Watermarking Neural Networks with Watermarked Images,,2020.0,5,"Watermarking neural networks is a quite important means to protect the intellectual property (IP) of neural networks. In this paper, we introduce a novel digital watermarking framework suitable for deep neural networks that output images as the results, in which any image outputted from a watermarked neural network must contain a certain watermark. Here, the host neural network to be protected and a watermark-extraction network are trained together, so that, by optimizing a combined loss function, the trained neural network can accomplish the original task while embedding a watermark into the outputted images. This work is totally different from previous schemes carrying a watermark by network weights or classification labels of the trigger set. By detecting watermarks in the outputted images, this technique can be adopted to identify the ownership of the host network and find whether an image is generated from a certain neural network or not. We demonstrate that this technique is effective and robust on a variety of image processing tasks, including image colorization, super-resolution, image editing, semantic segmentation and so on."
"Chunlei Peng, Nannan Wang, J. Li, Xinbo Gao",9473acc643c40316766401a9d1246a7ec3d4abca,Face Sketch Synthesis in the Wild via Deep Patch Representation-Based Probabilistic Graphical Model,IEEE Transactions on Information Forensics and Security,2020.0,4,"This paper considers the problem of face sketch synthesis in the wild, which transforms a face photo into a face sketch. Face sketch synthesis is widely applied in law enforcement as well as digital entertainment fields. However, the existing methods either focus on hand-crafted techniques where prior human experience is relied on or adopt deep learning techniques as an end-to-end framework, where facial details cannot be well represented. In this paper, we propose a novel approach for face sketch synthesis in the wild via a deep patch representation-based probabilistic graphical model (DeepPGM). A Siamese network is constructed to extract deep patch representation from a raw facial patch, where the representative detail information for robust face sketch synthesis can be exploited. The generated deep patch representation and facial image patches are then optimally combined through a probabilistic graphical model. The proposed DeepPGM approach not only outperforms the state-of-the-art on public face sketch datasets but also can cope with forensic photos in the wild conditions, including varying lightings, poses, occlusions, skin colors, and ethnic origins. The superiority of the proposed method is demonstrated by extensive experiments on two public face sketch datasets and real-world forensic photos in the wild."
"X. Xu, Cheng Deng, Muli Yang, H. Wang",1fe8fba745bf196dd8e3cc51774e182b82903626,Progressive Domain-Independent Feature Decomposition Network for Zero-Shot Sketch-Based Image Retrieval,IJCAI,2020.0,4,"Zero-shot sketch-based image retrieval (ZS-SBIR) is a specific cross-modal retrieval task for searching natural images given free-hand sketches under the zero-shot scenario. Most existing methods solve this problem by simultaneously projecting visual features and semantic supervision into a low-dimensional common space for efficient retrieval. However, such low-dimensional projection destroys the completeness of semantic knowledge in original semantic space, so that it is unable to transfer useful knowledge well when learning semantic from different modalities. Moreover, the domain information and semantic information are entangled in visual features, which is not conducive for cross-modal matching since it will hinder the reduction of domain gap between sketch and image. In this paper, we propose a Progressive Domain-independent Feature Decomposition (PDFD) network for ZS-SBIR. Specifically, with the supervision of original semantic knowledge, PDFD decomposes visual features into domain features and semantic ones, and then the semantic features are projected into common space as retrieval features for ZS-SBIR. The progressive projection strategy maintains strong semantic supervision. Besides, to guarantee the retrieval features to capture clean and complete semantic information, the cross-reconstruction loss is introduced to encourage that any combinations of retrieval features and domain features can reconstruct the visual features. Extensive experiments demonstrate the superiority of our PDFD over state-of-the-art competitors."
"Michael Shum, Stephan Zheng, Wojciech Kryscinski, Caiming Xiong, R. Socher",78945210cee2356b28393a4f2fdebd219d1c1aeb,Sketch-Fill-A-R: A Persona-Grounded Chit-Chat Generation Framework,NLP4CONVAI,2020.0,4,"Human-like chit-chat conversation requires agents to generate responses that are fluent, engaging and consistent. We propose Sketch-Fill-A-R, a framework that uses a persona-memory to generate chit-chat responses in three phases. First, it generates dynamic sketch responses with open slots. Second, it generates candidate responses by filling slots with parts of its stored persona traits. Lastly, it ranks and selects the final response via a language model score. Sketch-Fill-A-R outperforms a state-of-the-art baseline both quantitatively (10-point lower perplexity) and qualitatively (preferred by 55% heads-up in single-turn and 20% higher in consistency in multi-turn user studies) on the Persona-Chat dataset. Finally, we extensively analyze Sketch-Fill-A-R's responses and human feedback, and show it is more consistent and engaging by using more relevant responses and questions."
"Fang Xu, Wen Yang, Tianbi Jiang, Shijie Lin, Haowen Luo, Guisong Xia",23e6358d61af04ada9af67cf27d96a51c3685af9,Mental Retrieval of Remote Sensing Images via Adversarial Sketch-Image Feature Learning,IEEE Transactions on Geoscience and Remote Sensing,2020.0,4,"Searching the targets of interest in large-scale remote sensing images is a fundamental problem, which becomes a very challenging issue when there is no relevant example at hand but a mental picture in mind. Hand-drawn sketch as a precise and convenient expression of the mental picture makes sketch-based remote sensing image retrieval (SBRSIR) an ideal choice to cope with this issue. However, the accuracy of SBRSIR algorithm, which is critical to effective retrieval, is still far behind classic query-by-example image retrieval. Two central limiting factors for this performance gap are: 1) the lack of effective cross-domain representations for bridging the domain gap between sketches and remote sensing images and 2) the absence of large sketch/remote sensing image data sets for developing, evaluating, and comparing the SBRSIR approaches. In this article, we first develop a novel SBRSIR model to learn a deep joint embedding space with discriminative losses, where adversarial training is used for the embedding space to learn domain-invariant representations. Then, we contribute a sketch/remote sensing image data set specifically for SBRSIR and provide a benchmark for subsequent researchers. Extensive experiments on the data set and large scene images demonstrate the effectiveness and superiority of the method for both the seen and unseen categories."
"Yuhang Li, X. Chen, Binxin Yang, Zihan Chen, Zhihua Cheng, Zhengjun Zha",f4af1b8b126a985a44c820add005586ce9c94f99,DeepFacePencil: Creating Face Images from Freehand Sketches,ACM Multimedia,2020.0,4,"In this paper, we explore the task of generating photo-realistic face images from hand-drawn sketches. Existing image-to-image translation methods require a large-scale dataset of paired sketches and images for supervision. They typically utilize synthesized edge maps of face images as training data. However, these synthesized edge maps strictly align with the edges of the corresponding face images, which limit their generalization ability to real hand-drawn sketches with vast stroke diversity. To address this problem, we propose DeepFacePencil, an effective tool that is able to generate photo-realistic face images from hand-drawn sketches, based on a novel dual generator image translation network during training. A novel spatial attention pooling (SAP) is designed to adaptively handle stroke distortions which are spatially varying to support various stroke styles and different level of details. We conduct extensive experiments and the results demonstrate the superiority of our model over existing methods on both image quality and model generalization to hand-drawn sketches."
"Aneeshan Sain, A. Bhunia, Yongxin Yang, Tao Xiang, Yi-Zhe Song",c78094362d566c3411dc7b7dcbd70b4527bcc974,Cross-Modal Hierarchical Modelling for Fine-Grained Sketch Based Image Retrieval,BMVC,2020.0,4,"Sketch as an image search query is an ideal alternative to text in capturing the fine-grained visual details. Prior successes on fine-grained sketch-based image retrieval (FG-SBIR) have demonstrated the importance of tackling the unique traits of sketches as opposed to photos, e.g., temporal vs. static, strokes vs. pixels, and abstract vs. pixel-perfect. In this paper, we study a further trait of sketches that has been overlooked to date, that is, they are hierarchical in terms of the levels of detail -- a person typically sketches up to various extents of detail to depict an object. This hierarchical structure is often visually distinct. In this paper, we design a novel network that is capable of cultivating sketch-specific hierarchies and exploiting them to match sketch with photo at corresponding hierarchical levels. In particular, features from a sketch and a photo are enriched using cross-modal co-attention, coupled with hierarchical node fusion at every level to form a better embedding space to conduct retrieval. Experiments on common benchmarks show our method to outperform state-of-the-arts by a significant margin."
"Hangyu Lin, Yanwei Fu, Yugang Jiang, X. Xue",ca7f8542107643d158e065148ea06a9d8049c9a5,Sketch-BERT: Learning Sketch Bidirectional Encoder Representation From Transformers by Self-Supervised Learning of Sketch Gestalt,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,4,"Previous researches of sketches often considered sketches in pixel format and leveraged CNN based models in the sketch understanding. Fundamentally, a sketch is stored as a sequence of data points, a vector format representation, rather than the photo-realistic image of pixels. SketchRNN studied a generative neural representation for sketches of vector format by Long Short Term Memory networks (LSTM). Unfortunately, the representation learned by SketchRNN is primarily for the generation tasks, rather than the other tasks of recognition and retrieval of sketches. To this end and inspired by the recent BERT model, we present a model of learning Sketch Bidirectional Encoder Representation from Transformer (Sketch-BERT). We generalize BERT to sketch domain, with the novel proposed components and pre-training algorithms, including the newly designed sketch embedding networks, and the self-supervised learning of sketch gestalt. Particularly, towards the pre-training task, we present a novel Sketch Gestalt Model (SGM) to help train the Sketch-BERT. Experimentally, we show that the learned representation of Sketch-BERT can help and improve the performance of the downstream tasks of sketch recognition, sketch retrieval, and sketch gestalt."
"Mingming Hu, Jingtao Guo",7696f0febb723ee7e86286204b0744a7ee7594a8,Facial attribute-controlled sketch-to-image translation with generative adversarial networks,EURASIP J. Image Video Process.,2020.0,4,"Due to the rapid development of the generative adversarial networks (GANs) and convolution neural networks (CNN), increasing attention is being paid to face synthesis. In this paper, we address the new and challenging task of facial sketch-to-image synthesis with multiple controllable attributes. To achieve this goal, first, we propose a new attribute classification loss to ensure that the synthesized face image with the facial attributes, which the users desire to have. Second, we employ the reconstruction loss to synthesize the facial texture and structure information. Third, the adversarial loss is used to encourage visual authenticity. By incorporating above losses into a unified framework, our proposed method not only can achieve high-quality sketch-to-image translation, but also allow the users control the facial attributes of synthesized image. Extensive experiments show that user-provided facial attribute information effectively controls the process of facial sketch-to-image translation."
"Difan Liu, Mohamed Nabail, Aaron Hertzmann, E. Kalogerakis",94cbbae54005e429ab9a20cdade19caa8aab13f6,Neural Contours: Learning to Draw Lines From 3D Shapes,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2020.0,4,"This paper introduces a method for learning to generate line drawings from 3D models. Our architecture incorporates a differentiable module operating on geometric features of the 3D model, and an image-based module operating on view-based shape representations. At test time, geometric and view-based reasoning are combined with the help of a neural module to create a line drawing. The model is trained on a large number of crowdsourced comparisons of line drawings. Experiments demonstrate that our method achieves significant improvements in line drawing over the state-of-the-art when evaluated on standard benchmarks, resulting in drawings that are comparable to those produced by experienced human artists."
"Tianying Wang, Wei Qi Toh, Hao Zhang, Xiuchao Sui, Shaohua Li, Y. Liu, Wei Jing",656e65ab55ae6fe35f2d25ac6e6857e525c97a57,RoboCoDraw: Robotic Avatar Drawing with GAN-based Style Transfer and Time-efficient Path Optimization,AAAI,2020.0,4,"Robotic drawing has become increasingly popular as an entertainment and interactive tool. In this paper we present RoboCoDraw, a real-time collaborative robot-based drawing system that draws stylized human face sketches interactively in front of human users, by using the Generative Adversarial Network (GAN)-based style transfer and a Random-Key Genetic Algorithm (RKGA)-based path optimization. The proposed RoboCoDraw system takes a real human face image as input, converts it to a stylized avatar, then draws it with a robotic arm. A core component in this system is the Avatar-GAN proposed by us, which generates a cartoon avatar face image from a real human face. AvatarGAN is trained with unpaired face and avatar images only and can generate avatar images of much better likeness with human face images in comparison with the vanilla CycleGAN. After the avatar image is generated, it is fed to a line extraction algorithm and converted to sketches. An RKGA-based path optimization algorithm is applied to find a time-efficient robotic drawing path to be executed by the robotic arm. We demonstrate the capability of RoboCoDraw on various face images using a lightweight, safe collaborative robot UR5."
"Omid Poursaeed, Vladimir G. Kim, E. Shechtman, Jun Saito, Serge J. Belongie",18b32d678d8074a4de74d649e5817264ba5041c4,Neural Puppet: Generative Layered Cartoon Characters,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020.0,4,"We propose a learning based method for generating new animations of a cartoon character given a few example images. Our method is designed to learn from a traditionally animated sequence, where each frame is drawn by an artist, and thus the input images lack any common structure, correspondences, or labels. We express pose changes as a deformation of a layered 2.5D template mesh, and devise a novel architecture that learns to predict mesh deformations matching the template to a target image. This enables us to extract a common low-dimensional structure from a diverse set of character poses. We combine recent advances in differentiable rendering as well as mesh-aware models to successfully align common template even if only a few character images are available during training. In addition to coarse poses, character appearance also varies due to shading, out-of-plane motions, and artistic effects. We capture these subtle changes by applying an image translation network to refine the mesh rendering, providing an end-to-end model to generate new animations of a character with high visual quality. We demonstrate that our generative model can be used to synthesize in-between frames and to create data-driven deformation. Our template fitting procedure outperforms state-of-the-art generic techniques for detecting image correspondences."
"F. Liu, C. Zou, Xiaoming Deng, Ran Zuo, Yu-Kun Lai, Cuixia Ma, Yongjin Liu, Hongan Wang",2f8cf3fc1d809d5276fc74f519fe6d4c95bba686,SceneSketcher: Fine-Grained Image Retrieval with Scene Sketches,ECCV,2020.0,3,"Sketch-based image retrieval (SBIR) has been a popular research topic in recent years. Existing works concentrate on mapping the visual information of sketches and images to a semantic space at the object level. In this paper, for the first time, we study the fine-grained scene-level SBIR problem which aims at retrieving scene images satisfying the user’s specific requirements via a freehand scene sketch. We propose a graph embedding based method to learn the similarity measurement between images and scene sketches, which models the multi-modal information, including the size and appearance of objects as well as their layout information, in an effective manner. To evaluate our approach, we collect a dataset based on SketchyCOCO and extend the dataset using Coco-stuff. Comprehensive experiments demonstrate the significant potential of the proposed approach on the application of fine-grained scene-level image retrieval."
"Dorothea Scheunemann, V. Vijayakumar, H. Zeng, P. Durand, N. Leclerc, M. Brinkmann, M. Kemerink",887c126c548bf4ce7f56f081a8ef626a1aa4d11c,Rubbing and Drawing: Generic Ways to Improve the Thermoelectric Power Factor of Organic Semiconductors?,,2020.0,3,"Highly oriented polymer films can show considerable anisotropy in the thermoelectric properties leading to power factors beyond those predicted by the widely obeyed power law linking the thermopower S and the electrical conductivity σ as S ∝ σ−1/4. This has led to encouraging practical results with respect to the electrical conductivity, notwithstanding that the conditions necessary to enhance σ and S simultaneously are less clear. Here, kinetic Monte Carlo simulations are used to study the impact of structural anisotropy on the thermoelectric properties of disordered organic semiconductors. It is found that stretching is a suitable strategy to improve the conductivity along the direction of strain, whereas the effect on the power factor depends on the morphology the polymer crystallizes. In general, crystalline polymers show a simultaneous increase in σ and S which is not the case for amorphous polymers. Moreover, it is shown that the trends resulting from simulations based on variable‐range hopping are in good agreement with experiments and can describe the different functional dependencies in the S versus σ behavior of different directions."
"Zhaolong Zhang, Yuejie Zhang, Rui Feng, T. Zhang, Weiguo Fan",1b3a2aa23fb4e0313574b68e5fb7e3af3a76112c,Zero-Shot Sketch-Based Image Retrieval via Graph Convolution Network,AAAI,2020.0,3,"Zero-Shot Sketch-based Image Retrieval (ZS-SBIR) has been proposed recently, putting the traditional Sketch-based Image Retrieval (SBIR) under the setting of zero-shot learning. Dealing with both the challenges in SBIR and zero-shot learning makes it become a more difficult task. Previous works mainly focus on utilizing one kind of information, i.e., the visual information or the semantic information. In this paper, we propose a SketchGCN model utilizing the graph convolution network, which simultaneously considers both the visual information and the semantic information. Thus, our model can effectively narrow the domain gap and transfer the knowledge. Furthermore, we generate the semantic information from the visual information using a Conditional Variational Autoencoder rather than only map them back from the visual space to the semantic space, which enhances the generalization ability of our model. Besides, feature loss, classification loss, and semantic loss are introduced to optimize our proposed SketchGCN model. Our model gets a good performance on the challenging Sketchy and TU-Berlin datasets."
"Cheng Deng, X. Xu, H. Wang, Muli Yang, D. Tao",538a6426d18d7f80cf21d2fa2ec06f053e4ba3af,Progressive Cross-Modal Semantic Network for Zero-Shot Sketch-Based Image Retrieval,IEEE Transactions on Image Processing,2020.0,3,"Zero-shot sketch-based image retrieval (ZS-SBIR) is a specific cross-modal retrieval task that involves searching natural images through the use of free-hand sketches under the zero-shot scenario. Most previous methods project the sketch and image features into a low-dimensional common space for efficient retrieval, and meantime align the projected features to their semantic features (e.g., category-level word vectors) in order to transfer knowledge from seen to unseen classes. However, the projection and alignment are always coupled; as a result, there is a lack of explicit alignment that consequently leads to unsatisfactory zero-shot retrieval performance. To address this issue, we propose a novel progressive cross-modal semantic network. More specifically, it first explicitly aligns the sketch and image features to semantic features, then projects the aligned features to a common space for subsequent retrieval. We further employ cross-reconstruction loss to encourage the aligned features to capture complete knowledge about the two modalities, along with multi-modal Euclidean loss that guarantees similarity between the retrieval features from a sketch-image pair. Extensive experiments conducted on two popular large-scale datasets demonstrate that our proposed approach outperforms state-of-the-art competitors to a remarkable extent: by more than 3% on the Sketchy dataset and about 6% on the TU-Berlin dataset in terms of retrieval accuracy."
"Yurui Ren, Ge Li, S. Liu, Thomas H. Li",364193005b7b22c212780528215945af4c0bbda6,Deep Spatial Transformation for Pose-Guided Person Image Generation and Animation,IEEE Transactions on Image Processing,2020.0,3,"Pose-guided person image generation and animation aim to transform a source person image to target poses. These tasks require spatial manipulation of source data. However, Convolutional Neural Networks are limited by the lack of ability to spatially transform the inputs. In this article, we propose a differentiable global-flow local-attention framework to reassemble the inputs at the feature level. This framework first estimates global flow fields between sources and targets. Then, corresponding local source feature patches are sampled with content-aware local attention coefficients. We show that our framework can spatially transform the inputs in an efficient manner. Meanwhile, we further model the temporal consistency for the person image animation task to generate coherent videos. The experiment results of both image generation and animation tasks demonstrate the superiority of our model. Besides, additional results of novel view synthesis and face image animation show that our model is applicable to other tasks requiring spatial transformation. The source code of our project is available at https://github.com/RenYurui/Global-Flow-Local-Attention."
"Min Shi, Jia-qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang",525d226b9b14fe056e30c8f3261ece7b7eff11f9,Deep Line Art Video Colorization with a Few References,ArXiv,2020.0,3,"Coloring line art images based on the colors of reference images is an important stage in animation production, which is time-consuming and tedious. In this paper, we propose a deep architecture to automatically color line art videos with the same color style as the given reference images. Our framework consists of a color transform network and a temporal constraint network. The color transform network takes the target line art images as well as the line art and color images of one or more reference images as input, and generates corresponding target color images. To cope with larger differences between the target line art image and reference color images, our architecture utilizes non-local similarity matching to determine the region correspondences between the target image and the reference images, which are used to transform the local color information from the references to the target. To ensure global color style consistency, we further incorporate Adaptive Instance Normalization (AdaIN) with the transformation parameters obtained from a style embedding vector that describes the global color style of the references, extracted by an embedder. The temporal constraint network takes the reference images and the target image together in chronological order, and learns the spatiotemporal features through 3D convolution to ensure the temporal consistency of the target image and the reference image. Our model can achieve even better coloring results by fine-tuning the parameters with only a small amount of samples when dealing with an animation of a new style. To evaluate our method, we build a line art coloring dataset. Experiments show that our method achieves the best performance on line art video coloring compared to the state-of-the-art methods and other baselines."
"Homanga Bharadhwaj, Shoichiro Yamaguchi, S. Maeda",e2ed7503ecbbfa18922eeab4fa97aaddf0237bc7,MANGA: Method Agnostic Neural-policy Generalization and Adaptation,2020 IEEE International Conference on Robotics and Automation (ICRA),2020.0,3,"In this paper we target the problem of transferring policies across multiple environments with different dynamics parameters and motor noise variations, by introducing a framework that decouples the processes of policy learning and system identification. Efficiently transferring learned policies to an unknown environment with changes in dynamics configurations in the presence of motor noise is very important for operating robots in the real world, and our work is a novel attempt in that direction. We introduce MANGA: Method Agnostic Neural-policy Generalization and Adaptation, that trains dynamics conditioned policies and efficiently learns to estimate the dynamics parameters of the environment given off-policy state-transition rollouts in the environment. Our scheme is agnostic to the type of training method used - both reinforcement learning (RL) and imitation learning (IL) strategies can be used. We demonstrate the effectiveness of our approach by experimenting with four different MuJoCo agents and comparing against previously proposed transfer baselines."
"Jialu Huang, Jing Liao, S. Kwong",084368bcfe786de94a19e6da08255eb5ffdba152,Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2 Network,ArXiv,2020.0,3,"Image-to-Image (I2I) translation is a heated topic in academia, and it also has been applied in real-world industry for tasks like image synthesis, super-resolution, and colorization. However, traditional I2I translation methods train data in two or more domains together. This requires lots of computation resources. Moreover, the results are of lower quality, and they contain many more artifacts. The training process could be unstable when the data in different domains are not balanced, and modal collapse is more likely to happen. We proposed a new I2I translation method that generates a new model in the target domain via a series of model transformations on a pre-trained StyleGAN2 model in the source domain. After that, we proposed an inversion method to achieve the conversion between an image and its latent vector. By feeding the latent vector into the generated model, we can perform I2I translation between the source domain and target domain. Both qualitative and quantitative evaluations were conducted to prove that the proposed method can achieve outstanding performance in terms of image quality, diversity and semantic similarity to the input and reference images compared to state-of-the-art works."
"Chunlei Peng, N. Wang, Jie Li, Xinbo Gao",7a0331a5820fed23075ef4dae1ae79c2a96cdf5f,Universal Face Photo-Sketch Style Transfer via Multiview Domain Translation,IEEE Transactions on Image Processing,2020.0,3,"Face photo-sketch style transfer aims to convert a representation of a face from the photo (or sketch) domain to the sketch (respectively, photo) domain while preserving the character of the subject. It has wide-ranging applications in law enforcement, forensic investigation and digital entertainment. However, conventional face photo-sketch synthesis methods usually require training images from both the source domain and the target domain, and are limited in that they cannot be applied to universal conditions where collecting training images in the source domain that match the style of the test image is unpractical. This problem entails two major challenges: 1) designing an effective and robust domain translation model for the universal situation in which images of the source domain needed for training are unavailable, and 2) preserving the facial character while performing a transfer to the style of an entire image collection in the target domain. To this end, we present a novel universal face photo-sketch style transfer method that does not need any image from the source domain for training. The regression relationship between an input test image and the entire training image collection in the target domain is inferred via a deep domain translation framework, in which a domain-wise adaption term and a local consistency adaption term are developed. To improve the robustness of the style transfer process, we propose a multiview domain translation method that flexibly leverages a convolutional neural network representation with hand-crafted features in an optimal way. Qualitative and quantitative comparisons are provided for universal unconstrained conditions of unavailable training images from the source domain, demonstrating the effectiveness and superiority of our method for universal face photo-sketch style transfer."
"A. S. Girsang, B. A. Faruq, H. R. Herlianto, S. Simbolon",4607426e8dbe957fdbbfba3e02de452c5b9b3729,Collaborative Recommendation System in Users of Anime Films,,2020.0,2,"The recommendation system is one method to know the preference consumer by showing the potential object. This recommendation also helps the consumer gets the preference object. One of the popular objects in the recommendation is anime film. In this case, we conduct research to recommend anime films based on ratings of previously watched films. Collaborative filtering is a technique that consists of calculating similarities, predictions, and recommendations. This study is taken from dataset Kaggle which consists of 73,516 users and 12,294 anime. A user's history will be matched with the whole user's history with alternating least squares (ALS) method. The anime will be recommended based on that results. This method is expected to help millions of users find the desired anime."
"Alexander Wang, Mengye Ren, R. Zemel",cf0d9ea9e52d682ea95a0df39c4339e8f9d8fdcb,SketchEmbedNet: Learning Novel Concepts by Imitating Drawings,ArXiv,2020.0,2,Sketch drawings are an intuitive visual domain that generally preserves semantics. Previous work has shown that recurrent neural networks are capable of producing sketch drawings of a single or few classes at a time. In this work we focus on the representations developed by training a generative model to produce sketches from pixel images across many classes in a sketch domain. We find that the embeddings learned by this sketching model are extremely informative for visual tasks and infer compositional information. We then use them to exceed state-of-the-art performance in unsupervised few-shot classification on the Omniglot and mini-ImageNet benchmarks. We also leverage the generative capacity of our model to produce high quality sketches of novel classes based on just a single example.
"Jiawen Zhu, Xing Xu, Fumin Shen, R. K. Lee, Zebing Wang, Heng Tao Shen",4e9d3c4b52933f3abb04737237a2d3d103bd3f7f,Ocean: A Dual Learning Approach For Generalized Zero-Shot Sketch-Based Image Retrieval,2020 IEEE International Conference on Multimedia and Expo (ICME),2020.0,2,"Sketch-Based Image Retrieval (SBIR) is an emerging research area with many real-world applications. Recent studies have approached this research task under the more challenging zero-shot learning setting (ZS-SBIR), which assume classes in the target domain are unseen during the training stage. Many of the existing ZS-SBIR studies transferred the learned cross-modal (i.e., sketch and image) representations from the source domain to the target domain by leveraging side information in semantic embeddings. However, these ZS-SBIR methods are not able to generalize well to a more realistic setting to retrieve images from seen and unseen classes. To address the limitation of existing methods, we propose the cOmmon Conditional Encoder Adversarial Network (OCEAN) to perform generalized zero-shot sketch-based image retrieval (GZS-SBIR). The OCEAN model utilizes a dual learning framework to cyclically map the sketch and image features to a common semantic space, and project semantic features back to the relevant visual space by adversarial training. We conduct experiments on two publicly available datasets and demonstrate that our proposed model outperformed the state-of-the-arts baselines in both ZS-SBIR and GZS-SBIR tasks."
"Cong Bai, Jian Chen, Qing Ma, Pengyi Hao, Shengyong Chen",52bf9793d36223406d76831b91548d41a0b15509,Cross-domain representation learning by domain-migration generative adversarial network for sketch based image retrieval,J. Vis. Commun. Image Represent.,2020.0,2,"Abstract Sketch based image retrieval (SBIR), which uses free-hand sketches to search the images containing similar objects/scenes, is attracting more and more attentions as sketches could be got more easily with the development of touch devices. However, this task is difficult as the huge differences between sketches and images. In this paper, we propose a cross-domain representation learning framework to reduce these differences for SBIR. This framework aims to transfer sketches to images with the information learned both in the sketch domain and image domain by the proposed domain migration generative adversarial network (DMGAN). Furthermore, to reduce the representation gap between the generated images and natural images, a similarity learning network (SLN) is also proposed with the new designed loss function incorporating semantic information. Extensive experiments have been done from different aspects, including comparison with state-of-the-art methods. The results show that the proposed DMGAN and SLN really work for SBIR."
"Ushasi Chaudhuri, Biplab Banerjee, A. Bhattacharya, M. Datcu",bb87b1d90b5b157574d0510955ec9f6fb03085a8,A Simplified Framework for Zero-shot Cross-Modal Sketch Data Retrieval,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2020.0,2,"We deal with the problem of zero-shot cross-modal image retrieval involving color and sketch images through a novel deep representation learning technique. The problem of a sketch to image retrieval and vice-versa is of practical importance, and a trained model in this respect is expected to generalize beyond the training classes, e.g., the zero-shot learning scenario. Nonetheless, considering the drastic distributions-gap between both the modalities, a feature alignment is necessary to learn a shared feature space where retrieval can efficiently be carried out. Additionally, it should also be guaranteed that the shared space is semantically meaningful to aid in the zero-shot retrieval task. The very few existing techniques for zero-shot sketch-RGB image retrieval extend the deep generative models for learning the embedding space; however, training a typical GAN like model for multi-modal image data may be non-trivial at times. To this end, we propose a multi-stream encoder-decoder model that simultaneously ensures improved mapping between the RGB and sketch image spaces and high discrimination in the shared semantics-driven encoded feature space. Further, it is guaranteed that the class topology of the original semantic space is preserved in the encoded feature space, which subsequently reduces the model bias towards the training classes. Experimental results obtained on the benchmark Sketchy and TU-Berlin datasets establish the efficacy of our model as we outperform the existing state-of-the-art techniques by a considerable margin."
"Y. Zheng, Yifan Zhao, Mengyuan Ren, He Yan, Xiangju Lu, Junhui Liu, Jia Li",68de80079470f255093e6e030ddc0f3e8faa8e9f,Cartoon Face Recognition: A Benchmark Dataset,ACM Multimedia,2020.0,2,"Recent years have witnessed increasing attention in cartoon media, powered by the strong demands of industrial applications. As the first step to understand this media, cartoon face recognition is a crucial but less-explored task with few datasets proposed. In this work, we first present a new challenging benchmark dataset, consisting of 389,678 images of 5,013 cartoon characters annotated with identity, bounding box, pose, and other auxiliary attributes. The dataset, named iCartoonFace, is currently the largest-scale, high-quality, rich-annotated, and spanning multiple occurrences in the field of image recognition, including near-duplications, occlusions, and appearance changes. In addition, we provide two types of annotations for cartoon media, i.e., face recognition, and face detection, with the help of a semi-automatic labeling algorithm. To further investigate this challenging dataset, we propose a multi-task domain adaptation approach that jointly utilizes the human and cartoon domain knowledge with three discriminative regularizations. We hence perform a benchmark analysis of the proposed dataset and verify the superiority of the proposed approach in the cartoon face recognition task. The dataset is available at https://iqiyi.cn/icartoonface."
"Michael Cuffaro, Emerson P. Doyle",6a9564845d72ba41cd8f6f6e1ead0e0e6b7be92e,Essay Review of Tanya and Jeffrey Bub’s Totally Random: Why Nobody Understands Quantum Mechanics: A Serious Comic on Entanglement,,2020.0,2,"This is an extended essay review of Tanya and Jeffrey Bub’s Totally Random: Why Nobody Understands Quantum Mechanics: A serious comic on entanglement . We review the philosophical aspects of the book, provide suggestions for instructors on how to use the book in a class setting, and evaluate the authors’ artistic choices in the context of comics theory. Although Totally Random does not defend any particular interpretation of quantum mechanics, we find that, in its mode of presentation, Totally Random is a beautiful expression and illustration of the information-theoretic interpretation and its value."
"C. Plant, Sonja Biedermann, Christian Böhm",fd03cf5efe3e6e7c2cf652edc8610f30bcd4eb0d,Data Compression as a Comprehensive Framework for Graph Drawing and Representation Learning,KDD,2020.0,2,"Embedding a graph into feature space is a promising approach to understand its structure. Embedding into 2D or 3D space enables visualization; representation in higher-dimensional vector space (typically >100D) enables the application of data mining techniques. For the success of knowledge discovery it is essential that the distances between the embedded vertices truly reflect the structure of the graph. Our fundamental idea is to compress the adjacency matrix by predicting the existence of an edge from the Euclidean distance between the corresponding vertices in the embedding, and to use the achieved compression as a quality measure for the embedding. We call this quality measure Predictive Entropy (PE). PE uses a sigmoid function to define the probability which is monotonically decreasing with the Euclidean distance. We use this sigmoid probability to compress the adjacency matrix of the graph by an entropy coding. While PE could be used to assess the result of any graph drawing or representation learning method we particularly use it as objective function in our new method GEMPE (Graph Embedding by Minimizing the Predictive Entropy). We demonstrate in our experiments that GEMPE clearly outperforms comparison methods with respect to quality of the visual result, clustering and node-labeling accuracy on the discovered coordinates."
"Eloïse Berson, Catherine Soladi'e, Nicolas Stoiber",711a95275b97b3524be65431bd7d87d98ec326b3,Intuitive Facial Animation Editing Based On A Generative RNN Framework,Comput. Graph. Forum,2020.0,2,"For the last decades, the concern of producing convincing facial animation has garnered great interest, that has only been accelerating with the recent explosion of 3D content in both entertainment and professional activities. The use of motion capture and retargeting has arguably become the dominant solution to address this demand. Yet, despite high level of quality and automation performance‐based animation pipelines still require manual cleaning and editing to refine raw results, which is a time‐ and skill‐demanding process. In this paper, we look to leverage machine learning to make facial animation editing faster and more accessible to non‐experts. Inspired by recent image inpainting methods, we design a generative recurrent neural network that generates realistic motion into designated segments of an existing facial animation, optionally following user‐provided guiding constraints. Our system handles different supervised or unsupervised editing scenarios such as motion filling during occlusions, expression corrections, semantic content modifications, and noise filtering. We demonstrate the usability of our system on several animation editing use cases."
"Julia Gong, Yannick Hold-Geoffroy, Jingwan Lu",07eddf2e55ffd6ed85d4674923457cd32f06479b,AutoToon: Automatic Geometric Warping for Face Cartoon Generation,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020.0,2,"Caricature, a type of exaggerated artistic portrait, amplifies the distinctive, yet nuanced traits of human faces. This task is typically left to artists, as it has proven difficult to capture subjects’ unique characteristics well using automated methods. Recent development of deep end-to-end methods has achieved promising results in capturing style and higher-level exaggerations. However, a key part of caricatures, face warping, has remained challenging for these systems. In this work, we propose AutoToon, the first supervised deep learning method that yields high-quality warps for the warping component of caricatures. Completely disentangled from style, it can be paired with any stylization method to create diverse caricatures. In contrast to prior art, we leverage an SENet and spatial transformer module and train directly on artist warping fields, applying losses both prior to and after warping. As shown by our user studies, we achieve appealing exaggerations that amplify distinguishing features of the face while preserving facial detail."
"Wenqing Chu, W. Hung, Yi-Hsuan Tsai, Yu-Ting Chang, Yijun Li, Deng Cai, Ming-Hsuan Yang",1d08614bdad810514fc4d02b7a82d01cb24b8cf8,Learning to Caricature via Semantic Shape Transform,ArXiv,2020.0,2,"Caricature is an artistic drawing created to abstract or exaggerate facial features of a person. Rendering visually pleasing caricatures is a difficult task that requires professional skills, and thus it is of great interest to design a method to automatically generate such drawings. To deal with large shape changes, we propose an algorithm based on a semantic shape transform to produce diverse and plausible shape exaggerations. Specifically, we predict pixel-wise semantic correspondences and perform image warping on the input photo to achieve dense shape transformation. We show that the proposed framework is able to render visually pleasing shape exaggerations while maintaining their facial structures. In addition, our model allows users to manipulate the shape via the semantic map. We demonstrate the effectiveness of our approach on a large photograph-caricature benchmark dataset with comparisons to the state-of-the-art methods."
"Lucas Y Tian, Kevin Ellis, Marta Kryven, J. Tenenbaum",f1b7ea4a5c657ec359a12f619f877e36b70c0d13,Learning abstract structure for drawing by efficient motor program induction,NeurIPS,2020.0,2,"Humans flexibly solve new problems that differ qualitatively from those they were trained on. This ability to generalize is supported by learned concepts that capture structure common across different problems. Here we develop a naturalistic drawing task to study how humans rapidly acquire structured prior knowledge. The task requires drawing visual objects that share underlying structure, based on a set of composable geometric rules. We show that people spontaneously learn abstract drawing procedures that support generalization, and propose a model of how learners can discover these reusable drawing programs. Trained in the same setting as humans, and constrained to produce efficient motor actions, this model discovers new drawing routines that transfer to test objects and resemble learned features of human sequences. These results suggest that two principles guiding motor program induction in the model - abstraction (general programs that ignore object-specific details) and compositionality (recombining previously learned programs) - are key for explaining how humans learn structured internal representations that guide flexible reasoning and learning."
"Ashwinee Panda, D. Rothchild, Enayat Ullah, Nikita Ivkin, I. Stoica, Joseph E. Gonzalez, A. Preprint, Vladimir Braverman, R. Arora",a471904f5b224e17a3203a51d812d7ee1640d753,Communication-Efficient Federated Learning with Sketching,ICML 2020,2020.0,2,"Existing approaches to federated learning suffer from a communication bottleneck as well as convergence issues due to sparse client participation. In this paper we introduce a novel algorithm, called FedSketchedSGD, to overcome these challenges. FedSketchedSGD compresses model updates using a Count Sketch, and then takes advantage of the mergeability of sketches to combine model updates from many workers. A key insight in the design of FedSketchedSGD is that, because the Count Sketch is linear, momentum and error accumulation can both be carried out within the sketch. This allows the algorithm to move momentum and error accumulation from clients to the central aggregator, overcoming the challenges of sparse client participation while still achieving high compression rates. We prove that FedSketchedSGD has favorable convergence guarantees, and we demonstrate its empirical effectiveness by training two residual networks and a transformer model."
"Benjamin Coleman, Anshumali Shrivastava",d6f7dfa2f921cd2c0ce4997289470cec0093da18,A One-Pass Private Sketch for Most Machine Learning Tasks,ArXiv,2020.0,2,"Differential privacy (DP) is a compelling privacy definition that explains the privacy-utility tradeoff via formal, provable guarantees. Inspired by recent progress toward general-purpose data release algorithms, we propose a private sketch, or small summary of the dataset, that supports a multitude of machine learning tasks including regression, classification, density estimation, near-neighbor search, and more. Our sketch consists of randomized contingency tables that are indexed with locality-sensitive hashing and constructed with an efficient one-pass algorithm. We prove competitive error bounds for DP kernel density estimation. Existing methods for DP kernel density estimation scale poorly, often exponentially slower with an increase in dimensions. In contrast, our sketch can quickly run on large, high-dimensional datasets in a single pass. Exhaustive experiments show that our generic sketch delivers a similar privacy-utility tradeoff when compared to existing DP methods at a fraction of the computation cost. We expect that our sketch will enable differential privacy in distributed, large-scale machine learning settings."
"S. Shetty, M. Bershady, K. Westfall, M. Cappellari, N. Drory, D. Law, R. Yan, Kevin Bundy Kavli Institute for Astronomy, Astrophysics, P. University, D. O. Astronomy, U. Wisconsin--Madison, South African astronomical Observatory, U. C. Town, University of California Observatories, U. California, Santa Cruz, Sub-department of Astrophysics, D. Physics, U. Oxford, M. Observatory, The University of Texas at Austin, S. Institute, Astronomy, U. Kentucky",3da4b56aeec9f87ab2b9412d2b13423af03e9ba3,Stellar Population Synthesis with Distinct Kinematics: Multi-Age Asymmetric Drift in SDSS-IV MaNGA Galaxies,,2020.0,2,"We present the first asymmetric drift (AD) measurements for unresolved stellar populations of different characteristic ages above and below 1.5 Gyr. These measurements sample the age-velocity relation (AVR) in galaxy disks. In this first paper we develop two efficient algorithms to extract AD on a spaxel-by-spaxel basis from optical integral-field spectroscopic (IFS) data-cubes. The algorithms apply different spectral templates, one using simple stellar populations and the other a stellar library; their comparison allows us to assess systematic errors in derived multi-component velocities, such as template-mismatch. We test algorithm reliability using mock spectra and Monte Carlo Markov Chains on real data from the MaNGA survey in SDSS-IV. We quantify random and systematic errors in AD as a function of signal-to-noise and stellar population properties with the aim of applying this technique to large subsets of the MaNGA galaxy sample. As a demonstration of our methods, we apply them to an initial sample of seven galaxies with comparable stellar mass and color to the Milky Way. We find a wide range of distinct AD radial profiles for young and old stellar populations."
"Juyong Zhang, Hongrui Cai, Y. Guo, Zhuang Peng",10e0572fb9d977ca0f951218682042a0a08c8afb,Landmark Detection and 3D Face Reconstruction for Caricature using a Nonlinear Parametric Model,ArXiv,2020.0,2,"Caricature is an artistic abstraction of the human face by distorting or exaggerating certain facial features, while still retains a likeness with the given face. Due to the large diversity of geometric and texture variations, automatic landmark detection and 3D face reconstruction for caricature is a challenging problem and has rarely been studied before. In this paper, we propose the first automatic method for this task by a novel 3D approach. To this end, we first build a dataset with various styles of 2D caricatures and their corresponding 3D shapes, and then build a parametric model on vertex based deformation space for 3D caricature face. Based on the constructed dataset and the nonlinear parametric model, we propose a neural network based method to regress the 3D face shape and orientation from the input 2D caricature image. Ablation studies and comparison with baseline methods demonstrate the effectiveness of our algorithm design, and extensive experimental results demonstrate that our method works well for various caricatures. Our constructed dataset, source code and trained model are available at this https URL."
"Jiamin Liang, X. Yang, H. Li, Yi Wang, M. T. Van, Haoran Dou, Chao-Yu Chen, Jinghui Fang, Xiaowen Liang, Zixin Mai, Guowen Zhu, Zhiyi Chen, Dong Ni",b8124304bda2bfabc313a85a8958190ed2d7b49e,Synthesis and Edition of Ultrasound Images via Sketch Guided Progressive Growing GANS,2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI),2020.0,2,"Ultrasound (US) is widely accepted in clinic for anatomical structure inspection. However, lacking in resources to practice US scan, novices often struggle to learn the operation skills. Also, in the deep learning era, automated US image analysis is limited by the lack of annotated samples. Efficiently synthesizing realistic, editable and high resolution US images can solve the problems. The task is challenging and previous methods can only partially complete it. In this paper, we devise a new framework for US image synthesis. Particularly, we firstly adopt a sketch generative adversarial networks (Sgan) to introduce background sketch upon object mask in a conditioned generative adversarial network. With enriched sketch cues, Sgan can generate realistic US images with editable and fine-grained structure details. Although effective, Sgan is hard to generate high resolution US images. To achieve this, we further implant the Sgan into a progressive growing scheme (PGSgan). By smoothly growing both generator and discriminator, PGSgan can gradually synthesize US images from low to high resolution. By synthesizing ovary and follicle US images, our extensive perceptual evaluation, user study and segmentation results prove the promising efficacy and efficiency of the proposed PGSgan."
"Corentin Guezenoc, R. Séguier",80dd5eb2f52ac5d1e1996a820629c9a3661c0ea9,A Wide Dataset of Ear Shapes and Pinna-Related Transfer Functions Generated by Random Ear Drawings,The Journal of the Acoustical Society of America,2020.0,2,"Head-related transfer function individualization is a key matter in binaural synthesis. However, currently available databases are limited in size compared to the high dimensionality of the data. In this paper, the process of generating a synthetic dataset of 1000 ear shapes and matching sets of pinna-related transfer functions (PRTFs), named WiDESPREaD (wide dataset of ear shapes and pinna-related transfer functions obtained by random ear drawings), is presented and made freely available to other researchers. Contributions in this article are threefold. First, from a proprietary dataset of 119 three-dimensional left-ear scans, a matching dataset of PRTFs was built by performing fast-multipole boundary element method (FM-BEM) calculations. Second, the underlying geometry of each type of high-dimensional data was investigated using principal component analysis. It was found that this linear machine-learning technique performs better at modeling and reducing data dimensionality on ear shapes than on matching PRTF sets. Third, based on these findings, a method was devised to generate an arbitrarily large synthetic database of PRTF sets that relies on the random drawing of ear shapes and subsequent FM-BEM computations."
"Alex Lamb, Sherjil Ozair, Vikas Verma, David Ha",9f4d31009a666998918dea4da699361380e7f140,SketchTransfer: A Challenging New Task for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),2020.0,2,"Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). The failure of ma- chine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST → SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today’s best methods but has substantial room for improvement."
"Lu Tang, Qun Huang, Patrick P. C. Lee",93bb075afeaa4bfbb902afcfe9a7d2cdbfa0f689,A Fast and Compact Invertible Sketch for Network-Wide Heavy Flow Detection,IEEE/ACM Transactions on Networking,2020.0,2,"Fast detection of heavy flows (e.g., heavy hitters and heavy changers) in massive network traffic is challenging due to the stringent requirements of fast packet processing and limited resource availability. Invertible sketches are summary data structures that can recover heavy flows with small memory footprints and bounded errors, yet existing invertible sketches incur high memory access overhead that leads to performance degradation. We present MV-Sketch, a fast and compact invertible sketch that supports heavy flow detection with small and static memory allocation. MV-Sketch tracks candidate heavy flows inside the sketch data structure via the idea of majority voting, such that it incurs small memory access overhead in both update and query operations, while achieving high detection accuracy. We present theoretical analysis on the memory usage, performance, and accuracy of MV-Sketch in both local and network-wide scenarios. We further show how MV-Sketch can be implemented and deployed on P4-based programmable switches subject to hardware deployment constraints. We conduct evaluation in both software and hardware environments. Trace-driven evaluation in software shows that MV-Sketch achieves higher accuracy than existing invertible sketches, with up to $3.38\times $ throughput gain. We also show how to boost the performance of MV-Sketch with SIMD instructions. Furthermore, we evaluate MV-Sketch on a Barefoot Tofino switch and show how MV-Sketch achieves line-rate measurement with limited hardware resource overhead."
"Kurmanbek Kaiyrbekov, T. M. Sezgin",366a0b0887ab6881b2bfd78184116f434e77be46,Deep Stroke-Based Sketched Symbol Reconstruction and Segmentation,IEEE Computer Graphics and Applications,2020.0,2,"Hand-drawn objects usually consist of multiple semantically meaningful parts. In this article, we propose a neural network model that segments sketched symbols into stroke-level components. Our segmentation framework has two main elements: a fixed feature extractor and a multilayer perceptron (MLP) network that identifies a component based on the feature. As the feature extractor we utilize an encoder of a stroke-rnn, which is our newly proposed generative variational auto-encoder (VAE) model that reconstructs symbols on a stroke-by-stroke basis. Experiments show that a single encoder could be reused for segmenting multiple categories of sketched symbols with negligible effects on segmentation accuracies. Our segmentation scores surpass existing methodologies on an available small state-of-the-art dataset. Moreover, extensive evaluations on our newly annotated big dataset demonstrate that our framework obtains significantly better accuracies as compared to baseline models. We release the dataset to the community."
"M. Xie, Chengze Li, Xueting Liu, T. Wong",414f7c7b3335df83051efddabaa79dacf3fd32b2,Manga filling style conversion with screentone variational autoencoder,ACM Trans. Graph.,2020.0,2,"Western color comics and Japanese-style screened manga are two popular comic styles. They mainly differ in the style of region-filling. However, the conversion between the two region-filling styles is very challenging, and manually done currently. In this paper, we identify that the major obstacle in the conversion between the two filling styles stems from the difference between the fundamental properties of screened region-filling and colored region-filling. To resolve this obstacle, we propose a screentone variational autoencoder, ScreenVAE, to map the screened manga to an intermediate domain. This intermediate domain can summarize local texture characteristics and is interpolative. With this domain, we effectively unify the properties of screening and color-filling, and ease the learning for bidirectional translation between screened manga and color comics. To carry out the bidirectional translation, we further propose a network to learn the translation between the intermediate domain and color comics. Our model can generate quality screened manga given a color comic, and generate color comic that retains the original screening intention by the bitonal manga artist. Several results are shown to demonstrate the effectiveness and convenience of the proposed method. We also demonstrate how the intermediate domain can assist other applications such as manga inpainting and photo-to-comic conversion."
"Lvmin Zhang, Edgar Simo-Serra, Yi Ji, Chunping Liu",3e1a8c969e45a20c6e99d25cd51144c443711853,Generating Digital Painting Lighting Effects via RGB-space Geometry,ACM Trans. Graph.,2020.0,2,"We present an algorithm to generate digital painting lighting effects from a single image. Our algorithm is based on a key observation: Artists use many overlapping strokes to paint lighting effects, i.e., pixels with dense stroke history tend to gather more illumination strokes. Based on this observation, we design an algorithm to both estimate the density of strokes in a digital painting using color geometry and then generate novel lighting effects by mimicking artists’ coarse-to-fine workflow. Coarse lighting effects are first generated using a wave transform and then retouched according to the stroke density of the original illustrations into usable lighting effects. Our algorithm is content-aware, with generated lighting effects naturally adapting to image structures, and can be used as an interactive tool to simplify current labor-intensive workflows for generating lighting effects for digital and matte paintings. In addition, our algorithm can also produce usable lighting effects for photographs or three-dimensional rendered images. We evaluate our approach with both an in-depth qualitative and a quantitative analysis that includes a perceptual user study. Results show that our proposed approach is not only able to produce favorable lighting effects with respect to existing approaches, but also that it is able to significantly reduce the needed interaction time."
"Mingrui Zhu, J. Li, Nannan Wang, Xinbo Gao",c1f2e09588612b29a78fe5a66b1cb2840fcc4675,Knowledge Distillation for Face Photo-Sketch Synthesis.,IEEE transactions on neural networks and learning systems,2020.0,1,"Significant progress has been made with face photo-sketch synthesis in recent years due to the development of deep convolutional neural networks, particularly generative adversarial networks (GANs). However, the performance of existing methods is still limited because of the lack of training data (photo-sketch pairs). To address this challenge, we investigate the effect of knowledge distillation (KD) on training neural networks for the face photo-sketch synthesis task and propose an effective KD model to improve the performance of synthetic images. In particular, we utilize a teacher network trained on a large amount of data in a related task to separately learn knowledge of the face photo and knowledge of the face sketch and simultaneously transfer this knowledge to two student networks designed for the face photo-sketch synthesis task. In addition to assimilating the knowledge from the teacher network, the two student networks can mutually transfer their own knowledge to further enhance their learning. To further enhance the perception quality of the synthetic image, we propose a KD+ model that combines GANs with KD. The generator can produce images with more realistic textures and less noise under the guide of knowledge. Extensive experiments and a user study demonstrate the superiority of our models over the state-of-the-art methods."
"Yuri Sato, K. Mineshima",dfce6d568e56dc295f4aa209929dd8d64a42b4d6,"Depicting Negative Information in Photographs, Videos, and Comics: A Preliminary Analysis",Diagrams,2020.0,1,"It is often claimed that pictures are not well suited to representing negative information. Against this widely held view, we argue that a close look at how ordinary people use visual representations will show that negative information can be depicted in various interesting ways. We focus on three types of representations, namely, photographs, videos, and comics, and discuss design varieties for depicting negation."
"R. Gribonval, A. Chatalic, N. Keriven, Vincent Schellekens, L. Jacques, P. Schniter",b437afb2cb65b2d1a495593aab91b7132d184905,Sketching Datasets for Large-Scale Learning (long version),ArXiv,2020.0,1,"This article considers ""sketched learning,"" or ""compressive learning,"" an approach to large-scale machine learning where datasets are massively compressed before learning (e.g., clustering, classification, or regression) is performed. In particular, a ""sketch"" is first constructed by computing carefully chosen nonlinear random features (e.g., random Fourier features) and averaging them over the whole dataset. Parameters are then learned from the sketch, without access to the original dataset. This article surveys the current state-of-the-art in sketched learning, including the main concepts and algorithms, their connections with established signal-processing methods, existing theoretical guarantees-on both information preservation and privacy preservation, and important open problems."
"Zeyu Li, Cheng Deng, Erkun Yang, D. Tao",9a1e7148653a0a66d5f9ca999b7a82c1f98a1eb6,Staged Sketch-to-Image Synthesis via Semi-supervised Generative Adversarial Networks,,2020.0,1,"Sketch-based image synthesis is a challenging problem in computer graphics and vision. Existing approaches either require exact edge maps or rely on the retrieval of existing photographs, which limits their applications in real-world scenarios. Accordingly in this work, we propose a staged semisupervised generative adversarial networks based method for sketch-to-image synthesis, which can directly generate realistic images from novice sketches. More specifically, we first adopt a conditional generative adversarial network (CGAN) to extract class-wise representations from unpaired images. These classwise representations are then exploited and incorporated with another CGAN, which are used to generate realistic images from sketches. By incorporating the class-wise representations, our method can leverage both the general class information from unpaired images and the targeted object information from input sketches. Additionally, this network architecture also enables us to take full advantage of widely available unpaired images and learn more accurate class representations. Extensive experiments demonstrate, compared with state-of-the-art image translation methods, our approach can achieve more promising results and synthesize images with significantly better Inception Scores and Fréchet Inception Distance."
"Goluck Konuko, G. Valenzise, Stéphane Lathuilière",7cad0d582786d02e3afecb4f0868fe4ef0a95329,Ultra-low bitrate video conferencing using deep image animation,ArXiv,2020.0,1,"In this work we propose a novel deep learning approach for ultra-low bitrate video compression for video conferencing applications. To address the shortcomings of current video compression paradigms when the available bandwidth is extremely limited, we adopt a model-based approach that employs deep neural networks to encode motion information as keypoint displacement and reconstruct the video signal at the decoder side. The overall system is trained in an end-to-end fashion minimizing a reconstruction error on the encoder output. Objective and subjective quality evaluation experiments demonstrate that the proposed approach provides an average bitrate reduction for the same visual quality of more than 80% compared to HEVC."
"Yue Zhong, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song",1988e4154a28f72d46437602190042166b82e23f,Deep Sketch-Based Modeling: Tips and Tricks,2020 International Conference on 3D Vision (3DV),2020.0,1,"Deep image-based modeling received lots of attention in recent years, yet the parallel problem of sketch-based modeling has only been briefly studied, often as a potential application. In this work, for the first time, we identify the main differences between sketch and image inputs: (i) style variance, (ii) imprecise perspective, and (iii) sparsity. We discuss why each of these differences can pose a challenge, and even make a certain class of image-based methods inapplicable. We study alternative solutions to address each of the difference. By doing so, we drive out a few important insights: (i) sparsity commonly results in an incorrect prediction of foreground versus background, (ii) diversity of human styles, if not taken into account, can lead to very poor generalization properties, and finally (iii) unless a dedicated sketching interface is used, one can not expect sketches to match a perspective of a fixed viewpoint. Finally, we compare a set of representative deep single-image modeling solutions and show how their performance can be improved to tackle sketch input by taking into consideration the identified critical differences."
"Christian Böhm, C. Plant",7cbdce3b61bbb736219dccf023a801ce16fc477c,Massively Parallel Graph Drawing and Representation Learning,2020 IEEE International Conference on Big Data (Big Data),2020.0,1,"To fully exploit the performance potential of modern multi-core processors, machine learning and data mining algorithms for big data must be parallelized in multiple ways. Today’s CPUs consist of multiple cores, each following an independent thread of control, and each equipped with multiple arithmetic units which can perform the same operation on a vector of multiple data objects. Graph embedding, i.e. converting the vertices of a graph into numerical vectors is a data mining task of high importance and is useful for graph drawing (low-dimensional vectors) and graph representation learning (high-dimensional vectors). In this paper, we propose MulticoreGEMPE (Graph Embedding by Minimizing the Predictive Entropy), an information-theoretic method which can generate low and high-dimensional vectors. MulticoreGEMPE applies MIMD (Multiple Instructions Multiple Data, using OpenMP) and SIMD (Single Instructions Multiple Data, using AVX-512) parallelism. We propose general ideas applicable in other graph-based algorithms like vectorized hashing and vectorized reduction. Our experimental evaluation demonstrates the superiority of our approach."
"Yao Li, Xianggang Yu, Xiao-Guang Han, Nianjuan Jiang, Kui Jia, Jiangbo Lu",0707fa11994f08c1a9e0acea8d3d9f061700f1f2,A deep learning based interactive sketching system for fashion images design,PG,2020.0,1,"In this work, we propose an interactive system to design diverse high-quality garment images from fashion sketches and the texture information. The major challenge behind this system is to generate high-quality and detailed texture according to the user-provided texture information. Prior works mainly use the texture patch representation and try to map a small texture patch to a whole garment image, hence unable to generate high-quality details. In contrast, inspired by intrinsic image decomposition, we decompose this task into texture synthesis and shading enhancement. In particular, we propose a novel bi-colored edge texture representation to synthesize textured garment images and a shading enhancer to render shading based on the grayscale edges. The bi-colored edge representation provides simple but effective texture cues and color constraints, so that the details can be better reconstructed. Moreover, with the rendered shading, the synthesized garment image becomes more vivid."
"M. Kamari, O. Gunes",450248be5ec66ef6486baf4c39fb55b142f81d6b,Segmentation and Analysis of a Sketched Truss Frame Using Morphological Image Processing Techniques,ArXiv,2020.0,1,"Development of computational tools to analyze and assess the building capacities has had a major impact in civil engineering. The interaction with the structural software packages is becoming easier and the modeling tools are becoming smarter by automating the users role during their interaction with the software. One of the difficulties and the most time consuming steps involved in the structural modeling is defining the geometry of the structure to provide the analysis. This paper is dedicated to the development of a methodology to automate analysis of a hand sketched or computer generated truss frame drawn on a piece of paper. First, we focus on the segmentation methodologies for hand sketched truss components using the morphological image processing techniques, and then we provide a real time analysis of the truss. We visualize and augment the results on the input image to facilitate the public understanding of the truss geometry and internal forces. MATLAB is used as the programming language for the image processing purposes, and the truss is analyzed using Sap2000 API to integrate with MATLAB to provide a convenient structural analysis. This paper highlights the potential of the automation of the structural analysis using image processing to quickly assess the efficiency of structural systems. Further development of this framework is likely to revolutionize the way that structures are modeled and analyzed."
"K. Chung, De-Wei Hsieh, Chi-Huang Liao",0b625e0d64764b9b01396b47260864c9308954a6,Effective binarization for historically degraded as-built drawing maps using convolutional neural networks,Other Conferences,2020.0,1,"Binarizing historically degraded as-built drawing (HDAD) maps is a challenging job, especially in removing noise, yellowing areas, and folded lines while preserving the foreground components. This paper first proposes a convolutional neural networks-based (CNN-based) color classifier to determine the dominant color class of each HDAD block. Then, a dominant color driven- and CNN-based binarization method is proposed, producing a high-quality binarized HDAD map. Based on real HDAD dataset, the thorough experiments have been carried out to show that in terms of F-measure and perceptual effect, our binarization method substantially outperforms existing state-of-the art binarization methods."
"U.-Ram Ko, Hwan-Gue Cho",b852de0c475053619602eb93007f6f2c57150a32,SickZil-Machine: A Deep Learning Based Script Text Isolation System for Comics Translation,DAS,2020.0,1,"The translation of comics (and Manga) involves removing text from a foreign comic images and typesetting translated letters into it. The text in comics contain a variety of deformed letters drawn in arbitrary positions, in complex images or patterns. These letters have to be removed by experts, as computationally erasing these letters is very challenging. Although several classical image processing algorithms and tools have been developed, a completely automated method that could erase the text is still lacking. Therefore, we propose an image processing framework called ‘SickZil-Machine’ (SZMC) that automates the removal of text from comics. SZMC works through a two-step process. In the first step, the text areas are segmented at the pixel level. In the second step, the letters in the segmented areas are erased and inpainted naturally to match their surroundings. SZMC exhibited a notable performance, employing deep learning based image segmentation and image inpainting models. To train these models, we constructed 285 pairs of original comic pages, a text area-mask dataset, and a dataset of 31,497 comic pages. We identified the characteristics of the dataset that could improve SZMC performance. SZMC is available at: https://github.com/KUR-creative/SickZil-Machine."
"Hugo Bertiche, M. Madadi, S. Escalera",07057b43f44cbac9ffe9a2128a576c5c1a274bb4,DeePSD: Automatic Deep Skinning And Pose Space Deformation For 3D Garment Animation,ArXiv,2020.0,1,"We present a novel approach to the garment animation problem through deep learning. Previous approaches propose learning a single model for one or few garment types, or alternatively, extend a human body model to represent multiple garment types. These works are not able to generalize to arbitrarily complex outfits we commonly find in real life. Our proposed methodology is able to work with any topology, complexity and multiple layers of cloth. Because of this, it is also able to generalize to completely unseen outfits with complex details. We design our model such that it can be efficiently deployed on portable devices and achieve real-time performance. Finally, we present an approach for unsupervised learning."
"N. Fish, Lilach Perry, Amit H. Bermano, D. Cohen-Or",594bd2d526e5f5a932424c99716b7d7136be441d,SketchPatch: Sketch Stylization via Seamless Patch-level Synthesis,ACM Trans. Graph.,2020.0,1,"The paradigm of image-to-image translation is leveraged for the benefit of sketch stylization via transfer of geometric textural details. Lacking the necessary volumes of data for standard training of translation systems, we advocate for operation at the patch level, where a handful of stylized sketches provide ample mining potential for patches featuring basic geometric primitives. Operating at the patch level necessitates special consideration of full sketch translation, as individual translation of patches with no regard to neighbors is likely to produce visible seams and artifacts at patch borders. Aligned pairs of styled and plain primitives are combined to form input hybrids containing styled elements around the border and plain elements within, and given as input to a seamless translation (ST) generator, whose output patches are expected to reconstruct the fully styled patch. An adversarial addition promotes generalization and robustness to diverse geometries at inference time, forming a simple and effective system for arbitrary sketch stylization, as demonstrated upon a variety of styles and sketches."
"Koya Tango, Marie Katsurai, H. Maki, Ryosuke Goto",51500e023a282e94510cacba84635cccc279c6c1,Anime-to-Real Clothing: Cosplay Costume Generation via Image-to-Image Translation,ArXiv,2020.0,1,"Cosplay has grown from its origins at fan conventions into a billion-dollar global dress phenomenon. To facilitate imagination and reinterpretation from animated images to real garments, this paper presents an automatic costume image generation method based on image-to-image translation. Cosplay items can be significantly diverse in their styles and shapes, and conventional methods cannot be directly applied to the wide variation in clothing images that are the focus of this study. To solve this problem, our method starts by collecting and preprocessing web images to prepare a cleaned, paired dataset of the anime and real domains. Then, we present a novel architecture for generative adversarial networks (GANs) to facilitate high-quality cosplay image generation. Our GAN consists of several effective techniques to fill the gap between the two domains and improve both the global and local consistency of generated images. Experiments demonstrated that, with two types of evaluation metrics, the proposed GAN achieves better performance than existing methods. We also showed that the images generated by the proposed method are more realistic than those generated by the conventional methods. Our codes and pretrained model are available on the web."
"Dustin G. Mixon, Kaiying Xie",910b529f559a3d14ba8ff6d93865647c4c71b213,Sketching semidefinite programs for faster clustering,,2020.0,1,"Many clustering problems enjoy solutions by semidefinite programming. Theoretical results in this vein frequently consider data with a planted clustering and a notion of signal strength such that the semidefinite program exactly recovers the planted clustering when the signal strength is sufficiently large. In practice, semidefinite programs are notoriously slow, and so speedups are welcome. In this paper, we show how to sketch a popular semidefinite relaxation of a graph clustering problem known as minimum bisection, and our analysis supports a meta-claim that the clustering task is less computationally burdensome when there is more signal."
"Roman Ibrahimov, N. Zherdev, D. Tsetserukou",156b630bec5a4c37de52dec38c128ada3c8916c5,DroneLight: Drone Draws in the Air using Long Exposure Light Painting and ML,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),2020.0,1,"We propose a novel human-drone interaction paradigm where a user directly interacts with a drone to light-paint predefined patterns or letters through hand gestures. The user wears a glove which is equipped with an IMU sensor to draw letters or patterns in the midair. The developed ML algorithm detects the drawn pattern and the drone light-paints each pattern in midair in the real time. The proposed classification model correctly predicts all of the input gestures. The DroneLight system can be applied in drone shows, advertisements, distant communication through text or pattern, rescue, and etc. To our knowledge, it would be the world's first human-centric robotic system that people can use to send messages based on light-painting over distant locations (drone-based instant messaging). Another unique application of the system would be the development of vision-driven rescue system that reads light-painting by person who is in distress and triggers rescue alarm."
"Wen Ji, Kelei He, Jing Huo, Zheng Gu, Yang Gao",5cab071617d86f78aaae450ad95149583266639f,Unsupervised Domain Attention Adaptation Network for Caricature Attribute Recognition,ECCV,2020.0,1,"Caricature attributes provide distinctive facial features to help research in Psychology and Neuroscience. However, unlike the facial photo attribute datasets that have a quantity of annotated images, the annotations of caricature attributes are rare. To facility the research in attribute learning of caricatures, we propose a caricature attribute dataset, namely WebCariA. Moreover, to utilize models that trained by face attributes, we propose a novel unsupervised domain adaptation framework for cross-modality (i.e., photos to caricatures) attribute recognition, with an integrated inter- and intra-domain consistency learning scheme. Specifically, the inter-domain consistency learning scheme consisting an image-to-image translator to first fill the domain gap between photos and caricatures by generating intermediate image samples, and a label consistency learning module to align their semantic information. The intra-domain consistency learning scheme integrates the common feature consistency learning module with a novel attribute-aware attention-consistency learning module for a more efficient alignment. We did an extensive ablation study to show the effectiveness of the proposed method. And the proposed method also outperforms the state-of-the-art methods by a margin. The implementation of the proposed method is available at this https URL."
"A. Dutta, Zeynep Akata",66b92cfd4f5d79ba8e9369cc451f996146294660,Semantically Tied Paired Cycle Consistency for Any-Shot Sketch-Based Image Retrieval,International Journal of Computer Vision,2020.0,1,"Low-shot sketch-based image retrieval is an emerging task in computer vision, allowing to retrieve natural images relevant to hand-drawn sketch queries that are rarely seen during the training phase. Related prior works either require aligned sketch-image pairs that are costly to obtain or inefficient memory fusion layer for mapping the visual information to a semantic space. In this paper, we address any-shot, i.e. zero-shot and few-shot, sketch-based image retrieval (SBIR) tasks, where we introduce the few-shot setting for SBIR. For solving these tasks, we propose a semantically aligned paired cycle-consistent generative adversarial network (SEM-PCYC) for any-shot SBIR, where each branch of the generative adversarial network maps the visual information from sketch and image to a common semantic space via adversarial training. Each of these branches maintains cycle consistency that only requires supervision at the category level, and avoids the need of aligned sketch-image pairs. A classification criteria on the generators’ outputs ensures the visual to semantic space mapping to be class-specific. Furthermore, we propose to combine textual and hierarchical side information via an auto-encoder that selects discriminating side information within a same end-to-end model. Our results demonstrate a significant boost in any-shot SBIR performance over the state-of-the-art on the extended version of the challenging Sketchy, TU-Berlin and QuickDraw datasets."
"Jialu Huang, Jing Liao, Zhifeng Tan, S. Kwong",72271ef9dd1ff6ff2c9b749894d698c8e509a2c7,Multi-Density Sketch-to-Image Translation Network,ArXiv,2020.0,1,"Sketch-to-image (S2I) translation plays an important role in image synthesis and manipulation tasks, such as photo editing and colorization. Some specific S2I translation including sketch-to-photo and sketch-to-painting can be used as powerful tools in the art design industry. However, previous methods only support S2I translation with a single level of density, which gives less flexibility to users for controlling the input sketches. In this work, we propose the first multi-level density sketch-to-image translation framework, which allows the input sketch to cover a wide range from rough object outlines to micro structures. Moreover, to tackle the problem of noncontinuous representation of multi-level density input sketches, we project the density level into a continuous latent space, which can then be linearly controlled by a parameter. This allows users to conveniently control the densities of input sketches and generation of images. Moreover, our method has been successfully verified on various datasets for different applications including face editing, multi-modal sketch-to-photo translation, and anime colorization, providing coarse-to-fine levels of controls to these applications."
"Shu-Yu Chen, Wanchao Su, Lin Gao, Shi-hong Xia, Hongbo Fu",636654129898832964d64141e8cf0507d8d376a2,Deep Generation of Face Images from Sketches,ArXiv,2020.0,1,"Recent deep image-to-image translation techniques allow fast generation of face images from freehand sketches. However, existing solutions tend to overfit to sketches, thus requiring professional sketches or even edge maps as input. To address this issue, our key idea is to implicitly model the shape space of plausible face images and synthesize a face image in this space to approximate an input sketch. We take a local-to-global approach. We first learn feature embeddings of key face components, and push corresponding parts of input sketches towards underlying component manifolds defined by the feature vectors of face component samples. We also propose another deep neural network to learn the mapping from the embedded component features to realistic images with multi-channel feature maps as intermediate results to improve the information flow. Our method essentially uses input sketches as soft constraints and is thus able to produce high-quality face images even from rough and/or incomplete sketches. Our tool is easy to use even for non-artists, while still supporting fine-grained control of shape details. Both qualitative and quantitative evaluations show the superior generation ability of our system to existing and alternative solutions. The usability and expressiveness of our system are confirmed by a user study."
"Maryam Sadat Mirzaei, Kourosh Meshgi, Etienne Frigo, T. Nishida",67cc342ef301674b97ba91f5188b5a17ced5c37e,Animgan: A Spatiotemporally-Conditioned Generative Adversarial Network For Character Animation,2020 IEEE International Conference on Image Processing (ICIP),2020.0,1,"Producing realistic character animations is one of the essential tasks in human-AI interactions. Considered as a sequence of poses of a humanoid, the task can be considered as a sequence generation problem with spatiotemporal smoothness and realism constraints. Additionally, we wish to control the behavior of AI agents by giving them what to do and, more specifically, how to do it. We proposed a spatiotemporally-conditioned GAN that generates a sequence that is similar to a given sequence in terms of semantics and spatiotemporal dynamics. Using LSTM-based generator and graph ConvNet discriminator, this system is trained end-to-end on a large gathered dataset of gestures, expressions, and actions. Experiments showed that compared to traditional conditional GAN, our method creates plausible, realistic, and semantically relevant humanoid animation sequences that match user expectations."
"Devi Parikh, C. L. Zitnick",8bb02670b4c3d994bf080bf7ff5e7861b5c95900,Exploring Crowd Co-creation Scenarios for Sketches,ICCC,2020.0,1,"As a first step towards studying the ability of human crowds and machines to effectively co-create, we explore several human-only collaborative co-creation scenarios. The goal in each scenario is to create a digital sketch using a simple web interface. We find that settings in which multiple humans iteratively add strokes and vote on the best additions result in the sketches with highest perceived creativity (value + novelty). Lack of collaboration leads to a higher variance in quality and lower novelty or surprise. Collaboration without voting leads to high novelty but low quality."
"Uche M. Osahor, Hadi Kazemi, Ali Dabouei, N. Nasrabadi",006cc434de566be21fe39a26d85e1efa6866f93c,Quality Guided Sketch-to-Photo Image Synthesis,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2020.0,1,"Facial sketches drawn by artists are widely used for visual identification applications and mostly by law enforcement agencies, but the quality of these sketches depend on the ability of the artist to clearly replicate all the key facial features that could aid in capturing the true identity of a subject. Recent works have attempted to synthesize these sketches into plausible visual images to improve visual recognition and identification. However, synthesizing photo-realistic images from sketches proves to be an even more challenging task, especially for sensitive applications such as suspect identification. In this work, we propose a novel approach that adopts a generative adversarial network that synthesizes a single sketch into multiple synthetic images with unique attributes like hair color, sex, etc. We incorporate a hybrid discriminator which performs attribute classification of multiple target attributes, a quality guided encoder that minimizes the perceptual dissimilarity of the latent space embedding of the synthesized and real image at different layers in the network and an identity preserving network that maintains the identity of the synthesised image throughout the training process. Our approach is aimed at improving the visual appeal of the synthesised images while incorporating multiple attribute assignment to the generator without compromising the identity of the synthesised image. We synthesised sketches using XDOG filter for the CelebA, WVU Multi-modal and CelebA-HQ datasets and from an auxiliary generator trained on sketches from CUHK, IIT-D and FERET datasets. Our results are impressive compared to current state of the art."
"Pin-Chu Yang, Mohammed Al-Sada, Chang-Chieh Chiu, Kevin Kuo, T. P. Tomo, Kanata Suzuki, Nelson Yalta, Kuo-Hao Shu, T. Ogata",9341d479806195a2cf138a93c3cddd3a7f2dcedf,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),2020.0,1,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki’s novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world’s largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki’s design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion."
"Shuang Zhou, H. Mo, C. Li, M. Boquien, G. Rossi",8e583b28b072fb303d36bad16618cdbcd055d1c4,SDSS-IV MaNGA: Bayesian analysis of the star formation history of low-mass galaxies in the local Universe,,2020.0,1,"We measure the star formation histories (SFH) of a sample of low-mass galaxies with $M_\ast<10^9M_\odot$ from the SDSS-IV MaNGA survey. The large number of IFU spectra for each galaxy are either combined to reach a high signal to noise ratio or used to investigate spatial variations. We use Bayesian inferences based on full spectrum fitting. Our analysis based on Bayesian evidence ratio indicates a strong preference for a model that allows the presence of an old stellar population, and that an improper model for the SFH can significantly underestimate the old population in these galaxies. The addition of NIR photometry to the constraining data can further distinguish between different SFH model families and significantly tighten the constraints on the mass fraction in the old population. On average more than half of the stellar mass in present-day low-mass galaxies formed 8 Gyrs ago, while about 30\% within the past 4 Gyrs. Satellite galaxies on average have formed their stellar mass earlier than central galaxies, and stars in the outer regions of galaxy are younger than those in the central part. Our results suggest that most of the low-mass galaxies have an early episode of active star formation that produces a large fraction of their present stellar mass."
"Zipeng Ye, Ran Yi, M. Yu, Juyong Zhang, Yu-Kun Lai, Yongjin Liu",5b3353d27bfb074ce7150f9e6e1eaea477a5c9ac,3D-CariGAN: An End-to-End Solution to 3D Caricature Generation from Face Photos,ArXiv,2020.0,1,"Caricature is a kind of artistic style of human faces that attracts considerable research in computer vision. So far all existing 3D caricature generation methods require some information related to caricature as input, e.g., a caricature sketch or 2D caricature. However, this kind of input is difficult to provide by non-professional users. In this paper, we propose an end-to-end deep neural network model to generate high-quality 3D caricature with a simple face photo as input. The most challenging issue in our system is that the source domain of face photos (characterized by 2D normal faces) is significantly different from the target domain of 3D caricatures (characterized by 3D exaggerated face shapes and texture). To address this challenge, we (1) build a large dataset of 6,100 3D caricature meshes and use it to establish a PCA model in the 3D caricature shape space and (2) detect landmarks in the input face photo and use them to set up correspondence between 2D caricature and 3D caricature shape. Our system can automatically generate high-quality 3D caricatures. In many situations, users want to control the output by a simple and intuitive way, so we further introduce a simple-to-use interactive control with three horizontal and one vertical lines. Experiments and user studies show that our system is easy to use and can generate high-quality 3D caricatures."
Jiawei Zhang,63b60eb510ff1eca463d2650b489d2f5254d59a1,Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on Graph Semi-Supervised Classification,ArXiv,2020.0,1,"Existing graph neural networks may suffer from the ""suspended animation problem"" when the model architecture goes deep. Meanwhile, for some graph learning scenarios, e.g., nodes with text/image attributes or graphs with long-distance node correlations, deep graph neural networks will be necessary for effective graph representation learning. In this paper, we propose a new graph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph representation learning and node classification. DIFNET utilizes both neural gates and graph residual learning for node hidden state modeling, and includes an attention mechanism for node neighborhood information diffusion. Extensive experiments will be done in this paper to compare DIFNET against several state-of-the-art graph neural network models. The experimental results can illustrate both the learning performance advantages and effectiveness of DIFNET, especially in addressing the ""suspended animation problem""."
"Chengying Gao, Qi Liu, Qi Xu, Jianzhuang Liu, Limin Wang, C. Zou",29a7f3fd5164e38f046867fdc2d10fc67e183ab6,Image Generation from Freehand Scene Sketches,,2020.0,1,"We introduce the first method for automatic image generation from scene-level freehand sketches. Our model allows for controllable image generation by specifying the synthesis goal via freehand sketches. The key contribution is an attribute vector bridged generative adversarial network called edgeGAN which supports high visual-quality image content generation without using freehand sketches as training data. We build a large-scale composite dataset called SketchyCOCO to comprehensively evaluate our solution. We validate our approach on the task of both objectlevel and scene-level image generation on SketchyCOCO. We demonstrate the method’s capacity to generate realistic complex scene-level images from a variety of freehand sketches by quantitative, qualitative results, and ablation studies."
"Ravi Kiran Sarvadevabhatla, Shiv Surya, Trisha Mittal, R. Venkatesh Babu",71807a11819431cce1b29b9c64dbd876f1da39c7,"Pictionary-Style Word Guessing on Hand-Drawn Object Sketches: Dataset, Analysis and Deep Network Models",IEEE Transactions on Pattern Analysis and Machine Intelligence,2020.0,1,"The ability of intelligent agents to play games in human-like fashion is popularly considered a benchmark of progress in Artificial Intelligence. In our work, we introduce the first computational model aimed at Pictionary, the popular word-guessing social game. We first introduce Sketch-QA, a guessing task. Styled after Pictionary, Sketch-QA uses incrementally accumulated sketch stroke sequences as visual data. Sketch-QA involves asking a fixed question (“What object is being drawn?”) and gathering open-ended guess-words from human guessers. We analyze the resulting dataset and present many interesting findings therein. To mimic Pictionary-style guessing, we propose a deep neural model which generates guess-words in response to temporally evolving human-drawn object sketches. Our model even makes human-like mistakes while guessing, thus amplifying the human mimicry factor. We evaluate our model on the large-scale guess-word dataset generated via Sketch-QA task and compare with various baselines. We also conduct a Visual Turing Test to obtain human impressions of the guess-words generated by humans and our model. Experimental results demonstrate the promise of our approach for Pictionary and similarly themed games."
"W. Zhou, Jinyuan Jia",19efc8979824ba3a2a42f6494364719d58b80490,Training convolutional neural network for sketch recognition on large-scale dataset,Int. Arab J. Inf. Technol.,2020.0,1,"With the rapid development of computer vision technology, increasingly more focus has been put on image recognition. More specifically, a sketch is an important hand-drawn image that is garnering increased attention. Moreover, as handheld devices such as tablets, smartphones, etc. have become more popular, it has become increasingly more convenient for people to hand-draw sketches using this equipment. Hence, sketch recognition is a necessary task to improve the performance of intelligent equipment. In this paper, a sketch recognition learning approach is proposed that is based on the Visual Geometry Group16 Convolutional Neural Network (VGG16 CNN). In particular, in order to diminish the effect of the number of sketches on the learning method, we adopt a strategy of increasing the quantity to improve the diversity and scale of sketches. Initially, sketch features are extracted via the pretrained VGG16 CNN. Additionally, we obtain contextual features based on the traverse stroke scheme. Then, the VGG16 CNN is trained using a joint Bayesian method to update the related network parameters. Moreover, this network has been applied to predict the labels of input sketches in order to automatically recognize the label of a sketch. Last but not least, related experiments are conducted, and the comparison of our method with the state-of-the-art methods is performed, which shows that our approach is superior and feasible."
"Alex Lamb, Sherjil Ozair, Vikas Verma, David Ha",a93019ee139b2f2bf936717dce38868e950dee5a,SketchTransfer: A New Dataset for Exploring Detail-Invariance and the Abstractions Learned by Deep Networks,,2020.0,1,"Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). This capability goes beyond visual data: humans are easily able to recognize isolated melodies from musical pieces when heard for the first time, even if the only piece they've listened to previously is from an orchestra. Thus the failure of machine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST \xrightarrow SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today's best methods but has substantial room for improvement."
"Balázs Keszegh, Dömötör Pálvölgyi",6d4906f978d4e566cd19bbcc02e307cb9b17bace,Plane drawings of the generalized Delaunay-graphs for pseudo-disks,J. Comput. Geom.,2020.0,1,"We study general Delaunay-graphs, which are a natural generalizations of Delaunay triangulations to arbitrary families. We prove that for any finite pseudo-disk family and point set, there is a plane drawing of their Delaunay-graph such that every edge lies inside every pseudo-disk that contains its endpoints."
"K. Akita, Y. Morimoto, R. Tsuruno",bf03985a1b5d5fed16fd79ce85058a0bd8b38f4e,Deep-Eyes: Fully Automatic Anime Character Colorization with Painting of Details on Empty Pupils,Eurographics,2020.0,1,"Many studies have recently applied deep learning to the automatic colorization of line drawings. However, it is difficult to paint empty pupils using existing methods because the networks are trained with pupils that have edges, which are generated from color images using image processing. Most actual line drawings have empty pupils that artists must paint in. In this paper, we propose a novel network model that transfers the pupil details in a reference color image to input line drawings with empty pupils. We also propose a method for accurately and automatically coloring eyes. In this method, eye patches are extracted from a reference color image and automatically added to an input line drawing as color hints using our eye position estimation network. CCS Concepts • Computing methodologies → Image processing; • Applied computing → Fine arts;"
"Lvmin Zhang, Yi Ji, Chunping Liu",2f7093cc379ed47704de6ff4f905912c484908de,DanbooRegion: An Illustration Region Dataset,ECCV,2020.0,1,"Region is a fundamental element of various cartoon animation techniques and artistic painting applications. Achieving satisfactory region is essential to the success of these techniques. Motivated to assist diversiform region-based cartoon applications, we invite artists to annotate regions for in-the-wild cartoon images with several application-oriented goals: (1) To assist image-based cartoon rendering, relighting, and cartoon intrinsic decomposition literature, artists identify object outlines and eliminate lighting-and-shadow boundaries. (2) To assist cartoon inking tools, cartoon structure extraction applications, and cartoon texture processing techniques, artists clean-up texture or deformation patterns and emphasize cartoon structural boundary lines. (3) To assist region-based cartoon digitalization, clip-art vectorization, and animation tracking applications, artists inpaint and reconstruct broken or blurred regions in cartoon images. Given the typicality of these involved applications, this dataset is also likely to be used in other cartoon techniques. We detail the challenges in achieving this dataset and present a human-in-the-loop workflow namely Feasibility-based Assignment Recommendation (FAR) to enable large-scale annotating. The FAR tends to reduce artist trails-and-errors and encourage their enthusiasm during annotating. Finally, we present a dataset that contains a large number of artistic region compositions paired with corresponding cartoon illustrations. We also invite multiple professional artists to assure the quality of each annotation."
"Maksim Golyadkin, Ilya Makarov",d937684a392b110fd4b6e28dfa4ca8eaee552d78,Semi-automatic Manga Colorization Using Conditional Adversarial Networks,AIST,2020.0,1,"Manga colorization is time-consuming and hard to automate. In this paper, we propose a conditional adversarial deep learning approach for semi-automatic manga images colorization. The system directly maps a tuple of grayscale manga page image and sparse color hint constructed by the user to an output colorization. High-quality colorization can be obtained in a fully automated way, and color hints allow users to revise the colorization of every panel independently. We collect a dataset of manually colorized and grayscale manga images for training and evaluation. To perform supervised learning, we construct synthesized monochrome images from colorized. Furthermore, we suggest a few steps to reduce the domain gap between synthetic and real data. Their influence is evaluated both quantitatively and qualitatively. Our method can achieve even better results by fine-tuning with a small number of grayscale manga images of a new style. The code is available at github.com."
"Ushasi Chaudhuri, Biplab Banerjee, A. Bhattacharya, M. Datcu",15bdad0add3d4773c12570b976d4dde28b3c9b28,CrossATNet - a novel cross-attention based framework for sketch-based image retrieval,Image Vis. Comput.,2020.0,0,"Abstract We propose a novel framework for cross-modal zero-shot learning (ZSL) in the context of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema mainly considers simultaneous mappings among the two image views and the semantic side information. Therefore, it is desirable to consider fine-grained classes mainly in the sketch domain using highly discriminative and semantically rich feature space. However, the existing deep generative modeling based SBIR approaches majorly focus on bridging the gaps between the seen and unseen classes by generating pseudo-unseen-class samples. Besides, violating the ZSL protocol by not utilizing any unseen-class information during training, such techniques do not pay explicit attention to modeling the discriminative nature of the shared space. Also, we note that learning a unified feature space for both the multi-view visual data is a tedious task considering the significant domain difference between sketches and the color images. In this respect, as a remedy, we introduce a novel framework for zero-shot SBIR. While we define a cross-modal triplet loss to ensure the discriminative nature of the shared space, an innovative cross-modal attention learning strategy is also proposed to guide feature extraction from the image domain exploiting information from the respective sketch counterpart. In order to preserve the semantic consistency of the shared space, we consider a graph CNN based module which propagates the semantic class topology to the shared space. To ensure an improved response time during inference, we further explore the possibility of representing the shared space in terms of hash-codes. Experimental results obtained on the benchmark TU-Berlin and the Sketchy datasets confirm the superiority of CrossATNet in yielding the state-of-the-art results."
"K. M. A. Sultan, M. Jubair, Md. Nahidul Islam, Sayed Hossain Khan",1546f2b54c71d082d20311331ec011d197f06b83,toon2real: Translating Cartoon Images to Realistic Images,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),2020.0,0,"In terms of Image-to-image translation, Generative Adversarial Networks (GANs) has achieved great success even when it is used in the unsupervised dataset. In this work, we aim to translate cartoon images to photo-realistic images using GAN. We apply several state-of-the-art models to perform this task; however, they fail to perform good quality translations. We observe that the shallow difference between these two domains causes this issue. Based on this idea, we propose a method based on CycleGAN model for image translation from cartoon domain to photo-realistic domain. To make our model efficient, we implemented Spectral Normalization which added stability in our model. We demonstrate our experimental results and show that our proposed model has achieved the lowest Fréchet Inception Distance score and better results compared to another state-of-the-art technique, UNIT."
"Jatin Sharma, Shobha Lata",af3ac0dee3b0fa92ab67ebe07d60918c4ff4d47f,Draw your Neural Networks,ArXiv,2020.0,0,"Deep Neural Networks are the basic building blocks of modern Artificial Intelligence. They are increasingly replacing or augmenting existing software systems due to their ability to learn directly from the data and superior accuracy on variety of tasks. Existing Software Development Life Cycle (SDLC) methodologies fall short on representing the unique capabilities and requirements of AI Development and must be replaced with Artificial Intelligence Development Life Cycle (AIDLC) methodologies. In this paper, we discuss an alternative and more natural approach to develop neural networks that involves intuitive GUI elements such as blocks and lines to draw them instead of complex computer programming. We present Sketch framework, that uses this GUI-based approach to design and modify the neural networks and provides interoperability with traditional frameworks. The system provides popular layers and operations out-of-the-box and could import any supported pre-trained model making it a faster method to design and train complex neural networks and ultimately democratizing the AI by removing the learning curve."
"Yan Yang, M. Hossain, T. Gedeon, Shafin Rahman",d80c5166708ce51d66d1dc3d59ef17c45d10e937,S2FGAN: Semantically Aware Interactive Sketch-to-Face Translation,ArXiv,2020.0,0,"Interactive facial image manipulation attempts to edit single and multiple face attributes using a photo-realistic face and/or semantic mask as input. In the absence of the photo-realistic image (only sketch/mask available), previous methods only retrieve the original face but ignore the potential of aiding model controllability and diversity in the translation process. This paper proposes a sketch-to-image generation framework called S2FGAN, aiming to improve users' ability to interpret and flexibility of face attribute editing from a simple sketch. The proposed framework modifies the constrained latent space semantics trained on Generative Adversarial Networks (GANs). We employ two latent spaces to control the face appearance and adjust the desired attributes of the generated face. Instead of constraining the translation process by using a reference image, the users can command the model to retouch the generated images by involving the semantic information in the generation process. In this way, our method can manipulate single or multiple face attributes by only specifying attributes to be changed. Extensive experimental results on CelebAMask-HQ dataset empirically shows our superior performance and effectiveness on this task. Our method successfully outperforms state-of-the-art methods on attribute manipulation by exploiting greater control of attribute intensity."
"Yuhan Wang, Z. Lei, Liang Lan",9229dee18adce0f90de332f98fc56b90a991d979,Effective and Sparse Count-Sketch via k-means clustering,ArXiv,2020.0,0,"Count-sketch is a popular matrix sketching algorithm that can produce a sketch of an input data matrix X in O(nnz(X))time where nnz(X) denotes the number of non-zero entries in X. The sketched matrix will be much smaller than X while preserving most of its properties. Therefore, count-sketch is widely used for addressing high-dimensionality challenge in machine learning. However, there are two main limitations of count-sketch: (1) The sketching matrix used count-sketch is generated randomly which does not consider any intrinsic data properties of X. This data-oblivious matrix sketching method could produce a bad sketched matrix which will result in low accuracy for subsequent machine learning tasks (e.g.classification); (2) For highly sparse input data, count-sketch could produce a dense sketched data matrix. This dense sketch matrix could make the subsequent machine learning tasks more computationally expensive than on the original sparse data X. To address these two limitations, we first show an interesting connection between count-sketch and k-means clustering by analyzing the reconstruction error of the count-sketch method. Based on our analysis, we propose to reduce the reconstruction error of count-sketch by using k-means clustering algorithm to obtain the low-dimensional sketched matrix. In addition, we propose to solve k-mean clustering using gradient descent with -L1 ball projection to produce a sparse sketched matrix. Our experimental results based on six real-life classification datasets have demonstrated that our proposed method achieves higher accuracy than the original count-sketch and other popular matrix sketching algorithms. Our results also demonstrate that our method produces a sparser sketched data matrix than other methods and therefore the prediction cost of our method will be smaller than other matrix sketching methods."
"D. Law, X. Ji, F. Belfiore, M. Bershady, M. Cappellari, K. Westfall, R. Yan, D. Bizyaev, J. Brownstein, N. Drory, B. Andrews",d6d7910b02f72a78201a2b210b988fd6dee65c3d,SDSS-IV MaNGA: Refining Strong Line Diagnostic Classifications Using Spatially Resolved Gas Dynamics,,2020.0,0,"We use the statistical power of the MaNGA integral-field spectroscopic galaxy survey to improve the definition of strong line diagnostic boundaries used to classify gas ionization properties in galaxies. We detect line emission from 3.6 million spaxels distributed across 7400 individual galaxies spanning a wide range of stellar masses, star formation rates, and morphological types, and find that the gas-phase velocity dispersion σ Hα correlates strongly with traditional optical emission-line ratios such as [S ii]/Hα, [N ii]/Hα, [O i]/Hα, and [O iii]/Hβ. Spaxels whose line ratios are most consistent with ionization by galactic H ii regions exhibit a narrow range of dynamically cold line-of-sight velocity distributions (LOSVDs) peaked around 25 km s−1 corresponding to a galactic thin disk, while those consistent with ionization by active galactic nuclei (AGNs) and low-ionization emission-line regions (LI(N)ERs) have significantly broader LOSVDs extending to 200 km s−1. Star-forming, AGN, and LI(N)ER regions are additionally well separated from each other in terms of their stellar velocity dispersion, stellar population age, Hα equivalent width, and typical radius within a given galaxy. We use our observations to revise the traditional emission-line diagnostic classifications so that they reliably identify distinct dynamical samples both in two-dimensional representations of the diagnostic line ratio space and in a multidimensional space that accounts for the complex folding of the star-forming model surface. By comparing the MaNGA observations to the SDSS single-fiber galaxy sample, we note that the latter is systematically biased against young, low-metallicity star-forming regions that lie outside of the 3″ fiber footprint."
Funda Durupinar,bc3b6a00c7a3707de58f2e03ca772a57e395b737,Personality-Driven Gaze Animation with Conditional Generative Adversarial Networks,ArXiv,2020.0,0,"We present a generative adversarial learning approach to synthesize gaze behavior of a given personality. We train the model using an existing data set that comprises eye-tracking data and personality traits of 42 participants performing an everyday task. Given the values of Big-Five personality traits (openness, conscientiousness, extroversion, agreeableness, and neuroticism), our model generates time series data consisting of gaze target, blinking times, and pupil dimensions. We use the generated data to synthesize the gaze motion of virtual agents on a game engine."
"X. Tan, W. Lyu, A. Rosendo",7ef7e63e39923f2eb1fbc58aea43d83b8e98a4b0,CircuitBot: Learning to Survive with Robotic Circuit Drawing,ArXiv,2020.0,0,"Robots with the ability to actively acquire power from surroundings will be greatly beneficial for long-term autonomy, and to survive in dynamic, uncertain environments. In this work, a scenario is presented where a robot has limited energy, and the only way to survive is to access the energy from a power source. With no cables or wires available, the robot learns to construct an electrical path and avoid potential obstacles during the connection. We present this robot, capable of drawing connected circuit patterns with graphene-based conductive ink. A state-of-the-art Mix-Variable Bayesian Optimization is adopted to optimize the placement of conductive shapes to maximize the power this robot receives. Our results show that, within a small number of trials, the robot learns to build parallel circuits to maximize the voltage received and avoid obstacles which steal energy from the robot."
"Yunkui Pang, Zhiqing Pan, Ruiyang Sun, Shuchong Wang",5a565aef3e61187d92aa2fa61fb6ee294a63be8e,Sketch-Inspector: a Deep Mixture Model for High-Quality Sketch Generation of Cats,ISVC,2020.0,0,"With the involvement of artificial intelligence (AI), sketches can be automatically generated under certain topics. Even though breakthroughs have been made in previous studies in this area, a relatively high proportion of the generated figures are too abstract to recognize, which illustrates that AIs fail to learn the general pattern of the target object when drawing. This paper posits that supervising the process of stroke generation can lead to a more accurate sketch interpretation. Based on that, a sketch generating system with an assistant convolutional neural network (CNN) predictor to suggest the shape of the next stroke is presented in this paper. In addition, a CNN-based discriminator is introduced to judge the recognizability of the end product. Since the base-line model is ineffective at generating multi-class sketches, we restrict the model to produce one category. Because the image of a cat is easy to identify, we consider cat sketches selected from the QuickDraw data set. This paper compares the proposed model with the original Sketch-RNN on 75K human-drawn cat sketches. The result indicates that our model produces sketches with higher quality than human's sketches."
"Ilkin Safarli, Youjia Zhou, Bei Wang",114d60778a8f48c78f205ebe41d5ef25e04286d4,Interpreting Graph Drawing with Multi-Agent Reinforcement Learning,ArXiv,2020.0,0,"Applying machine learning techniques to graph drawing has become an emergent area of research in visualization. In this paper, we interpret graph drawing as a multi-agent reinforcement learning (MARL) problem. We first demonstrate that a large number of classic graph drawing algorithms, including force-directed layouts and stress majorization, can be interpreted within the framework of MARL. Using this interpretation, a node in the graph is assigned to an agent with a reward function. Via multi-agent reward maximization, we obtain an aesthetically pleasing graph layout that is comparable to the outputs of classic algorithms. The main strength of a MARL framework for graph drawing is that it not only unifies a number of classic drawing algorithms in a general formulation, but also supports the creation of novel graph drawing algorithms by introducing a diverse set of reward functions."
"F. Geiger, Michelle Martin, Monika Pichlmair, Ilhan Aslan, Hannes Ritschel, Björn Bittner, Elisabeth Andr'e",b7cd12c96381989f1b122c095f095e0d322d4e1e,Drawing with AI - Exploring Collaborative Inking Experiences Based on Mid-air Pointing and Reinforcement Learning,ArXiv,2020.0,0,"Digitalization is changing the nature of tools and materials, which are used in artistic practices in professional and non-professional settings. For example, today it is common that even children express their ideas and explore their creativity by drawing on tablets as digital canvases. While there are many software-based tools, which resemble traditional tools, such as various forms of virtual brushes, erasers, etc. in contrast to traditional materials there is potential in augmenting software-based tools and digital canvases with artificial intelligence. Curious about how it would feel to interact with a digital canvas, which would be in contrast to a traditional canvas dynamic, responsive, and potentially able to continuously adapt to its user's input, we developed a drawing application and conducted a qualitative study with 14 users. In this paper, we describe details of our design process, which lead up to using a k-armed bandit as a simple form of reinforcement learning and a LeapMotion sensor to allow people from all walks of like, old and young to draw on pervasive displays, small and large, positioned near or far."
"Juli'an Del Gobbo, Rosana Matuk Herrera",3912eebbd9f9f2ef27dcad7cfbfcb0049601082b,Unconstrained Text Detection in Manga,ArXiv,2020.0,0,"The detection and recognition of unconstrained text is an open problem in research. Text in comic books has unusual styles that raise many challenges for text detection. This work aims to identify text characters at a pixel level in a comic genre with highly sophisticated text styles: Japanese manga. To overcome the lack of a manga dataset with individual character level annotations, we create our own. Most of the literature in text detection use bounding box metrics, which are unsuitable for pixel-level evaluation. Thus, we implemented special metrics to evaluate performance. Using these resources, we designed and evaluated a deep network model, outperforming current methods for text detection in manga in most metrics."
"Faria Huq, Anindya Iqbal, Nafees Ahmed",b17867c98b87929945c1472e503f9441193236f0,Holistic static and animated 3D scene generation from diverse text descriptions,ArXiv,2020.0,0,"We propose a framework for holistic static and animated 3D scene generation from diverse text descriptions. Prior works of scene generation rely on static rule-based entity extraction from natural language description. However, this limits the usability of a practical solution. To overcome this limitation, we use one of state-of-the-art architecture - TransformerXL. Instead of rule-based extraction, our framework leverages the rich contextual encoding which allows us to process a larger range (diverse) of possible natural language descriptions. We empirically show how our proposed mechanism generalizes even on novel combinations of object-features during inference. We also show how our framework can jointly generate static and animated 3D scene efficiently. We modify CLEVR to generate a large, scalable dataset - Integrated static and animated 3D scene (Iscene). Data preparation code and pre-trained model available at - this https URL."
"Zheng Gu, Chuanqi Dong, Jing Huo, Wenbin Li, Yang Gao",cc3e53365dc25d4015da37664e5908496a071d6d,CariMe: Unpaired Caricature Generation with Multiple Exaggerations,ArXiv,2020.0,0,"Caricature generation aims to translate real photos into caricatures with artistic styles and shape exaggerations while maintaining the identity of the subject. Different from the generic image-to-image translation, drawing a caricature automatically is a more challenging task due to the existence of various spacial deformations. Previous caricature generation methods are obsessed with predicting definite image warping from a given photo while ignoring the intrinsic representation and distribution for exaggerations in caricatures. This limits their ability on diverse exaggeration generation. In this paper, we generalize the caricature generation problem from instance-level warping prediction to distribution-level deformation modeling. Based on this assumption, we present the first exploration for unpaired CARIcature generation with Multiple Exaggerations (CariMe). Technically, we propose a Multi-exaggeration Warper network to learn the distribution-level mapping from photo to facial exaggerations. This makes it possible to generate diverse and reasonable exaggerations from randomly sampled warp codes given one input photo. To better represent the facial exaggeration and produce fine-grained warping, a deformation-field-based warping method is also proposed, which helps us to capture more detailed exaggerations than other point-based warping methods. Experiments and two perceptual studies prove the superiority of our method comparing with other state-of-the-art methods, showing the improvement of our work on caricature generation."
"Andre Beckus, George K. Atia",1147972b8d8bd834bb3f48a7581e52aa7c98fa86,Sketch-based community detection in evolving networks,ArXiv,2020.0,0,"We consider an approach for community detection in time-varying networks. At its core, this approach maintains a small sketch graph to capture the essential community structure found in each snapshot of the full network. We demonstrate how the sketch can be used to explicitly identify six key community events which typically occur during network evolution: growth, shrinkage, merging, splitting, birth and death. Based on these detection techniques, we formulate a community detection algorithm which can process a network concurrently exhibiting all processes. One advantage afforded by the sketch-based algorithm is the efficient handling of large networks. Whereas detecting events in the full graph may be computationally expensive, the small size of the sketch allows changes to be quickly assessed. A second advantage occurs in networks containing clusters of disproportionate size. The sketch is constructed such that there is equal representation of each cluster, thus reducing the possibility that the small clusters are lost in the estimate. We present a new standardized benchmark based on the stochastic block model which models the addition and deletion of nodes, as well as the birth and death of communities. When coupled with existing benchmarks, this new benchmark provides a comprehensive suite of tests encompassing all six community events. We provide a set of numerical results demonstrating the advantages of our approach both in run time and in the handling of small clusters."
"Vincent Schellekens, L. Jacques",ed980b4e65e29ee845563fe3b43d50df6ad150a3,When compressive learning fails: blame the decoder or the sketch?,ArXiv,2020.0,0,"In compressive learning, a mixture model (a set of centroids or a Gaussian mixture) is learned from a sketch vector, that serves as a highly compressed representation of the dataset. This requires solving a non-convex optimization problem, hence in practice approximate heuristics (such as CLOMPR) are used. In this work we explore, by numerical simulations, properties of this non-convex optimization landscape and those heuristics."
"K. Chung, De-Wei Hsieh",f95e2909a029c9acde696bf76f1d82aeffb96698,Novel and Effective CNN-Based Binarization for Historically Degraded As-built Drawing Maps,ArXiv,2020.0,0,"Binarizing historically degraded as-built drawing (HDAD) maps is a new challenging job, especially in terms of removing the three artifacts, namely noise, the yellowing areas, and the folded lines, while preserving the foreground components well. In this paper, we first propose a semi-automatic labeling method to create the HDAD-pair dataset of which each HDAD-pair consists of one HDAD map and its binarized HDAD map. Based on the created training HDAD-pair dataset, we propose a convolutional neural network-based (CNN-based) binarization method to produce high-quality binarized HDAD maps. Based on the testing HDAD maps, the thorough experimental data demonstrated that in terms of the accuracy, PSNR (peak-signal-to-noise-ratio), and the perceptual effect of the binarized HDAD maps, our method substantially outperforms the nine existing binarization methods. In addition, with similar accuracy, the experimental results demonstrated the significant execution-time reduction merit of our method relative to the retrained version of the state-of-the-art CNN-based binarization methods."
"Juli'an Del Gobbo, Rosana Matuk Herrera",80b802e551b5f4f34d5596c1595abe6ea7b2334a,Unconstrained Text Detection in Manga: a New Dataset and Baseline,ECCV Workshops,2020.0,0,"The detection and recognition of unconstrained text is an open problem in research. Text in comic books has unusual styles that raise many challenges for text detection. This work aims to binarize text in a comic genre with highly sophisticated text styles: Japanese manga. To overcome the lack of a manga dataset with text annotations at a pixel level, we create our own. To improve the evaluation and search of an optimal model, in addition to standard metrics in binarization, we implement other special metrics. Using these resources, we designed and evaluated a deep network model, outperforming current methods for text binarization in manga in most metrics."
"Julian Walter, J. Zink, J. Baumeister, A. Wolff",69e38a1ad1a9c3d905371d3bb172a31a1429f80f,Layered Drawing of Undirected Graphs with Generalized Port Constraints,Graph Drawing,2020.0,0,"The aim of this research is a practical method to draw cable plans of complex machines. Such plans consist of electronic components and cables connecting specific ports of the components. Since the machines are configured for each client individually, cable plans need to be drawn automatically. The drawings must be well readable so that technicians can use them to debug the machines. In order to model plug sockets, we introduce port groups; within a group, ports can change their position (which we use to improve the aesthetics of the layout), but together the ports of a group must form a contiguous block. 
We approach the problem of drawing such cable plans by extending the well-known Sugiyama framework such that it incorporates ports and port groups. Since the framework assumes directed graphs, we propose several ways to orient the edges of the given undirected graph. We compare these methods experimentally, both on real-world data and synthetic data that carefully simulates real-world data. We measure the aesthetics of the resulting drawings by counting bends and crossings. Using these metrics, we compare our approach to Kieler [JVLC 2014], a library for drawing graphs in the presence of port constraints."
"Christoph Hertrich, F. Schröder, R. Steiner",bee1ceba06d3c12653bb5a2666fbb016a31edb60,Coloring Drawings of Graphs,ArXiv,2020.0,0,"We consider face-colorings of drawings of graphs in the plane. Given a multi-graph $G$ together with a drawing $\Gamma(G)$ in the plane with only finitely many crossings, we define a face-$k$-coloring of $\Gamma(G)$ to be a coloring of the maximal connected regions of the drawing, the faces, with $k$ colors such that adjacent faces have different colors. By the $4$-color theorem, every drawing of a bridgeless graph has a face-$4$-coloring. A drawing of a graph is facially $2$-colorable if and only if the underlying graph is Eulerian. We show that every graph without degree 1 vertices admits a $3$-colorable drawing. This leads to the natural question which graphs $G$ have the property that each of its drawings has a $3$-coloring. We say that such a graph $G$ is facially $3$-colorable. We derive several sufficient and necessary conditions for this property: we show that every $4$-edge-connected graph and every graph admitting a nowhere-zero $3$-flow is facially $3$-colorable. We also discuss circumstances under which facial $3$-colorability guarantees the existence of a nowhere-zero $3$-flow. On the negative side, we present an infinite family of facially $3$-colorable graphs without a nowhere-zero $3$-flow. On the positive side, we formulate a conjecture which has a surprising relation to a famous open problem by Tutte known as the $3$-flow-conjecture. We prove our conjecture for subcubic and for $K_{3,3}$-minor-free graphs."
"O. Aichholzer, M. Hoffmann, Johannes Obenaus, Rosna Paul, Daniel Perz, Nadja Seiferth, B. Vogtenhuber, A. Weinberger",a4e6ca08d9bf64629bdda53365234b05fc58b9d5,Plane Spanning Trees in Edge-Colored Simple Drawings of Kn,Graph Drawing,2020.0,0,"Karolyi, Pach, and Toth proved that every 2-edge-colored straight-line drawing of the complete graph contains a monochromatic plane spanning tree. It is open if this statement generalizes to other classes of drawings, specifically, to simple drawings of the complete graph. These are drawings where edges are represented by Jordan arcs, any two of which intersect at most once. We present two partial results towards such a generalization. First, we show that the statement holds for cylindrical simple drawings. (In a cylindrical drawing, all vertices are placed on two concentric circles and no edge crosses either circle.) Second, we introduce a relaxation of the problem in which the graph is $k$-edge-colored, and the target structure must be hypochromatic, that is, avoid (at least) one color class. In this setting, we show that every $\lceil (n+5)/6\rceil$-edge-colored monotone simple drawing of $K_n$ contains a hypochromatic plane spanning tree. (In a monotone drawing, every edge is represented as an $x$-monotone curve.)"
"Ushasi Chaudhuri, Biplab Banerjee, A. Bhattacharya, M. Datcu",5aa194c1d0dad1f689c7c222135e93fa011a985e,A Zero-Shot Sketch-based Inter-Modal Object Retrieval Scheme for Remote Sensing Images,ArXiv,2020.0,0,"Conventional existing retrieval methods in remote sensing (RS) are often based on a uni-modal data retrieval framework. In this work, we propose a novel inter-modal triplet-based zero-shot retrieval scheme utilizing a sketch-based representation of RS data. The proposed scheme performs efficiently even when the sketch representations are marginally prototypical of the image. We conducted experiments on a new bi-modal image-sketch dataset called Earth on Canvas (EoC) conceived during this study. We perform a thorough bench-marking of this dataset and demonstrate that the proposed network outperforms other state-of-the-art methods for zero-shot sketch-based retrieval framework in remote sensing."
"Xiaoyu Li, Bo Zhang, Jing Liao, P. Sander",034300b0576f3291c8bb5f29bd9ef221d4244c6b,Deep Sketch-guided Cartoon Video Synthesis,ArXiv,2020.0,0,"We propose a novel framework to produce cartoon videos by fetching the color information from two input keyframes while following the animated motion guided by a user sketch. The key idea of the proposed approach is to estimate the dense cross-domain correspondence between the sketch and cartoon video frames, following by a blending module with occlusion estimation to synthesize the middle frame guided by the sketch. After that, the inputs and the synthetic frame equipped with established correspondence are fed into an arbitrary-time frame interpolation pipeline to generate and refine additional inbetween frames. Finally, a video post-processing approach is used to further improve the result. Compared to common frame interpolation methods, our approach can address frames with relatively large motion and also has the flexibility to enable users to control the generated video sequences by editing the sketch guidance. By explicitly considering the correspondence between frames and the sketch, our methods can achieve high-quality synthetic results compared with image synthesis methods. Our results show that our system generalizes well to different movie frames, achieving better results than existing solutions."
"Nan Zhuang, Cheng Yang",27e0aabd3e58413f6796bbc820a416875591b169,Few-shot Knowledge Transfer for Fine-grained Cartoon Face Generation,ArXiv,2020.0,0,"In this paper, we are interested in generating fine-grained cartoon faces for various groups. We assume that one of these groups consists of sufficient training data while the others only contain few samples. Although the cartoon faces of these groups share similar style, the appearances in various groups could still have some specific characteristics, which makes them differ from each other. A major challenge of this task is how to transfer knowledge among groups and learn group-specific characteristics with only few samples. In order to solve this problem, we propose a two-stage training process. First, a basic translation model for the basic group (which consists of sufficient data) is trained. Then, given new samples of other groups, we extend the basic model by creating group-specific branches for each new group. Group-specific branches are updated directly to capture specific appearances for each group while the remaining group-shared parameters are updated indirectly to maintain the distribution of intermediate feature space. In this manner, our approach is capable to generate high-quality cartoon faces for various groups."
"Benjamin W. Priest, Alec M. Dunton, G. Sanders",3121e21bc64f8413a327582605ccdc131ea534ec,Scaling Graph Clustering with Distributed Sketches,2020 IEEE High Performance Extreme Computing Conference (HPEC),2020.0,0,"The unsupervised learning of community structure, in particular the partitioning vertices into clusters or communities, is a canonical and well-studied problem in exploratory graph analysis. However, like most graph analyses the introduction of immense scale presents challenges to traditional methods. Spectral clustering in distributed memory, for example, requires hundreds of expensive bulk-synchronous communication rounds to compute an embedding of vertices to a few eigenvectors of a graph associated matrix. Furthermore, the whole computation might need to be repeated if the underlying graph changes some low percentage of edge updates. We present a method inspired by spectral clustering where we instead use matrix sketches derived from random dimension-reducing projections. We show that our method produces embeddings that yield performant clustering results given a fully-dynamic stochastic block model stream using both the fast Johnson-Lindenstrauss and CountSketch transforms. We also discuss the effects of stochastic block model parameters upon the required dimensionality of the subsequent embeddings, and show how random projections could significantly improve the performance of graph clustering in distributed memory."
"O. Giudice, Dario Allegra, Francesco Guarnera, F. Stanco, S. Battiato",14888e1b2a21c16cbe7497cb9313eb8f46568e5b,Animated Gif Optimization By Adaptive Color Local Table Management,2020 IEEE International Conference on Image Processing (ICIP),2020.0,0,"After thirty years of the GIF file format, today is becoming more popular than ever: being a great way of communication for friends and communities on Instant Messengers and Social Networks. While being so popular, the original compression method to encode GIF images have not changed a bit. On the other hand popularity means that storage saving becomes an issue for hosting platforms. In this paper a parametric optimization technique for animated GIFs will be presented. The proposed technique is based on Local Color Table selection and color remapping in order to create optimized animated GIFs while preserving the original format. The technique achieves good results in terms of byte reduction with limited or no loss of perceived color quality. Tests carried out on 1000 GIF files demonstrate the effectiveness of the proposed optimization strategy."
"Peng Xu, Yongye Huang, Tongtong Yuan, Tao Xiang, Timothy M. Hospedales, Yi-Zhe Song, Liang Wang",4ff9df1d2a289a3cb04cbb129cdcb8a5d9085f94,On Learning Semantic Representations for Million-Scale Free-Hand Sketches,ArXiv,2020.0,0,"In this paper, we study learning semantic representations for million-scale free-hand sketches. This is highly challenging due to the domain-unique traits of sketches, e.g., diverse, sparse, abstract, noisy. We propose a dual-branch CNNRNN network architecture to represent sketches, which simultaneously encodes both the static and temporal patterns of sketch strokes. Based on this architecture, we further explore learning the sketch-oriented semantic representations in two challenging yet practical settings, i.e., hashing retrieval and zero-shot recognition on million-scale sketches. Specifically, we use our dual-branch architecture as a universal representation framework to design two sketch-specific deep models: (i) We propose a deep hashing model for sketch retrieval, where a novel hashing loss is specifically designed to accommodate both the abstract and messy traits of sketches. (ii) We propose a deep embedding model for sketch zero-shot recognition, via collecting a large-scale edge-map dataset and proposing to extract a set of semantic vectors from edge-maps as the semantic knowledge for sketch zero-shot domain alignment. Both deep models are evaluated by comprehensive experiments on million-scale sketches and outperform the state-of-the-art competitors."
"D. Shamma, Anthony Dunnigan, L. Kennedy",04187259522208047aa862defba3fe4344b9b3f8,Automatic Photo to Ideophone Manga Matching,ArXiv,2020.0,0,"Photo applications offer tools for annotation via text and stickers. Ideophones, mimetic and onomatopoeic words, which are common in graphic novels, have yet to be explored for photo annotation use. We present a method for automatic ideophone recommendation and positioning of the text on photos. These annotations are accomplished by obtaining a list of ideophones with English definitions and applying a suite of visual object detectors to the image. Next, a semantic embedding maps the visual objects to the possible relevant ideophones. Our system stands in contrast to traditional computer vision-based annotation systems, which stop at recommending object and scene-level annotation, by providing annotations that are communicative, fun, and engaging. We test these annotations in Japanese and find they carry a strong preference and increase enjoyment and sharing likelihood when compared to unannotated and object-based annotated photos."
"L.S.Pilyugin, E.K.Grebel, I.A.Zinchenko, M.A.Lara-Lopez, Y.A.Nefedyev, V.M.Shulga",84968a1d0b671c847b6e095696d5b1228d278c00,Circumnuclear regions of different BPT types in star-forming MaNGA galaxies: AGN detectability,,2020.0,0,"We consider the circumnuclear regions of star-forming MaNGA galaxies. The spaxels spectra are classified as active-galactic-nucleuslike (AGN-like), H II-region-like (or SF-like), and intermediate (INT) spectra according to their positions on the Baldwin-PhillipsTerlevich (BPT) diagram. There are the following four configurations of the radiation distributions in the circumnuclear regions in (massive) galaxies: 1) AGN+INT, the innermost region of the AGN-like radiation is surrounded by a ring of radiation of the intermediate type; 2) INT, the central area of radiation of the intermediate type; 3) SF+INT, the inner region of the H II-region-like radiation is surrounded by a ring of radiation of the intermediate type; and 4) SF, the central area of the H II-region-like radiation only. The low ionization nuclear emission line regions (LINERs) of configurations 1 and 2 are examined. The spaxel spectra of the LINERs form a sequences on the BPT diagram, that is, they lie along the known AGN-SF mixing line trajectories. The diagnostic line ratios of the spaxels spectra change smoothly with radius, from AGN-like (or INT) line ratios at the galactic center to H II-region-like at larger galactocentric distances. This is in agreement with the paradigm that the LINERs are excited by AGN activity. We found that the AGN and INT radiation in the circumnuclear region is accompanied by an enhanced gas velocity dispersion σgas. The radius of the area of the AGN and INT radiation is similar to the radius of the area with enhanced σgas, and the central σgas,c correlates with the luminosity of the AGN+INT area. We assume that the gas velocity dispersion can serve as an indicator of the AGN activity. An appreciable enhancement of σgas,c was also measured in the SF-type centers of massive galaxies. The values of σgas,c for the SF-type centers partly overlap with those of the AGN-type centers. This suggests that the manifestation of the circumnuclear region as AGN or as SF on the BPT diagram depends not only on the value of σgas,c (the level of the AGN activity) but it is also governed by an additional parameter(s). We find that there is a demarcation line between the positions of the AGN-type and SF-type objects on the central gas velocity dispersion – central Hα surface brightness diagram, in the sense that an object with a given value of σgas,c is an AGN-type only if the central Hα surface brightness is lower than some value."
"Filip Andersson, Simon Arvidsson",56c2089a44c576a05d340d4dc14afa61d7e016df,Generative Adversarial Networks for photo to Hayao Miyazaki style cartoons,ArXiv,2020.0,0,"This paper takes on the problem of transferring the style of cartoon images to real-life photographic images by implementing previous work done by CartoonGAN. We trained a Generative Adversial Network(GAN) on over 60 000 images from works by Hayao Miyazaki at Studio Ghibli. To evaluate our results, we conducted a qualitative survey comparing our results with two state-of-the-art methods. 117 survey results indicated that our model on average outranked state-of-the-art methods on cartoon-likeness."
"Manish Bhattarai, D. Oyen, J. Castorena, Liping Yang, B. Wohlberg",c26752aa3969fe3a94005090f1cb705a50fb58d7,Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2020.0,0,"Resolution of the complex problem of image retrieval for diagram images has yet to be reached. Deep learning methods continue to excel in the fields of object detection and image classification applied to natural imagery. However, the application of such methodologies applied to binary imagery remains limited due to lack of crucial features such as textures,color and intensity information. This paper presents a deep learning based method for image-based search for binary patent images by taking advantage of existing large natural image repositories for image search and sketch-based methods (Sketches are not identical to diagrams, but they do share some characteristics; for example, both imagery types are gray scale (binary), composed of contours, and are lacking in texture). We begin by using deep learning to generate sketches from natural images for image retrieval and then train a second deep learning model on the sketches. We then use our small set of manually labeled patent diagram images via transfer learning to adapt the image search from sketches of natural images to diagrams. Our experiment results show the effectiveness of deep learning with transfer learning for detecting near-identical copies in patent images and querying similar images based on content."
"Zhang Qian, Wang Bo, Wen Wei, Li Hai, L. Hui",88da334b236cd2acec9b452aacfb57450a63b7a3,Line Art Correlation Matching Network for Automatic Animation Colorization,,2020.0,0,"Automatic animation line art colorization is a challenging computer vision problem since line art is a highly sparse and abstracted information and there exists a strict requirement for the color and style consistency between frames. Recently, a lot of GAN(Generative Adversarial Network) based image-to-image transfer method for single line art colorization has emerged. ey can generate perceptually appealing result conditioned on line art. However,these methods can not be adopted to the task of animation colorization because of the lack of consideration of in-between frame consistency. Existing Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permied. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee. Request permissions from permissions@acm.org."
"Zuheng Ming, J. Burie, Muhammad Muzzamil Luqman",7a49bed6ce511a892737970f361c4990ace75d2a,Cross-modal Multi-task Learning for Graphic Recognition of Caricature Face,ArXiv,2020.0,0,"Face recognition of realistic visual images has been well studied and made a significant progress in the recent decade. Unlike the realistic visual images, the face recognition of the caricatures is far from the performance of the visual images. This is largely due to the extreme non-rigid distortions of the caricatures introduced by exaggerating the facial features to strengthen the characters. The heterogeneous modalities of the caricatures and the visual images result the caricature-visual face recognition is a cross-modal problem. In this paper, we propose a method to conduct caricature-visual face recognition via multi-task learning. Rather than the conventional multi-task learning with fixed weights of tasks, this work proposes an approach to learn the weights of tasks according to the importance of tasks. The proposed multi-task learning with dynamic tasks weights enables to appropriately train the hard task and easy task instead of being stuck in the over-training easy task as conventional methods. The experimental results demonstrate the effectiveness of the proposed dynamic multi-task learning for cross-modal caricature-visual face recognition. The performances on the datasets CaVI and WebCaricature show the superiority over the state-of-art methods."
"Yingyu Liang, Zhao Song, M. Wang, Lin F. Yang, X. Yang",31ede48853bf5aa52bc79e7b6326a06657e7ac3a,Sketching Transformed Matrices with Applications to Natural Language Processing,AISTATS,2020.0,0,"Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in memory but is in a disk or is presented in a data stream. However, we need to compute a matrix decomposition of the entry-wisely transformed matrix, $f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space efficient way? Many machine learning applications indeed need to deal with such large transformed matrices, for example word embedding method in NLP needs to work with the pointwise mutual information (PMI) matrix, while the entrywise transformation makes it difficult to apply known linear algebraic tools. Existing approaches for this problem either need to store the whole matrix and perform the entry-wise transformation afterwards, which is space consuming or infeasible, or need to redesign the learning method, which is application specific and requires substantial remodeling. 
In this paper, we first propose a space-efficient sketching algorithm for computing the product of a given small matrix with the transformed matrix. It works for a general family of transformations with provable small error bounds and thus can be used as a primitive in downstream learning tasks. We then apply this primitive to a concrete application: low-rank approximation. We show that our approach obtains small error and is efficient in both space and time. We complement our theoretical results with experiments on synthetic and real data."
"Haodi Hou, Jing Huo, J. Wu, Yu-Kun Lai, Y. Gao",0498a8d81f1c9521a93ff2a2ffdf7b2411294458,MW-GAN: Multi-Warping GAN for Caricature Generation with Multi-Style Geometric Exaggeration,ArXiv,2020.0,0,"Given an input face photo, the goal of caricature generation is to produce stylized, exaggerated caricatures that share the same identity as the photo. It requires simultaneous style transfer and shape exaggeration with rich diversity, and meanwhile preserving the identity of the input. To address this challenging problem, we propose a novel framework called Multi-Warping GAN (MW-GAN), including a style network and a geometric network that are designed to conduct style transfer and geometric exaggeration respectively. We bridge the gap between the style and landmarks of an image with corresponding latent code spaces by a dual way design, so as to generate caricatures with arbitrary styles and geometric exaggeration, which can be specified either through random sampling of latent code or from a given caricature sample. Besides, we apply identity preserving loss to both image space and landmark space, leading to a great improvement in quality of generated caricatures. Experiments show that caricatures generated by MW-GAN have better quality than existing methods."
"Yugang Chen, Muchun Chen, Chaoyue Song, Bingbing Ni",600b9eced5b9c399cf510dd3d908e97a61fd325f,CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator,MMM,2020.0,0,"Instance based photo cartoonization is one of the challenging image stylization tasks which aim at transforming realistic photos into cartoon style images while preserving the semantic contents of the photos. State-of-the-art Deep Neural Networks (DNNs) methods still fail to produce satisfactory results with input photos in the wild, especially for photos which have high contrast and full of rich textures. This is due to that: cartoon style images tend to have smooth color regions and emphasized edges which are contradict to realistic photos which require clear semantic contents, i.e., textures, shapes etc. Previous methods have difficulty in satisfying cartoon style textures and preserving semantic contents at the same time. In this work, we propose a novel ""CartoonRenderer"" framework which utilizing a single trained model to generate multiple cartoon styles. In a nutshell, our method maps photo into a feature model and renders the feature model back into image space. In particular, cartoonization is achieved by conducting some transformation manipulation in the feature space with our proposed Soft-AdaIN. Extensive experimental results show our method produces higher quality cartoon style images than prior arts, with accurate semantic content preservation. In addition, due to the decoupling of whole generating process into ""Modeling-Coordinating-Rendering"" parts, our method could easily process higher resolution photos, which is intractable for existing methods."
"Saisubramaniam Gopalakrishnan, Pranshu Ranjan Singh, Yasin Yazici, Chuan-Sheng Foo, V. Chandrasekhar, Arulmurugan Ambikapathi",404252910ac613b89c192555542f0821a3c2ece5,Classification Representations Can be Reused for Downstream Generations,ArXiv,2020.0,0,"Contrary to the convention of using supervision for class-conditioned $\it{generative}$ $\it{modeling}$, this work explores and demonstrates the feasibility of a learned supervised representation space trained on a discriminative classifier for the $\it{downstream}$ task of sample generation. Unlike generative modeling approaches that aim to $\it{model}$ the manifold distribution, we directly $\it{represent}$ the given data manifold in the classification space and leverage properties of latent space representations to generate new representations that are guaranteed to be in the same class. Interestingly, such representations allow for controlled sample generations for any given class from existing samples and do not require enforcing prior distribution. We show that these latent space representations can be smartly manipulated (using convex combinations of $n$ samples, $n\geq2$) to yield meaningful sample generations. Experiments on image datasets of varying resolutions demonstrate that downstream generations have higher classification accuracy than existing conditional generative models while being competitive in terms of FID."
"Hui Su, Jin Fang",a6b0788821ee54940c5518568671ff13320bfaa0,Avatar Artist Using GAN,,2020.0,0,"human sketches would be expressive and abstract at the same time. Generating anime avatars from simple or even bad face drawing is an interesting area. Lots of related work has been done such as auto-coloring sketches to anime or transforming real photos to anime. However, there aren’t many interesting works yet to show how to generate anime avatars from just some simple drawing input. In this project, we propose using GAN to generate anime avatars from sketches."
"K. Akita, Y. Morimoto, R. Tsuruno",ad8adbd99d50320789c06b5a6495b06b449efff0,Colorization of Line Drawings with Empty Pupils,Comput. Graph. Forum,2020.0,0,"Many studies have recently applied deep learning to the automatic colorization of line drawings. However, it is difficult to paint empty pupils using existing methods because the convolutional neural network are trained with pupils that have edges, which are generated from color images using image processing. Most actual line drawings have empty pupils that artists must paint in. In this paper, we propose a novel network model that transfers the pupil details in a reference color image to input line drawings with empty pupils. We also propose a method for accurately and automatically colorizing eyes. In this method, eye patches are extracted from a reference color image and automatically added to an input line drawing as color hints using our pupil position estimation network."
"Wenbo Zheng, Lan Yan, F. Wang, Chao Gou",cfb7b3cd096e571337f6a5fd6a26b94a982ca6d1,"Learning from the Past: Meta-Continual Learning with Knowledge Embedding for Jointly Sketch, Cartoon, and Caricature Face Recognition",ACM Multimedia,2020.0,0,"This paper deals with a challenging task of learning from different modalities by tackling the difficulty problem of jointly face recognition between abstract-like sketches, cartoons, caricatures and real-life photographs. Due to the significant variations in the abstract faces, building vision models for recognizing data from these modalities is an extremely challenging. We propose a novel framework termed as Meta-Continual Learning with Knowledge Embedding to address the task of jointly sketch, cartoon, and caricature face recognition. In particular, we firstly present a deep relational network to capture and memorize the relation among different samples. Secondly, we present the construction of our knowledge graph that relates image with the label as the guidance of our meta-learner. We then design a knowledge embedding mechanism to incorporate the knowledge representation into our network. Thirdly, to mitigate catastrophic forgetting, we use a meta-continual model that updates our ensemble model and improves its prediction accuracy. With this meta-continual model, our network can learn from its past. The final classification is derived from our network by learning to compare the features of samples. Experimental results demonstrate that our approach achieves significantly higher performance compared with other state-of-the-art approaches."
"Puneet Mangla, Nupur Kumari, M. Singh, V. Balasubramanian, Balaji Krishnamurthy",9003b24d61aeb282cd3467fbc46fb1c37a1a0cf2,Data Instance Prior for Transfer Learning in GANs,ArXiv,2020.0,0,"Recent advances in generative adversarial networks (GANs) have shown remarkable progress in generating high-quality images. However, this gain in performance depends on the availability of a large amount of training data. In limited data regimes, training typically diverges, and therefore the generated samples are of low quality and lack diversity. Previous works have addressed training in low data setting by leveraging transfer learning and data augmentation techniques. We propose a novel transfer learning method for GANs in the limited data domain by leveraging informative data prior derived from self-supervised/supervised pre-trained networks trained on a diverse source domain. We perform experiments on several standard vision datasets using various GAN architectures (BigGAN, SNGAN, StyleGAN2) to demonstrate that the proposed method effectively transfers knowledge to domains with few target images, outperforming existing state-of-the-art techniques in terms of image quality and diversity. We also show the utility of data instance prior in large-scale unconditional image generation and image editing tasks."
"Yeongseop Lee, Seongjin Lee",8e8b0174dabf6548f9bbf8050cfd0ee63bc999d6,Automatic Colorization of Anime Style Illustrations Using a Two-Stage Generator,,2020.0,0,"Line-arts are used in many ways in the media industry. However, line-art colorization is tedious, labor-intensive, and time consuming. For such reasons, a Generative Adversarial Network (GAN)-based image-to-image colorization method has received much attention because of its promising results. In this paper, we propose to use color a point hinting method with two GAN-based generators used for enhancing the image quality. To improve the coloring performance of drawing with various line styles, generator takes account of the loss of the line-art. We propose a Line Detection Model (LDM) which is used in measuring line loss. LDM is a method of extracting line from a color image. We also propose histogram equalizer in the input line-art to generalize the distribution of line styles. This approach allows the generalization of the distribution of line style without increasing the complexity of inference stage. In addition, we propose seven segment hint pointing constraints to evaluate the colorization performance of the model with Fréchet Inception Distance (FID) score. We present visual and qualitative evaluations of the proposed methods. The result shows that using histogram equalization and LDM enabled line loss exhibits the best result. The Base model with XDoG (eXtended Difference-Of-Gaussians)generated line-art with and without color hints exhibits FID for colorized images score of 35.83 and 44.70, respectively, whereas the proposed model in the same scenario exhibits 32.16 and 39.77, respectively."
"Damitha Sandeepa Lenadora, Rakhitha Ranathunge, Chamath Samarawickrama, Yumantha De Silva, I. Perera, Anuradha, Welivita",a8e150600931a80aab6433c005aeafad5eb73488,Extraction of Semantic Content and Styles in Comic Books,,2020.0,0,"Digitisation of comic books would play a crucial role in identifying new areas in which digital comics can be used. Currently, existing systems in this domain lack the capacity to achieve complete digitisation. Digitisation requires a thorough analysis of the semantic content within comic books. This can be further sub-categorised as detection and identification of comic book characters, extraction and analysis of panels as well as texts, derivation of associations between characters and speech balloons, and analysis of different styles of reading. This paper provides an overview of using several object-detection models to detect semantic content in comics. This analysis showed that, under the constraint of limited computational capacity, YOLOv3 was the best-suited model out of the models evaluated. A study of text extraction and recognition using Optical Character Recognition, a method for determining associable speech balloons, as well as a distance-based approach for associations between characters and speech balloons are also presented here. This association method provides an increased accuracy compared to the Euclidean distance-based approach. Finally, a study on comic style is provided along with a learning model with an accuracy of 0.89 to analyse the reading order of comics."
"J. Li, Nan Gao, T. Shen, Weitong Zhang, Tao Mei, Hui Ren",728fe8dd3a9cb43da565d6c49d08c39d862e84af,SketchMan: Learning to Create Professional Sketches,ACM Multimedia,2020.0,0,"Human free-hand sketches have been studied in various fields including sketch recognition, synthesis and sketch-based image retrieval. We propose a new challenging task sketch enhancement (SE) defined in an ill-posed space, i.e. enhancing a non-professional sketch (NPS) to a professional sketch (PS), which is a creative generation task different from sketch abstraction, sketch completion and sketch variation. For the first time we release a database of NPS with PS for anime characters. We cast sketch enhancement as an image-to-image translation problem by exploiting the relationship to corresponding intensive or sparse pixel domains for sketch domain. Specifically, we explore three different routines based on conditional generative adversarial network (cGAN), i.e. Sketch-Sketch (SS), Sketch-Colorization-Sketch (SCS) and Sketch-Abstraction-Sketch (SAS). SS is a one-stage model that directly maps NPS to PS, while SCS and SAS are two-stage models where auxiliary inputs, grayscale parsing and shape parsing, are involved. Multiple metrics are used to evaluate the performance of the models in both the sketch domain and other low-level feature domains. With quantitative and qualitative analysis of the experiments, we have established solid baselines, which, we hope, could encourage more research conducted on this task. Our dataset is publicly available via https://github.com/LCXCUC/SketchMan2020."
"Rameen Abdal, Yipeng Qin, Peter Wonka",62931b3e0dce8748364e19c87ef318e22ec59c7f,Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,200,"We propose an efficient algorithm to embed a given image into the latent space of StyleGAN. This embedding enables semantic image editing operations that can be applied to existing photographs. Taking the StyleGAN trained on the FFHD dataset as an example, we show results for image morphing, style transfer, and expression transfer. Studying the results of the embedding algorithm provides valuable insights into the structure of the StyleGAN latent space. We propose a set of experiments to test what class of images can be embedded, how they are embedded, what latent space is suitable for embedding, and if the embedding is semantically meaningful."
"Aliaksandr Siarohin, Stéphane Lathuilière, S. Tulyakov, E. Ricci, N. Sebe",edce7f037c840b7db2612f47c35ae374c4a80e3a,Animating Arbitrary Objects via Deep Motion Transfer,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,89,"This paper introduces a novel deep learning framework for image animation. Given an input image with a target object and a driving video sequence depicting a moving object, our framework generates a video in which the target object is animated according to the driving sequence. This is achieved through a deep architecture that decouples appearance and motion information. Our framework consists of three main modules: (i) a Keypoint Detector unsupervisely trained to extract object keypoints, (ii) a Dense Motion prediction network for generating dense heatmaps from sparse keypoints, in order to better encode motion information and (iii) a Motion Transfer Network, which uses the motion heatmaps and appearance information extracted from the input image to synthesize the output frames. We demonstrate the effectiveness of our method on several benchmark datasets, spanning a wide variety of object appearances, and show that our approach outperforms state-of-the-art image animation and video generation methods."
"Young-Sim Jo, Jongyoul Park",c4230706b89529bb136e3c00ee7fb01f9d8d77b0,SC-FEGAN: Face Editing Generative Adversarial Network With User’s Sketch and Color,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,88,"We present a novel image editing system that generates images as the user provides free-form masks, sketches and color as inputs. Our system consists of an end-to-end trainable convolutional network. In contrast to the existing methods, our system utilizes entirely free-form user input in terms of color and shape. This allows the system to respond to the user’s sketch and color inputs, using them as guidelines to generate an image. In this work, we trained the network with an additional style loss, which made it possible to generate realistic results despite large portions of the image being removed. Our proposed network architecture SC-FEGAN is well suited for generating high-quality synthetic images using intuitive user inputs."
"K. Westfall, M. Cappellari, M. Bershady, K. Bundy, F. Belfiore, X. Ji, D. Law, A. Schaefer, S. Shetty, C. Tremonti, R. Yan, B. Andrews, J. Brownstein, B. Cherinka, L. Coccato, N. Drory, C. Maraston, T. Parikh, J. S'anchez-Gallego, Daniel I. Thomas, A. Weijmans, J. Barrera-Ballesteros, Cheng Du, D. Goddard, N. Li, K. Masters, Hector Javier Ibarra Medel, S. S'anchez, Meng Yang, Zheng Zheng, S. Zhou",43346e850e0e31af392c57172838bf6fc35227cb,The data analysis pipeline for the SDSS-IV MaNGA IFU Galaxy Survey : overview,,2019.0,55,"Mapping Nearby Galaxies at Apache Point Observatory (MaNGA) is acquiring integral-field spectroscopy for the largest sample of galaxies to date. By 2020, the MaNGA Survey --- one of three core programs in the fourth-generation Sloan Digital Sky Survey (SDSS-IV) --- will have observed a statistically representative sample of 10$^4$ galaxies in the local Universe ($z\lesssim0.15$). In addition to a robust data-reduction pipeline (DRP), MaNGA has developed a data-analysis pipeline (DAP) that provides higher-level data products. To accompany the first public release of its code base and data products, we provide an overview of the MaNGA DAP, including its software design, workflow, measurement procedures and algorithms, performance, and output data model. In conjunction with our companion paper Belfiore et al., we also assess the DAP output provided for 4718 observations of 4648 unique galaxies in the recent SDSS Data Release 15 (DR15). These analysis products focus on measurements that are close to the data and require minimal model-based assumptions. Namely, we provide stellar kinematics (velocity and velocity dispersion), emission-line properties (kinematics, fluxes, and equivalent widths), and spectral indices (e.g., D4000 and the Lick indices). We find that the DAP provides robust measurements and errors for the vast majority ($>$99%) of analyzed spectra. We summarize assessments of the precision and accuracy of our measurements as a function of signal-to-noise, and provide specific guidance to users regarding the limitations of the data. The MaNGA DAP software is publicly available and we encourage community involvement in its development."
"Konstantinos Vougioukas, S. Petridis, M. Pantic",f06ab43069480c09d7170075a6ea74669a71f139,Realistic Speech-Driven Facial Animation with GANs,International Journal of Computer Vision,2019.0,54,"Speech-driven facial animation is the process that automatically synthesizes talking characters based on speech signals. The majority of work in this domain creates a mapping from audio features to visual features. This approach often requires post-processing using computer graphics techniques to produce realistic albeit subject dependent results. We present an end-to-end system that generates videos of a talking head, using only a still image of a person and an audio clip containing speech, without relying on handcrafted intermediate features. Our method generates videos which have (a) lip movements that are in sync with the audio and (b) natural facial expressions such as blinks and eyebrow movements. Our temporal GAN uses 3 discriminators focused on achieving detailed frames, audio-visual synchronization, and realistic expressions. We quantify the contribution of each component in our model using an ablation study and we provide insights into the latent representation of the model. The generated videos are evaluated based on sharpness, reconstruction quality, lip-reading accuracy, synchronization as well as their ability to generate natural blinks."
"A. Dutta, Zeynep Akata",96112f58cae6cbb85528ab1cb01550d106dc4ae8,Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,47,"Zero-shot sketch-based image retrieval (SBIR) is an emerging task in computer vision, allowing to retrieve natural images relevant to sketch queries that might not been seen in the training phase. Existing works either require aligned sketch-image pairs or inefficient memory fusion layer for mapping the visual information to a semantic space. In this work, we propose a semantically aligned paired cycle-consistent generative (SEM-PCYC) model for zero-shot SBIR, where each branch maps the visual information to a common semantic space via an adversarial training. Each of these branches maintains a cycle consistency that only requires supervision at category levels, and avoids the need of highly-priced aligned sketch-image pairs. A classification criteria on the generators' outputs ensures the visual to semantic space mapping to be discriminating. Furthermore, we propose to combine textual and hierarchical side information via a feature selection auto-encoder that selects discriminating side information within a same end-to-end model. Our results demonstrate a significant boost in zero-shot SBIR performance over the state-of-the-art on the challenging Sketchy and TU-Berlin datasets."
"I. Santesteban, M. Otaduy, D. Casas",d091b3ce51f976594440c3548dd8b99dee1c42ef,Learning‐Based Animation of Clothing for Virtual Try‐On,Comput. Graph. Forum,2019.0,47,"This paper presents a learning‐based clothing animation method for highly efficient virtual try‐on simulation. Given a garment, we preprocess a rich database of physically‐based dressed character simulations, for multiple body shapes and animations. Then, using this database, we train a learning‐based model of cloth drape and wrinkles, as a function of body shape and dynamics. We propose a model that separates global garment fit, due to body shape, from local garment wrinkles, due to both pose dynamics and body shape. We use a recurrent neural network to regress garment wrinkles, and we achieve highly plausible nonlinear effects, in contrast to the blending artifacts suffered by previous methods. At runtime, dynamic virtual try‐on animations are produced in just a few milliseconds for garments with thousands of triangles. We show qualitative and quantitative analysis of results."
"Sounak Dey, Pau Riba, A. Dutta, J. Lladós, Yi-Zhe Song",5c2b23d8bd04542b43d341515e39bfc169f9788f,Doodle to Search: Practical Zero-Shot Sketch-Based Image Retrieval,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,45,"In this paper, we investigate the problem of zero-shot sketch-based image retrieval (ZS-SBIR), where human sketches are used as queries to conduct retrieval of photos from unseen categories. We importantly advance prior arts by proposing a novel ZS-SBIR scenario that represents a firm step forward in its practical application. The new setting uniquely recognizes two important yet often neglected challenges of practical ZS-SBIR, (i) the large domain gap between amateur sketch and photo, and (ii) the necessity for moving towards large-scale retrieval. We first contribute to the community a novel ZS-SBIR dataset, QuickDraw-Extended, that consists of 330,000 sketches and 204,000 photos spanning across 110 categories. Highly abstract amateur human sketches are purposefully sourced to maximize the domain gap, instead of ones included in existing datasets that can often be semi-photorealistic. We then formulate a ZS-SBIR framework to jointly model sketches and photos into a common embedding space. A novel strategy to mine the mutual information among domains is specifically engineered to alleviate the domain gap. External semantic knowledge is further embedded to aid semantic transfer. We show that, rather surprisingly, retrieval performance significantly outperforms that of state-of-the-art on existing datasets that can already be achieved using a reduced version of our model. We further demonstrate the superior performance of our full model by comparing with a number of alternatives on the newly proposed dataset. The new dataset, plus all training and testing code of our model, will be publicly released to facilitate future research."
"Maxwell Nye, Luke B. Hewitt, J. Tenenbaum, Armando Solar-Lezama",6c72cff44294e050f75b47f1027889f539e11347,Learning to Infer Program Sketches,ICML,2019.0,44,"Our goal is to build systems which write code automatically from the kinds of specifications humans can most easily provide, such as examples and natural language instruction. The key idea of this work is that a flexible combination of pattern recognition and explicit reasoning can be used to solve these complex programming problems. We propose a method for dynamically integrating these types of information. Our novel intermediate representation and training algorithm allow a program synthesis system to learn, without direct supervision, when to rely on pattern recognition and when to perform symbolic search. Our model matches the memorization and generalization performance of neural synthesis and symbolic search, respectively, and achieves state-of-the-art performance on a dataset of simple English description-to-code programming problems."
"Atsuhiro Noguchi, T. Harada",1e10a58cd3d3974d083ec5aa323e5d10c43fc061,Image Generation From Small Datasets via Batch Statistics Adaptation,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,41,"Thanks to the recent development of deep generative models, it is becoming possible to generate high-quality images with both fidelity and diversity. However, the training of such generative models requires a large dataset. To reduce the amount of data required, we propose a new method for transferring prior knowledge of the pre-trained generator, which is trained with a large dataset, to a small dataset in a different domain. Using such prior knowledge, the model can generate images leveraging some common sense that cannot be acquired from a small dataset. In this work, we propose a novel method focusing on the parameters for batch statistics, scale and shift, of the hidden layers in the generator. By training only these parameters in a supervised manner, we achieved stable training of the generator, and our method can generate higher quality images compared to previous methods without collapsing, even when the dataset is small (~100). Our results show that the diversity of the filters acquired in the pre-trained generator is important for the performance on the target domain. Our method makes it possible to add a new class or domain to a pre-trained generator without disturbing the performance on the original domain. Code is available at github.com/nogu-atsu/small-dataset-image-generation"
"Alaaeldin El-Nouby, Shikhar Sharma, Hannes Schulz, Devon Hjelm, Layla El Asri, S. Kahou, Yoshua Bengio, Graham W.Taylor",19f894ab29ed7895b9a0cc7435866da69e9a63c6,"Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction",2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,35,"Conditional text-to-image generation is an active area of research, with many possible applications. Existing research has primarily focused on generating a single image from available conditioning information in one step. One practical extension beyond one-step generation is a system that generates an image iteratively, conditioned on ongoing linguistic input or feedback. This is significantly more challenging than one-step generation tasks, as such a system must understand the contents of its generated images with respect to the feedback history, the current feedback, as well as the interactions among concepts present in the feedback history. In this work, we present a recurrent image generation model which takes into account both the generated output up to the current step as well as all past instructions for generation. We show that our model is able to generate the background, add new objects, and apply simple transformations to existing objects. We believe our approach is an important step toward interactive generation. Code and data is available at: https://www.microsoft.com/en-us/research/project/generative-neural-visual-artist-geneva/."
"F. Belfiore, K. Westfall, A. Schaefer, M. Cappellari, X. Ji, M. Bershady, C. Tremonti, D. Law, R. Yan, K. Bundy, S. Shetty, N. Drory, Daniel I. Thomas, E. Emsellem, S. S'anchez",cbe5198bdcbe9553a5b40fe158906ae3b130d818,The Data Analysis Pipeline for the SDSS-IV MaNGA IFU Galaxy Survey: Emission-Line Modeling,,2019.0,34,"SDSS-IV MaNGA (Mapping Nearby Galaxies at Apache Point Observatory) is the largest integral-field spectroscopy survey to date, aiming to observe a statistically representative sample of 10,000 low-redshift galaxies. In this paper we study the reliability of the emission-line fluxes and kinematic properties derived by the MaNGA Data Analysis Pipeline (DAP). We describe the algorithmic choices made in the DAP with regards to measuring emission-line properties, and the effect of our adopted strategy of simultaneously fitting the continuum and line emission. The effect of random errors are quantified by studying various fit-quality metrics, idealized recovery simulations and repeat observations. This analysis demonstrates that the emission lines are well-fit in the vast majority of the MaNGA dataset and the derived fluxes and errors are statistically robust. The systematic uncertainty on emission-line properties introduced by the choice of continuum templates is also discussed. In particular, we test the effect of using different stellar libraries and simple stellar-population models on the derived emission-line fluxes and the effect of introducing different tying prescriptions for the emission-line kinematics. We show that these effects can generate large ($>$ 0.2 dex) discrepancies at low signal-to-noise and for lines with low equivalent width (EW); however, the combined effect is noticeable even for H$\alpha$ EW $>$ 6 \AA. We provide suggestions for optimal use of the data provided by SDSS data release 15 and propose refinements on the DAP for future MaNGA data releases."
"Arnab Ghosh, Richard Zhang, P. Dokania, O. Wang, Alexei A. Efros, Philip H. S. Torr, E. Shechtman",da435005ef2028a1ac2d8d46aec9c045e92c0891,Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,30,"We propose an interactive GAN-based sketch-to-image translation method that helps novice users easily create images of simple objects. The user starts with a sparse sketch and a desired object category, and the network then recommends its plausible completion(s) and shows a corresponding synthesized image. This enables a feedback loop, where the user can edit the sketch based on the network's recommendations, while the network is able to better synthesize the image that the user might have in mind. In order to use a single model for a wide array of object classes, we introduce a gating-based approach for class conditioning, which allows us to generate distinct classes without feature mixing, from a single generator network."
"Forrest Huang, J. Canny, Jeffrey Nichols",f02ce7cbb5421c78f59535acba471cd5e32eae65,Swire: Sketch-based User Interface Retrieval,CHI,2019.0,29,"Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, finding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly reflected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the first large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, for the first time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workflows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process."
"Mingjin Zhang, Ruxin Wang, Xinbo Gao, J. Li, D. Tao",f306c0d24a5eb338b7a577a17d8b35d78716d880,Dual-Transfer Face Sketch–Photo Synthesis,IEEE Transactions on Image Processing,2019.0,28,"Recognizing the identity of a sketched face from a face photograph dataset is a critical yet challenging task in many applications, not least law enforcement and criminal investigations. An intelligent sketched face identification system would rely on automatic face sketch synthesis from photographs, thereby avoiding the cost of artists manually drawing sketches. However, conventional face sketch–photo synthesis methods tend to generate sketches that are consistent with the artists’drawing styles. Identity-specific information is often overlooked, leading to unsatisfactory identity verification and recognition performance. In this paper, we discuss the reasons why conventional methods fail to recover identity-specific information. Then, we propose a novel dual-transfer face sketch–photo synthesis framework composed of an inter-domain transfer process and an intra-domain transfer process. In the inter-domain transfer, a regressor of the test photograph with respect to the training photographs is learned and transferred to the sketch domain, ensuring the recovery of common facial structures during synthesis. In the intra-domain transfer, a mapping characterizing the relationship between photographs and sketches is learned and transferred across different identities, such that the loss of identity-specific information is suppressed during synthesis. The fusion of information recovered by the two processes is straightforward by virtue of an ad hoc information splitting strategy. We employ both linear and nonlinear formulations to instantiate the proposed framework. Experiments on The Chinese University of Hong Kong face sketch database demonstrate that compared to the current state-of-the-art the proposed framework produces more identifiable facial structures and yields higher face recognition performance in both the photo and sketch domains."
"Zhen He, J. Li, Daxue Liu, Hangen He, D. Barber",e799c5c7e169f471950eb76dbb329c2d031347ae,Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,27,"Online Multi-Object Tracking (MOT) from videos is a challenging computer vision task which has been extensively studied for decades. Most of the existing MOT algorithms are based on the Tracking-by-Detection (TBD) paradigm combined with popular machine learning approaches which largely reduce the human effort to tune algorithm parameters. However, the commonly used supervised learning approaches require the labeled data (e.g., bounding boxes), which is expensive for videos. Also, the TBD framework is usually suboptimal since it is not end-to-end, i.e., it considers the task as detection and tracking, but not jointly. To achieve both label-free and end-to-end learning of MOT, we propose a Tracking-by-Animation framework, where a differentiable neural model first tracks objects from input frames and then animates these objects into reconstructed frames. Learning is then driven by the reconstruction error through backpropagation. We further propose a Reprioritized Attentive Tracking to improve the robustness of data association. Experiments conducted on both synthetic and real video datasets show the potential of the proposed model. Our project page is publicly available at: https://github.com/zhen-he/tracking-by-animation"
"Qing Liu, Lingxi Xie, Huiyu Wang, A. Yuille",d974d0bdba8974e5bafb5211efbb8303c7fdc540,Semantic-Aware Knowledge Preservation for Zero-Shot Sketch-Based Image Retrieval,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,25,"Sketch-based image retrieval (SBIR) is widely recognized as an important vision problem which implies a wide range of real-world applications. Recently, research interests arise in solving this problem under the more realistic and challenging setting of zero-shot learning. In this paper, we investigate this problem from the viewpoint of domain adaptation which we show is critical in improving feature embedding in the zero-shot scenario. Based on a framework which starts with a pre-trained model on ImageNet and fine-tunes it on the training set of SBIR benchmark, we advocate the importance of preserving previously acquired knowledge, e.g., the rich discriminative features learned from ImageNet, to improve the model's transfer ability. For this purpose, we design an approach named Semantic-Aware Knowledge prEservation (SAKE), which fine-tunes the pre-trained model in an economical way and leverages semantic information, e.g., inter-class relationship, to achieve the goal of knowledge preservation. Zero-shot experiments on two extended SBIR datasets, TU-Berlin and Sketchy, verify the superior performance of our approach. Extensive diagnostic experiments validate that knowledge preserved benefits SBIR in zero-shot settings, as a large fraction of the performance gain is from the more properly structured feature embedding for photo images."
"Hyunsu Kim, Ho Young Jhoo, Eunhyeok Park, S. Yoo",d57622db429112152ee726bbee80ddd567c342bc,Tag2Pix: Line Art Colorization Using Text Tag With SECat and Changing Loss,2019 IEEE/CVF International Conference on Computer Vision (ICCV),2019.0,25,"Line art colorization is expensive and challenging to automate. A GAN approach is proposed, called Tag2Pix, of line art colorization which takes as input a grayscale line art and color tag information and produces a quality colored image. First, we present the Tag2Pix line art colorization dataset. A generator network is proposed which consists of convolutional layers to transform the input line art, a pre-trained semantic extraction network, and an encoder for input color information. The discriminator is based on an auxiliary classifier GAN to classify the tag information as well as genuineness. In addition, we propose a novel network structure called SECat, which makes the generator properly colorize even small features such as eyes, and also suggest a novel two-step training method where the generator and discriminator first learn the notion of object and shape and then, based on the learned notion, learn colorization, such as where and how to place which color. We present both quantitative and qualitative evaluations which prove the effectiveness of the proposed method."
"Shengchuan Zhang, R. Ji, Jie Hu, Xiaoqiang Lu, Xuelong Li",3334cb3c87fd05cae076b5f6543aab750668dbe7,Face Sketch Synthesis by Multidomain Adversarial Learning,IEEE Transactions on Neural Networks and Learning Systems,2019.0,24,"Given a training set of face photo-sketch pairs, face sketch synthesis targets at learning a mapping from the photo domain to the sketch domain. Despite the exciting progresses made in the literature, it retains as an open problem to synthesize high-quality sketches against blurs and deformations. Recent advances in generative adversarial training provide a new insight into face sketch synthesis, from which perspective the existing synthesis pipelines can be fundamentally revisited. In this paper, we present a novel face sketch synthesis method by multidomain adversarial learning (termed MDAL), which overcomes the defects of blurs and deformations toward high-quality synthesis. The principle of our scheme relies on the concept of “interpretation through synthesis.” In particular, we first interpret face photographs in the photodomain and face sketches in the sketch domain by reconstructing themselves respectively via adversarial learning. We define the intermediate products in the reconstruction process as latent variables, which form a latent domain. Second, via adversarial learning, we make the distributions of latent variables being indistinguishable between the reconstruction process of the face photograph and that of the face sketch. Finally, given an input face photograph, the latent variable obtained by reconstructing this face photograph is applied for synthesizing the corresponding sketch. Quantitative comparisons to the state-of-the-art methods demonstrate the superiority of the proposed MDAL method."
"Kaiyue Pang, Ke Li, Yongxin Yang, Honggang Zhang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song",09d0f5df43f3e037f7278b8a5d01ce4169e520e6,Generalising Fine-Grained Sketch-Based Image Retrieval,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,24,"Fine-grained sketch-based image retrieval (FG-SBIR) addresses matching specific photo instance using free-hand sketch as a query modality. Existing models aim to learn an embedding space in which sketch and photo can be directly compared. While successful, they require instance-level pairing within each coarse-grained category as annotated training data. Since the learned embedding space is domain-specific, these models do not generalise well across categories. This limits the practical applicability of FG-SBIR. In this paper, we identify cross-category generalisation for FG-SBIR as a domain generalisation problem, and propose the first solution. Our key contribution is a novel unsupervised learning approach to model a universal manifold of prototypical visual sketch traits. This manifold can then be used to paramaterise the learning of a sketch/photo representation. Model adaptation to novel categories then becomes automatic via embedding the novel sketch in the manifold and updating the representation and retrieval function accordingly. Experiments on the two largest FG-SBIR datasets, Sketchy and QMUL-Shoe-V2, demonstrate the efficacy of our approach in enabling cross-category generalisation of FG-SBIR."
"Yichun Shi, Debayan Deb, Anil K. Jain",4be83c3570280068ab527f008f8f7a4a02f14aaf,WarpGAN: Automatic Caricature Generation,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,24,"We propose, WarpGAN, a fully automatic network that can generate caricatures given an input face photo. Besides transferring rich texture styles, WarpGAN learns to automatically predict a set of control points that can warp the photo into a caricature, while preserving identity. We introduce an identity-preserving adversarial loss that aids the discriminator to distinguish between different subjects. Moreover, WarpGAN allows customization of the generated caricatures by controlling the exaggeration extent and the visual styles. Experimental results on a public domain dataset, WebCaricature, show that WarpGAN is capable of generating caricatures that not only preserve the identities but also outputs a diverse set of caricatures for each input photo. Five caricature experts suggest that caricatures generated by WarpGAN are visually similar to hand-drawn ones and only prominent facial features are exaggerated."
"Jiawei Zhang, Lin Meng",7b2da0b4afed3d0dff484f2d7785b4eb5bbb8f56,GResNet: Graph Residual Network for Reviving Deep GNNs from Suspended Animation,ArXiv,2019.0,23,"The existing graph neural networks (GNNs) based on the spectral graph convolutional operator have been criticized for its performance degradation, which is especially common for the models with deep architectures. In this paper, we further identify the suspended animation problem with the existing GNNs. Such a problem happens when the model depth reaches the suspended animation limit, and the model will not respond to the training data any more and become not learnable. Analysis about the causes of the suspended animation problem with existing GNNs will be provided in this paper, whereas several other peripheral factors that will impact the problem will be reported as well. To resolve the problem, we introduce the GResNet (Graph Residual Network) framework in this paper, which creates extensively connected highways to involve nodes' raw features or intermediate representations throughout the graph for all the model layers. Different from the other learning settings, the extensive connections in the graph data will render the existing simple residual learning methods fail to work. We prove the effectiveness of the introduced new graph residual terms from the norm preservation perspective, which will help avoid dramatic changes to the node's representations between sequential layers. Detailed studies about the GResNet framework for many existing GNNs, including GCN, GAT and LoopyNet, will be reported in the paper with extensive empirical experiments on real-world benchmark datasets."
"Yijun Li, Chen Fang, Aaron Hertzmann, E. Shechtman, Ming-Hsuan Yang",b981faf67f377532a8f4b1c9ce7381351186d548,Im2Pencil: Controllable Pencil Illustration From Photographs,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,23,"We propose a high-quality photo-to-pencil translation method with fine-grained control over the drawing style. This is a challenging task due to multiple stroke types (e.g., outline and shading), structural complexity of pencil shading (e.g., hatching), and the lack of aligned training data pairs. To address these challenges, we develop a two-branch model that learns separate filters for generating sketchy outlines and tonal shading from a collection of pencil drawings. We create training data pairs by extracting clean outlines and tonal illustrations from original pencil drawings using image filtering techniques, and we manually label the drawing styles. In addition, our model creates different pencil styles (e.g., line sketchiness and shading style) in a user-controllable manner. Experimental results on different types of pencil drawings show that the proposed algorithm performs favorably against existing methods in terms of quality, diversity and user evaluations."
"Mingrui Zhu, J. Li, N. Wang, Xinbo Gao",734aa504f63ad260f9cf60aa5fa7ba641a0623a6,A Deep Collaborative Framework for Face Photo–Sketch Synthesis,IEEE Transactions on Neural Networks and Learning Systems,2019.0,21,"Great breakthroughs have been made in the accuracy and speed of face photo–sketch synthesis in recent years. Regression-based methods have gained increasing attention, which benefit from deeper and faster end-to-end convolutional neural networks. However, most of these models typically formulate the mapping from photo domain <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula> to sketch domain <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> as a unidirectional feedforward mapping, <inline-formula> <tex-math notation=""LaTeX"">$G: X \to Y$ </tex-math></inline-formula>, and vice versa, <inline-formula> <tex-math notation=""LaTeX"">$F: Y \to X$ </tex-math></inline-formula>; thus, the utilization of mutual interaction between two opposite mappings is lacking. Therefore, we proposed a collaborative framework for face photo–sketch synthesis. The concept behind our model was that a middle latent domain <inline-formula> <tex-math notation=""LaTeX"">$\widetilde {Z}$ </tex-math></inline-formula> between the photo domain <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula> and the sketch domain <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> can be learned during the learning procedure of <inline-formula> <tex-math notation=""LaTeX"">$G: X \to Y$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$F: Y \to X$ </tex-math></inline-formula> by introducing a collaborative loss that makes full use of two opposite mappings. This strategy can constrain the two opposite mappings and make them more symmetrical, thus making the network more suitable for the photo–sketch synthesis task and obtaining higher quality generated images. Qualitative and quantitative experiments demonstrated the superior performance of our model in comparison with the existing state-of-the-art solutions."
"J. Fischer, H. D. S'anchez, M. Bernardi",a04bf483d1fa129362b3d0c0fe0a71443cf4b4ed,SDSS-IV MaNGA PyMorph Photometric and Deep Learning Morphological Catalogues and implications for bulge properties and stellar angular momentum,,2019.0,21,"We describe the SDSS-IV MaNGA PyMorph Photometric (MPP-VAC) and MaNGA Deep Learning Morphology (MDLM-VAC) Value Added Catalogs. The MPP-VAC provides photometric parameters from S\'ersic and S\'ersic+Exponential fits to the 2D surface brightness profiles of the MaNGA DR15 galaxy sample. Compared to previous PyMorph analyses of SDSS imaging, our analysis of the MaNGA DR15 incorporates three improvements: the most recent SDSS images; modified criteria for determining bulge-to-disk decompositions; and the fits in MPP-VAC have been eye-balled, and re-fit if necessary, for additional reliability. A companion catalog, the MDLM-VAC, provides Deep Learning-based morphological classifications for the same galaxies. The MDLM-VAC includes a number of morphological properties (e.g., a TType, and a finer separation between elliptical and S0 galaxies). Combining the MPP- and MDLM-VACs allows to show that the MDLM morphological classifications are more reliable than previous work. It also shows that single-S\'ersic fits to late- and early-type galaxies are likely to return S\'ersic indices of $n \le 2$ and $\ge 4$, respectively, and this correlation between $n$ and morphology extends to the bulge component as well. While the former is well-known, the latter contradicts some recent work suggesting little correlation between $n$-bulge and morphology. Combining both VACs with MaNGA's spatially resolved spectroscopy allows us to study how the stellar angular momentum depends on morphological type. We find correlations between stellar kinematics, photometric properties, and morphological type even though the spectroscopic data played no role in the construction of the MPP- and MDLM-VACs."
"Andreas Kipf, D. Vorona, Jonas Müller, Thomas Kipf, B. Radke, Viktor Leis, P. Boncz, Thomas Neumann, A. Kemper",2c78f8d7a96de4671631291442d7e71c99f218d9,Estimating Cardinalities with Deep Sketches,SIGMOD Conference,2019.0,18,"We introduce Deep Sketches, which are compact models of databases that allow us to estimate the result sizes of SQL queries. Deep Sketches are powered by a new deep learning approach to cardinality estimation that can capture correlations between columns, even across tables. Our demonstration allows users to define such sketches on the TPC-H and IMDb datasets, monitor the training process, and run ad-hoc queries against trained sketches. We also estimate query cardinalities with HyPer and PostgreSQL to visualize the gains over traditional cardinality estimators."
"Lei Li, Hongbo Fu, C. Tai",18917ef4b86f997fc391525860ec959370fbd5b1,Fast Sketch Segmentation and Labeling With Deep Learning,IEEE Computer Graphics and Applications,2019.0,17,"We present a simple and efficient method based on deep learning to automatically decompose sketched objects into semantically valid parts. We train a deep neural network to transfer existing segmentations and labelings from three-dimensional (3-D) models to freehand sketches without requiring numerous well-annotated sketches as training data. The network takes the binary image of a sketched object as input and produces a corresponding segmentation map with per-pixel labelings as output. A subsequent postprocess procedure with multilabel graph cuts further refines the segmentation and labeling result. We validate our proposed method on two sketch datasets. Experiments show that our method outperforms the state-of-the-art method in terms of segmentation and labeling accuracy and is significantly faster, enabling further integration in interactive drawing systems. We demonstrate the efficiency of our method in a sketch-based modeling application that automatically transforms input sketches into 3-D models by part assembly."
"Lu Tang, Qun Huang, Patrick P. C. Lee",b806df53e05ca4a603799080dd57141e7260157f,MV-Sketch: A Fast and Compact Invertible Sketch for Heavy Flow Detection in Network Data Streams,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications,2019.0,17,"Fast detection of heavy flows (e.g., heavy hitters and heavy changers) in massive network traffic is challenging due to the stringent requirements of fast packet processing and limited resource availability. Invertible sketches are summary data structures that can recover heavy flows with small memory footprints and bounded errors, yet existing invertible sketches incur high memory access overhead that leads to performance degradation. We present MV-Sketch, a fast and compact invertible sketch that supports heavy flow detection with small and static memory allocation. MV-Sketch tracks candidate heavy flows inside the sketch data structure via the idea of majority voting, such that it incurs small memory access overhead in both update and query operations, while achieving high detection accuracy. We present theoretical analysis on the memory usage, performance, and accuracy of MV-Sketch. Trace-driven evaluation shows that MV-Sketch achieves higher accuracy than existing invertible sketches, with up to $3.38 \times$ throughput gain. We also show how to boost the performance of MV-Sketch with SIMD instructions."
"B. Li, Nhat Linh Vu, Xiaowen Zhou",fef892daaa2106f15207dcfc4e2d33e70f58560b,Exit problems for general draw-down times of spectrally negative Lévy processes,Journal of Applied Probability,2019.0,17,"Abstract For spectrally negative Lévy processes, we prove several fluctuation results involving a general draw-down time, which is a downward exit time from a dynamic level that depends on the running maximum of the process. In particular, we find expressions of the Laplace transforms for the two-sided exit problems involving the draw-down time. We also find the Laplace transforms for the hitting time and creeping time over the running-maximum related draw-down level, respectively, and obtain an expression for a draw-down associated potential measure. The results are expressed in terms of scale functions for the spectrally negative Lévy processes."
"Tianyang Zhang, Huazhu Fu, Yitian Zhao, Jun Cheng, Mengjie Guo, Zaiwang Gu, B. Yang, Yuting Xiao, Shenghua Gao, J. Liu",65de24ee61408b12c012ed60038e63b22628b45a,SkrGAN: Sketching-rendering Unconditional Generative Adversarial Networks for Medical Image Synthesis,MICCAI,2019.0,16,"Generative Adversarial Networks (GANs) have the capability of synthesizing images, which have been successfully applied to medical image synthesis tasks. However, most of existing methods merely consider the global contextual information and ignore the fine foreground structures, e.g., vessel, skeleton, which may contain diagnostic indicators for medical image analysis. Inspired by human painting procedure, which is composed of stroking and color rendering steps, we propose a Sketching-rendering Unconditional Generative Adversarial Network (SkrGAN) to introduce a sketch prior constraint to guide the medical image generation. In our SkrGAN, a sketch guidance module is utilized to generate a high quality structural sketch from random noise, then a color render mapping is used to embed the sketch-based representations and resemble the background appearances. Experimental results show that the proposed SkrGAN achieves the state-of-the-art results in synthesizing images for various image modalities, including retinal color fundus, X-Ray, Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). In addition, we also show that the performances of medical image segmentation method have been improved by using our synthesized images as data augmentation."
"Tharun Medini, Qixuan Huang, Yiqiu Wang, V. Mohan, Anshumali Shrivastava",ace729d08648d221ee47f489e790995d19ff370e,Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products,NeurIPS,2019.0,15,"In the last decade, it has been shown that many hard AI tasks, especially in NLP, can be naturally modeled as extreme classification problems leading to improved precision. However, such models are prohibitively expensive to train due to the memory blow-up in the last layer. For example, a reasonable softmax layer for the dataset of interest in this paper can easily reach well beyond 100 billion parameters (>400 GB memory). To alleviate this problem, we present Merged-Average Classifiers via Hashing (MACH), a generic K-classification algorithm where memory provably scales at O(logK) without any strong assumption on the classes. MACH is subtly a count-min sketch structure in disguise, which uses universal hashing to reduce classification with a large number of classes to few embarrassingly parallel and independent classification tasks with a small (constant) number of classes. MACH naturally provides a technique for zero communication model parallelism. We experiment with 6 datasets; some multiclass and some multilabel, and show consistent improvement over respective state-of-the-art baselines. In particular, we train an end-to-end deep classifier on a private product search dataset sampled from Amazon Search Engine with 70 million queries and 49.46 million products. MACH outperforms, by a significant margin,the state-of-the-art extreme classification models deployed on commercial search engines: Parabel and dense embedding models. Our largest model has 6.4 billion parameters and trains in less than 35 hours on a single p3.16x machine. Our training times are 7-10x faster, and our memory footprints are 2-4x smaller than the best baselines. This training time is also significantly lower than the one reported by Google's mixture of experts (MoE) language model on a comparable model size and hardware."
"F. Liu, Xiaoming Deng, Yu-Kun Lai, Yongjin Liu, Cuixia Ma, Hongan Wang",e35ffd775fd4431c99b93153abd9104c0a79a886,SketchGAN: Joint Sketch Completion and Recognition With Generative Adversarial Network,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,14,"Hand-drawn sketch recognition is a fundamental problem in computer vision, widely used in sketch-based image and video retrieval, editing, and reorganization. Previous methods often assume that a complete sketch is used as input; however, hand-drawn sketches in common application scenarios are often incomplete, which makes sketch recognition a challenging problem. In this paper, we propose SketchGAN, a new generative adversarial network (GAN) based approach that jointly completes and recognizes a sketch, boosting the performance of both tasks. Specifically, we use a cascade Encode-Decoder network to complete the input sketch in an iterative manner, and employ an auxiliary sketch recognition task to recognize the completed sketch. Experiments on the Sketchy database benchmark demonstrate that our joint learning approach achieves competitive sketch completion and recognition performance compared with the state-of-the-art methods. Further experiments using several sketch-based applications also validate the performance of our method."
"Ziqiang Zheng, Haiyong Zheng, Z. Yu, Zhaorui Gu, Bing Zheng",cbbad813023eefef5feb156c00e7831bf2b746e6,Photo-to-Caricature Translation on Faces in the Wild,Neurocomputing,2019.0,14,"Recently, image-to-image translation has been made much progress owing to the success of conditional Generative Adversarial Networks (cGANs). However, it's still very challenging for translation tasks with the requirement of high-level visual information conversion, such as photo-to-caricature translation that requires satire, exaggeration, lifelikeness and artistry. We present an approach for learning to translate faces in the wild from the source photo domain to the target caricature domain with different styles, which can also be used for other high-level image-to-image translation tasks. In order to capture global structure with local statistics while translation, we design a dual pathway model of cGAN with one global discriminator and one patch discriminator. Beyond standard convolution (Conv), we propose a new parallel convolution (ParConv) to construct Parallel Convolutional Neural Networks (ParCNNs) for both global and patch discriminators, which can combine the information from previous layer with the current layer. For generator, we provide three more extra losses in association with adversarial loss to constrain consistency for generated output itself and with the target. Also the style can be controlled by the input style info vector. Experiments on photo-to-caricature translation of faces in the wild show considerable performance gain of our proposed method over state-of-the-art translation methods as well as its potential real applications."
"Marie-Lena Eckert, Kiwon Um, N. Thuerey",0c82b43aa9655dcc5243a00c17ed09ddaa1ef973,ScalarFlow: a large-scale volumetric data set of real-world scalar transport flows for computer animation and machine learning,ACM Trans. Graph.,2019.0,14,"In this paper, we present ScalarFlow, a first large-scale data set of reconstructions of real-world smoke plumes. We additionally propose a framework for accurate physics-based reconstructions from a small number of video streams. Central components of our algorithm are a novel estimation of unseen inflow regions and an efficient regularization scheme. Our data set includes a large number of complex and natural buoyancy-driven flows. The flows transition to turbulent flows and contain observable scalar transport processes. As such, the ScalarFlow data set is tailored towards computer graphics, vision, and learning applications. The published data set will contain volumetric reconstructions of velocity and density, input image sequences, together with calibration data, code, and instructions how to recreate the commodity hardware capture setup. We further demonstrate one of the many potential application areas: a first perceptual evaluation study, which reveals that the complexity of the captured flows requires a huge simulation resolution for regular solvers in order to recreate at least parts of the natural complexity contained in the captured data."
"Tian Li, Zaoxing Liu, V. Sekar, Virginia Smith",4ad13b83c0510f9e830e3583722f75e3ab2697e8,Privacy for Free: Communication-Efficient Learning with Differential Privacy Using Sketches,ArXiv,2019.0,14,"Communication and privacy are two critical concerns in distributed learning. Many existing works treat these concerns separately. In this work, we argue that a natural connection exists between methods for communication reduction and privacy preservation in the context of distributed machine learning. In particular, we prove that Count Sketch, a simple method for data stream summarization, has inherent differential privacy properties. Using these derived privacy guarantees, we propose a novel sketch-based framework (DiffSketch) for distributed learning, where we compress the transmitted messages via sketches to simultaneously achieve communication efficiency and provable privacy benefits. Our evaluation demonstrates that DiffSketch can provide strong differential privacy guarantees (e.g., $\varepsilon$= 1) and reduce communication by 20-50x with only marginal decreases in accuracy. Compared to baselines that treat privacy and communication separately, DiffSketch improves absolute test accuracy by 5%-50% while offering the same privacy guarantees and communication compression."
"Jiaxin Chen, Jie Qin, L. Liu, F. Zhu, Fumin Shen, J. Xie, L. Shao",4ec5fc8daf92dec2b086a98e34429f99ec716c94,Deep Sketch-Shape Hashing With Segmented 3D Stochastic Viewing,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2019.0,13,"Sketch-based 3D shape retrieval has been extensively studied in recent works, most of which focus on improving the retrieval accuracy, whilst neglecting the efficiency. In this paper, we propose a novel framework for efficient sketch-based 3D shape retrieval, i.e., Deep Sketch-Shape Hashing (DSSH), which tackles the challenging problem from two perspectives. Firstly, we propose an intuitive 3D shape representation method to deal with unaligned shapes with arbitrary poses. Specifically, the proposed Segmented Stochastic-viewing Shape Network models discriminative 3D representations by a set of 2D images rendered from multiple views, which are stochastically selected from non-overlapping spatial segments of a 3D sphere. Secondly, Batch-Hard Binary Coding (BHBC) is developed to learn semantics-preserving compact binary codes by mining the hardest samples. The overall framework is jointly learned by developing an alternating iteration algorithm. Extensive experimental results on three benchmarks show that DSSH improves both the retrieval efficiency and accuracy remarkably, compared to the state-of-the-art methods."
"Zohar S. Karnin, E. Liberty",233fe6feeee53f0eda5f6a8b26a3a174fce5542d,"Discrepancy, Coresets, and Sketches in Machine Learning",COLT,2019.0,13,"This paper defines the notion of class discrepancy for families of functions. It shows that low discrepancy classes admit small offline and streaming coresets. We provide general techniques for bounding the class discrepancy of machine learning problems. As corollaries of the general technique we bound the discrepancy (and therefore coreset complexity) of logistic regression, sigmoid activation loss, matrix covariance, kernel density and any analytic function of the dot product or the squared distance. Our results prove the existence of epsilon-approximation O(sqrt{d}/epsilon) sized coresets for the above problems. This resolves the long-standing open problem regarding the coreset complexity of Gaussian kernel density estimation. We provide two more related but independent results. First, an exponential improvement of the widely used merge-and-reduce trick which gives improved streaming sketches for any low discrepancy problem. Second, an extremely simple deterministic algorithm for finding low discrepancy sequences (and therefore coresets) for any positive semi-definite kernel. This paper establishes some explicit connections between class discrepancy, coreset complexity, learnability, and streaming algorithms."
"Aviv Gabbay, Yedid Hoshen",5b2b9b9ee2ad444a23b8d9f27e4f929d9094dc42,Style Generator Inversion for Image Enhancement and Animation,ArXiv,2019.0,13,"One of the main motivations for training high quality image generative models is their potential use as tools for image manipulation. Recently, generative adversarial networks (GANs) have been able to generate images of remarkable quality. Unfortunately, adversarially-trained unconditional generator networks have not been successful as image priors. One of the main requirements for a network to act as a generative image prior, is being able to generate every possible image from the target distribution. Adversarial learning often experiences mode-collapse, which manifests in generators that cannot generate some modes of the target distribution. Another requirement often not satisfied is invertibility i.e. having an efficient way of finding a valid input latent code given a required output image. In this work, we show that differently from earlier GANs, the very recently proposed style-generators are quite easy to invert. We use this important observation to propose style generators as general purpose image priors. We show that style generators outperform other GANs as well as Deep Image Prior as priors for image enhancement tasks. The latent space spanned by style-generators satisfies linear identity-pose relations. The latent space linearity, combined with invertibility, allows us to animate still facial images without supervision. Extensive experiments are performed to support the main contributions of this paper."
"C. Zou, Haoran Mo, Chengying Gao, Ruofei Du, Hongbo Fu",98c1715b17db5a992b4e2e99f55957e70f3e51b7,Language-based colorization of scene sketches,ACM Trans. Graph.,2019.0,12,"Being natural, touchless, and fun-embracing, language-based inputs have been demonstrated effective for various tasks from image generation to literacy education for children. This paper for the first time presents a language-based system for interactive colorization of scene sketches, based on semantic comprehension. The proposed system is built upon deep neural networks trained on a large-scale repository of scene sketches and cartoonstyle color images with text descriptions. Given a scene sketch, our system allows users, via language-based instructions, to interactively localize and colorize specific foreground object instances to meet various colorization requirements in a progressive way. We demonstrate the effectiveness of our approach via comprehensive experimental results including alternative studies, comparison with the state-of-the-art methods, and generalization user studies. Given the unique characteristics of language-based inputs, we envision a combination of our interface with a traditional scribble-based interface for a practical multimodal colorization system, benefiting various applications. The dataset and source code can be found at https://github.com/SketchyScene/SketchySceneColorization."
"Nhu-Van Nguyen, Christophe Rigaud, J. Burie",04e0e37cbce88ee6167b0eab5045c25c0919c390,Multi-task Model for Comic Book Image Analysis,MMM,2019.0,12,"Comic book image analysis methods often propose multiple algorithms or models for multiple tasks like panels and characters detection, balloons segmentation and text recognition, etc. In this work, we aim to reduce the complexity for comic book image analysis by proposing one model which can learn multiple tasks called Comic MTL. In addition to the detection task and segmentation task, we integrate the relation analysis task for balloons and characters into the Comic MTL model. The experiments with our model are carried out on the eBDtheque dataset which contains the annotations for panels, balloons, characters and also the relations balloon-character. We show that the Comic MTL model can detect the association between balloons and their speakers (comic characters) and handle other tasks like panels, characters detection and balloons segmentation with promising results."
"Serkan Cabi, Sergio Gómez Colmenarejo, Alexander Novikov, Ksenia Konyushkova, Scott E. Reed, Rae Jeong, Konrad Zolna, Yusuf Aytar, D. Budden, Mel Vecerík, Oleg O. Sushkov, David Barker, Jonathan Scholz, Misha Denil, N. D. Freitas, Ziyu Wang",cac78ad6696d6b6370942679f7d0e4425ef4b3e7,A Framework for Data-Driven Robotics,ArXiv,2019.0,12,"We present a framework for data-driven robotics that makes use of a large dataset of recorded robot experience and scales to several tasks using learned reward functions. We show how to apply this framework to accomplish three different object manipulation tasks on a real robot platform. Given demonstrations of a task together with task-agnostic recorded experience, we use a special form of human annotation as supervision to learn a reward function, which enables us to deal with real-world tasks where the reward signal cannot be acquired directly. Learned rewards are used in combination with a large dataset of experience from different tasks to learn a robot policy offline using batch RL. We show that using our approach it is possible to train agents to perform a variety of challenging manipulation tasks including stacking rigid objects and handling cloth."
"Guanzhong Tian, Yi Yuan, Y. Liu",a13a25e2b1b08f40f3642fa856a3d18c9fffb060,Audio2Face: Generating Speech/Face Animation from Single Audio with Attention-Based Bidirectional LSTM Networks,2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW),2019.0,12,"We propose an end to end deep learning approach for generating real-time facial animation from just audio. Specifically, our deep architecture employs deep bidirectional long short-term memory network and attention mechanism to discover the latent representations of time-varying contextual information within the speech and recognize the significance of different information contributed to certain face status. Therefore, our model is able to drive different levels of facial movements at inference and automatically keep up with the corresponding pitch and latent speaking style in the input audio, with no assumption or further human intervention. Evaluation results show that our method could not only generate accurate lip movements from audio, but also successfully regress the speaker's time-varying facial movements."
"J. Tan, Chee Seng Chan, Joon Huang Chuah",9d6dbaf44d4437d9a27970bbc65e542706eae49f,COMIC: Toward A Compact Image Captioning Model With Attention,IEEE Transactions on Multimedia,2019.0,12,"Recent works in image captioning have shown very promising raw performance. However, we realize that most of these encoder–decoder style networks with attention do not scale naturally to large vocabulary size, making them difficult to deploy on embedded systems with limited hardware resources. This is because the size of word and output embedding matrices grow proportionally with the size of vocabulary, adversely affecting the compactness of these networks. To address this limitation, this paper introduces a brand new idea in the domain of image captioning. That is, we tackle the problem of compactness of image captioning models which is hitherto unexplored. We showed that our proposed model, named COMIC for compact image captioning, achieves comparable results in five common evaluation metrics with state-of-the-art approaches on both MS-COCO and InstaPIC-1.1M datasets despite having an embedded vocabulary size that is 39×−99× smaller."
"Mingjin Zhang, N. Wang, Yunsong Li, Xinbo Gao",34631f7432c4c17746338c20e9f32250285d3745,Deep Latent Low-Rank Representation for Face Sketch Synthesis,IEEE Transactions on Neural Networks and Learning Systems,2019.0,11,"Face sketch synthesis is useful and profitable in digital entertainment. Most existing face sketch synthesis methods rely on the assumption that facial photographs/sketches form a low-dimensional manifold. Once the training data are insufficient, the manifold could not characterize the identity-specific information that is included in a test photograph but excluded in the training data. Thus, the synthesized sketch would lose this information, such as glasses, earrings, hairstyles, and hairpins. To provide the sufficient data and satisfy the assumption on manifold, we propose a novel face sketch synthesis framework based on deep latent low-rank representation (DLLRR) in this paper. The DLLRR induces the hidden training sketches with the identity-specific information as the hidden data to the insufficient original training sketches as the observed data. And it searches the lowest rank representation on the candidates of a test photograph from the both hidden and observed data. For the strong representational capability of the coupled autoencoder, we leverage it to reveal the hidden data. Experiment results on face photograph–sketch database illustrate that the proposed method can successfully provide the sufficient training data with the identity-specific information. And compared to the state of the arts, the proposed method synthesizes more clean and vivid face sketches."
"Titir Dutta, Soma Biswas",485363cb469c0ec61e347da9ab26b9901bee9e5f,Style-Guided Zero-Shot Sketch-based Image Retrieval,BMVC,2019.0,11,"Given a sketch query from a previously unseen category, the goal of zero-shot sketchbased image retrieval (ZS-SBIR) is to retrieve semantically meaningful images from a given database. The knowledge-gap between the seen and unseen categories along with sketch-image domain shift makes this an extremely challenging problem. In this work, we propose a novel framework which decomposes each image and sketch into its domainindependent content and a domain, as well as data-dependent variation/style component. Specifically, given a query sketch and a search set of images, we utilize the image specific styles to guide the generation of fake images using the query content to be used for retrieval. Extensive experiments on two large-scale sketch-image datasets, Sketchy extended and TU-Berlin show that the proposed approach performs better or comparable to the state-of-the-art in both ZS-SBIR and generalized ZS-SBIR protocols."
"V. Verma, Aakansha Mishra, Ashish Mishra, Piyush Rai",39dcab483fa37155506e0a02c252cee5ebf0e463,Generative Model for Zero-Shot Sketch-Based Image Retrieval,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2019.0,11,"We present a probabilistic model for Sketch-Based Image Retrieval (SBIR) where, at retrieval time, we are given sketches from novel classes, that were not present at training time. Existing SBIR methods, most of which rely on learning class-wise correspondences between sketches and images, typically work well only for previously seen sketch classes, and result in poor retrieval performance on novel classes. To address this, we propose a generative model that learns to generate images, conditioned on a given novel class sketch. This enables us to reduce the SBIR problem to a standard image-to-image search problem. Our model is based on an inverse auto-regressive flow based variational autoencoder, with a feedback mechanism to ensure robust image generation. We evaluate our model on two very challenging datasets, Sketchy, and TU Berlin, with novel train-test split. The proposed approach significantly outperforms various baselines on both the datasets."
"Zhongyuan Hu, Haoran Xie, Tsukasa Fukusato, Takahiro Sato, T. Igarashi",3f01c12eca034542126f760d6c5c4768a76c2a92,Sketch2VF: Sketch‐based flow design with conditional generative adversarial network,Comput. Animat. Virtual Worlds,2019.0,11,"We present an interactive user interface to support sketch‐based fluid design with a perceptual understanding of human sketches. In particular, the proposed system generates a 2D fluid animation from hand‐drawn sketches. The proposed system utilizes a conditional generative adversarial network model to generate stationary velocity fields from a sketch input. The network model is trained with hand‐drawn strokes and corresponding 2D velocity fields. On the basis of the generated velocity field, the system calculates fluid dynamics using a semi‐Lagrangian method. We ran a user study of the proposed system and confirmed that the proposed interface is effective for a 2D fluid design and that the system achieves good results based on user input."
"Dmitriy Smirnov, Mikhail Bessmeltsev, J. Solomon",548840b2593d485789634b75dde7cfad6498e18c,Deep Sketch-Based Modeling of Man-Made Shapes,ArXiv,2019.0,11,"Sketch-based modeling aims to model 3D geometry using a concise and easy to create---but extremely ambiguous---input: artist sketches. Most conventional sketch-based modeling systems target smooth shapes and, to counter the ambiguity, put manually-designed priors on the 3D shape; they also typically require clean, vectorized input. Recent approaches attempt to learn those priors from data but often produce low-quality output. Focusing on piecewise-smooth man-made shapes, we address these issues by presenting a deep learning-based system to infer a complete man-made 3D shape from a single bitmap sketch. Given a sketch, our system infers a set of parametric surfaces that realize the drawing in 3D. To capture the piecewise smooth geometry of man-made shapes, we learn a special shape representation---a deformable parametric template composed of Coons patches. Naively training such a system, however, would suffer from lack of data and from self-intersections of the parametric surfaces. To address this, we introduce a synthetic sketch augmentation pipeline as well as a loss function that biases the network to output non-self-intersecting shapes. We demonstrate the efficacy of our system on a gallery of synthetic and real artist sketches as well as via comparison to related work."
"T. Ohtsuki, Tomohiro Mano",5fa6c0b42f05cf436b4e32d5f9aec5fc9c45b977,Drawing Phase Diagrams of Random Quantum Systems by Deep Learning the Wave Functions,,2019.0,11,"Applications of neural networks to condensed matter physics are becoming popular and beginning to be well accepted. Obtaining and representing the ground and excited state wave functions are examples of such applications. Another application is analyzing the wave functions and determining their quantum phases. Here, we review the recent progress of using the multilayer convolutional neural network, so-called deep learning, to determine the quantum phases in random electron systems. After training the neural network by the supervised learning of wave functions in restricted parameter regions in known phases, the neural networks can determine the phases of the wave functions in wide parameter regions in unknown phases; hence, the phase diagrams are obtained. We demonstrate the validity and generality of this method by drawing the phase diagrams of two- and higher dimensional Anderson metal-insulator transitions and quantum percolations as well as disordered topological systems such as three-dimensional topological insulators and Weyl semimetals. Both real-space and Fourier space wave functions are analyzed. The advantages and disadvantages over conventional methods are discussed."
"S. Durocher, Debajyoti Mondal",10b23e5f212e2c1a155302f732235bee1ffaf262,Drawing plane triangulations with few segments,Comput. Geom.,2019.0,11,"Dujmovi c, Eppstein, Suderman, and Wood showed that every 3-connected plane graph G with n vertices admits a straight-line drawing with at most 2:5n 3 segments, which is also the best known upper bound when restricted to plane triangulations. On the other hand, they showed that there exist triangulations requiring 2n 6 segments. In this paper we show that every plane triangulation admits a straight-line drawing with at most (7n 2 0 10)=3 2:33n segments, where 0 is the number of cyclic faces in the minimum realizer of G. If the input triangulation is 4-connected, then our algorithm computes a drawing with at most (9n 9)=4 2:25n segments. For general plane graphs with n vertices and m edges, our algorithm requires at most (16n 3m 28)=3 5:33n m segments, which is smaller than 2:5n 3 for all m 2:84n."
"N. Cao, Xin Yan, Yang Shi, Chaoran Chen",53f239effe5deaae51bbdce6c04da25088f067fa,AI-Sketcher : A Deep Generative Model for Producing High-Quality Sketches,AAAI,2019.0,10,"Sketch drawings play an important role in assisting humans in communication and creative design since ancient period. This situation has motivated the development of artificial intelligence (AI) techniques for automatically generating sketches based on user input. Sketch-RNN, a sequence-to-sequence variational autoencoder (VAE) model, was developed for this purpose and known as a state-of-the-art technique. However, it suffers from limitations, including the generation of lowquality results and its incapability to support multi-class generations. To address these issues, we introduced AI-Sketcher, a deep generative model for generating high-quality multiclass sketches. Our model improves drawing quality by employing a CNN-based autoencoder to capture the positional information of each stroke at the pixel level. It also introduces an influence layer to more precisely guide the generation of each stroke by directly referring to the training data. To support multi-class sketch generation, we provided a conditional vector that can help differentiate sketches under various classes. The proposed technique was evaluated based on two large-scale sketch datasets, and results demonstrated its power in generating high-quality sketches."
"Hangyu Lin, Yanwei Fu, Peng Lu, S. Gong, X. Xue, Yugang Jiang",d038d3f13560f43941401007361292dd741b601d,TC-Net for iSBIR: Triplet Classification Network for Instance-level Sketch Based Image Retrieval,ACM Multimedia,2019.0,10,"Sketch has been employed as an effective communication tool to express the abstract and intuitive meaning of object. While content-based sketch recognition has been studied for several decades, the instance-level Sketch Based Image Retrieval (iSBIR) task has attracted significant research attention recently. In many previous iSBIR works -- TripletSN, and DSSA, edge maps were employed as intermediate representations in bridging the cross-domain discrepancy between photos and sketches. However, it is nontrivial to efficiently train and effectively use the edge maps in an iSBIR system. Particularly, we find that such an edge map based iSBIR system has several major limitations. First, the system has to be pre-trained on a significant amount of edge maps, either from large-scale sketch datasets, e.g., TU-Berlin~\citeeitz2012hdhso, or converted from other large-scale image datasets, e.g., ImageNet-1K\citedeng2009imagenet dataset. Second, the performance of such an iSBIR system is very sensitive to the quality of edge maps. Third and empirically, the multi-cropping strategy is essentially very important in improving the performance of previous iSBIR systems. To address these limitations, this paper advocates an end-to-end iSBIR system without using the edge maps. Specifically, we present a Triplet Classification Network (TC-Net) for iSBIR which is composed of two major components: triplet Siamese network, and auxiliary classification loss. Our TC-Net can break the limitations existed in previous works. Extensive experiments on several datasets validate the efficacy of the proposed network and system."
"Kezhen Chen, I. Rabkina, Matthew D. McLure, Kenneth D. Forbus",140eaa631e502373348bf9318505ce2a70b01f6f,Human-Like Sketch Object Recognition via Analogical Learning,AAAI,2019.0,10,"Deep learning systems can perform well on some image recognition tasks. However, they have serious limitations, including requiring far more training data than humans do and being fooled by adversarial examples. By contrast, analogical learning over relational representations tends to be far more data-efficient, requiring only human-like amounts of training data. This paper introduces an approach that combines automatically constructed qualitative visual representations with analogical learning to tackle a hard computer vision problem, object recognition from sketches. Results from the MNIST dataset and a novel dataset, the Coloring Book Objects dataset, are provided. Comparison to existing approaches indicates that analogical generalization can be used to identify sketched objects from these datasets with several orders of magnitude fewer examples than deep learning systems require."
"Jungwoo Choi, Heeryon Cho, Jinjoo Song, S. Yoon",e22e7caae760c9282f43b87ae574f608651244ec,SketchHelper: Real-Time Stroke Guidance for Freehand Sketch Retrieval,IEEE Transactions on Multimedia,2019.0,10,"Text-based retrieval systems have been popular, but content-based retrieval systems have gained widespread acceptance in recent years to directly retrieve diverse media based on their visual content, such as color, texture, and shape. Among many content-based retrieval systems, sketch-based media retrieval systems have attracted attention recently with the proliferation of tablet PCs and smart mobile devices. Sketch-based retrieval requires the user to draw a freehand sketch query, but freehand drawing can be challenging for those with limited drawing skills. This degrades retrieval performance, since successful retrieval depends on the quality of the sketch query image drawn by the user. To address this issue, we propose a real-time stroke guidance for freehand sketch retrieval that continuously displays next-stroke shadow sketches on the canvas based on the user's step-by-step partial strokes. We train a stroke guidance network that learns the mapping between the step-wise stroke relations to predict the user's next stroke. The proposed stroke guidance for freehand sketch retrieval system runs on a five step next-stroke prediction model that identifies candidate next-stroke sketches from a database of millions of sketches. The system retrieves variable number of sketch object classes at different drawing stages. During the initial sketching stage, diverse drawing possibilities are covered by retrieving multiple sketch classes; as the sketching progresses, the intended sketch class is narrowed down to one. Deep binary hashing is employed for efficient similarity matching of relevant next-stroke sketches. We extend the Google QuickDraw dataset to create a five step sketch stroke database. Qualitative and quantitative experiments are conducted to verify the effectiveness of the proposed system, which can be utilized for drawing guidance, tracing, and sketch retrieval. Tracing refers to the act of copying the shadowed line of a guiding image by drawing over its lines."
"Hua Zhang, Peng She, Y. Liu, Jianhou Gan, Xiaochun Cao, H. Foroosh",731cb8de34020152772dcc5a101fc59495bcb1b1,Learning Structural Representations via Dynamic Object Landmarks Discovery for Sketch Recognition and Retrieval,IEEE Transactions on Image Processing,2019.0,10,"State-of-the-art methods on sketch classification and retrieval are based on deep convolutional neural network to learn representations. Although deep neural networks have the ability to model images with hierarchical representations by convolution kernels, they cannot automatically extract the structural representations of object categories in a human-perceptible way. Furthermore, sketch images usually have large-scale visual variations caused by the styles of drawing or viewpoints, which make it difficult to develop generalized representations using the fixed computational mode of convolutional kernel. In this paper, our aim is to address the problem of fixed computational mode in feature extraction process without extra supervision. We propose a novel architecture to dynamically discover the object landmarks and learn the discriminative structural representations. Our model is composed of two components: a representative landmark discovering module that localizes the key points on the object and a category-aware representation learning module that develops the category-specific features. Specifically, we develop a structure-aware offset layer to dynamically localize the representative landmarks, which is optimized based on the category labels without extra supervision. After that, a diversity branch is introduced to extract the global discriminative features for each category. Finally, we employ a multi-task loss function to develop an end-to-end trainable architecture. At testing time, we fuse all the predictions with different number of landmarks to achieve the final results. Through extensive experiments, we compare our model with several state-of-the-art methods on two challenging datasets, TU-Berlin and Sketchy, for sketch classification and retrieval, and the experimental results demonstrate the effectiveness of our proposed model."
"Milan Ceska, Christian Hensel, Sebastian Junges, J. Katoen",5812b3f76df6352c159d7885d20f67563207cb63,Counterexample-Driven Synthesis for Probabilistic Program Sketches,FM,2019.0,10,"Probabilistic programs are key to deal with uncertainty in e.g. controller synthesis. They are typically small but intricate. Their development is complex and error prone requiring quantitative reasoning over a myriad of alternative designs. To mitigate this complexity, we adopt counterexample-guided inductive synthesis (CEGIS) to automatically synthesise finite-state probabilistic programs. Our approach leverages efficient model checking, modern SMT solving, and counterexample generation at program level. Experiments on practically relevant case studies show that design spaces with millions of candidate designs can be fully explored using a few thousand verification queries."
"Zaoxing Liu, Tian Li, Virginia Smith, V. Sekar",cb68e7849eb9ba864926fd869570f04f6ec4edd1,Enhancing the Privacy of Federated Learning with Sketching,ArXiv,2019.0,9,"In response to growing concerns about user privacy, federated learning has emerged as a promising tool to train statistical models over networks of devices while keeping data localized. Federated learning methods run training tasks directly on user devices and do not share the raw user data with third parties. However, current methods still share model updates, which may contain private information (e.g., one's weight and height), during the training process. Existing efforts that aim to improve the privacy of federated learning make compromises in one or more of the following key areas: performance (particularly communication cost), accuracy, or privacy. To better optimize these trade-offs, we propose that \textit{sketching algorithms} have a unique advantage in that they can provide both privacy and performance benefits while maintaining accuracy. We evaluate the feasibility of sketching-based federated learning with a prototype on three representative learning models. Our initial findings show that it is possible to provide strong privacy guarantees for federated learning without sacrificing performance or accuracy. Our work highlights that there exists a fundamental connection between privacy and communication in distributed settings, and suggests important open problems surrounding the theoretical understanding, methodology, and system design of practical, private federated learning."
"Shuang Zhou, H. Mo, C. Li, Zheng Zheng, N. Li, Cheng Du, S. Mao, T. Parikh, R. Lane, Daniel I. Thomas",7065e7ae440eee6cbc0bf68d417147d81f8bb193,SDSS-IV MaNGA: stellar initial mass function variation inferred from Bayesian analysis of the integral field spectroscopy of early-type galaxies,,2019.0,9,"We analyze the stellar initial mass functions (IMF) of a large sample of early type galaxies (ETGs) provided by MaNGA. The large number of IFU spectra of individual galaxies provide high signal-to-noise composite spectra that are essential for constraining IMF and to investigate possible radial gradients of the IMF within individual galaxies. The large sample of ETGs also make it possible to study how the IMF shape depends on various properties of galaxies. We adopt a novel approach to study IMF variations in ETGs, use Bayesian inferences based on full spectrum fitting. The Bayesian method provides a statistically rigorous way to explore potential degeneracy in spectrum fitting, and to distinguish different IMF models with Bayesian evidence. We find that the IMF slope depends systematically on galaxy velocity dispersion, in that galaxies of higher velocity dispersion prefer a more bottom-heavy IMF, but the dependence is almost entirely due to the change of metallicity, $Z$, with velocity dispersion. The IMF shape also depends on stellar age, $A$, but the dependence is completely degenerate with that on metallicity through a combination $AZ^{-1.42}$. Using independent age and metallicity estimates we find that the IMF variation is produced by metallicity instead of age. The IMF near the centers of massive ETGs appears more bottom-heavy than that in the outer parts, while a weak opposite trend is seen for low-mass ETGs. Uncertainties produced by star formation history, dust extinction, $\alpha$-element abundance enhancement and noise in the spectra are tested."
"M. Graham, M. Cappellari, M. Bershady, N. Drory",2788e7a7d1b9085ba67e581127e63bf0172ad642,SDSS-IV MaNGA: New benchmark for the connection between stellar angular momentum and environment: a study of about 900 groups/clusters,,2019.0,9,"It has been observed that low redshift early-type galaxies can be separated into slow and fast rotators according to a proxy of specific stellar angular momentum, $\lambda_{R_e}$. Detailed studies of a handful of nearby clusters have shown that slow rotators are generally found at the centres of clusters where the number density is highest, whereas the fast rotators trace the trend followed by early-type galaxies of increasing in number with local density. In this paper, we study the environmental distribution of slow and fast rotators using the stellar kinematics of about 3900 galaxies from the Sloan Digital Sky Survey's Mapping Nearby Galaxies at Apache Point Observatory survey. For galaxies in groups closer than $z=0.08$ that are not observed with MaNGA but satisfy the necessary conditions for slow rotators, we visually assign slow/fast rotator classifications to obtain a complete sample. Our final catalogue contains about 900 groups of five or more members. We observe the kinematic morphology-density (kT-$\Sigma$) relation for each group and find an increasing fraction of massive slow rotators with increasing number density. We provide evidence suggesting that the observed lack of trends in angular momentum with environment at fixed stellar mass is partly because the maximum density varies between clusters, and that the locations of massive slow rotators are strongly correlated with peak densities in galaxy groups and clusters. We conclude that the (projected) number density relative to the cluster peak is more fundamental than the absolute number density in influencing the abundance of slow rotators. We find that the kT-$\Sigma$ relation does exist at fixed stellar mass, and we rule out the hypothesis that the kT-$\Sigma$ relation is a result of dynamical friction alone, instead arguing that massive slow rotators grow hierarchically in tandem with their host clusters."
"Wei-Hong Li, Zhuowei Zhong, W. Zheng",1565bf91f8fdfe5f5168a5050b1418debc662151,One-pass Person Re-identification by Sketch Online Discriminant Analysis,Pattern Recognit.,2019.0,9,"Person re-identification (re-id) is to match people across disjoint camera views in a multi-camera system, and re-id has been an important technology applied in smart city in recent years. However, the majority of existing person re-id methods are not designed for processing sequential data in an online way. This ignores the real-world scenario that person images detected from multi-cameras system are coming sequentially. While there is a few work on discussing online re-id, most of them require considerable storage of all passed data samples that have been ever observed, and this could be unrealistic for processing data from a large camera network. In this work, we present an onepass person re-id model that adapts the re-id model based on each newly observed data and no passed data are directly used for each update. More specifically, we develop an Sketch online Discriminant Analysis (SoDA) by embedding sketch processing into Fisher discriminant analysis (FDA). SoDA can efficiently keep the main data variations of all passed samples in a low rank matrix when processing sequential data samples, and estimate the approximate within-class variance (i.e. within-class covariance matrix) from the sketch data information. We provide theoretical analysis on the effect of the estimated approximate within-class covariance matrix. In particular, we derive upper and lower bounds on the Fisher discriminant score (i.e. the quotient between between-class variation and within-class variation after feature transformation) in order to investigate how the optimal feature transformation learned by SoDA sequentially approximates the offline FDA that is learned on all observed data. Extensive experimental results have shown the effectiveness of our SoDA and empirically support our theoretical analysis."
"Yao Xie, Peng Xu, Zhanyu Ma",8fef6210d39a43b445b66447b56a4dbf2463be2c,Deep Zero-Shot Learning for Scene Sketch,2019 IEEE International Conference on Image Processing (ICIP),2019.0,8,"We introduce a novel problem of scene sketch zero-shot learning (SSZSL), which is a challenging task, since (i) different from photo, the gap between common semantic domain (e.g., word vector) and sketch is too huge to exploit common semantic knowledge as the bridge for knowledge transfer, and (ii) compared with single-object sketch, more expressive feature representation for scene sketch is required to accommodate its high-level of abstraction and complexity. To overcome these challenges, we propose a deep embedding model for scene sketch zero-shot learning. In particular, we propose the augmented semantic vector to conduct domain alignment by fusing multi-modal semantic knowledge (e.g., cartoon image, natural image, text description), and adopt attention-based network for scene sketch feature learning. Moreover, we propose a novel distance metric to improve the similarity measure during testing. Extensive experiments and ablation studies demonstrate the benefit of our sketch-specific design."
"K. Li, Kaiyue Pang, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales, Honggang Zhang",9146e2d2b49805582ea5a3cf54a0fa0ba3fa7486,Toward Deep Universal Sketch Perceptual Grouper,IEEE Transactions on Image Processing,2019.0,8,"Human free-hand sketches provide the useful data for studying human perceptual grouping, where the grouping principles such as the Gestalt laws of grouping are naturally in play during both the perception and sketching stages. In this paper, we make the first attempt to develop a universal sketch perceptual grouper. That is, a grouper that can be applied to sketches of any category created with any drawing style and ability, to group constituent strokes/segments into semantically meaningful object parts. The first obstacle to achieving this goal is the lack of large-scale datasets with grouping annotation. To overcome this, we contribute the largest sketch perceptual grouping dataset to date, consisting of 20 000 unique sketches evenly distributed over 25 object categories. Furthermore, we propose a novel deep perceptual grouping model learned with both generative and discriminative losses. The generative loss improves the generalization ability of the model, while the discriminative loss guarantees both local and global grouping consistency. Extensive experiments demonstrate that the proposed grouper significantly outperforms the state-of-the-art competitors. In addition, we show that our grouper is useful for a number of sketch analysis tasks, including sketch semantic segmentation, synthesis, and fine-grained sketch-based image retrieval."
"David Dubray, Jochen Laubrock",38d8dc12c7bd49619b39ebe28d1459fb2cfa1960,Deep CNN-Based Speech Balloon Detection and Segmentation for Comic Books,2019 International Conference on Document Analysis and Recognition (ICDAR),2019.0,8,"We develop a method for the automated detection and segmentation of speech balloons in comic books, including their carrier and tails. Our method is based on a deep convolutional neural network that was trained on annotated pages of the Graphic Narrative Corpus. More precisely, we are using a fully convolutional network approach inspired by the U-Net architecture, combined with a VGG-16 based encoder. The trained model delivers state-of-the-art performance with an F1-score of over 0.94. Qualitative results suggest that wiggly tails, curved corners, and even illusory contours do not pose a major problem. Furthermore, the model has learned to distinguish speech balloons from captions. We compare our model to earlier results and discuss some possible applications."
"Badih Ghazi, R. Panigrahy, Joshua R. Wang",881a0d88cbd9f7ae1d3e91cf6b16b043c8f87ee8,Recursive Sketches for Modular Deep Learning,ICML,2019.0,8,"We present a mechanism to compute a sketch (succinct summary) of how a complex modular deep network processes its inputs. The sketch summarizes essential information about the inputs and outputs of the network and can be used to quickly identify key components and summary statistics of the inputs. Furthermore, the sketch is recursive and can be unrolled to identify sub-components of these components and so forth, capturing a potentially complicated DAG structure. These sketches erase gracefully; even if we erase a fraction of the sketch at random, the remainder still retains the `high-weight' information present in the original sketch. The sketches can also be organized in a repository to implicitly form a `knowledge graph'; it is possible to quickly retrieve sketches in the repository that are related to a sketch of interest; arranged in this fashion, the sketches can also be used to learn emerging concepts by looking for new clusters in sketch space. Finally, in the scenario where we want to learn a ground truth deep network, we show that augmenting input/output pairs with these sketches can theoretically make it easier to do so."
"Hao Tang, Xinya Chen, Wei Wang, D. Xu, Jason J. Corso, N. Sebe, Yan Yan",8085dea1a342e18dd6f12bd4cbfb5703d92b4201,Attribute-Guided Sketch Generation,2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019),2019.0,8,"Facial attributes are important since they provide a detailed description and determine the visual appearance of human faces. In this paper, we aim at converting a face image to a sketch while simultaneously generating facial attributes. To this end, we propose a novel Attribute-Guided Sketch Generative Adversarial Network (ASGAN) which is an end-to-end framework and contains two pairs of generators and discriminators, one of which is used to generate faces with attributes while the other one is employed for image-to-sketch translation. The two generators form a W-shaped network (W-net) and they are trained jointly with a weight-sharing constraint. Additionally, we also propose two novel discriminators, the residual one focusing on attribute generation and the triplex one helping to generate realistic looking sketches. To validate our model, we have created a new large dataset with 8,804 images, named the Attribute Face Photo & Sketch (AFPS) dataset which is the first dataset containing attributes associated to face sketch images. The experimental results demonstrate that the proposed network (i) generates more photo-realistic faces with sharper facial attributes than baselines and (ii) has good generalization capability on different generative tasks."
"Dan Lu, Zhenxue Chen, Q. M. Wu, Xuetao Zhang",e56ae44cdd8a2a89c76514bed7488d1f0ca33487,FCN based preprocessing for exemplar-based face sketch synthesis,Neurocomputing,2019.0,7,"Abstract Most of the current exemplar-based face sketch synthesis approaches directly synthesize face sketches from face photos. However, due to the great difference between face photos and sketches, as well as the cluttered backgrounds in photo images, there tends to be some noise, deformation and missing parts on the synthesized face sketches by most of the exemplar-based methods. Besides, most exemplar-based methods exist a common problem: they only produce satisfactory results when training and test samples originate from the same dataset. To address these issues, in this paper we propose a simple but effective method which consists of two stages: the preprocessing stage and the sketch synthesis stage. In the preprocessing stage, we first design a fully convolutional neural network for preprocessing (pFCN). To fit the preprocessing task, the pFCN is trained by an L1 based total loss function, which is simple yet could enhance the facial features. Then the full-size photo is fed to the well-trained pFCN to generate the feature map, which we call a semi-sketch since it bridges the discrepancy between photo and sketch. At the sketch synthesis stage, the semi-sketches and an existing exemplar-based method are employed to synthesize the final sketches. Extensive experiments on public face sketch datasets verify that the proposed two-stage method improves the sketch synthesis quality of the state-of-the-art exemplar-based methods in terms of both recognition accuracy and perceptual quality. In addition, the experiments on cross-dataset indicate that the proposed method provides a new means for strengthening the generalization ability of the exemplar-based method."
"Yanfu Yan, K. Lu, Jian Xue, Pengcheng Gao, Jiayi Lyu",1aef088a6f3d12afb8e048cc098c6a32643c0d85,FEAFA: A Well-Annotated Dataset for Facial Expression Analysis and 3D Facial Animation,2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW),2019.0,7,"Facial expression analysis based on machine learning requires large number of well-annotated data to reflect different changes in facial motion, but all of existing datasets, to the best of our knowledge, are limited to rough annotations for action units, including only their absence, presence, or a five-level intensity. To meet the need for videos labeled in great detail, we present a well-annotated dataset named FEAFA. One hundred and twenty-two participants were recorded in real-world conditions. 99,356 frames were manually labeled using Expression Quantitative Tool developed by us to quantify the re-defined action units according to Facial Action Coding System. Each action unit is well-annotated with a floating point number between 0 and 1. To provide a baseline for use in future research, a benchmark for the regression of action unit values based on Convolutional Neural Networks are presented. We also demonstrate the potential of FEAFA for 3D facial animation. Almost all state-of-the-art algorithms for facial animation are achieved based on 3D face reconstruction. We hence propose a novel method that drives virtual characters only based on action unit value regression of the 2D video frames of source actors."
"D. Giunchi, Stuart James, Donald Degraen, A. Steed",e370faf1676574e80545329af8164ec42b389f8d,Mixing realities for sketch retrieval in Virtual Reality,VRCAI,2019.0,6,"Users within a Virtual Environment often need support designing the environment around them with the need to find relevant content while remaining immersed. We focus on the familiar sketch-based interaction to support the process of content placing and specifically investigate how interactions from a tablet or desktop translate into the virtual environment. To understand sketching interaction within a virtual environment, we compare different methods of sketch interaction, i.e., 3D mid-air sketching, 2D sketching on a virtual tablet, 2D sketching on a fixed virtual whiteboard, and 2D sketching on a real tablet. The user remains immersed within the environment and queries a database containing detailed 3D models and replace them into the virtual environment. Our results show that 3D mid-air sketching is considered to be a more intuitive method to search a collection of models; while the addition of physical devices creates confusion due to the complications of their inclusion within a virtual environment. While we pose our work as a retrieval problem for 3D models of chairs, our results are extendable to other sketching tasks for virtual environments."
"Alex Klein, Zerrin Yumak, Arjen Beij, A. Stappen",2d864fe3d8145f32a23e4f5bafb2c8e2af67c062,Data-driven Gaze Animation using Recurrent Neural Networks,MIG,2019.0,6,"We present a data-driven gaze animation method using recurrent neural networks. The neural network is trained with motion capture data including different poses such as standing, sitting, and lying down and is able to learn the constraints related with each particular pose. A simplified version of the neural network is also presented for Level of Detail (LOD) animation. We compare various neural network architectures and show that our method produces natural gaze motion in real-time. Results from a user study conducted among game industry professionals shows that our method has better perceived naturalness compared to the procedural gaze animation system of a well-known game company. Our approach is the first one to show the feasibility of gaze motions using deep neural networks."
"Nhu-Van Nguyen, Christophe Rigaud, J. Burie",684726bf4cd22b09110ae62faa899617b8b00e2f,Comic MTL: optimized multi-task learning for comic book image analysis,International Journal on Document Analysis and Recognition (IJDAR),2019.0,6,"Comic book image analysis methods often propose multiple algorithms or models for multiple tasks like panel and character (body and face) detection, balloon segmentation, text recognition, etc. In this work, we aim to reduce the processing time for comic book image analysis by proposing one model that can learn multiple tasks called Comic MTL instead of using one model per task. In addition to detection and segmentation tasks, we integrate the relation analysis task for balloons and characters into the Comic MTL model. The experiments are carried out on DCM772 and eBDtheque public datasets that contain the annotations for panels, balloons, characters and also the associations between balloon and character. We show that the Comic MTL model can detect the associations between balloons and their speakers (comic characters) and handle other tasks like panel and character detection and also balloons segmentation with promising results."
"Ruizheng Wu, Xiaodong Gu, Xin Tao, Xiaoyong Shen, Yu-Wing Tai, Jiaya Jia",515ec130736879b3a78859b51ed27e316ed75223,Landmark Assisted CycleGAN for Cartoon Face Generation,ArXiv,2019.0,6,"In this paper, we are interested in generating an cartoon face of a person by using unpaired training data between real faces and cartoon ones. A major challenge of this task is that the structures of real and cartoon faces are in two different domains, whose appearance differs greatly from each other. Without explicit correspondence, it is difficult to generate a high quality cartoon face that captures the essential facial features of a person. In order to solve this problem, we propose landmark assisted CycleGAN, which utilizes face landmarks to define landmark consistency loss and to guide the training of local discriminator in CycleGAN. To enforce structural consistency in landmarks, we utilize the conditional generator and discriminator. Our approach is capable to generate high-quality cartoon faces even indistinguishable from those drawn by artists and largely improves state-of-the-art."
"Kurmanbek Kaiyrbekov, T. M. Sezgin",ad5b0e2e66c6e4b7cba638eb4f829ac211223329,Stroke-based sketched symbol reconstruction and segmentation,ArXiv,2019.0,6,"Hand-drawn objects usually consist of multiple semantically meaningful parts. For example, a stick figure consists of a head, a torso, and pairs of legs and arms. Efficient and accurate identification of these subparts promises to significantly improve algorithms for stylization, deformation, morphing and animation of 2D drawings. In this paper, we propose a neural network model that segments symbols into stroke-level components. Our segmentation framework has two main elements: a fixed feature extractor and a Multilayer Perceptron (MLP) network that identifies a component based on the feature. As the feature extractor we utilize an encoder of a stroke-rnn, which is our newly proposed generative Variational Auto-Encoder (VAE) model that reconstructs symbols on a stroke by stroke basis. Experiments show that a single encoder could be reused for segmenting multiple categories of sketched symbols with negligible effects on segmentation accuracies. Our segmentation scores surpass existing methodologies on an available small state of the art dataset. Moreover, extensive evaluations on our newly annotated big dataset demonstrate that our framework obtains significantly better accuracies as compared to baseline models. We release the dataset to the community."
"Long Zhao, Fangda Han, Xi Peng, Xun Zhang, Mubbasir Kapadia, V. Pavlovic, D. Metaxas",34ad523bfefd8307e8b98187d9bf0a199fa81fc6,Sketch-based Face Editing in Video Using Identity Deformation Transfer,Comput. Graph.,2019.0,6,"We address the problem of using hand-drawn sketch to edit facial identity, such as enlarging the shape or modifying the position of eyes or mouth, in the whole video. This task is formulated as a 3D face model reconstruction and deformation problem. We first introduce a two-stage real-time 3D face model fitting schema to recover facial identity and expressions from the video. We recognize the user's editing intention from the input sketch as a set of facial modifications. A novel identity deformation algorithm is then proposed to transfer these deformations from 2D space to 3D facial identity directly, while preserving the facial expressions. Finally, these changes are propagated to the whole video with the modified identity. Experimental results demonstrate that our method can effectively edit facial identity in video based on the input sketch with high consistency and fidelity."
"Weihao Xia, Yujiu Yang, Jing-Hao Xue",4dd8abe61cb7711a695a0bf60ebeb720cb589c96,Cali-Sketch: Stroke Calibration and Completion for High-Quality Face Image Generation from Poorly-Drawn Sketches,ArXiv,2019.0,6,"Image generation task has received increasing attention because of its wide application in security and entertainment. Sketch-based face generation brings more fun and better quality of image generation due to supervised interaction. However, When a sketch poorly aligned with the true face is given as input, existing supervised image-to-image translation methods often cannot generate acceptable photo-realistic face images. To address this problem, in this paper we propose Cali-Sketch, a poorly-drawn-sketch to photo-realistic-image generation method. Cali-Sketch explicitly models stroke calibration and image generation using two constituent networks: a Stroke Calibration Network (SCN), which calibrates strokes of facial features and enriches facial details while preserving the original intent features; and an Image Synthesis Network (ISN), which translates the calibrated and enriched sketches to photo-realistic face images. In this way, we manage to decouple a difficult cross-domain translation problem into two easier steps. Extensive experiments verify that the face photos generated by Cali-Sketch are both photo-realistic and faithful to the input sketches, compared with state-of-the-art methods"
"Hsin-Ying Hsieh, Chieh-Yu Chen, Yu-Shuen Wang, Jung-Hong Chuang",6fdcb668a61041f2a2770416f04d8bf0eff7a408,BasketballGAN: Generating Basketball Play Simulation Through Sketching,ACM Multimedia,2019.0,6,"We present a data-driven basketball set play simulation. Given an offensive set play sketch, our method simulates potential scenarios that may occur in the game. The simulation provides coaches and players with insights on how a given set play can be executed. To achieve the goal, we train a conditional adversarial network on NBA movement data to imitate the behaviors of how players move around the court through two major components: a generator that learns to generate natural player movements based on a latent noise and a user sketched set play; and a discriminator that is used to evaluate the realism of the basketball play. To improve the quality of simulation, we minimize 1.) a dribbler loss to prevent the ball from drifting away from the dribbler; 2.) a defender loss to prevent the dribbler from not being defended; 3.) a ball passing loss to ensure the straightness of passing trajectories; and 4) an acceleration loss to minimize unnecessary players' movements. To evaluate our system, we objectively compared real and simulated basketball set plays. Besides, a subjective test was conducted to judge whether a set play was real or generated by our network. On average, the mean correct rates to the binary tests were 56.17 %. Experiment results and the evaluations demonstrated the effectiveness of our system."
"T. Munz, M. Burch, Toon van Benthem, Y. Poels, Fabian Beck, D. Weiskopf",8573cf3de085ba939d157e906829b6b96faa9115,Overlap-Free Drawing of Generalized Pythagoras Trees for Hierarchy Visualization,2019 IEEE Visualization Conference (VIS),2019.0,6,"Generalized Pythagoras trees were developed for visualizing hierarchical data, producing organic, fractal-like representations. However, the drawback of the original layout algorithm is visual overlap of tree branches. To avoid such overlap, we introduce an adapted drawing algorithm using ellipses instead of circles to recursively place tree nodes representing the subhierarchies. Our technique is demonstrated by resolving overlap in diverse real-world and generated datasets, while comparing the results to the original approach."
"Shikang Yu, Hu Han, S. Shan, A. Dantcheva, Xilin Chen",88d2602b0c700048f79099f100ff90061aba81e4,Improving Face Sketch Recognition via Adversarial Sketch-Photo Transformation,2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019),2019.0,6,"Face sketch-photo transformation has broad applications in forensics, law enforcement, and digital entertainment, particular for face recognition systems that are designed for photo-to-photo matching. While there are a number of methods for face photo-to-sketch transformation, studies on sketch-to-photo transformation remain limited. In this paper, we propose a novel conditional CycleGAN for face sketch-to-photo transformation. Specifically, we leverage the advantages of CycleGAN and conditional GANs and design a feature-level loss to assure the high quality of the generated face photos from sketches. The generated face photos are used, as a replacement of face sketches, and particularly for face identification against a gallery set of mugshot photos. Experimental results on the public-domain database CUFSF show that the proposed approach is able to generate realistic photos from sketches, and the generated photos are instrumental in improving the sketch identification accuracy against a large gallery set."
"Mingrui Zhu, N. Wang, Xinbo Gao, J. Li, Zhifeng Li",0c8da8e0ef2f48d96be19e4ebce67dd04c5ec419,Face Photo-Sketch Synthesis via Knowledge Transfer,IJCAI,2019.0,5,"Despite deep neural networks have demonstrated strong power in face photo-sketch synthesis task, their performance, however, are still limited by the lack of training data (photo-sketch pairs). Knowledge Transfer (KT), which aims at training a smaller and fast student network with the information learned from a larger and accurate teacher network, has attracted much attention recently due to its superior performance in the acceleration and compression of deep neural networks. This work has brought us great inspiration that we can train a relatively small student network on limited training data by transferring knowledge from a larger teacher model trained on enough training data for other tasks. Therefore, we propose a novel knowledge transfer framework to synthesize face photos from face sketches or synthesize face sketches from face photos. Particularly, we utilize two teacher networks trained on large amount of data in related task to learn knowledge of face photos and knowledge of face sketches separately and transfer them to two student networks simultaneously. The two student networks, one for photo → sketch task and the other for sketch → photo task, can mimic and transform two kind of knowledge and transfer their knowledge mutually. With the proposed method, we can train a model which has superior performance using a small set of photosketch pairs. We validate the effectiveness of our method across several datasets. Quantitative and qualitative evaluations illustrate that our model outperforms other state-of-the-art methods in generating face sketches (or photos) with high visual quality and recognition ability."
"F. Wang, Shujin Lin, Hefeng Wu, H. Li, Ruomei Wang, Xiaonan Luo, Xiangjian He",c61236874e13da131cbc66fbb47bc33f282eb899,SPFusionNet: Sketch Segmentation Using Multi-modal Data Fusion,2019 IEEE International Conference on Multimedia and Expo (ICME),2019.0,5,"The sketch segmentation problem remains largely unsolved because conventional methods are greatly challenged by the highly abstract appearances of freehand sketches and their numerous shape variations. In this work, we tackle such challenges by exploiting different modes of sketch data in a unified framework. Specifically, we propose a deep neural network SPFusionNet to capture the characteristic of sketch by fusing from its image and point set modes. The image modal component SketchNet learns hierarchically abstract ro-bust features and utilizes multi-level representations to produce pixel-wise feature maps, while the point set-modal component SPointNet captures local and global contexts of the sampled point set to produce point-wise feature maps. Then our framework aggregates these feature maps by a fusion network component to generate the sketch segmentation result. The extensive experimental evaluation and comparison with peer methods on our large SketchSeg dataset verify the effectiveness of the proposed framework."
"Wenyuan Wang, Zhimin Zhang",01a7bdbae7833207ee5d41f74c21046a69e0fb21,Optimal loss-carry-forward taxation for Lévy risk processes stopped at general draw-down time,Advances in Applied Probability,2019.0,5,"Abstract Motivated by Avram, Vu and Zhou (2017), Kyprianou and Zhou (2009), Li, Vu and Zhou (2017), Wang and Hu (2012), and Wang and Zhou (2018), we consider in this paper the problem of maximizing the expected accumulated discounted tax payments of an insurance company, whose reserve process (before taxes are deducted) evolves as a spectrally negative Lévy process with the usual exclusion of negative subordinator or deterministic drift. Tax payments are collected according to the very general loss-carry-forward tax system introduced in Kyprianou and Zhou (2009). To achieve a balance between taxation optimization and solvency, we consider an interesting modified objective function by considering the expected accumulated discounted tax payments of the company until the general draw-down time, instead of until the classical ruin time. The optimal tax return function and the optimal tax strategy are derived, and some numerical examples are also provided."
"Yeyao Zhang, Eleftheria Tsipidi, S. Schriber, Mubbasir Kapadia, M. Gross, Ashutosh Modi",2815d46dc0092c5a89b043aef3a6a7805db753a7,Generating Animations from Screenplays,*SEM@NAACL-HLT,2019.0,5,"Automatically generating animation from natural language text finds application in a number of areas e.g. movie script writing, instructional videos, and public safety. However, translating natural language text into animation is a challenging task. Existing text-to-animation systems can handle only very simple sentences, which limits their applications. In this paper, we develop a text-to-animation system which is capable of handling complex sentences. We achieve this by introducing a text simplification step into the process. Building on an existing animation generation system for screenwriting, we create a robust NLP pipeline to extract information from screenplays and map them to the system's knowledge base. We develop a set of linguistic transformation rules that simplify complex sentences. Information extracted from the simplified sentences is used to generate a rough storyboard and video depicting the text. Our sentence simplification module outperforms existing systems in terms of BLEU and SARI metrics.We further evaluated our system via a user study: 68 % participants believe that our system generates reasonable animation from input screenplays."
"Sitao Xiang, Hao Li",135dc574a3f879f853f47c48a1d6a66ca71c32b7,Disentangling Style and Content in Anime Illustrations,ArXiv,2019.0,5,"Existing methods for AI-generated artworks still struggle with generating high-quality stylized content, where high-level semantics are preserved, or separating fine-grained styles from various artists. We propose a novel Generative Adversarial Disentanglement Network which can disentangle two complementary factors of variations when only one of them is labelled in general, and fully decompose complex anime illustrations into style and content in particular. Training such model is challenging, since given a style, various content data may exist but not the other way round. Our approach is divided into two stages, one that encodes an input image into a style independent content, and one based on a dual-conditional generator. We demonstrate the ability to generate high-fidelity anime portraits with a fixed content and a large variety of styles from over a thousand artists, and vice versa, using a single end-to-end network and with applications in style transfer. We show this unique capability as well as superior output to the current state-of-the-art."
"Wenbo Zheng, Lan Yan, Chao Gou, Wenwen Zhang, F. Wang",f0147bc1e95cfaddbcad61d835cb3ed0cd47b45f,A Relation Network Embedded with Prior Features for Few-Shot Caricature Recognition,2019 IEEE International Conference on Multimedia and Expo (ICME),2019.0,5,"Caricature is a simple and abstract description of a person using her/his exaggerated characteristics. Due to amplified facial variations in the caricatures and significant differences among caricature and real face modalities, building vision models for recognizing each other between these modalities is an extremely challenging task. In addition, it is not easy to collect abundant samples of real faces and corresponding caricatures for training vision models, which makes the recognition more difficult. In this paper, we propose a novel relation network via meta learning to address the problem of few-shot caricature face recognition. In particular, we present a deep relation network to capture and memorize the relation among different samples. To employ the prior knowledge, we combine learned deep and handcrafted features to form the hybrid-prior representation via joint meta learning. Final recognition is derived from our relation network by learning to compare between the hybrid-prior features of samples. Experimental results on three caricature datasets of WebCaricature, IIIT-CFW, and Caricature-207 demonstrate that our method performs better than many existing ones for few-shot caricature recognition."
"Yu Xia, S. Wang, Yanran Li, L. You, Xiaosong Yang, J. Zhang",25ad74087e31758576aa5c823594a5f8678ad7a7,Fine-Grained Color Sketch-Based Image Retrieval,CGI,2019.0,4,"We propose a novel fine-grained color sketch-based image retrieval (CSBIR) approach. The CSBIR problem is investigated for the first time using deep learning networks, in which deep features are used to represent color sketches and images. A novel ranking method considering both shape matching and color matching is also proposed. In addition, we build a CSBIR dataset with color sketches and images to train and test our method. The results show that our method has better retrieval performance."
"Runtao Liu, Qian Yu, Stella X. Yu",5a4b04bd1da682fcc080078ebf28c4f92ece74b6,An Unpaired Sketch-to-Photo Translation Model,ArXiv,2019.0,4,"Sketch-based image synthesis aims to generate a photo image given a sketch. It is a challenging task; because sketches are drawn by non-professionals and only consist of strokes, they usually exhibit shape deformation and lack visual cues, i.e., colors and textures. Thus translation from sketch to photo involves two aspects: shape and color (texture). Existing methods cannot handle this task well, as they mostly focus on solving one translation. In this work, we show that the key to this task lies in decomposing the translation into two subtasks, shape translation and colorization. Correspondingly, we propose a model consisting of two sub-networks, with each one tackling one sub-task. We also find that, when translating shapes, specific drawing styles affect the generated results significantly and may even lead to failure. To make our model more robust to drawing style variations, we design a data augmentation strategy and re-purpose an attention module, aiming to make our model pay less attention to distracted regions of a sketch. Besides, a conditional module is adapted for color translation to improve diversity and increase users’ control over the generated results. Both quantitative and qualitative comparisons are presented to show the superiority of our approach. In addition, as a side benefit, our model can synthesize high-quality sketches from photos inversely. We also demonstrate how these generated photos and sketches can benefit other applications, such as sketch-based image retrieval."
"Vanita Jain, P. Agrawal, Subham Banga, R. Kapoor, Shashwat Gulyani",99b24dbc8247bdc46ac0b84d7e349f3d253727e4,Sketch2Code: Transformation of Sketches to UI in Real-time Using Deep Neural Network,ArXiv,2019.0,4,"User Interface (UI) prototyping is a necessary step in the early stages of application development. Transforming sketches of a Graphical User Interface (UI) into a coded UI application is an uninspired but time-consuming task performed by a UI designer. An automated system that can replace human efforts for straightforward implementation of UI designs will greatly speed up this procedure. The works that propose such a system primarily focus on using UI wireframes as input rather than hand-drawn sketches. In this paper, we put forward a novel approach wherein we employ a Deep Neural Network that is trained on our custom database of such sketches to detect UI elements in the input sketch. Detection of objects in sketches is a peculiar visual recognition task that requires a specific solution that our deep neural network model attempts to provide. The output from the network is a platform-independent UI representation object. The UI representation object is a dictionary of key-value pairs to represent the UI elements recognized along with their properties. This is further consumed by our UI parser which creates code for different platforms. The intrinsic platform-independence allows the model to create a UI prototype for multiple platforms with single training. This two-step approach without the need for two trained models improves over other methods giving time-efficient results (average time: 129 ms) with good accuracy."
"Pegah Karimi, N. Davis, M. Maher, Kazjon Grace, L. Lee",f530e480fa614e10cd93d39b66a2b011b62cd645,Relating Cognitive Models of Design Creativity to the Similarity of Sketches Generated by an AI Partner,Creativity & Cognition,2019.0,4,"This paper presents and evaluates a new method for inspiring creativity in a co-creative design system. The method uses a computational model of aconceptual shift based on clustering of deep features from a database of sketches. The co-creative sketching tool maps a user's sketch to a sketch of a distinct category that has high, medium, or low visual and semantic similarity. We hypothesize that the degree of similarity between the user's and the system's sketches is associated with a range of cognitive models of creativity in a design context. We report on the findings of an empirical study that analyzes different design scenarios in which the user sketches in response to a proposed conceptual shift. The findings show that how similar the computational agent's sketch is to the user's original sketch is related to the presence of three types of design creativity in the user's response: combinatorial, exploratory, and transformational."
"Yi Guo, Zhuming Zhang, Chu Han, Wenbo Hu, Chengze Li, T. Wong",95e2b19874868720845112b80c4820fd5e7124a5,Deep Line Drawing Vectorization via Line Subdivision and Topology Reconstruction,Comput. Graph. Forum,2019.0,4,"Vectorizing line drawing is necessary for the digital workflows of 2D animation and engineering design. But it is challenging due to the ambiguity of topology, especially at junctions. Existing vectorization methods either suffer from low accuracy or cannot deal with high‐resolution images. To deal with a variety of challenging containing different kinds of complex junctions, we propose a two‐phase line drawing vectorization method that analyzes the global and local topology. In the first phase, we subdivide the lines into partial curves, and in the second phase, we reconstruct the topology at junctions. With the overall topology estimated in the two phases, we can trace and vectorize the curves. To qualitatively and quantitatively evaluate our method and compare it with the existing methods, we conduct extensive experiments on not only existing datasets but also our newly synthesized dataset which contains different types of complex and ambiguous junctions. Experimental statistics show that our method greatly outperforms existing methods in terms of computational speed and achieves visually better topology reconstruction accuracy."
"Meijuan Ye, Shizhe Zhou, Hongbo Fu",3aa4e569a27f2484b9103d0d83b495cd1bfa36bd,DeepShapeSketch : Generating hand drawing sketches from 3D objects,2019 International Joint Conference on Neural Networks (IJCNN),2019.0,4,"Freehand sketches are an important medium for expressing and communicating ideas. However creating a meaningful and understandable sketch drawing is not always an easy task especially for unskillful users. Existing methods for rendering 3D shape into line drawings such as Suggestive Contours, only consider the geometry-dependent and view-dependent information thus leads to over-regular or over-perfect results which doesn’t look like a human freehand drawing. For this challenge we address the problem of producing freehand line drawing sketches from a 3D object under a given viewpoint automatically. The core solution here is a recurrent generative deep neural network, which learns a functional mapping from the suggestive contours of a 3D shape to a more abstract sketch representation. We drop the encoder of the generator, i.e., use only a decoder to achieve better stability of the sketch structure. Users can tune the level of freehand style of the generated sketches by changing a single parameter. Experiments show that our results are expressive enough to faithfully describe the input shape and at the same time be with the style of freehand drawings created by a real human. We also perform a comparative user study to verify the quality and style of generated sketch results over existing methods. We also retrain our network using several different mingled dataset to test the extendibility of our method for this particular application. As far as our knowledge this work is the first research effort to automate the generation of human-like freehand sketches directly from 3D shapes."
"Kamran Ali, Ilkin Isler, C. Hughes",32791057cb542ec00c4c1d98bfeffbf4c3aaefa8,Facial Expression Recognition Using Human to Animated-Character Expression Translation,ArXiv,2019.0,4,"Facial expression recognition is a challenging task due to two major problems: the presence of inter-subject variations in facial expression recognition dataset and impure expressions posed by human subjects. In this paper we present a novel Human-to-Animation conditional Generative Adversarial Network (HA-GAN) to overcome these two problems by using many (human faces) to one (animated face) mapping. Specifically, for any given input human expression image, our HA-GAN transfers the expression information from the input image to a fixed animated identity. Stylized animated characters from the Facial Expression Research Group-Database (FERGDB) are used for the generation of fixed identity. By learning this many-to-one identity mapping function using our proposed HA-GAN, the effect of inter-subject variations can be reduced in Facial Expression Recognition(FER). We also argue that the expressions in the generated animated images are pure expressions and since FER is performed on these generated images, the performance of facial expression recognition is improved. Our initial experimental results on the state-of-the-art datasets show that facial expression recognition carried out on the generated animated images using our HA-GAN framework outperforms the baseline deep neural network and produces comparable or even better results than the state-of-the-art methods for facial expression recognition."
"Seok-Hee Hong, P. Eades, Marnijati Torkel, Ziyang Wang, David Chae, Sungpack Hong, Daniel Langerenken, H. Chafi",4c139134513b6b4eb6e89c460f8a9166c9bb95e2,Multi-level Graph Drawing using Infomap Clustering,Graph Drawing,2019.0,4,"Infomap clustering finds the community structures that minimize the expected description length of a random walk trajectory; algorithms for infomap clustering run fast in practice for large graphs. In this paper we leverage the effectiveness of Infomap clustering combined with the multi-level graph drawing paradigm. Experiments show that our new Infomap based multi-level algorithm produces good visualization of large and complex networks, with significant improvement in quality metrics."
"Zhengyuan Yang, Yixuan Zhang, Jiebo Luo",cbdd08a1f2896f6f304cfa9befef2400f22e0f67,Human-Centered Emotion Recognition in Animated GIFs,2019 IEEE International Conference on Multimedia and Expo (ICME),2019.0,4,"As an intuitive way of expression emotion, the animated Graphical Interchange Format (GIF) images have been widely used on social media. Most previous studies on automated GIF emotion recognition fail to effectively utilize GIF's unique properties, and this potentially limits the recognition performance. In this study, we demonstrate the importance of human related information in GIFs and conduct human-centered GIF emotion recognition with a proposed Keypoint Attended Visual Attention Network (KAVAN). The framework consists of a facial attention module and a hierarchical segment temporal module. The facial attention module exploits the strong relationship between GIF contents and human characters, and extracts frame-level visual feature with a focus on human faces. The Hierarchical Segment LSTM (HS-LSTM) module is then proposed to better learn global GIF representations. Our proposed framework outperforms the state-of-the-art on the MIT GIFGIF dataset. Furthermore, the facial attention module provides reliable facial region mask predictions, which improves the model's interpretability."
"Xinyu Li, Wei Zhang, T. Shen, Tao Mei",e34cb01b6eba277d7f129fb96f0646a630f51ea7,Everyone is a Cartoonist: Selfie Cartoonization with Attentive Adversarial Networks,2019 IEEE International Conference on Multimedia and Expo (ICME),2019.0,4,"Selfie and cartoon are two popular artistic forms that are widely presented in our daily life. Despite the great progress in image translation/stylization, few techniques focus specifically on selfie cartoonization, since cartoon images usually contain artistic abstraction (e.g., large smoothing areas) and exaggeration (e.g., large/delicate eyebrows). In this paper, we address this problem by proposing a selfie cartoonization Generative Adversarial Network (scGAN), which mainly uses an attentive adversarial network (AAN) to emphasize specific facial regions and ignore low-level details. More specifically, we first design a cycle-like architecture to enable training with unpaired data. Then we design three losses from different aspects. A total variation loss is used to highlight important edges and contents in cartoon portraits. An attentive cycle loss is added to lay more emphasis on delicate facial areas such as eyes. In addition, a perceptual loss is included to eliminate artifacts and improve robustness of our method. Experimental results show that our method is capable of generating different cartoon styles and outperforms a number of state-of-the-art methods."
"Akari Ishikawa, Edson Bollis, S. Avila",938d3fd2cede997006cae88bdc26b2af92e4d384,Combating the Elsagate Phenomenon: Deep Learning Architectures for Disturbing Cartoons,2019 7th International Workshop on Biometrics and Forensics (IWBF),2019.0,4,"Watching cartoons can be useful for children’s intellectual, social and emotional development. However, the most popular video sharing platform today provides many videos with Elsagate content. Elsagate is a phenomenon that depicts childhood characters in disturbing circumstances (e.g., gore, toilet humor, drinking urine, stealing). Even with this threat easily available for children, there is no work in the literature addressing the problem. As the first to explore disturbing content in cartoons, we proceed from the most recent pornography detection literature applying deep convolutional neural networks combined with static and motion information of the video. Our solution is compatible with mobile platforms and achieved 92.6% of accuracy. Our goal is not only to introduce the first solution but also to bring up the discussion around Elsagate."
"Jie Chen, G. Liu, X. Chen",10a9c5d183e7e7df51db8bfa366bc862262b37d7,AnimeGAN: A Novel Lightweight GAN for Photo Animation,,2019.0,4,"In this paper, a novel approach for transforming photos of real-world scenes into anime style images is proposed, which is a meaningful and challenging task in computer vision and artistic style transfer. The approach we proposed combines neural style transfer and generative adversarial networks (GANs) to achieve this task. For this task, some existing methods have not achieved satisfactory animation results. The existing methods usually have some problems, among which significant problems mainly include: 1) the generated images have no obvious animated style textures; 2) the generated images lose the content of the original images; 3) the parameters of the network require the large memory capacity. In this paper, we propose a novel lightweight generative adversarial network, called AnimeGAN, to achieve fast animation style transfer. In addition, we further propose three novel loss functions to make the generated images have better animation visual effects. These loss function are grayscale style loss, grayscale adversarial loss and color reconstruction loss. The proposed AnimeGAN can be easily end-to-end trained with unpaired training data. The parameters of AnimeGAN require the lower memory capacity. Experimental results show that our method can rapidly transform real-world photos into high-quality anime images and outperforms state-of-the-art methods."
"Anubha Pandey, Ashish Mishra, V. Verma, Anurag Mittal",bf395589a99eb7ce812948302b60bd0032916342,Adversarial Joint-Distribution Learning for Novel Class Sketch-Based Image Retrieval,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),2019.0,3,"In the information retrieval task, sketch-based image retrieval (SBIR) has drawn significant attention owing to the ease with which sketches can be drawn. The existing deep learning methods for the SBIR are very unrealistic in the real scenario, and its performance reduces drastically for unseen class test examples. Recently, Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) has drawn a lot of attention due to its ability to retrieve the novel/unseen class images at test time. These methods try to project sketch features into the image domain by learning a distribution conditioned on the sketch. We propose a new framework for ZS-SBIR that models joint distribution between the sketch and image domain using a generative adversarial network. The joint distribution modeling ability of our generative model helps to reduce the domain gap between the sketches and images. Our framework helps to synthesize the novel class image features using sketch features. The generative ability of our model for the unseen/novel classes, conditioned on sketch feature, allows it to perform well on the seen as well as unseen class sketches. We conduct extensive experiments on two widely used SBIR benchmark datasets-Sketchy and Tu-Berlin and obtain significant improvement over the existing state-of-the-art. We will release the code publicly for reproducibility of results."
"Yonggang Qi, Z. Tan",9866afa5dbdb741b617e221b0474f41005e01c73,SketchSegNet+: An End-to-End Learning of RNN for Multi-Class Sketch Semantic Segmentation,IEEE Access,2019.0,3,"We investigate the problem of stroke-level sketch segmentation, which is to automatically assign strokes of a given sketch with semantic labels. Solving the problem of sketch segmentation opens the door for fine-grained sketch interpretation, which can benefit many novel sketch-based applications, including sketch recognition and sketch-based image retrieval. In this paper, we propose an approach for multi-class sketch semantic segmentation by considering it as a sequence-to-sequence generation problem. Specifically, an end-to-end learned network SketchSegNet+, built on recurrent neural networks (RNN), is presented to translate a sequence of strokes into a sequence of semantic labels. In addition, a large-scale stroke-level sketch segmentation dataset is constructed for the first time, which is composed of 150K annotated free-hand human sketch selected from QuickDraw. The dataset will be released publicly. The experimental results of stroke-level sketch semantic segmentation on this novel dataset and the SPG dataset demonstrate the effectiveness of our approach."
"Wentao Chao, Liang Chang, Xuguang Wang, Jian Cheng, Xiaoming Deng, F. Duan",3d3b7c039318535b02573ceb13f81b8247b3e1b0,High-Fidelity Face Sketch-To-Photo Synthesis Using Generative Adversarial Network,2019 IEEE International Conference on Image Processing (ICIP),2019.0,3,"Face sketch-photo synthesis has important usage in law enforcement and human authentication. Due to the sparse information (no color or texture), the abstraction level, the diversity of sketches, and the domain gap between sketch and photo, it is challenging to synthesize a photo-realistic photo from an input sketch. Moreover, the deficiency of data also restricts the synthesis performance. In this paper, we present a high-fidelity face sketch-photo synthesis method using Generation Adversarial Network (GAN). Our network adopts a deep residual U-Net as generator and a Patch-GAN with residual blocks as discriminator. We design effective loss functions by enforcing pixels, edges and high-level features of the produced face photos. Moreover, we augment the CUHK sketch dataset using an effective sampling method. With the improved GAN and augmented dataset, we achieve high-fidelity face photos. Qualitative and quantitative experiments demonstrate the approach outperforms other method. Further experiments with a sketch-based photo editing application also validate the performance of our method."
"K. Sasaki, T. Ogata",0f3cfd9c75d22d2ba3ba78ae87638b2f6aae0880,Adaptive Drawing Behavior by Visuomotor Learning Using Recurrent Neural Networks,IEEE Transactions on Cognitive and Developmental Systems,2019.0,3,"Drawing is a medium that represents an idea as drawn lines, and drawing behavior requires complex cognitive abilities to process visual and motor information. One way to understand aspects of these abilities is constructing computational models that can replicate these abilities rather than explaining the phenomena by building plausible models by a top-down manner. In this paper, we proposed a supervised learning model that can be trained using examples of visuomotor sequences from drawings made by human. Additionally, we demonstrated that the proposed model has functions of: 1) associating motions to depict the given picture image and 2) adapting to drawing behavior to complete a given part of the drawing process. This dynamical model is implemented by recurrent neural networks that have images and motion as their input and output. Through experiments that involved learning human drawing sequences, the model was able to associate appropriate motions to achieve depiction targets while adapting to a given part of the drawing process. Furthermore, we demonstrate that including visual information in the model improved performance robustness against noisy lines in the input data."
"Xianlin Zhang, Xueming Li, Yang Liu, Fangxiang Feng",2f39c39f5a824b05f179a9efe7688f9971a3f587,A survey on freehand sketch recognition and retrieval,Image Vis. Comput.,2019.0,3,"Abstract With the development of digital devices and pressure sensing equipment, research into freehand sketches from touch-screen interfaces has increased significantly in recent years. As such, we provide the first comprehensive survey of recognition tasks based on sketch generation, freehand sketch classification, sketch-based image retrieval (SBIR), fine-grained sketch-based image retrieval (FG-SBIR), and sketch-based 3D shape image retrieval. Specifically, SBIR and FG-SBIR were the main focus of the survey. Primary technologies and benchmark datasets related to all sketch-based recognition topics are also discussed, along with future trends for this promising technology."
"V. Varshaneya, S. Balasubramanian, V. Balasubramanian",20311dfcbf8f023c4f6d77961c65ec7b4d958803,Teaching GANs to Sketch in Vector Format,ArXiv,2019.0,3,"Sketching is more fundamental to human cognition than speech. Deep Neural Networks (DNNs) have achieved the state-of-the-art in speech-related tasks but have not made significant development in generating stroke-based sketches a.k.a sketches in vector format. Though there are Variational Auto Encoders (VAEs) for generating sketches in vector format, there is no Generative Adversarial Network (GAN) architecture for the same. In this paper, we propose a standalone GAN architecture SkeGAN and a VAE-GAN architecture VASkeGAN, for sketch generation in vector format. SkeGAN is a stochastic policy in Reinforcement Learning (RL), capable of generating both multidimensional continuous and discrete outputs. VASkeGAN hybridizes a VAE and a GAN, in order to couple the efficient representation of data by VAE with the powerful generating capabilities of a GAN, to produce visually appealing sketches. We also propose a new metric called the Ske-score which quantifies the quality of vector sketches. We have validated that SkeGAN and VASkeGAN generate visually appealing sketches by using Human Turing Test and Ske-score."
"Maciej Pesko, Adam Svystun, Pawel Andruszkiewicz, P. Rokita, T. Trzciński",4c81212a1ecca6b160631fea7f2a6cbff6f74012,Comixify: Transform video into a comics,Fundam. Informaticae,2019.0,3,"In this paper, we propose a solution to transform a video into a comics. We approach this task using a neural style algorithm based on Generative Adversarial Networks (GANs). Several recent works in the field of Neural Style Transfer showed that producing an image in the style of another image is feasible. In this paper, we build up on these works and extend the existing set of style transfer use cases with a working application of video comixification. To that end, we train an end-to-end solution that transforms input video into a comics in two stages. In the first stage, we propose a state-of-the-art keyframes extraction algorithm that selects a subset of frames from the video to provide the most comprehensive video context and we filter those frames using image aesthetic estimation engine. In the second stage, the style of selected keyframes is transferred into a comics. To provide the most aesthetically compelling results, we selected the most state-of-the art style transfer solution and based on that implement our own ComixGAN framework. The final contribution of our work is a Web-based working application of video comixification available at this http URL."
"Yifan Hu, Lei Shi, Qingsong Liu",87bdfc6f36e044c33b251d3179d442ffd412307c,A Coloring Algorithm for Disambiguating Graph and Map Drawings,IEEE Transactions on Visualization and Computer Graphics,2019.0,3,"Drawings of non-planar graphs always result in edge crossings. When there are many edges crossing at small angles, it is often difficult to follow these edges, because of the multiple visual paths resulted from the crossings that slow down eye movements. In this paper we propose an algorithm that disambiguates the edges with automatic selection of distinctive colors. Our proposed algorithm computes a near optimal color assignment of a dual collision graph, using a novel branch-and-bound procedure applied to a space decomposition of the color gamut. We give examples demonstrating this approach in real world graphs and maps, as well as a user study to establish its effectiveness and limitations."
"Yliess Hati, Gregor Jouet, F. Rousseaux, Clément Duhart",4180a603f66f03a3663b967d8a53d267ff4a43e5,PaintsTorch: a User-Guided Anime Line Art Colorization Tool with Double Generator Conditional Adversarial Network,,2019.0,3,"The lack of information provided by line arts makes user guided-colorization a challenging task for computer vision. Recent contributions from the deep learning community based on Generative Adversarial Network (GAN) have shown incredible results compared to previous techniques. These methods employ user input color hints as a way to condition the network. The current state of the art has shown the ability to generalize and generate realistic and precise colorization by introducing a custom dataset and a new model with its training pipeline. Nevertheless, their approach relies on randomly sampled pixels as color hints for training. Thus, in this contribution, we introduce a stroke simulation based approach for hint generation, making the model more robust to messy inputs. We also propose a new cleaner dataset, and explore the use of a double generator GAN to improve visual fidelity."
"Weiguo Wan, Hyo Jong Lee",60abcc0818ecb2bccdf902d9480b7a672940b8d8,Generative Adversarial Multi-Task Learning for Face Sketch Synthesis and Recognition,2019 IEEE International Conference on Image Processing (ICIP),2019.0,3,"Face sketch synthesis and recognition have wide range of applications in law enforcement. Despite the impressive progresses have been made in faces sketch and recognition, most existing researches regard them as two separate tasks. In this paper, we propose a generative adversarial multitask learning method in order to deal with face sketch synthesis and recognition simultaneously. Our framework is based on generative adversarial networks (GAN), in which an improved deep network named residual dense U-Net is used as generator to synthesize face sketch image and a multi-task discriminator is designed to not only guide the generator to produce more realistic sketch image, but also extract discriminative face feature. In addition, except the common adversarial loss, the perceptual loss and triplet loss are adopted for the learning of generator and discriminator, respectively. Compared with the state-of-the-art methods, the proposed method obtains better results in terms of face sketch synthesis and recognition."
"Fang Xu, Ruixiang Zhang, Wen Yang, Guisong Xia",5f69859be251e70abfe7a752b878dc868b833361,Mental Retrieval of Large-Scale Satellite Images Via Learned Sketch-Image Deep Features,IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium,2019.0,2,"Searching targets of interest in large-scale satellite images is an imperative task, which becomes a challenging issue when the targets reside only in the mind of the user as a set of subjective visual patterns. In this paper, we take the advantage of hand-drawn sketches’ strong intuition of describing mental target to address the problem of no available exemplar query. We introduce a multi-level-of-detail model to learn a cross-domain representation for bridging the gap between sketches and satellite images. To train the model, we propose a novel method of generating satellite images with corresponding level of details based on generative adversarial network. Experiments on both large-scale satellite images and commonly used RS datasets demonstrate the effectiveness and superiority of our method."
"N. Inoue, D. Ito, N. Xu, J. Yang, Brian L. Price, T. Yamasaki",4da2c38314787225e88ff13515070ff9fc433277,Learning to Trace: Expressive Line Drawing Generation from Photographs,Comput. Graph. Forum,2019.0,2,"In this paper, we present a new computational method for automatically tracing high‐resolution photographs to create expressive line drawings. We define expressive lines as those that convey important edges, shape contours, and large‐scale texture lines that are necessary to accurately depict the overall structure of objects (similar to those found in technical drawings) while still being sparse and artistically pleasing. Given a photograph, our algorithm extracts expressive edges and creates a clean line drawing using a convolutional neural network (CNN). We employ an end‐to‐end trainable fully‐convolutional CNN to learn the model in a data‐driven manner. The model consists of two networks to cope with two sub‐tasks; extracting coarse lines and refining them to be more clean and expressive. To build a model that is optimal for each domain, we construct two new datasets for face/body and manga background. The experimental results qualitatively and quantitatively demonstrate the effectiveness of our model. We further illustrate two practical applications."
"Y. Zheng, H. Yao, Xiaoshuai Sun",1961ad34f7824b1d19dbd7f9a8641528323464af,"Deep Semantic Parsing of Freehand Sketches with Homogeneous Transformation, Soft-Weighted Loss, and Staged Learning",ArXiv,2019.0,2,"In this paper, we propose a novel deep framework for part-level semantic parsing of freehand sketches, which makes three main contributions that are experimentally shown to have substantial practical merit. First, we introduce a new idea named homogeneous transformation to address the problem of domain adaptation. For the task of sketch parsing, there is no available data of labeled freehand sketches that can be directly used for model training. An alternative solution is to learn from the existing parsing data of real images, while the domain adaptation is an inevitable problem. Unlike existing methods that utilize the edge maps of real images to approximate freehand sketches, the proposed homogeneous transformation method transforms the data from two different domains into a homogeneous space to minimize the semantic gap. Second, we design a soft-weighted loss function as guidance for the training process, which gives attention to both the ambiguous label boundary and class imbalance. Third, we present a staged learning strategy to improve the parsing performance of the trained model, which takes advantage of the shared information and specific characteristic from different sketch categories. Extensive experimental results demonstrate the effectiveness of these methods. Specifically, to evaluate the generalization ability of our homogeneous transformation method, additional experiments at the task of sketch-based image retrieval are conducted on the QMUL FG-SBIR dataset. By integrating the proposed three methods into a unified framework, our final deep semantic sketch parsing (DeepSSP) model achieves the state-of-the-art on the public SketchParse dataset."
"X. Xu, H. Wang, L. Li, Cheng Deng",8278f5cb33ebe9e5e06221e5d95fcfdb6cc5ef24,Semantic Adversarial Network for Zero-Shot Sketch-Based Image Retrieval,ArXiv,2019.0,2,"Zero-shot sketch-based image retrieval (ZS-SBIR) is a specific cross-modal retrieval task for retrieving natural images with free-hand sketches under zero-shot scenario. Previous works mostly focus on modeling the correspondence between images and sketches or synthesizing image features with sketch features. However, both of them ignore the large intra-class variance of sketches, thus resulting in unsatisfactory retrieval performance. In this paper, we propose a novel end-to-end semantic adversarial approach for ZS-SBIR. Specifically, we devise a semantic adversarial module to maximize the consistency between learned semantic features and category-level word vectors. Moreover, to preserve the discriminability of synthesized features within each training category, a triplet loss is employed for the generative module. Additionally, the proposed model is trained in an end-to-end strategy to exploit better semantic features suitable for ZS-SBIR. Extensive experiments conducted on two large-scale popular datasets demonstrate that our proposed approach remarkably outperforms state-of-the-art approaches by more than 12\% on Sketchy dataset and about 3\% on TU-Berlin dataset in the retrieval."
"Hao Wang, Cheng Deng, Xinxu Xu, W. Liu, Xinbo Gao, D. Tao",f76e2ac241859bf497aceb7321cd9c86c874e37c,Stacked Semantic-Guided Network for Zero-Shot Sketch-Based Image Retrieval,ArXiv,2019.0,2,"Zero-shot sketch-based image retrieval (ZS-SBIR) is a task of cross-domain image retrieval from a natural image gallery with free-hand sketch under a zero-shot scenario. Previous works mostly focus on a generative approach that takes a highly abstract and sparse sketch as input and then synthesizes the corresponding natural image. However, the intrinsic visual sparsity and large intra-class variance of the sketch make the learning of the conditional decoder more difficult and hence achieve unsatisfactory retrieval performance. In this paper, we propose a novel stacked semantic-guided network to address the unique characteristics of sketches in ZS-SBIR. Specifically, we devise multi-layer feature fusion networks that incorporate different intermediate feature representation information in a deep neural network to alleviate the intrinsic sparsity of sketches. In order to improve visual knowledge transfer from seen to unseen classes, we elaborate a coarse-to-fine conditional decoder that generates coarse-grained category-specific corresponding features first (taking auxiliary semantic information as conditional input) and then generates fine-grained instance-specific corresponding features (taking sketch representation as conditional input). Furthermore, regression loss and classification loss are utilized to preserve the semantic and discriminative information of the synthesized features respectively. Extensive experiments on the large-scale Sketchy dataset and TU-Berlin dataset demonstrate that our proposed approach outperforms state-of-the-art methods by more than 20\% in retrieval performance."
"Y. Zhang, Guoyao Su, Yonggang Qi, Jie Yang",690913b22275e4360bc3770948a84999c5c440a8,Unpaired Image-to-Sketch Translation Network for Sketch Synthesis,2019 IEEE Visual Communications and Image Processing (VCIP),2019.0,2,"Image-to-sketch translation is to learn the mapping between an image and a corresponding human drawn sketch. Machine can be trained to mimic the human drawing process using a training set of aligned image-sketch pairs. However, to collect such paired data is quite expensive or even unavailable for many cases since sketches exhibit various level of abstractness and drawing preferences. Hence we present an approach for learning an image-to-sketch translation network via unpaired examples. A translation network, which can translate the representation in image latent space to sketch domain, is trained in unsupervised setting. To prevent the problem of representation shifting in cross-domain translation, a novel cycle+ consistency loss is explored. Experimental results on sketch recognition and sketch-based image retrieval demonstrate the effectiveness of our approach."
"Shichao Li, Y. Zheng, Xiangju Lu, Bo Peng",ddbdf7f435f0339584db7c594cf6973b9a727f37,iCartoonFace: A Benchmark of Cartoon Person Recognition,ArXiv,2019.0,2,"Cartoons receive increasingly attention and have a huge global market. Cartoon person recognition has a wealth of application scenarios. However, there is no large and high quality dataset for cartoon person recognition. It limit the development of recognition algorithms. In this paper, we propose the first large unconstrained cartoon database called iCartoonFace. We have released the dataset publicly available to promote cartoon person recognition research\footnote{The dataset can be applied by sending email to zhengyi01@qiyi.com}. The dataset contains 68,312 images of 2,639 identities. The dataset consists of persons which come from cartoon videos. The samples are extracted from public available images on website and online videos on iQiYi company. All images pass through a careful manual annotation process. We evaluated the state-of-the-art image classification and face recognition algorithms on the iCartoonFace dataset as a baseline. A dataset fusion method which utilize face feature to improve the performance of cartoon recognition task is proposed. Experimental performance show that the performance of baseline models much worse than human performance. The proposed dataset fusion method achieves a 4.74% improvement over the baseline model. In a word, state-of-the-art algorithms for classification and recognition are far from being perfect for unconstrained cartoon person recognition."
"F. D. Luca, Md. Iqbal Hossain, S. Kobourov",5d96027045a5ac6df3967fc70083be4db098e067,Symmetry Detection and Classification in Drawings of Graphs,Graph Drawing,2019.0,2,"Symmetry is a key feature observed in nature (from flowers and leaves, to butterflies and birds) and in human-made objects (from paintings and sculptures, to manufactured objects and architectural design). Rotational, translational, and especially reflectional symmetries, are also important in drawings of graphs. Detecting and classifying symmetries can be very useful in algorithms that aim to create symmetric graph drawings and in this paper we present a machine learning approach for these tasks. Specifically, we show that deep neural networks can be used to detect reflectional symmetries with 92% accuracy. We also build a multi-class classifier to distinguish between reflectional horizontal, reflectional vertical, rotational, and translational symmetries. Finally, we make available a collection of images of graph drawings with specific symmetric features that can be used in machine learning systems for training, testing and validation purposes. Our datasets, best trained ML models, source code are available online."
"A. Jenal, Nikolay Savinov, Torsten Sattler, Gaurav Chaurasia",b91d2b4c7cb96b0598a5ca4922bfe92eba88baba,RNN-based Generative Model for Fine-Grained Sketching,ArXiv,2019.0,2,"Deep generative models have shown great promise when it comes to synthesising novel images. While they can generate images that look convincing on a higher-level, generating fine-grained details is still a challenge. In order to foster research on more powerful generative approaches, this paper proposes a novel task: generative modelling of 2D tree skeletons. Trees are an interesting shape class because they exhibit complexity and variations that are well-suited to measure the ability of a generative model to generated detailed structures. We propose a new dataset for this task and demonstrate that state-of-the-art generative models fail to synthesise realistic images on our benchmark, even though they perform well on current datasets like MNIST digits. Motivated by these results, we propose a novel network architecture based on combining a variational autoencoder using Recurrent Neural Networks and a convolutional discriminator. The network, error metrics and training procedure are adapted to the task of fine-grained sketching. Through quantitative and perceptual experiments, we show that our model outperforms previous work and that our dataset is a valuable benchmark for generative models. We will make our dataset publicly available."
"T. Mchedlidze, M. Radermacher, Ignaz Rutter, Nina Zimbel",29b92a9dc3ad3f52dc8bfd0425ed2588ba9ba42c,Drawing Clustered Graphs on Disk Arrangements,WALCOM,2019.0,2,"Let $G=(V, E)$ be a planar graph and let $\mathcal{C}$ be a partition of $V$. We refer to the graphs induced by the vertex sets in $\mathcal{C}$ as Clusters. Let $D_{\mathcal C}$ be an arrangement of disks with a bijection between the disks and the clusters. Akitaya et al. give an algorithm to test whether $(G, \mathcal{C})$ can be embedded onto $D_{\mathcal C}$ with the additional constraint that edges are routed through a set of pipes between the disks. Based on such an embedding, we prove that every clustered graph and every disk arrangement without pipe-disk intersections has a planar straight-line drawing where every vertex is embedded in the disk corresponding to its cluster. This result can be seen as an extension of the result by Alam et al. who solely consider biconnected clusters. Moreover, we prove that it is NP-hard to decide whether a clustered graph has such a straight-line drawing, if we permit pipe-disk intersections."
"F. D. Luca, Md. Iqbal Hossain, S. Kobourov, A. Lubiw, Debajyoti Mondal",c8cec2f0f4bce763f73e5f80ac4f63e2202cc369,Recognition and drawing of stick graphs,Theor. Comput. Sci.,2019.0,2,"Abstract A Stick graph is an intersection graph of axis-aligned segments such that the left end-points of the horizontal segments and the bottom end-points of the vertical segments lie on a “ground line,” a line with slope −1. It is an open question to decide in polynomial time whether a given bipartite graph G with bipartition A ∪ B has a Stick representation where the vertices in A and B correspond to horizontal and vertical segments, respectively. We prove that G has a Stick representation if and only if there are orderings of A and B such that G's bipartite adjacency matrix with rows A and columns B excludes three small ‘forbidden’ submatrices. This is similar to characterizations for other classes of bipartite intersection graphs. We present an algorithm to test whether given orderings of A and B permit a Stick representation respecting those orderings, and to find such a representation if it exists. The algorithm runs in time linear in the size of the adjacency matrix. For the case when only the ordering of A is given, or neither ordering is given, we present some partial results about graphs that are, or are not, Stick representable."
"Evan Byrne, A. Chatalic, R. Gribonval, P. Schniter",c6e321230ae479406ee9491e956385c095e9c0c7,Sketched Clustering via Hybrid Approximate Message Passing,IEEE Transactions on Signal Processing,2019.0,2,"In sketched clustering, a dataset of <inline-formula><tex-math notation=""LaTeX"">$T$</tex-math></inline-formula> samples is first sketched down to a vector of modest size, from which the centroids are subsequently extracted. Its advantages include 1) reduced storage complexity and 2) centroid extraction complexity independent of <inline-formula><tex-math notation=""LaTeX"">$T$</tex-math></inline-formula>. For the sketching methodology recently proposed by Keriven <italic>et al.</italic>, which can be interpreted as a random sampling of the empirical characteristic function, we propose a sketched clustering algorithm based on approximate message passing. Numerical experiments suggest that our approach is more efficient than the state-of-the-art sketched clustering algorithm “CL-OMPR” (in both computational and sample complexity) and more efficient than k-means++ when <inline-formula><tex-math notation=""LaTeX"">$T$</tex-math></inline-formula> is large."
"Jiangtong Li, Zhixin Ling, Li Niu, Liqing Zhang",1adc07c4b164c6b92afab5d05f79b30f98cf148e,Zero-Shot Sketch-Based Image Retrieval with Structure-aware Asymmetric Disentanglement,,2019.0,1,"The goal of Sketch-Based Image Retrieval (SBIR) is using free-hand sketches to retrieve images of the same category from a natural image gallery. However, SBIR requires all test categories to be seen during training, which cannot be guaranteed in real-world applications. So we investigate more challenging Zero-Shot SBIR (ZS-SBIR), in which test categories do not appear in the training stage. After realizing that sketches mainly contain structure information while images contain additional appearance information, we attempt to achieve structure-aware retrieval via asymmetric disentanglement.For this purpose, we propose our STRucture-aware Asymmetric Disentanglement (STRAD) method, in which image features are disentangled into structure features and appearance features while sketch features are only projected to structure space. Through disentangling structure and appearance space, bi-directional domain translation is performed between the sketch domain and the image domain. Extensive experiments demonstrate that our STRAD method remarkably outperforms state-of-the-art methods on three large-scale benchmark datasets."
"Shutaro Kuwabara, Ryutarou Ohbuchi, T. Furuya",5a1f2b6331476279b02ba78ceb815db6b49a9f27,Query by Partially-Drawn Sketches for 3D Shape Retrieval,2019 International Conference on Cyberworlds (CW),2019.0,1,"Hand-drawn sketch is a powerful modality to query 3D shape models. However, specifying a detailed 3D shape by a sketch on the first try without reference (i.e., 3D model or real object) is difficult. In this paper, we aim at a sketch-based 3D shape retrieval system that tolerates coarsely drawn or incomplete sketches having small number of strokes. Such a system could be used to start a sketch-retrieve-refine interactive loop that could lead to a 3D shape having required shape details. Proposed algorithm uses deep feature embedding into common feature embedding space to compare sketches and 3D shape models. To handle coarse or incomplete sketches, a sketch, which is a sequence of strokes, is augmented by removing stroke for training a pair of DNNs to extract sketch features. A sketch feature is a fusion of an image based feature extracted by a convolutional neural network (CNN) and a 2D point sequence feature extracted by using a recurrent neural network (RNN). Embedding of 3D shape feature and the sketch feature is learned by using triplet loss. Experimental evaluation of the proposed method is performed using (simulated) incomplete sketches created by removing part of their strokes. The experiments show that sketch stroke removal augmentation significantly improved retrieval accuracy if queried by using such incomplete sketches."
"Jiangtong Li, Zhixin Ling, Li Niu, Liqing Zhang",60f547f5a59c23749bb86be5770c3458631f6d13,Bi-Directional Domain Translation for Zero-Shot Sketch-Based Image Retrieval,ArXiv,2019.0,1,"The goal of Sketch-Based Image Retrieval (SBIR) is using free-hand sketches to retrieve images of the same category from a natural image gallery. However, SBIR requires all categories to be seen during training, which cannot be guaranteed in real-world applications. So we investigate more challenging Zero-Shot SBIR (ZS-SBIR), in which test categories do not appear in the training stage. Traditional SBIR methods are prone to be category-based retrieval and cannot generalize well from seen categories to unseen ones. In contrast, we disentangle image features into structure features and appearance features to facilitate structure-based retrieval. To assist feature disentanglement and take full advantage of disentangled information, we propose a Bi-directional Domain Translation (BDT) framework for ZS-SBIR, in which the image domain and sketch domain can be translated to each other through disentangled structure and appearance features. Finally, we perform retrieval in both structure feature space and image feature space. Extensive experiments demonstrate that our proposed approach remarkably outperforms state-of-the-art approaches by about 8% on the Sketchy dataset and over 5% on the TU-Berlin dataset."
"Y. Zheng, H. Yao, Xiaoshuai Sun, S. Zhang, Sicheng Zhao, F. Porikli",7337716e7f9912105fca7dd1f8db9fe836ba58be,Sketch-Specific Data Augmentation for Freehand Sketch Recognition,ArXiv,2019.0,1,"Sketch recognition remains a significant challenge due to the limited training data and the substantial intra-class variance of freehand sketches for the same object. Conventional methods for this task often rely on the availability of the temporal order of sketch strokes, additional cues acquired from different modalities and supervised augmentation of sketch datasets with real images, which also limit the applicability and feasibility of these methods in real scenarios. 
In this paper, we propose a novel sketch-specific data augmentation (SSDA) method that leverages the quantity and quality of the sketches automatically. From the aspect of quantity, we introduce a Bezier pivot based deformation (BPD) strategy to enrich the training data. Towards quality improvement, we present a mean stroke reconstruction (MSR) approach to generate a set of novel types of sketches with smaller intra-class variances. Both of these solutions are unrestricted from any multi-source data and temporal cues of sketches. Furthermore, we show that some recent deep convolutional neural network models that are trained on generic classes of real images can be better choices than most of the elaborate architectures that are designed explicitly for sketch recognition. As SSDA can be integrated with any convolutional neural networks, it has a distinct advantage over the existing methods. Our extensive experimental evaluations demonstrate that the proposed method achieves state-of-the-art results (84.27%) on the TU-Berlin dataset, outperforming the human performance by a remarkable 11.17% increase. We also present a new benchmark named Sketchy-R to facilitate future research in sketch recognition. Finally, more experiments show the practical value of our approach to the task of sketch-based image retrieval."
"Chuo Li, Yuan Zhou, Jianxing Yang",f822beeceac48facbd2676113173a632c7fcb26b,Sketch-Based Image Retrieval via a Semi-Heterogeneous Cross-Domain Network,2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW),2019.0,1,"We propose a novel semi-heterogeneous network for sketch-based image retrieval (SBIR). By exploring different feature-extracting network structures and data augmentation algorithms, we design a high-performance deep-network based method for SBIR. Our work consists of three stages: 1) we propose a novel deep SBIR optimization model, termed a semi-heterogeneous network, to capture the cross-view similarities between different categories; 2) we develop a novel feature extraction method to find a cross-domain representation which contains the line information of sketches while retaining the original information of images; 3) we explore a more comprehensive structure though different parameter and network settings for further performance improvement. Based on our experiments on a widely used dataset, our approach significantly outperforms state-of-the-art methods."
"Roberta Falcone, A. Montanari, L. Anderlucci",f2120e422e11a47974ab98602e6b35980cba2d6c,Matrix sketching for supervised classification with imbalanced classes,ArXiv,2019.0,1,"Matrix sketching is a recently developed data compression technique. An input matrix A is efficiently approximated with a smaller matrix B, so that B preserves most of the properties of A up to some guaranteed approximation ratio. In so doing numerical operations on big data sets become faster. Sketching algorithms generally use random projections to compress the original dataset and this stochastic generation process makes them amenable to statistical analysis. The statistical properties of sketching algorithms have been widely studied in the context of multiple linear regression. In this paper we propose matrix sketching as a tool for rebalancing class sizes in supervised classification with imbalanced classes. It is well-known in fact that class imbalance may lead to poor classification performances especially as far as the minority class is concerned."
"Zuheng Ming, J. Burie, Muhammad Muzzamil Luqman",796fedd4b6dcdd709e6f721be3c4c5c35e4fdb63,Dynamic Deep Multi-task Learning for Caricature-Visual Face Recognition,2019 International Conference on Document Analysis and Recognition Workshops (ICDARW),2019.0,1,"Rather than the visual images, the face recognition of the caricatures is far from the performance of the visual images. The challenge is the extreme non-rigid distortions of the caricatures introduced by exaggerating the facial features to strengthen the characters. In this paper, we propose dynamic multi-task learning based on deep CNNs for cross-modal caricature-visual face recognition. Instead of the conventional multi-task learning with fixed weights of the tasks, the proposed dynamic multi-task learning dynamically updates the weights of tasks according to the importance of the tasks, which enables the training of the networks focus on the hard task instead of being stuck in the overtraining of the easy task. The experimental results demonstrate the effectiveness of the dynamic multi-task learning for caricature-visual face recognition. The performance evaluated on the datasets CaVI and WebCaricature show the superiority over the state-of-art methods. The implementation code is available here."
"A. Nivaggioli, D. Rohmer",03ea37a0d14d28a3b5887ab4450cebeef56d0fa1,Animation Synthesis Triggered by Vocal Mimics,MIG,2019.0,1,"We propose a method leveraging the naturally time-related expressivity of our voice to control an animation composed of a set of short events. The user records itself mimicking onomatopoeia sounds such as ”Tick”, ”Pop”, or ”Chhh” which are associated with specific animation events. The recorded soundtrack is automatically analyzed to extract every instant and types of sounds. We finally synthesize an animation where each event type and timing correspond with the soundtrack. In addition to being a natural way to control animation timing, we demonstrate that multiple stories can be efficiently generated by recording different voice sequences. Also, the use of more than one soundtrack allows us to control different characters with overlapping actions."
"Junkun Jiang, Ruomei Wang, Shujin Lin, Fei Wang",e1c12faef6bba799b1e865dd7e876c59d4e4ed4f,SFSegNet: Parse Freehand Sketches using Deep Fully Convolutional Networks,2019 International Joint Conference on Neural Networks (IJCNN),2019.0,1,"Parsing sketches via semantic segmentation is attractive but challenging, because (i) free-hand drawings are abstract with large variances in depicting objects due to different drawing styles and skills; (ii) distorting lines drawn on the touchpad make sketches more difficult to be recognized; (iii) the high-performance image segmentation via deep learning technologies needs enormous annotated sketch datasets during the training stage.In this paper, we propose a Sketch-target deep FCN Segmentation Network(SFSegNet) for automatic free-hand sketch segmentation, labeling each sketch in a single object with multiple parts. SFSegNet has an end-to-end network process between the input sketches and the segmentation results, composed of 2 parts: (i) a modified deep Fully Convolutional Network(FCN) using a reweighting strategy to ignore background pixels and classify which part each pixel belongs to; (ii) affine transform encoders that attempt to canonicalize the shaking strokes. We train our network with the dataset that consists of 10,000 annotated sketches, to find an extensively applicable model to segment stokes semantically in one ground truth. Extensive experiments are carried out and segmentation results show that our method outperforms other state-of-the-art networks."
"P. Kindermann, T. Mchedlidze, T. Schneck, A. Symvonis",cde0d67ad38307c4e0bcc7222b5aef48f291454b,Drawing planar graphs with few segments on a polynomial grid,Graph Drawing,2019.0,1,"The visual complexity of a graph drawing can be measured by the number of geometric objects used for the representation of its elements. In this paper, we study planar graph drawings where edges are represented by few segments. In such a drawing, one segment may represent multiple edges forming a path. Drawings of planar graphs with few segments were intensively studied in the past years. However, the area requirements were only considered for limited subclasses of planar graphs. In this paper, we show that trees have drawings with $3n/4-1$ segments and $n^2$ area, improving the previous result of $O(n^{3.58})$. We also show that 3-connected planar graphs and biconnected outerplanar graphs have a drawing with $8n/3-O(1)$ and $3n/2-O(1)$ segments, respectively, and $O(n^3)$ area."
"S. Li, J. Lynch",155c7794346366da94ba841eb81e9ec41feb2d6e,A Sketch of Some Stochastic Models and Analysis Methods for Fiber Bundle Failure under Increasing Tensile Load,,2019.0,1,"Fiber bundle models (FBM's) have been used to model the failure of fibrous composites as load-sharing systems since the 1960's when Rosen (1964 and 1965) conducted some remarkable experiments on unidirectional fibrous composites. These experiments gave seminal insights into their failure under increasing tensile load. However, over the last thirty years FBM's have been used to model catastrophic failure in other situations by the physical science community and others. The purpose of this paper is to sketch some research on load-sharing models and statistical analysis methods that have been overlooked by this community. These are illustrated by summarizing the findings regarding Rosen's Specimen A experiments and presenting the necessary results needed for this. Related research about the bundle breaking strength distribution and the joint distribution (the Gibbs measure) regarding the state (failed or unfailed) of the bundle components at a given load per component, $s$, is also given."
"João Reis, G. Gonçalves",fca045a799ae1500ecc654130f645d105df63e7e,A Zero-Shot Learning application in Deep Drawing process using Hyper-Process Model,ArXiv,2019.0,1,"One of the consequences of passing from mass production to mass customization paradigm in the nowadays industrialized world is the need to increase flexibility and responsiveness of manufacturing companies. The high-mix / low-volume production forces constant accommodations of unknown product variants, which ultimately leads to high periods of machine calibration. The difficulty related with machine calibration is that experience is required together with a set of experiments to meet the final product quality. Unfortunately, all possible combinations of machine parameters is so high that is difficult to build empirical knowledge. Due to this fact, normally trial and error approaches are taken making one-of-a-kind products not viable. Therefore, a Zero-Shot Learning (ZSL) based approach called hyper-process model (HPM) to learn the relation among multiple tasks is used as a way to shorten the calibration phase. Assuming each product variant is a task to solve, first, a shape analysis on data to learn common modes of deformation between tasks is made, and secondly, a mapping between these modes and task descriptions is performed. Ultimately, the present work has two main contributions: 1) Formulation of an industrial problem into a ZSL setting where new process models can be generated for process optimization and 2) the definition of a regression problem in the domain of ZSL. For that purpose, a 2-d deep drawing simulated process was used based on data collected from the Abaqus simulator, where a significant number of process models were collected to test the effectiveness of the approach. The obtained results show that is possible to learn new tasks without any available data (both labeled and unlabeled) by leveraging information about already existing tasks, allowing to speed up the calibration phase and make a quicker integration of new products into manufacturing systems."
"Lingna Dai, Fei Gao, R. Li, JiaCheng Yu, Xiaoyuan Shen, Huilin Xiong, Weilun Wu",af90f86a54487be4df6c47d7c10a3b9b0590d8c3,Gated Fusion of Discriminant Features for Caricature Recognition,IScIDE,2019.0,1,"Caricature recognition is a challenging problem, because there are typically geometric deformations between photographs and caricatures. It is nontrivial to learn discriminant large-margin features. To combat this challenge, we propose a novel framework by using a gated fusion of global and local discriminant features. First, we employ A-Softmax loss to jointly learn angularly discriminant features of the whole face and local facial parts. Besides, we use the convolutional block attention module (CBAM) to further boost the discriminant ability of the learnt features. Next, we use global features as dominant representation and local features as supplemental ones; and propose a gated fusion unit to automatically learn the weighting factors for these local parts and moderate local features correspondingly. Finally, an integration of all these features is used for caricature recognition. Extensive experiments are conducted on the cross-modal face recognition task. Results show that, our method significantly boosts previous state-of-the-art Rank-1 and Rank-10 from 36.27% to 55.29% and from 64.37% to 85.78%, respectively, for caricature-to-photograph (C2P) recognition. Besides, our method achieves a Rank-1 of 60.81% and Rank-10 of 89.26% for photograph-to-caricature (P2C) recognition."
"Koki Tsubota, Daiki Ikami, K. Aizawa",a406e516915640b0844174acdadbc8b5603a1443,Synthesis of Screentone Patterns of Manga Characters,2019 IEEE International Symposium on Multimedia (ISM),2019.0,1,"Manga or Japanese comics are a popular medium and their images comprise line drawings and screentones. This study investigates the screentone synthesis task that involves translation from line drawings to manga images. Screentones have regular patterns that are difficult to synthesize. To address this problem, we propose a method to translate line drawings into manga images by generating pixel-wise screentone class labels instead of generating manga images directly. To train a screentone label generator, we create paired data of line drawings and pixel-wise screentone class labels that we obtain by applying to manga images a screentone removal and a screentone classifier, respectively. We train the screentone classifier using paired data of simulated manga images and pixel-wise screentone class labels. In tests, we conduct post-processing to reduce noise in the generated pixel-wise screentone labels. Experiments show that our proposed method produces reasonable screentone patterns. In comparison with results obtained using a baseline method of image-to-image translations, our results are comparable or more visually appealing."
"Harrish Thasarathan, Mehran Ebrahimi",bbc37cf2c5f78199bf358ccbad64ce3298f60c09,Artist-Guided Semiautomatic Animation Colorization,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),2019.0,0,"There is a delicate balance between automating repetitive work in creative domains while staying true to an artist's vision. The animation industry regularly outsources large animation workloads to foreign countries where labor is inexpensive and long hours are common. Automating part of this process can be incredibly useful for reducing costs and creating manageable workloads for major animation studios and outsourced artists. We present a method for automating line art colorization by keeping artists in the loop to successfully reduce this workload while staying true to an artist's vision. By incorporating color hints and temporal information to an adversarial image-to-image framework, we show that it is possible to meet the balance between automation and authenticity through artist's input to generate colored frames with temporal consistency."
"Kaifu Yang, Wen-Wen Jiang, Tengfei Zhan, Yong-Jie Li",796406e940f99bbf9e34d3c01521e2a971a92ea5,Line Drawings of Natural Scenes Guide Visual Attention,ArXiv,2019.0,0,"Visual search is an important strategy of the human visual system for fast scene perception. The guided search theory suggests that the global layout or other top-down sources of scenes play a crucial role in guiding object searching. In order to verify the specific roles of scene layout and regional cues in guiding visual attention, we executed a psychophysical experiment to record the human fixations on line drawings of natural scenes with an eye-tracking system in this work. We collected the human fixations of ten subjects from 498 natural images and of another ten subjects from the corresponding 996 human-marked line drawings of boundaries (two boundary maps per image) under free-viewing condition. The experimental results show that with the absence of some basic features like color and luminance, the distribution of the fixations on the line drawings has a high correlation with that on the natural images. Moreover, compared to the basic cues of regions, subjects pay more attention to the closed regions of line drawings which are usually related to the dominant objects of the scenes. Finally, we built a computational model to demonstrate that the fixation information on the line drawings can be used to significantly improve the performances of classical bottom-up models for fixation prediction in natural scenes. These results support that Gestalt features and scene layout are important cues for guiding fast visual object searching."
"Arpita Dutta, S. Biswas",fad944dbb3edbc6a52a220e9ba5ba1c2dbe86985,CNN Based Extraction of Panels/Characters from Bengali Comic Book Page Images,2019 International Conference on Document Analysis and Recognition Workshops (ICDARW),2019.0,0,"Peoples nowadays prefer to use digital gadgets like cameras or mobile phones for capturing documents. Automatic extraction of panels/characters from the images of a comic document is challenging due to the wide variety of drawing styles adopted by writers, beneficial for readers to read them on mobile devices at any time and useful for automatic digitization. Most of the methods for localization of panel/character rely on the connected component analysis or page background mask and are applicable only for a limited comic dataset. This work proposes a panel/character localization architecture based on the features of YOLO and CNN for extraction of both panels and characters from comic book images. The method achieved remarkable results on Bengali Comic Book Image dataset (BCBId) consisting of total 4130 images, developed by us as well as on a variety of publicly available comic datasets in other languages, i.e. eBDtheque, Manga 109 and DCM dataset."
"Yuki Endo, Yoshihiro Kanamori, Shigeru Kuriyama",bf234eb0d6f4eae787be83c8d9756e8c34e2e80a,Animating landscape,ACM Trans. Graph.,2019.0,0,"Automatic generation of a high-quality video from a single image remains a challenging task despite the recent advances in deep generative models. This paper proposes a method that can create a high-resolution, long-term animation using convolutional neural networks (CNNs) from a single landscape image where we mainly focus on skies and waters. Our key observation is that the motion (e.g., moving clouds) and appearance (e.g., time-varying colors in the sky) in natural scenes have different time scales. We thus learn them separately and predict them with decoupled control while handling future uncertainty in both predictions by introducing latent codes. Unlike previous methods that infer output frames directly, our CNNs predict spatially-smooth intermediate data, i.e., for motion, flow fields for warping, and for appearance, color transfer maps, via self-supervised learning, i.e., without explicitly-provided ground truth. These intermediate data are applied not to each previous output frame, but to the input image only once for each output frame. This design is crucial to alleviate error accumulation in long-term predictions, which is the essential problem in previous recurrent approaches. The output frames can be looped like cinemagraph, and also be controlled directly by specifying latent codes or indirectly via visual annotations. We demonstrate the effectiveness of our method through comparisons with the state-of-the-arts on video prediction as well as appearance manipulation. Resultant videos, codes, and datasets will be available at http://www.cgg.cs.tsukuba.ac.jp/~endo/projects/AnimatingLandscape."
"Yecheng Lyu, X. Huang, Ziming Zhang",e5bc162b60c01e1bd1ebe3d017be5665db626ca6,Graph-Preserving Grid Layout: A Simple Graph Drawing Method for Graph Classification using CNNs,ArXiv,2019.0,0,"Graph convolutional networks (GCNs) suffer from the irregularity of graphs, while more widely-used convolutional neural networks (CNNs) benefit from regular grids. To bridge the gap between GCN and CNN, in contrast to previous works on generalizing the basic operations in CNNs to graph data, in this paper we address the problem of how to project undirected graphs onto the grid in a {\em principled} way where CNNs can be used as backbone for geometric deep learning. To this end, inspired by the literature of graph drawing we propose a novel graph-preserving grid layout (GPGL), an integer programming that minimizes the topological loss on the grid. Technically we propose solving GPGL approximately using a {\em regularized} Kamada-Kawai algorithm, a well-known nonconvex optimization technique in graph drawing, with a vertex separation penalty that improves the rounding performance on top of the solutions from relaxation. Using GPGL we can easily conduct data augmentation as every local minimum will lead to a grid layout for the same graph. Together with the help of multi-scale maxout CNNs, we demonstrate the empirical success of our method for graph classification."
Shusen Wang,d6f1ea34931d769915f84ab1ac6686ca76abc89d,Matrix Sketching for Secure Collaborative Machine Learning,ArXiv,2019.0,0,"Collaborative machine learning (ML), also known as federated ML, allows participants to jointly train a model without data sharing. To update the model parameters, the central parameter server broadcasts model parameters to the participants, and the participants send ascending directions such as gradients to the server. While data do not leave a participant's device, the communicated gradients and parameters will leak a participant's privacy. Prior work proposed attacks that infer participant's privacy from gradients and parameters, and they showed simple defenses like dropout and differential privacy do not help much. 
To defend privacy leakage, we propose a method called Double Blind Collaborative Learning (DBCL) which is based on random matrix sketching. The high-level idea is to apply a random transformation to the parameters, data, and gradients in every iteration so that the existing attacks will fail or become less effective. While it improves the security of collaborative ML, DBCL does not increase the computation and communication cost much and does not hurt prediction accuracy at all. DBCL can be potentially applied to decentralized collaborative ML to defend privacy leakage."
"R. Fernandez-Fernandez, J. Victores, D. Estevez, C. Balaguer",969636469bfd4d8066aee51dd76f19f77e3c8bbe,"Quick, Stat!: A Statistical Analysis of the Quick, Draw! Dataset",ArXiv,2019.0,0,"The Quick, Draw! Dataset is a Google dataset with a collection of 50 million drawings, divided in 345 categories, collected from the users of the game Quick, Draw!. In contrast with most of the existing image datasets, in the Quick, Draw! Dataset, drawings are stored as time series of pencil positions instead of a bitmap matrix composed by pixels. This aspect makes this dataset the largest doodle dataset available at the time. The Quick, Draw! Dataset is presented as a great opportunity to researchers for developing and studying machine learning techniques. Due to the size of this dataset and the nature of its source, there is a scarce of information about the quality of the drawings contained. In this paper, a statistical analysis of three of the classes contained in the Quick, Draw! Dataset is depicted: mountain, book and whale. The goal is to give to the reader a first impression of the data collected in this dataset. For the analysis of the quality of the drawings, a Classification Neural Network was trained to obtain a classification score. Using this classification score and the parameters provided by the dataset, a statistical analysis of the quality and nature of the drawings contained in this dataset is provided."
"Y. Guo, Luo Jiang, Lin Cai, Juyong Zhang",7b7ed6c242b84692ec67326896f48306b8b4fd5a,3D Magic Mirror: Automatic Video to 3D Caricature Translation,ArXiv,2019.0,0,"Caricature is an abstraction of a real person which distorts or exaggerates certain features, but still retains a likeness. While most existing works focus on 3D caricature reconstruction from 2D caricatures or translating 2D photos to 2D caricatures, this paper presents a real-time and automatic algorithm for creating expressive 3D caricatures with caricature style texture map from 2D photos or videos. To solve this challenging ill-posed reconstruction problem and cross-domain translation problem, we first reconstruct the 3D face shape for each frame, and then translate 3D face shape from normal style to caricature style by a novel identity and expression preserving VAE-CycleGAN. Based on a labeling formulation, the caricature texture map is constructed from a set of multi-view caricature images generated by CariGANs. The effectiveness and efficiency of our method are demonstrated by comparison with baseline implementations. The perceptual study shows that the 3D caricatures generated by our method meet people's expectations of 3D caricature style."
"Yinjie Lei, Ziqin Zhou, Pingping Zhang, Yulan Guo, Zijun Ma, Lingqiao Liu",ccaa891dcfb7c5ed77411af3788743badd7d5e6d,A Sketch Based 3D Shape Retrieval Approach Based on Efficient Deep Point-to-Subspace Metric Learning,ArXiv,2019.0,0,"One key issue in managing a large scale 3D shape dataset is to identify an effective way to retrieve a shape-of-interest. The sketch-based query, which enjoys the flexibility in representing the user’s intention, has received growing interests in recent years due to the popularization of the touchscreen technology. Essentially, the sketch depicts an abstraction of an shape in a certain view while the shape contains the full 3D information. Matching between them is a cross-modality retrieval problem, and the state-of-the-art solution is to project the sketch and the 3D shape into a common space with which the cross-modality similarity can be calculated by the feature similarity/distance within. However, for a given query, only part of the viewpoints of the 3D shape is representative. Thus, blindly projecting a 3D shape into a feature vector without considering what is the query will inevitably bring query-unrepresentative information. To handle this issue, in this paper we propose a Deep Point-to-Subspace Metric Learning (DPSML) framework to project a sketch into a feature vector and a 3D shape into a subspace spanned by a few selected basis feature vectors. The similarity between them is defined as the distance between the query feature vector and its closest point in the subspace by solving an optimization problem on the fly. Note that, the closest point is query-adaptive and can reflect the viewpoint information that is representative to the given query. To efficiently learn such a deep model, we formulate it as a classification problem with a ∗Corresponding author Email addresses: yinjie@scu.edu.cn (Yinjie Lei), ziqinzhou@stu.scu.edu.cn (Ziqin Zhou), jssxzhpp@mail.dlut.edu.cn (Pingping Zhang), yulan.guo@nudt.edu.cn (Yulan Guo), mazijun@stu.scu.edu.cn (Zijun Ma), lingqiao.liu@adelaide.edu.au (Lingqiao Liu) Preprint submitted to Elsevier March 4, 2019 ar X iv :1 90 3. 00 11 7v 1 [ cs .C V ] 1 M ar 2 01 9 special classifier design. To reduce the redundancy of 3D shapes, we also introduce a Representative-View Selection (RVS) module to select the most representative views of a 3D shape. By conducting extensive experiments on various datasets, we show that the proposed approach can achieve superior performance over its competitive baselines and attain the state-of-the-art performance."
"Jomara Sandbulte, Jessica Kropczynski, J. Carroll",0e78c4b14a37710b33fb6127d32f1a95d891788c,Using Key Player Analysis as a Method for Examining the Role of Community Animators in Technology Adoption,ArXiv,2019.0,0,"This paper examines the role of community animators in technology adoption. Community animators are individuals that actively build social networks and broker ties between nodes in those networks. The present study observes technology adoption patterns through data collected from a mobile application at a local arts festival. A social network was constructed through photo-sharing and interaction within the app. Given this data, we propose the use of key player analysis to identify community animators. In addition, we use a graph invariant (i.e., fragmentation in the network) to describe the role and impact of key players on the full network of interactions. Our results contribute to literature on technology adoption in usability studies by proposing a method to quantify and identify the theoretical concept of community animators. We further analyze the types of community animators to be found in early adoption of technology: the early adopters themselves, and the initiating developers."
Dichao Hu,5940a89a01d4f2d7a02134e313a917899a56c5f6,Examining performance of sketch-to-image translation models with multiclass automatically generated paired training data,Other Conferences,2019.0,0,"Image translation is a computer vision task that involves translating one representation of the scene into another. Various approaches have been proposed and achieved highly desirable results. Nevertheless, its accomplishment requires abundant paired training data which are expensive to acquire. Therefore, models for translation are usually trained on a set of paired training data which are carefully and laboriously designed. Our work is focused on learning through automatically generated paired data. We propose a method to generate fake sketches from images using an adversarial network and then pair the images with corresponding fake sketches to form large-scale multi-class paired training data for training a sketch-to-image translation model. Our model is an encoder-decoder architecture where the encoder generates fake sketches from images and the decoder performs sketch-to-image translation. Qualitative results show that the encoder can be used for generating large-scale multi-class paired data under low supervision. Our current dataset now contains 61255 image and (fake) sketch pairs from 256 different categories. These figures can be greatly increased in the future thanks to our weak reliance on manually labelled data."
"Gayoung Lee, Dohyun Kim, Y. Yoo, Dongyoon Han, Jung-Woo Ha, Jaehyuk Chang",f1b1e792d8b498a7bcf95162785c44b20f90b2ba,Unpaired Sketch-to-Line Translation via Synthesis of Sketches,SIGGRAPH Asia Technical Briefs,2019.0,0,"Converting hand-drawn sketches into clean line drawings is a crucial step for diverse artistic works such as comics and product designs. Recent data-driven methods using deep learning have shown their great abilities to automatically simplify sketches on raster images. Since it is difficult to collect or generate paired sketch and line images, lack of training data is a main obstacle to use these models. In this paper, we propose a training scheme that requires only unpaired sketch and line images for learning sketch-to-line translation. To do this, we first generate realistic paired sketch and line images from unpaired sketch and line images using rule-based line augmentation and unsupervised texture conversion. Next, with our synthetic paired data, we train a model for sketch-to-line translation using supervised learning. Compared to unsupervised methods that use cycle consistency losses, our model shows better performance at removing noisy strokes. We also show that our model simplifies complicated sketches better than models trained on a limited number of handcrafted paired data."
Brian C. Britt,38eaad7c9fcb1cf3d8819677a827e5ce211eb8e7,"Content Curation, Evaluation, and Refinement on a Nonlinearly Directed Imageboard: Lessons From Danbooru",,2019.0,0,"While linearly directed imageboards like 4chan have been extensively studied, user participation on nonlinearly directed imageboards, or “boorus,” has been overlooked despite high activity, expansive multimedia repositories with user-defined classifications and evaluations, and unique affordances prioritizing mutual content curation, evaluation, and refinement over overt discourse. To address the gap in the literature related to participatory engagement on nonlinearly directed imageboards, user activity around the full database of N = 2 , 987 , 525 submissions to Danbooru, a prominent nonlinearly directed imageboard, was evaluated using regression. The results illustrate the role played by the affordances of nonlinearly directed imageboards and the visible attributes of individual submissions in shaping the user processes of content curation, evaluation, and refinement, as well as the interrelationships between these three core activities. These results provide a foundation for further research within the unique environments of nonlinearly directed imageboards and suggest practical applications across online domains."
"Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, K. W. Lin",498afde3bfd1e274af389b76328c881109057115,Interactive Anime Sketch Colorization with Style Consistency via a Deep Residual Neural Network,2019 International Conference on Technologies and Applications of Artiﬁcial Intelligence (TAAI),2019.0,0,"Anime line sketch colorization is to fill a variety of colors the anime sketch, to make it colorful and diverse. The coloring problem is not a new research direction in the field of deep learning technology. Because of coloring of the anime sketch does not have fixed color and we can't take texture or shadow as reference, so it is difficult to learn and have a certain standard to determine whether it is correct or not. After generative adversarial networks (GANs) was proposed, some used GANs to do coloring research, achieved some result, but the coloring effect is limited. This study proposes a method use deep residual network, and adding discriminator to network, that expect the color of colored images can consistent with the desired color by the user and can achieve good coloring results."
"Xu-Yao Zhang, Fei Yin, Yanming Zhang, C. Liu, Yoshua Bengio",572b98c8d9b3f4f0078f8d1565ecfb9ccb3bfcab,Drawing and Recognizing Chinese Characters with Recurrent Neural Network,IEEE Transactions on Pattern Analysis and Machine Intelligence,2018.0,177,"Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters."
"Wengling Chen, James Hays",bbe3d39adcb41ad2824204c0b0d299d77c2d8363,SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,120,"Synthesizing realistic images from human drawn sketches is a challenging problem in computer graphics and vision. Existing approaches either need exact edge maps, or rely on retrieval of existing photographs. In this work, we propose a novel Generative Adversarial Network (GAN) approach that synthesizes plausible images from 50 categories including motorcycles, horses and couches. We demonstrate a data augmentation technique for sketches which is fully automatic, and we show that the augmented data is helpful to our task. We introduce a new network building block suitable for both the generator and discriminator which improves the information flow by injecting the input image at multiple scales. Compared to state-of-the-art image translation methods, our approach generates more realistic images and achieves significantly higher Inception Scores."
"Y. Chen, Yu-Kun Lai, Yongjin Liu",6394a5b15281180591bdf7e6fbdf704bccc899ed,CartoonGAN: Generative Adversarial Networks for Photo Cartoonization,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,115,"In this paper, we propose a solution to transforming photos of real-world scenes into cartoon style images, which is valuable and challenging in computer vision and computer graphics. Our solution belongs to learning based methods, which have recently become popular to stylize images in artistic forms such as painting. However, existing methods do not produce satisfactory results for cartoonization, due to the fact that (1) cartoon styles have unique characteristics with high level simplification and abstraction, and (2) cartoon images tend to have clear edges, smooth color shading and relatively simple textures, which exhibit significant challenges for texture-descriptor-based loss functions used in existing methods. In this paper, we propose CartoonGAN, a generative adversarial network (GAN) framework for cartoon stylization. Our method takes unpaired photos and cartoon images for training, which is easy to use. Two novel losses suitable for cartoonization are proposed: (1) a semantic content loss, which is formulated as a sparse regularization in the high-level feature maps of the VGG network to cope with substantial style variation between photos and cartoons, and (2) an edge-promoting adversarial loss for preserving clear edges. We further introduce an initialization phase, to improve the convergence of the network to the target manifold. Our method is also much more efficient to train than existing methods. Experimental results show that our method is able to generate high-quality cartoon images from real-world photos (i.e., following specific artists' styles and with clear edges and smooth shading) and outperforms state-of-the-art methods."
"Tiziano Portenier, Qiyang Hu, A. Szabó, S. Bigdeli, P. Favaro, Matthias Zwicker",c8a5c5c8e1293b7e877a848b7a9e5426c5400651,FaceShop: Deep Sketch-based Face Image Editing,ACM Trans. Graph.,2018.0,77,"We present a novel system for sketch-based face image editing, enabling users to edit images intuitively by sketching a few strokes on a region of interest. Our interface features tools to express a desired image manipulation by providing both geometry and color constraints as user-drawn strokes. As an alternative to the direct user input, our proposed system naturally supports a copy-paste mode, which allows users to edit a given image region by using parts of another exemplar image without the need of hand-drawn sketching at all. The proposed interface runs in real-time and facilitates an interactive and iterative workflow to quickly express the intended edits. Our system is based on a novel sketch domain and a convolutional neural network trained end-to-end to automatically learn to render image regions corresponding to the input strokes. To achieve high quality and semantically consistent results we train our neural network on two simultaneous tasks, namely image completion and image translation. To the best of our knowledge, we are the first to combine these two tasks in a unified framework for interactive image editing. Our results show that the proposed sketch domain, network architecture, and training procedure generalize well to real user input and enable high quality synthesis results without additional post-processing."
"V. Murali, Letao Qi, Swarat Chaudhuri, C. Jermaine",d11777ca327c6d91de34d1d2ac50316b905578b2,Neural Sketch Learning for Conditional Program Generation,ICLR,2018.0,74,"We study the problem of generating source code in a strongly typed, Java-like programming language, given a label (for example a set of API calls or types) carrying a small amount of information about the code that is desired. The generated programs are expected to respect a ""realistic"" relationship between programs and labels, as exemplified by a corpus of labeled programs available during training. 
Two challenges in such conditional program generation are that the generated programs must satisfy a rich set of syntactic and semantic constraints, and that source code contains many low-level features that impede learning. We address these problems by training a neural generator not on code but on program sketches, or models of program syntax that abstract out names and operations that do not generalize across programs. During generation, we infer a posterior distribution over sketches, then concretize samples from this distribution into type-safe programs using combinatorial techniques. We implement our ideas in a system for generating API-heavy Java code, and show that it can often predict the entire body of a method given just a few API calls or data types that appear in the method."
"N. Wang, Xinbo Gao, J. Li",648d326990ed78d2160139c1ab307a7b3e44b1bb,Random sampling for fast face sketch synthesis,Pattern Recognit.,2018.0,70,"Exemplar-based face sketch synthesis plays an important role in both digital entertainment and law enforcement. It generally consists of two parts: neighbor selection and reconstruction weight representation. The most time-consuming or main computation complexity for exemplar-based face sketch synthesis methods lies in the neighbor selection process. State-of-the-art face sketch synthesis methods perform neighbor selection online in a data-driven manner by $K$ nearest neighbor ($K$-NN) searching. Actually, the online search increases the time consuming for synthesis. Moreover, since these methods need to traverse the whole training dataset for neighbor selection, the computational complexity increases with the scale of the training database and hence these methods have limited scalability. In this paper, we proposed a simple but effective offline random sampling in place of online $K$-NN search to improve the synthesis efficiency. Extensive experiments on public face sketch databases demonstrate the superiority of the proposed method in comparison to state-of-the-art methods, in terms of both synthesis quality and time consumption. The proposed method could be extended to other heterogeneous face image transformation problems such as face hallucination. We release the source codes of our proposed methods and the evaluation metrics for future study online: this http URL."
"Peng Xu, Qiyue Yin, Yongye Huang, Yi-Zhe Song, Zhanyu Ma, Liang Wang, Tao Xiang, W. Kleijn, Jun Guo",9e0e927091acbbebd4036f1a7290b65c94bc241a,Cross-modal subspace learning for fine-grained sketch-based image retrieval,Neurocomputing,2018.0,68,"Sketch-based image retrieval (SBIR) is challenging due to the inherent domain-gap between sketch and photo. Compared with pixel-perfect depictions of photos, sketches are iconic renderings of the real world with highly abstract. Therefore, matching sketch and photo directly using low-level visual clues are unsufficient, since a common low-level subspace that traverses semantically across the two modalities is non-trivial to establish. Most existing SBIR studies do not directly tackle this cross-modal problem. This naturally motivates us to explore the effectiveness of cross-modal retrieval methods in SBIR, which have been applied in the image-text matching successfully. In this paper, we introduce and compare a series of state-of-the-art cross-modal subspace learning methods and benchmark them on two recently released fine-grained SBIR datasets. Through thorough examination of the experimental results, we have demonstrated that the subspace learning can effectively model the sketch-photo domain-gap. In addition we draw a few key insights to drive future research."
"Sasi Kiran Yelamarthi, M. K. K. Reddy, Ashish Mishra, Anurag Mittal",5b015487b7727aceed934333090a562641110401,A Zero-Shot Framework for Sketch-based Image Retrieval,ECCV,2018.0,60,"Sketch-based image retrieval (SBIR) is the task of retrieving images from a natural image database that correspond to a given hand-drawn sketch. Ideally, an SBIR model should learn to associate components in the sketch (say, feet, tail, etc.) with the corresponding components in the image having similar shape characteristics. However, current evaluation methods simply focus only on coarse-grained evaluation where the focus is on retrieving images which belong to the same class as the sketch but not necessarily having the same shape characteristics as in the sketch. As a result, existing methods simply learn to associate sketches with classes seen during training and hence fail to generalize to unseen classes. In this paper, we propose a new benchmark for zero-shot SBIR where the model is evaluated on novel classes that are not seen during training. We show through extensive experiments that existing models for SBIR that are trained in a discriminative setting learn only class specific mappings and fail to generalize to the proposed zero-shot setting. To circumvent this, we propose a generative approach for the SBIR task by proposing deep conditional generative models that take the sketch as an input and fill the missing information stochastically. Experiments on this new benchmark created from the “Sketchy” dataset, which is a large-scale database of sketch-photo pairs demonstrate that the performance of these generative models is significantly better than several state-of-the-art approaches in the proposed zero-shot framework of the coarse-grained SBIR task."
"Konstantinos Vougioukas, S. Petridis, M. Pantic",f722b0a7a9b7709d693b9d39195c779832a943fe,End-to-End Speech-Driven Facial Animation with Temporal GANs,BMVC,2018.0,60,"Speech-driven facial animation is the process which uses speech signals to automatically synthesize a talking character. The majority of work in this domain creates a mapping from audio features to visual features. This often requires post-processing using computer graphics techniques to produce realistic albeit subject dependent results. We present a system for generating videos of a talking head, using a still image of a person and an audio clip containing speech, that doesn't rely on any handcrafted intermediate features. To the best of our knowledge, this is the first method capable of generating subject independent realistic videos directly from raw audio. Our method can generate videos which have (a) lip movements that are in sync with the audio and (b) natural facial expressions such as blinks and eyebrow movements. We achieve this by using a temporal GAN with 2 discriminators, which are capable of capturing different aspects of the video. The effect of each component in our system is quantified through an ablation study. The generated videos are evaluated based on their sharpness, reconstruction quality, and lip-reading accuracy. Finally, a user study is conducted, confirming that temporal GANs lead to more natural sequences than a static GAN-based approach."
"Lidan Wang, V. Sindagi, V. Patel",71c7191815fd15045a7bfb2ebc21a193d41ab551,High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks,2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018),2018.0,59,"Synthesizing face sketches from real photos and its inverse have many applications. However, photo/sketch synthesis remains a challenging problem due to the fact that photo and sketch have different characteristics. In this work, we consider this task as an image-to-image translation problem and explore the recently popular generative models (GANs) to generate high-quality realistic photos from sketches and sketches from photos. Recent GAN-based methods have shown promising results on image-to-image translation problems and photo-to-sketch synthesis in particular, however, they are known to have limited abilities in generating high-resolution realistic images. To this end, we propose a novel synthesis framework called Photo-Sketch Synthesis using Multi-Adversarial Networks, (PS2-MAN) that iteratively generates low resolution to high resolution images in an adversarial way. The hidden layers of the generator are supervised to first generate lower resolution images followed by implicit refinement in the network to generate higher resolution images. Furthermore, since photo-sketch synthesis is a coupled/paired translation problem, we leverage the pair information using CycleGAN framework. Both Image Quality Assessment (IQA) and Photo-Sketch Matching experiments are conducted to demonstrate the superior performance of our framework in comparison to existing state-of-the-art solutions. Code available at: https://github.com/lidan1/PhotoSketchMAN."
"J. Delanoy, A. Bousseau, Mathieu Aubry, Phillip Isola, Alexei A. Efros",0badddb4b4185fec90681b24b3933cd1f3a90cea,3D Sketching using Multi-View Deep Volumetric Prediction,PACMCGIT,2018.0,53,"Sketch-based modeling strives to bring the ease and immediacy of drawing to the 3D world. However, while drawings are easy for humans to create, they are very challenging for computers to interpret due to their sparsity and ambiguity. We propose a data-driven approach that tackles this challenge by learning to reconstruct 3D shapes from one or more drawings. At the core of our approach is a deep convolutional neural network (CNN) that predicts occupancy of a voxel grid from a line drawing. This CNN provides an initial 3D reconstruction as soon as the user completes a single drawing of the desired shape. We complement this single-view network with an updater CNN that refines an existing prediction given a new drawing of the shape created from a novel viewpoint. A key advantage of our approach is that we can apply the updater iteratively to fuse information from an arbitrary number of viewpoints, without requiring explicit stroke correspondences between the drawings. We train both CNNs by rendering synthetic contour drawings from hand-modeled shape collections as well as from procedurally-generated abstract shapes. Finally, we integrate our CNNs in an interactive modeling system that allows users to seamlessly draw an object, rotate it to see its 3D reconstruction, and refine it by re-drawing from another vantage point using the 3D reconstruction as guidance."
"Yifan Liu, Zengchang Qin, T. Wan, Zhenbo Luo",252a2d2a2c99ae33cca1435e0441c5ea556fac71,Auto-painter: Cartoon image generation from sketch by using conditional Wasserstein generative adversarial networks,Neurocomputing,2018.0,53,"Abstract Recently, realistic image generation using deep neural networks has become a hot topic in machine learning and computer vision. Such an image can be generated at pixel level by learning from a large collection of images. Learning to generate colorful cartoon images from black-and-white sketches is not only an interesting research problem, but also a useful application in digital entertainment. In this paper, we investigate the sketch-to-image synthesis problem by using conditional generative adversarial networks (cGAN). We propose a model called auto-painter which can automatically generate compatible colors given a sketch. Wasserstein distance is used in training cGAN to overcome model collapse and enable the model converged much better. The new model is not only capable of painting hand-draw sketch with compatible colors, but also allowing users to indicate preferred colors. Experimental results on different sketch datasets show that the auto-painter performs better than other existing image-to-image methods."
"Peng Xu, Yongye Huang, Tongtong Yuan, Kaiyue Pang, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales, Zhanyu Ma, Jun Guo",be9ea8b40b5a422ccceefcc32c7ca7f0cb1bc579,SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,52,"We propose a deep hashing framework for sketch retrieval that, for the first time, works on a multi-million scale human sketch dataset. Leveraging on this large dataset, we explore a few sketch-specific traits that were otherwise under-studied in prior literature. Instead of following the conventional sketch recognition task, we introduce the novel problem of sketch hashing retrieval which is not only more challenging, but also offers a better testbed for large-scale sketch analysis, since: (i) more fine-grained sketch feature learning is required to accommodate the large variations in style and Abstraction, and (ii) a compact binary code needs to be learned at the same time to enable efficient retrieval. Key to our network design is the embedding of unique characteristics of human sketch, where (i) a two-branch CNN-RNN architecture is adapted to explore the temporal ordering of strokes, and (ii) a novel hashing loss is specifically designed to accommodate both the temporal and Abstract traits of sketches. By working with a 3.8M sketch dataset, we show that state-of-the-art hashing models specifically engineered for static images fail to perform well on temporal sketch data. Our network on the other hand not only offers the best retrieval performance on various code sizes, but also yields the best generalization performance under a zero-shot setting and when re-purposed for sketch recognition. Such superior performances effectively demonstrate the benefit of our sketch-specific design."
"Jifei Song, Kaiyue Pang, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",93c7c75f513f06b063e5b44be1de286681af944e,Learning to Sketch with Shortcut Cycle Consistency,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,51,"To see is to sketch - free-hand sketching naturally builds ties between human and machine vision. In this paper, we present a novel approach for translating an object photo to a sketch, mimicking the human sketching process. This is an extremely challenging task because the photo and sketch domains differ significantly. Furthermore, human sketches exhibit various levels of sophistication and abstraction even when depicting the same object instance in a reference photo. This means that even if photo-sketch pairs are available, they only provide weak supervision signal to learn a translation model. Compared with existing supervised approaches that solve the problem of D(E(photo)) â†’ sketch), where E(Â·) and D(Â·) denote encoder and decoder respectively, we take advantage of the inverse problem (e.g., D(E(sketch) â†’ photo), and combine with the unsupervised learning tasks of within-domain reconstruction, all within a multi-task learning framework. Compared with existing unsupervised approaches based on cycle consistency (i.e., D(E(D(E(photo)))) â†’ photo), we introduce a shortcut consistency enforced at the encoder bottleneck (e.g., D(E(photo)) â†’ photo) to exploit the additional self-supervision. Both qualitative and quantitative results show that the proposed model is superior to a number of state-of-the-art alternatives. We also show that the synthetic sketches can be used to train a better fine-grained sketch-based image retrieval (FG-SBIR) model, effectively alleviating the problem of sketch data scarcity."
"Yongyi Lu, Shangzhe Wu, Yu-Wing Tai, C. Tang",2ad18180c313fd8b6fb6a9d87922974d111a26a3,Image Generation from Sketch Constraint Using Contextual GAN,ECCV,2018.0,51,"In this paper we investigate image generation guided by hand sketch. When the input sketch is badly drawn, the output of common image-to-image translation follows the input edges due to the hard condition imposed by the translation process. Instead, we propose to use sketch as weak constraint, where the output edges do not necessarily follow the input edges. We address this problem using a novel joint image completion approach, where the sketch provides the image context for completing, or generating the output image. We train a generated adversarial network, i.e, contextual GAN to learn the joint distribution of sketch and the corresponding image by using joint images. Our contextual GAN has several advantages. First, the simple joint image representation allows for simple and effective learning of joint distribution in the same image-sketch space, which avoids complicated issues in cross-domain learning. Second, while the output is related to its input overall, the generated features exhibit more freedom in appearance and do not strictly align with the input features as previous conditional GANs do. Third, from the joint image’s point of view, image and sketch are of no difference, thus exactly the same deep joint image completion network can be used for image-to-sketch generation. Experiments evaluated on three different datasets show that our contextual GAN can generate more realistic images than state-of-the-art conditional GANs on challenging inputs and generalize well on common categories."
"N. Wang, Xinbo Gao, Leiyu Sun, J. Li",8376287a7f2401a36295aad094fd85e966df5dc4,Anchored Neighborhood Index for Face Sketch Synthesis,IEEE Transactions on Circuits and Systems for Video Technology,2018.0,47,"Exemplar-based face sketch synthesis has long been impeded by the difficulty of accurate neighbor selection. Given a test patch extracted from the test photograph, the <inline-formula> <tex-math notation=""LaTeX"">$K$ </tex-math></inline-formula>-nearest neighbor (<inline-formula> <tex-math notation=""LaTeX"">$K$ </tex-math></inline-formula>-NN) matching algorithm is generally performed by existing methods to find <inline-formula> <tex-math notation=""LaTeX"">$K$ </tex-math></inline-formula>-nearest photograph patches in the training data set, which contains some pairs of face sketches and photographs. Then, the training sketch patches corresponding to the selected nearest photograph patches are taken as the candidate to synthesize the target sketch patch. In the aforementioned neighbor selection process, training sketch patches is not taken into consideration in the process of <inline-formula> <tex-math notation=""LaTeX"">$K$ </tex-math></inline-formula>-nearest neighbor selection. In this paper, we proposed a simple yet effective neighbor selection algorithm, namely, anchored neighborhood index (ANI), to boost the synthesis performance by taking training sketch patches into the consideration. In addition, the proposed ANI can be conducted offline and, thus, it does not increase the computational complexity. Extensive experiments on public available database demonstrate that the proposed algorithm achieves superior performance compared with the state-of-the-art methods in terms of both objective image quality scores and face recognition accuracy."
"Kaidi Cao, Jing Liao, L. Yuan",3712c0706269c6f177e9c2b24b2d47b7ef186128,CariGANs: Unpaired Photo-to-Caricature Translation,ACM Trans. Graph.,2018.0,47,"Facial caricature is an art form of drawing faces in an exaggerated way to convey humor or sarcasm. In this paper, we propose the first Generative Adversarial Network (GAN) for unpaired photo-to-caricature translation, which we call ""CariGANs"". It explicitly models geometric exaggeration and appearance stylization using two components: CariGeoGAN, which only models the geometry-to-geometry transformation from face photos to caricatures, and CariStyGAN, which transfers the style appearance from caricatures to face photos without any geometry deformation. In this way, a difficult cross-domain translation problem is decoupled into two easier tasks. The perceptual study shows that caricatures generated by our CariGANs are closer to the hand-drawn ones, and at the same time better persevere the identity, compared to state-of-the-art methods. Moreover, our CariGANs allow users to control the shape exaggeration degree and change the color/texture style by tuning the parameters or giving an example caricature."
"Lvmin Zhang, Chengze Li, T. Wong, Yi Ji, Chunping Liu",7d01e5c4ab3e4ddeadcda107d946a705c70ac4c8,Two-stage sketch colorization,ACM Trans. Graph.,2018.0,46,"Sketch or line art colorization is a research field with significant market demand. Different from photo colorization which strongly relies on texture information, sketch colorization is more challenging as sketches may not have texture. Even worse, color, texture, and gradient have to be generated from the abstract sketch lines. In this paper, we propose a semi-automatic learning-based framework to colorize sketches with proper color, texture as well as gradient. Our framework consists of two stages. In the first drafting stage, our model guesses color regions and splashes a rich variety of colors over the sketch to obtain a color draft. In the second refinement stage, it detects the unnatural colors and artifacts, and try to fix and refine the result. Comparing to existing approaches, this two-stage design effectively divides the complex colorization task into two simpler and goal-clearer subtasks. This eases the learning and raises the quality of colorization. Our model resolves the artifacts such as water-color blurring, color distortion, and dull textures. We build an interactive software based on our model for evaluation. Users can iteratively edit and refine the colorization. We evaluate our learning model and the interactive system through an extensive user study. Statistics shows that our method outperforms the state-of-art techniques and industrial applications in several aspects including, the visual quality, the ability of user control, user experience, and other metrics."
"U. Muhammad, Yongxin Yang, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",4feb17463f78ac0365a6ca1ba1ba90efe7e4a768,Learning Deep Sketch Abstraction,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,44,"Human free-hand sketches have been studied in various contexts including sketch recognition, synthesis and fine-grained sketch-based image retrieval (FG-SBIR). A fundamental challenge for sketch analysis is to deal with drastically different human drawing styles, particularly in terms of abstraction level. In this work, we propose the first stroke-level sketch abstraction model based on the insight of sketch abstraction as a process of trading off between the recognizability of a sketch and the number of strokes used to draw it. Concretely, we train a model for abstract sketch generation through reinforcement learning of a stroke removal policy that learns to predict which strokes can be safely removed without affecting recognizability. We show that our abstraction model can be used for various sketch analysis tasks including: (1) modeling stroke saliency and understanding the decision of sketch recognition models, (2) synthesizing sketches of variable abstraction for a given category, or reference object instance in a photo, and (3) training a FG-SBIR model with photos only, bypassing the expensive photo-sketch pair collection step."
"Aaron Gokaslan, Vivek Ramanujan, Daniel Ritchie, K. Kim, J. Tompkin",798cc4f05ac0699215d0083130c2793be17803fc,Improving Shape Deformation in Unsupervised Image-to-Image Translation,ECCV,2018.0,44,"Unsupervised image-to-image translation techniques are able to map local texture between two domains, but they are typically unsuccessful when the domains require larger shape change. Inspired by semantic segmentation, we introduce a discriminator with dilated convolutions that is able to use information from across the entire image to train a more context-aware generator. This is coupled with a multi-scale perceptual loss that is better able to represent error in the underlying shape of objects. We demonstrate that this design is more capable of representing shape deformation in a challenging toy dataset, plus in complex mappings with significant dataset variation between humans, dolls, and anime faces, and between cats and dogs."
"N. Wang, W. Zha, J. Li, Xinbo Gao",170bf8139c1a39777c4732bb85588914a9bbb639,Back projection: An effective postprocessing method for GAN-based face sketch synthesis,Pattern Recognit. Lett.,2018.0,42,"Abstract We consider the image transformation problems in this paper, where an input face photo is transformed into a sketch, i.e. face sketch synthesis. It plays important role in video surveillance-based law enforcement. Recent methods for such problems typically train feed-forward convolutional neural networks (CNN) or graphical probabilistic models. In this paper, inspired by the recent success in generating images of generative adversarial networks (GAN), we employ GAN to perform this task. However, accompanying with fine textures generated by GAN model, noise appears among the generated results. We proposed a back projection method to reconstruct the synthesized results. Extensive experiments on public face databases illustrate the effectiveness and superiority of the proposed method compared with state-of-the-art methods. The proposed back projection strategy can be extended to other GAN-based image-to-image translation problems. Data and implementation code in this paper are available online at www.ihitworld.com/WNN/Back_Projection.zip ."
"Jingyi Zhang, Fumin Shen, L. Liu, F. Zhu, Mengyang Yu, L. Shao, Heng Tao Shen, L. Gool",77be85f6c3c465ef8e17d3ec6251794cf4ff5940,Generative Domain-Migration Hashing for Sketch-to-Image Retrieval,ECCV,2018.0,39,"Due to the succinct nature of free-hand sketch drawings, sketch-based image retrieval (SBIR) has abundant practical use cases in consumer electronics. However, SBIR remains a long-standing unsolved problem mainly because of the significant discrepancy between the sketch domain and the image domain. In this work, we propose a Generative Domain-migration Hashing (GDH) approach, which for the first time generates hashing codes from synthetic natural images that are migrated from sketches. The generative model learns a mapping that the distributions of sketches can be indistinguishable from the distribution of natural images using an adversarial loss, and simultaneously learns an inverse mapping based on the cycle consistency loss in order to enhance the indistinguishability. With the robust mapping learned from the generative model, GDH can migrate sketches to their indistinguishable image counterparts while preserving the domain-invariant information of sketches. With an end-to-end multi-task learning framework, the generative model and binarized hashing codes can be jointly optimized. Comprehensive experiments of both category-level and fine-grained SBIR on multiple large-scale datasets demonstrate the consistently balanced superiority of GDH in terms of efficiency, memory costs and effectiveness (Models and code at https://github.com/YCJGG/GDH)."
"Jiawei Jiang, Fangcheng Fu, Tong Yang, B. Cui",ddf54b76d8f56f8973139d8ffe92a5e69217a3c3,SketchML: Accelerating Distributed Machine Learning with Data Sketches,SIGMOD Conference,2018.0,38,"To address the challenge of explosive big data, distributed machine learning (ML) has drawn the interests of many researchers. Since many distributed ML algorithms trained by stochastic gradient descent (SGD) involve communicating gradients through the network, it is important to compress the transferred gradient. A category of low-precision algorithms can significantly reduce the size of gradients, at the expense of some precision loss. However, existing low-precision methods are not suitable for many cases where the gradients are sparse and nonuniformly distributed. In this paper, we study is there a compression method that can efficiently handle a sparse and nonuniform gradient consisting of key-value pairs? Our first contribution is a sketch based method that compresses the gradient values. Sketch is a class of algorithms using a probabilistic data structure to approximate the distribution of input data. We design a quantile-bucket quantification method that uses a quantile sketch to sort gradient values into buckets and encodes them with the bucket indexes. To further compress the bucket indexes, our second contribution is a sketch algorithm, namely MinMaxSketch. MinMaxSketch builds a set of hash tables and solves hash collisions with a MinMax strategy. The third contribution of this paper is a delta-binary encoding method that calculates the increment of the gradient keys and stores them with fewer bytes. We also theoretically discuss the correctness and the error bound of three proposed methods. To the best of our knowledge, this is the first effort combining data sketch with ML. We implement a prototype system in a real cluster of our industrial partner Tencent Inc., and show that our method is up to 10X faster than existing methods."
"Kyungho Lee, Seyoung Lee, J. Lee",faa5ca261d56b0a70cd3ae34e289388acfc8967f,Interactive character animation by learning multi-objective control,ACM Trans. Graph.,2018.0,37,"We present an approach that learns to act from raw motion data for interactive character animation. Our motion generator takes a continuous stream of control inputs and generates the character's motion in an online manner. The key insight is modeling rich connections between a multitude of control objectives and a large repertoire of actions. The model is trained using Recurrent Neural Network conditioned to deal with spatiotemporal constraints and structural variabilities in human motion. We also present a new data augmentation method that allows the model to be learned even from a small to moderate amount of training data. The learning process is fully automatic if it learns the motion of a single character, and requires minimal user intervention if it deals with props and interaction between multiple characters."
"Yuanzheng Ci, Xinzhu Ma, Zhihui Wang, Haojie Li, Z. Luo",6850306dfe557dc5eea689bb778f9033a203f3b3,User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks,ACM Multimedia,2018.0,37,"Scribble colors based line art colorization is a challenging computer vision problem since neither greyscale values nor semantic information is presented in line arts, and the lack of authentic illustration-line art training pairs also increases difficulty of model generalization. Recently, several Generative Adversarial Nets (GANs) based methods have achieved great success. They can generate colorized illustrations conditioned on given line art and color hints. However, these methods fail to capture the authentic illustration distributions and are hence perceptually unsatisfying in the sense that they often lack accurate shading. To address these challenges, we propose a novel deep conditional adversarial architecture for scribble based anime line art colorization. Specifically, we integrate the conditional framework with WGAN-GP criteria as well as the perceptual loss to enable us to robustly train a deep network that makes the synthesized images more natural and real. We also introduce a local features network that is independent of synthetic data. With GANs conditioned on features from such network, we notably increase the generalization capability over ""in the wild"" line arts. Furthermore, we collect two datasets that provide high-quality colorful illustrations and authentic line arts for training and benchmarking. With the proposed model trained on our illustration dataset, we demonstrate that images synthesized by the presented approach are considerably more realistic and precise than alternative approaches."
"Jing Huo, Wenbin Li, Y. Shi, Yang Gao, Hujun Yin",4d1e46b1dcec1c9cbc4e7ff80dbf73e5e7ebcd67,WebCaricature: a benchmark for caricature recognition,BMVC,2018.0,33,"Studying caricature recognition is fundamentally important to understanding of face perception. However, little research has been conducted in the computer vision community, largely due to the shortage of suitable datasets. In this paper, a new caricature dataset is built, with the objective to facilitate research in caricature recognition. All the caricatures and face images were collected from the Web. Compared with two existing datasets, this dataset is much more challenging, with a much greater number of available images, artistic styles and larger intra-personal variations. Evaluation protocols are also offered together with their baseline performances on the dataset to allow fair comparisons. Besides, a framework for caricature face recognition is presented to make a thorough analyze of the challenges of caricature recognition. By analyzing the challenges, the goal is to show problems that worth to be further investigated. Additionally, based on the evaluation protocols and the framework, baseline performances of various state-of-the-art algorithms are provided. A conclusion is that there is still a large space for performance improvement and the analyzed problems still need further investigation."
"Toru Ogawa, Atsushi Otsubo, Rei Narita, Yusuke Matsui, T. Yamasaki, K. Aizawa",460845e06ca99f292fa2265beb4e535d20ba16f8,Object Detection for Comics using Manga109 Annotations,ArXiv,2018.0,31,"With the growth of digitized comics, image understanding techniques are becoming important. In this paper, we focus on object detection, which is a fundamental task of image understanding. Although convolutional neural networks (CNN)-based methods archived good performance in object detection for naturalistic images, there are two problems in applying these methods to the comic object detection task. First, there is no large-scale annotated comics dataset. The CNN-based methods require large-scale annotations for training. Secondly, the objects in comics are highly overlapped compared to naturalistic images. This overlap causes the assignment problem in the existing CNN-based methods. To solve these problems, we proposed a new annotation dataset and a new CNN model. We annotated an existing image dataset of comics and created the largest annotation dataset, named Manga109-annotations. For the assignment problem, we proposed a new CNN-based detector, SSD300-fork. We compared SSD300-fork with other detection methods using Manga109-annotations and confirmed that our model outperformed them based on the mAP score."
"Nils Reimers, Iryna Gurevych",530549235717fa98c9d3c44650609516030f1c56,Why Comparing Single Performance Scores Does Not Allow to Draw Conclusions About Machine Learning Approaches,ArXiv,2018.0,31,"Developing state-of-the-art approaches for specific tasks is a major driving force in our research community. Depending on the prestige of the task, publishing it can come along with a lot of visibility. The question arises how reliable are our evaluation methodologies to compare approaches? 
One common methodology to identify the state-of-the-art is to partition data into a train, a development and a test set. Researchers can train and tune their approach on some part of the dataset and then select the model that worked best on the development set for a final evaluation on unseen test data. Test scores from different approaches are compared, and performance differences are tested for statistical significance. 
In this publication, we show that there is a high risk that a statistical significance in this type of evaluation is not due to a superior learning approach. Instead, there is a high risk that the difference is due to chance. For example for the CoNLL 2003 NER dataset we observed in up to 26% of the cases type I errors (false positives) with a threshold of p < 0.05, i.e., falsely concluding a statistically significant difference between two identical approaches. 
We prove that this evaluation setup is unsuitable to compare learning approaches. We formalize alternative evaluation setups based on score distributions."
"Panagiotis A. Traganitis, G. Giannakis",15b07dae17f184c8e6efbc9d2b58526d8e8dc9d4,Sketched Subspace Clustering,IEEE Transactions on Signal Processing,2018.0,30,"The immense amount of daily generated and communicated data presents unique challenges in their processing. Clustering, the grouping of data without the presence of ground-truth labels, is an important tool for drawing inferences from data. Subspace clustering (SC) is a relatively recent method that is able to successfully classify nonlinearly separable data in a multitude of settings. In spite of their high clustering accuracy, SC methods incur prohibitively high computational complexity when processing large volumes of high-dimensional data. Inspired by random sketching approaches for dimensionality reduction, the present paper introduces a randomized scheme for SC, termed Sketch-SC, tailored for large volumes of high-dimensional data. Sketch-SC accelerates the computationally heavy parts of state-of-the-art SC approaches by compressing the data matrix across both dimensions using random projections, thus enabling fast and accurate large-scale SC. Performance analysis as well as extensive numerical tests on real data corroborate the potential of Sketch-SC and its competitive performance relative to state-of-the-art scalable SC approaches."
"Tu Bui, Leo Sampaio Ferraz Ribeiro, M. Ponti, J. Collomosse",a5c6b78c93f1ff3bad5d498cbc78b1483bd91073,Sketching out the details: Sketch-based image retrieval using convolutional neural networks with multi-stage regression,Comput. Graph.,2018.0,27,"Abstract We propose and evaluate several deep network architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. We study the ability of our networks to generalize across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. In addition to a detailed comparative study of network configurations, we contribute by describing a hybrid multi-stage training network that exploits both contrastive and triplet networks to exceed state of the art performance on several SBIR benchmarks by a significant margin. Datasets and models are available at http://www.cvssp.org ."
"Jiaxin Chen, Yi Fang",2acfd3378b71e3ec5723bc6e454c064414b6aaa0,Deep Cross-modality Adaptation via Semantics Preserving Adversarial Learning for Sketch-based 3D Shape Retrieval,ECCV,2018.0,27,"Due to the large cross-modality discrepancy between 2D sketches and 3D shapes, retrieving 3D shapes by sketches is a significantly challenging task. To address this problem, we propose a novel framework to learn a discriminative deep cross-modality adaptation model in this paper. Specifically, we first separately adopt two metric networks, following two deep convolutional neural networks (CNNs), to learn modality-specific discriminative features based on an importance-aware metric learning method. Subsequently, we explicitly introduce a cross-modality transformation network to compensate for the divergence between two modalities, which can transfer features of 2D sketches to the feature space of 3D shapes. We develop an adversarial learning based method to train the transformation model, by simultaneously enhancing the holistic correlations between data distributions of two modalities, and mitigating the local semantic divergences through minimizing a cross-modality mean discrepancy term. Experimental results on the SHREC 2013 and SHREC 2014 datasets clearly show the superior retrieval performance of our proposed model, compared to the state-of-the-art approaches."
"Guoxian Dai, J. Xie, Yi Fang",d1a9c16b4a66ce41cf86273ffbdd0e3426f958ca,Deep Correlated Holistic Metric Learning for Sketch-Based 3D Shape Retrieval,IEEE Transactions on Image Processing,2018.0,27,"How to effectively retrieve desired 3D models with simple queries is a long-standing problem in computer vision community. The model-based approach is quite straightforward but nontrivial, since people could not always have the desired 3D query model available by side. Recently, large amounts of wide-screen electronic devices are prevail in our daily lives, which makes the sketch-based 3D shape retrieval a promising candidate due to its simpleness and efficiency. The main challenge of sketch-based approach is the huge modality gap between sketch and 3D shape. In this paper, we proposed a novel deep correlated holistic metric learning (DCHML) method to mitigate the discrepancy between sketch and 3D shape domains. The proposed DCHML trains two distinct deep neural networks (one for each domain) jointly, which learns two deep nonlinear transformations to map features from both domains into a new feature space. The proposed loss, including discriminative loss and correlation loss, aims to increase the discrimination of features within each domain as well as the correlation between different domains. In the new feature space, the discriminative loss minimizes the intra-class distance of the deep transformed features and maximizes the inter-class distance of the deep transformed features to a large margin within each domain, while the correlation loss focused on mitigating the distribution discrepancy across different domains. Different from existing deep metric learning methods only with loss at the output layer, our proposed DCHML is trained with loss at both hidden layer and output layer to further improve the performance by encouraging features in the hidden layer also with desired properties. Our proposed method is evaluated on three benchmarks, including 3D Shape Retrieval Contest 2013, 2014, and 2016 benchmarks, and the experimental results demonstrate the superiority of our proposed method over the state-of-the-art methods."
"Wanchao Su, Dong Du, X. Yang, Shizhe Zhou, Hongbo Fu",24f2076e69ef28fe44ba16201c88a516817ccdda,Interactive Sketch-Based Normal Map Generation with Deep Neural Networks,PACMCGIT,2018.0,26,"High-quality normal maps are important intermediates for representing complex shapes. In this paper, we propose an interactive system for generating normal maps with the help of deep learning techniques. Utilizing the Generative Adversarial Network (GAN) framework, our method produces high quality normal maps with sketch inputs. In addition, we further enhance the interactivity of our system by incorporating user-specified normals at selected points. Our method generates high quality normal maps in real time. Through comprehensive experiments, we show the effectiveness and robustness of our method. A thorough user study indicates the normal maps generated by our method achieve a lower perceptual difference from the ground truth compared to the alternative methods."
"Hideaki Yanagisawa, T. Yamashita, Hiroshi Watanabe",e48342c8a57f8bbeb27bf124b1ae296660e39c4e,A study on object detection method from manga images using CNN,2018 International Workshop on Advanced Image Technology (IWAIT),2018.0,25,"Japanese comics (manga) are popular content worldwide. In order to acquire metadata from manga images, techniques automatic recognition of manga content have been studied. Recently, Convolutional Neural Network (CNN) has been applied to object detection in manga images. R-CNN and Fast R-CNN generate region proposals by Selective Search. Faster R-CNN generates them using CNN layers called Region Proposal Network (RPN). Single Shot MultiBox Detector (SSD), the latest detection method, performs object classification and box adjustment for small regions in an image. These methods are effective to natural images. However, it is unclear whether such methods work properly to manga images or not, since those image features are different from natural images. In this paper, we examine the effectiveness of manga object detection by comparing Fast R-CNN, Faster R-CNN, and SSD. Here, manga objects are panel layout, speech balloon, character face, and text. Experimental results show that Fast R-CNN is effective for panel layout and speech balloon, whereas Faster R-CNN is ef­fective for character face and text."
"Xing Di, V. Patel",91e9e19a06614197b5431410cecd29762223e04e,Face Synthesis from Visual Attributes via Sketch using Conditional VAEs and GANs,ArXiv,2018.0,22,"Automatic synthesis of faces from visual attributes is an important problem in computer vision and has wide applications in law enforcement and entertainment. With the advent of deep generative convolutional neural networks (CNNs), attempts have been made to synthesize face images from attributes and text descriptions. In this paper, we take a different approach, where we formulate the original problem as a stage-wise learning problem. We first synthesize the facial sketch corresponding to the visual attributes and then we reconstruct the face image based on the synthesized sketch. The proposed Attribute2Sketch2Face framework, which is based on a combination of deep Conditional Variational Autoencoder (CVAE) and Generative Adversarial Networks (GANs), consists of three stages: (1) Synthesis of facial sketch from attributes using a CVAE architecture, (2) Enhancement of coarse sketches to produce sharper sketches using a GAN-based framework, and (3) Synthesis of face from sketch using another GAN-based network. Extensive experiments and comparison with recent methods are performed to verify the effectiveness of the proposed attribute-based three stage face synthesis method."
"Nhu-Van Nguyen, Christophe Rigaud, J. Burie",9a7784eea6bfa62bf2834ee0b87a3cdda46006f2,Digital Comics Image Indexing Based on Deep Learning,J. Imaging,2018.0,22,"The digital comic book market is growing every year now, mixing digitized and digital-born comics. Digitized comics suffer from a limited automatic content understanding which restricts online content search and reading applications. This study shows how to combine state-of-the-art image analysis methods to encode and index images into an XML-like text file. Content description file can then be used to automatically split comic book images into sub-images corresponding to panels easily indexable with relevant information about their respective content. This allows advanced search in keywords said by specific comic characters, action and scene retrieval using natural language processing. We get down to panel, balloon, text, comic character and face detection using traditional approaches and breakthrough deep learning models, and also text recognition using LSTM model. Evaluations on a dataset composed of online library content are presented, and a new public dataset is also proposed."
"Jui-Hsien Wang, Ante Qu, Timothy R. Langlois, Doug L. James",40f03f885e25b2b235b1e8a373da9decc4218bb3,Toward wave-based sound synthesis for computer animation,ACM Trans. Graph.,2018.0,22,"We explore an integrated approach to sound generation that supports a wide variety of physics-based simulation models and computer-animated phenomena. Targeting high-quality offline sound synthesis, we seek to resolve animation-driven sound radiation with near-field scattering and diffraction effects. The core of our approach is a sharp-interface finite-difference time-domain (FDTD) wavesolver, with a series of supporting algorithms to handle rapidly deforming and vibrating embedded interfaces arising in physics-based animation sound. Once the solver rasterizes these interfaces, it must evaluate acceleration boundary conditions (BCs) that involve model-and phenomena-specific computations. We introduce acoustic shaders as a mechanism to abstract away these complexities, and describe a variety of implementations for computer animation: near-rigid objects with ringing and acceleration noise, deformable (finite element) models such as thin shells, bubble-based water, and virtual characters. Since time-domain wave synthesis is expensive, we only simulate pressure waves in a small region about each sound source, then estimate a far-field pressure signal. To further improve scalability beyond multi-threading, we propose a fully time-parallel sound synthesis method that is demonstrated on commodity cloud computing resources. In addition to presenting results for multiple animation phenomena (water, rigid, shells, kinematic deformers, etc.) we also propose 3D automatic dialogue replacement (3DADR) for virtual characters so that pre-recorded dialogue can include character movement, and near-field shadowing and scattering sound effects."
"A. Elgammal, Yan Kang, M. D. Leeuw",fd969d68c63e8b964a77c545f40bfd043e19a3d6,"Picasso, Matisse, or a Fake? Automated Analysis of Drawings at the Stroke Level for Attribution and Authentication",AAAI,2018.0,22,"This paper proposes a computational approach for analysis of strokes in line drawings by artists. We aim at developing an AI methodology that facilitates attribution of drawings of unknown authors in a way that is not easy to be deceived by forged art. The methodology used is based on quantifying the characteristics of individual strokes in drawings. We propose a novel algorithm for segmenting individual strokes. We designed and compared different hand-crafted and learned features for the task of quantifying stroke characteristics. We also propose and compare different classification methods at the drawing level. We experimented with a dataset of 300 digitized drawings with over 80 thousands strokes. The collection mainly consisted of drawings of Pablo Picasso, Henry Matisse, and Egon Schiele, besides a small number of representative works of other artists. The experiments shows that the proposed methodology can classify individual strokes with accuracy 70%-90%, and aggregate over drawings with accuracy above 80%, while being robust to be deceived by fakes (with accuracy 100% for detecting fakes in most settings)."
"Chunlei Peng, Xinbo Gao, N. Wang, J. Li",6d67122213b3a07fff23da8afc34dac818fae615,"Face recognition from multiple stylistic sketches: Scenarios, datasets, and evaluation",Pattern Recognit.,2018.0,21,"Matching a face sketch against mug shots, which plays an important role in law enforcement and security, is an interesting and challenging topic in face recognition community. Although great progress has been made in recent years, main focus is the face recognition based on SINGLE sketch in existing studies. In this paper, we present a fundamental study of face recognition from multiple stylistic sketches. Three specific scenarios with corresponding datasets are carefully introduced to mimic real-world situations: (1) recognition from multiple hand-drawn sketches; (2) recognition from hand-drawn sketch and composite sketches; (3) recognition from multiple composite sketches. We further provide the evaluation protocols and several benchmarks on these proposed scenarios. Finally, we discuss the plenty of challenges and possible future directions that worth to be further investigated. All the materials will be publicly available online (Available at http://chunleipeng.com/FRMSketches.html.) for comparisons and further study of this problem."
"V. Pihur, Aleksandra Korolova, Frederick Liu, Subhash Sankuratripati, M. Yung, Dachuan Huang, Ruogu Zeng",ac5c598bd29c8a51e7b5917877e778dd8042be39,"Differentially-Private ""Draw and Discard"" Machine Learning",ArXiv,2018.0,20,"In this work, we propose a novel framework for privacy-preserving client-distributed machine learning. It is motivated by the desire to achieve differential privacy guarantees in the local model of privacy in a way that satisfies all systems constraints using asynchronous client-server communication and provides attractive model learning properties. We call it ""Draw and Discard"" because it relies on random sampling of models for load distribution (scalability), which also provides additional server-side privacy protections and improved model quality through averaging. We present the mechanics of client and server components of ""Draw and Discard"" and demonstrate how the framework can be applied to learning Generalized Linear models. We then analyze the privacy guarantees provided by our approach against several types of adversaries and showcase experimental results that provide evidence for the framework's viability in practical deployments."
"Chaofeng Chen, Xiao Tan, K. K. Wong",89fa9a4f3adf745cc36d4c2a840739c85d59b1f1,Face Sketch Synthesis with Style Transfer Using Pyramid Column Feature,2018 IEEE Winter Conference on Applications of Computer Vision (WACV),2018.0,19,"In this paper, we propose a novel framework based on deep neural networks for face sketch synthesis from a photo. Imitating the process of how artists draw sketches, our framework synthesizes face sketches in a cascaded manner. A content image is first generated that outlines the shape of the face and the key facial features. Textures and shadings are then added to enrich the details of the sketch. We utilize a fully convolutional neural network (FCNN) to create the content image, and propose a style transfer approach to introduce textures and shadings based on a newly proposed pyramid column feature. We demonstrate that our style transfer approach based on the pyramid column feature can not only preserve more sketch details than the common style transfer method, but also surpasses traditional patch based methods. Quantitative and qualitative evaluations suggest that our framework outperforms other state-of-the-arts methods, and can also generalize well to different test images."
"B. Kim, O. Wang, A. C. Öztireli, M. Gross",9184b0c04013bfdfd82f4f271b5f017396c2f085,Semantic Segmentation for Line Drawing Vectorization Using Neural Networks,Comput. Graph. Forum,2018.0,19,"In this work, we present a method to vectorize raster images of line art. Inverting the rasterization procedure is inherently ill‐conditioned, as there exist many possible vector images that could yield the same raster image. However, not all of these vector images are equally useful to the user, especially if performing further edits is desired. We therefore define the problem of computing an instance segmentation of the most likely set of paths that could have created the raster image. Once the segmentation is computed, we use existing vectorization approaches to vectorize each path, and then combine all paths into the final output vector image. To determine which set of paths is most likely, we train a pair of neural networks to provide semantic clues that help resolve ambiguities at intersection and overlap regions. These predictions are made considering the full context of the image, and are then globally combined by solving a Markov Random Field (MRF). We demonstrate the flexibility of our method by generating results on character datasets, a synthetic random line dataset, and a dataset composed of human drawn sketches. For all cases, our system accurately recovers paths that adhere to the semantics of the drawings."
"Decheng Liu, J. Li, N. Wang, Chunlei Peng, Xinbo Gao",38785f9833c23c4b88be17b644452ccbb4764bf0,Composite components-based face sketch recognition,Neurocomputing,2018.0,19,"Abstract Composite face sketch recognition is a challenging problem in face recognition, which is important for law enforcement. Considering composite sketch is generated from facial components, a component-based representation approach (CBR) was proposed to match composite sketch to photos recently. They extract multi-scale local binary pattern (MLBP) feature from every component and use the fusion of four most discriminative components as the final matching score, ignoring the inherent structure of composite sketch and the fusion does not take the full components’ information into consideration. This paper presents a novel composite sketch recognition method by extracting scale-invariant feature transform (SIFT) feature and histogram of oriented gradient (HOG) feature from components, fusing different features at score level, combining facial components with linear function. In our proposed method, feature fusion could extract local texture and structure feature from composite sketches. The linear combination not only reserves complete component information but also protrudes different components contribution to the holistic face image. In addition, we show the detailed procedure of composite sketch generation experiment, helping build related face database. Experiments on several public composite sketch databases (including a newly published UoM-SGFS database) demonstrate that our proposed method achieves superior performance compared with state-of-the-art methods."
"Hadi Kazemi, S. M. Iranmanesh, Ali Dabouei, Sobhan Soleymani, N. Nasrabadi",189eedfc81ee47b2b44caf8bfe816726697ba421,Facial Attributes Guided Deep Sketch-to-Photo Synthesis,2018 IEEE Winter Applications of Computer Vision Workshops (WACVW),2018.0,18,"Face sketch-photo synthesis is a critical application in law enforcement and digital entertainment industry. Despite the significant improvements in sketch-to-photo synthesis techniques, existing methods have still serious limitations in practice, such as the need for paired data in the training phase or having no control on enforcing facial attributes over the synthesized image. In this work, we present a new framework, which is a conditional version of Cycle-GAN, conditioned on facial attributes. The proposed network forces facial attributes, such as skin and hair color, on the synthesized photo and does not need a set of aligned face-sketch pairs during its training. We evaluate the proposed network by training on two real and synthetic sketch datasets. The hand-sketch images of the FERET dataset and the color face images from the WVU Multi-modal dataset are used as an unpaired input to the proposed conditional CycleGAN with the skin color as the controlled face attribute. For more attribute guided evaluation, a synthetic sketch dataset is created from the CelebA dataset and used to evaluate the performance of the network by forcing several desired facial attributes on the synthesized faces."
"Jochen Laubrock, Sven Hohenstein, Matthias Kümmerer",c42ea000d543c1fa4adc4af58930c869cc1b12aa,Attention to Comics : Cognitive Processing During the Reading of Graphic Literature,,2018.0,16,
"Philippe Wacker, Adrian Wagner, S. Voelker, J. Borchers",6209593903a78265162c8b04609d0d4a6e92df1a,Physical Guides: An Analysis of 3D Sketching Performance on Physical Objects in Augmented Reality,CHI Extended Abstracts,2018.0,15,"Augmented Reality (AR) lets users sketch 3D designs directly attached to existing physical objects. These objects provide natural haptic feedback whenever the pen touches them, and, unlike in VR, there is no need to digitize the physical object first. Especially in Personal Fabrication, this lets non-professional designers quickly create simple 3D models that fit existing physical objects. We studied how accurately visual lines and concave/convex surfaces let users draw 3D shapes attached to physical vs. virtual objects in AR. Results show that tracing physical objects is 48% more accurate, but takes longer than tracing virtual objects. Concave physical edges further improve accuracy due to their haptic guidance. Our findings provide initial metrics when designing AR sketching systems."
"Hadi Kazemi, Sobhan Soleymani, Ali Dabouei, S. M. Iranmanesh, N. Nasrabadi",646030fe70672299b099adede5c446115826f4f6,Attribute-Centered Loss for Soft-Biometrics Guided Face Sketch-Photo Recognition,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2018.0,15,"Face sketches are able to capture the spatial topology of a face while lacking some facial attributes such as race, skin, or hair color. Existing sketch-photo recognition approaches have mostly ignored the importance of facial attributes. In this paper, we propose a new loss function, called attribute-centered loss, to train a Deep Coupled Convolutional Neural Network (DCCNN) for facial attribute guided sketch to photo matching. Specifically, an attribute-centered loss is proposed which learns several distinct centers, in a shared embedding space, for photos and sketches with different combinations of attributes. The DCCNN simultaneously is trained to map photos and pairs of testified attributes and corresponding forensic sketches around their associated centers, while preserving the spatial topology information. Importantly, the centers learn to keep a relative distance from each other, related to their number of contradictory attributes. Extensive experiments are performed on composite (E-PRIP) and semi-forensic (IIIT-D Semi-forensic) databases. The proposed method significantly outperforms the state-of-the-art."
"Shengchuan Zhang, R. Ji, Jie Hu, Yue Gao, Chia-Wen Lin",f3002f126f7da75f838637cc314b5f8adc09da53,Robust Face Sketch Synthesis via Generative Adversarial Fusion of Priors and Parametric Sigmoid,IJCAI,2018.0,14,"Despite the extensive progress in face sketch synthesis, existing methods are mostly workable under constrained conditions, such as fixed illumination, pose, background and ethnic origin that are hardly to control in real-world scenarios. The key issue lies in the difficulty to use data under fixed conditions to train a model against imaging variations. In this paper, we propose a novel generative adversarial network termed pGAN, which can generate face sketches efficiently using training data under fixed conditions and handle the aforementioned uncontrolled conditions. In pGAN, we embed key photo priors into the process of synthesis and design a parametric sigmoid activation function for compensating illumination variations. Compared to the existing methods, we quantitatively demonstrate that the proposed method can work well on face photos in the wild."
"Hadi Kazemi, Fariborz Taherkhani, N. Nasrabadi",a943fc93201dcb37940fa0428d98a5c55fb4dd35,Unsupervised Facial Geometry Learning for Sketch to Photo Synthesis,2018 International Conference of the Biometrics Special Interest Group (BIOSIG),2018.0,14,"Face sketch-photo synthesis is a critical application in law enforcement and digital entertainment industry where the goal is to learn the mapping between a face sketch image and its corresponding photo-realistic image. However, the limited number of paired sketch-photo training data usually prevents the current frameworks to learn a robust mapping between the geometry of sketches and their matching photo-realistic images. Consequently, in this work, we present an approach for learning to synthesize a photo-realistic image from a face sketch in an unsupervised fashion. In contrast to current unsupervised image-to-image translation techniques, our framework leverages a novel perceptual discriminator to learn the geometry of human face. Learning racial prior information empowers the network to remove the geometrical artifacts in the face sketch. We demonstrate that a simultaneous optimization of the face photo generator network, employing the proposed perceptual discriminator in combination with a texture-wise discriminator, results in a significant improvement in quality and recognition rate of the synthesized photos. We evaluate the proposed network by conducting extensive experiments on multiple baseline sketch-photo datasets."
"Natasha Jaques, Jesse Engel, David R Ha, Fred Bertsch, Rosalind W. Picard, D. Eck",0ed249f270b37ca979fb385f7dcb6bffe83a7afc,Learning via social awareness: improving sketch representations with facial feedback,ICLR,2018.0,14,"In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model."
"Lu Pang, Yaowei Wang, Yi-Zhe Song, Tiejun Huang, Yonghong Tian",974fea3530307da6d22ef91c6765f5404514b3c5,Cross-Domain Adversarial Feature Learning for Sketch Re-identification,ACM Multimedia,2018.0,14,"Under person re-identification (Re-ID), a query photo of the target person is often required for retrieval. However, one is not always guaranteed to have such a photo readily available under a practical forensic setting. In this paper, we define the problem of Sketch Re-ID, which instead of using a photo as input, it initiates the query process using a professional sketch of the target person. This is akin to the traditional problem of forensic facial sketch recognition, yet with the major difference that our sketches are whole-body other than just the face. This problem is challenging because sketches and photos are in two distinct domains. Specifically, a sketch is the abstract description of a person. Besides, person appearance in photos is variational due to camera viewpoint, human pose and occlusion. We address the Sketch Re-ID problem by proposing a cross-domain adversarial feature learning approach to jointly learn the identity features and domain-invariant features. We employ adversarial feature learning to filter low-level interfering features and remain high-level semantic information. We also contribute to the community the first Sketch Re-ID dataset with 200 persons, where each person has one sketch and two photos from different cameras associated. Extensive experiments have been performed on the proposed dataset and other common sketch datasets including CUFSF and QUML-shoe. Results show that the proposed method outperforms the state-of-the-arts."
Eugene d'Eon,4152f640e59396c35c6c8d0775e52624a5369062,A Reciprocal Formulation of Nonexponential Radiative Transfer. 1: Sketch and Motivation,ArXiv,2018.0,14,"Abstract Previous proposals to permit nonexponential free-path statistics in radiative transfer have not included support for volume and boundary sources that are spatially uncorrelated from the scattering events in the medium. Birth-collision free paths are treated identically to collision–collision free paths and application of this to general, bounded scenes with inclusions leads to nonreciprocal transport. Beginning with reciprocity as a desired property, we propose a new way to integrate nonexponential transport theory into general scenes. We distinguish between the free-path-length statistics between correlated medium particles and the free-path-length statistics beginning at locations not correlated to medium particles, such as boundary surfaces, inclusions, and uncorrelated sources. Reciprocity requires that the uncorrelated free-path distributions are simply the normalized transmittance of the correlated free-path distributions. The combination leads to an equilibrium imbedding of a previously derived generalized transport equation into bounded domains. We compare predictions of this approach to Monte Carlo simulation of multiple scattering from negatively correlated suspensions of monodispersive hard spheres in bounded two-dimensional domains and demonstrate improved performance relative to previous work. We also derive new, exact, reciprocal, single-scattering solutions for plane-parallel half-spaces over a variety of nonexponential media types."
"Ryohei Suzuki, Masanori Koyama, Takeru Miyato, Taizan Yonetsuji, Huachun Zhu",fe6b20332d37c50722aee0c6133df6c70826d27f,Spatially Controllable Image Synthesis with Internal Representation Collaging,,2018.0,14,"We present a novel CNN-based image editing strategy that allows the user to change the semantic information of an image over an arbitrary region by manipulating the feature-space representation of the image in a trained GAN model. We will present two variants of our strategy: (1) spatial conditional batch normalization (sCBN), a type of conditional batch normalization with user-specifiable spatial weight maps, and (2) feature-blending, a method of directly modifying the intermediate features. Our methods can be used to edit both artificial image and real image, and they both can be used together with any GAN with conditional normalization layers. We will demonstrate the power of our method through experiments on various types of GANs trained on different datasets. Code will be available at this https URL."
"D. Giunchi, Stuart James, A. Steed",28a4eee26e16c62a1c5f1e3ee30f26e6f6203561,3D sketching for interactive model retrieval in virtual reality,Expressive,2018.0,13,"We describe a novel method for searching 3D model collections using free-form sketches within a virtual environment as queries. As opposed to traditional sketch retrieval, our queries are drawn directly onto an example model. Using immersive virtual reality the user can express their query through a sketch that demonstrates the desired structure, color and texture. Unlike previous sketch-based retrieval methods, users remain immersed within the environment without relying on textual queries or 2D projections which can disconnect the user from the environment. We perform a test using queries over several descriptors, evaluating the precision in order to select the most accurate one. We show how a convolutional neural network (CNN) can create multi-view representations of colored 3D sketches. Using such a descriptor representation, our system is able to rapidly retrieve models and in this way, we provide the user with an interactive method of navigating large object datasets. Through a user study we demonstrate that by using our VR 3D model retrieval system, users can perform search more quickly and intuitively than with a naive linear browsing method. Using our system users can rapidly populate a virtual environment with specific models from a very large database, and thus the technique has the potential to be broadly applicable in immersive editing systems."
"X. Wang, X. Chen, Zhengjun Zha",63fef3b0fc6683ca48f88c3b7b51fa9a6e492936,Sketchpointnet: A Compact Network for Robust Sketch Recognition,2018 25th IEEE International Conference on Image Processing (ICIP),2018.0,13,"Sketch recognition is a challenging image processing task. In this paper, we propose a novel point-based network with a compact architecture, named SketchPointNet, for robust sketch recognition. Sketch features are hierarchically learned from three mini PointNets, by successively sampling and grouping 2D points in a bottom-up fashion. SketchPointNet exploits both temporal and spatial context in strokes during point sampling and grouping. By directly consuming the sparse points, SketchPointN et is very compact and efficient. Compared with state-of-the-art techniques, SketchPointNet achieves comparable performance on the challenging TU-Berlin dataset while it significantly reduces the network size."
"Conghui Hu, Da Li, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",b6922c5ef4760b92cae2bcb164927708e75a7b22,Sketch-a-Classifier: Sketch-Based Photo Classifier Generation,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,2018.0,13,"Contemporary deep learning techniques have made image recognition a reasonably reliable technology. However training effective photo classifiers typically takes numerous examples which limits image recognition's scalability and applicability to scenarios where images may not be available. This has motivated investigation into zero-shot learning, which addresses the issue via knowledge transfer from other modalities such as text. In this paper we investigate an alternative approach of synthesizing image classifiers: almost directly from a user's imagination, via freehand sketch. This approach doesn't require the category to be nameable or describable via attributes as per zero-shot learning. We achieve this via training a model regression network to map from free-hand sketch space to the space of photo classifiers. It turns out that this mapping can be learned in a category-agnostic way, allowing photo classifiers for new categories to be synthesized by user with no need for annotated training photos. We also demonstrate that this modality of classifier generation can also be used to enhance the granularity of an existing photo classifier, or as a complement to name-based zero-shot learning."
"Chaofeng Chen, W. Liu, Xiao Tan, K. K. Wong",de81d0b319d382f6db9f9580600cd63a951a29e4,Semi-Supervised Learning for Face Sketch Synthesis in the Wild,ACCV,2018.0,12,"Face sketch synthesis has made great progress in the past few years. Recent methods based on deep neural networks are able to generate high quality sketches from face photos. However, due to the lack of training data (photo-sketch pairs), none of such deep learning based methods can be applied successfully to face photos in the wild. In this paper, we propose a semi-supervised deep learning architecture which extends face sketch synthesis to handle face photos in the wild by exploiting additional face photos in training. Instead of supervising the network with ground truth sketches, we first perform patch matching in feature space between the input photo and photos in a small reference set of photo-sketch pairs. We then compose a pseudo sketch feature representation using the corresponding sketch feature patches to supervise our network. With the proposed approach, we can train our networks using a small reference set of photo-sketch pairs together with a large face photo dataset without ground truth sketches. Experiments show that our method achieves state-of-the-art performance both on public benchmarks and face photos in the wild. Codes are available at https://github.com/chaofengc/Face-Sketch-Wild."
"A. Chatalic, R. Gribonval, N. Keriven",27b8776291b329e2edac93105f2949fd0cfc7701,Large-Scale High-Dimensional Clustering with Fast Sketching,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2018.0,12,"In this paper, we address the problem of high-dimensional k-means clustering in a large-scale setting, i.e. for datasets that comprise a large number of items. Sketching techniques have already been used to deal with this “large-scale” issue, by compressing the whole dataset into a single vector of random nonlinear generalized moments from which the $k$ centroids are then retrieved efficiently. However, this approach usually scales quadratically with the dimension; to cope with high-dimensional datasets, we show how to use fast structured random matrices to compute the sketching operator efficiently. This yields significant speed-ups and memory savings for high-dimensional data, while the clustering results are shown to be much more stable, both on artificial and real datasets."
"Sounak Dey, A. Dutta, S. Ghosh, Ernest Valveny, J. Lladós, U. Pal",e9ac7adc8db3030707102efa07c06bd38aea233e,Learning Cross-Modal Deep Embeddings for Multi-Object Image Retrieval using Text and Sketch,2018 24th International Conference on Pattern Recognition (ICPR),2018.0,12,"In this work we introduce a cross modal image retrieval system that allows both text and sketch as input modalities for the query. A cross-modal deep network architecture is formulated to jointly model the sketch and text input modalities as well as the the image output modality, learning a common embedding between text and images and between sketches and images. In addition, an attention model is used to selectively focus the attention on the different objects of the image, allowing for retrieval with multiple objects in the query. Experiments show that the proposed method performs the best in both single and multiple object image retrieval in standard datasets."
"K. Hamada, Kentaro Tachibana, Tianqi Li, Hiroto Honda, Y. Uchida",307e8d67c24b6ef9960bd6a2a03722a471bf4ddd,Full-body High-resolution Anime Generation with Progressive Structure-conditional Generative Adversarial Networks,ECCV Workshops,2018.0,12,"We propose Progressive Structure-conditional Generative Adversarial Networks (PSGAN), a new framework that can generate full-body and high-resolution character images based on structural information. Recent progress in generative adversarial networks with progressive training has made it possible to generate high-resolution images. However, existing approaches have limitations in achieving both high image quality and structural consistency at the same time. Our method tackles the limitations by progressively increasing the resolution of both generated images and structural conditions during training. In this paper, we empirically demonstrate the effectiveness of this method by showing the comparison with existing approaches and video generation results of diverse anime characters at 1024x1024 based on target pose sequences. We also create a novel dataset containing full-body 1024x1024 high-resolution images and exact 2D pose keypoints using Unity 3D Avatar models."
"Peng Lu, Gao Huang, Yanwei Fu, G. Guo, Hangyu Lin",f7e29da51cb2e4ee6721dbe96cdc9727ccdb744a,Learning Large Euclidean Margin for Sketch-based Image Retrieval,ArXiv,2018.0,11,"This paper addresses the problem of Sketch-Based Image Retrieval (SBIR), for which bridge the gap between the data representations of sketch images and photo images is considered as the key. Previous works mostly focus on learning a feature space to minimize intra-class distances for both sketches and photos. In contrast, we propose a novel loss function, named Euclidean Margin Softmax (EMS), that not only minimizes intra-class distances but also maximizes inter-class distances simultaneously. It enables us to learn a feature space with high discriminability, leading to highly accurate retrieval. In addition, this loss function is applied to a conditional network architecture, which could incorporate the prior knowledge of whether a sample is a sketch or a photo. We show that the conditional information can be conveniently incorporated to the recently proposed Squeeze and Excitation (SE) module, lead to a conditional SE (CSE) module. Extensive experiments are conducted on two widely used SBIR benchmark datasets. Our approach, although being very simple, achieved new state-of-the-art on both datasets, surpassing existing methods by a large margin."
"Jianhui Zhang, Yilan Chen, Lei Li, Hongbo Fu, C. Tai",8faa2f72699fe1dc35b643a711a02a15f6b65475,Context-based sketch classification,Expressive,2018.0,11,"We present a novel context-based sketch classification framework using relations extracted from scene images. Most of existing methods perform sketch classification by considering individually sketched objects and often fail to identify their correct categories, due to the highly abstract nature of sketches. For a sketched scene containing multiple objects, we propose to classify a sketched object by considering its surrounding context in the scene, which provides vital cues for alleviating its recognition ambiguity. We learn such context knowledge from a database of scene images by summarizing the inter-object relations therein, such as co-occurrence, relative positions and sizes. We show that the context information can be used for both incremental sketch classification and sketch co-classification. Our method outperforms a state-of-the-art single-object classification method, evaluated on a new dataset of sketched scenes."
"Lingjing Wang, Cheng Qian, Jifei Wang, Yi Fang",886a50f269ace4b140ddee9d4c7277743b27e250,Unsupervised Learning of 3D Model Reconstruction from Hand-Drawn Sketches,ACM Multimedia,2018.0,11,"3D objects modeling has gained considerable attention in the visual computing community. We propose a low-cost unsupervised learning model for 3D objects reconstruction from hand-drawn sketches. Recent advancements in deep learning opened new opportunities to learn high-quality 3D objects from 2D sketches via supervised networks. However, the limited availability of labeled 2D hand-drawn sketches data (i.e. sketches and its corresponding 3D ground truth models) hinders the training process of supervised methods. In this paper, driven by a novel design of combination of retrieval and reconstruction process, we developed a learning paradigm to reconstruct 3D objects from hand-drawn sketches, without the use of well-labeled hand-drawn sketch data during the entire training process. Specifically, the paradigm begins with the training of an adaption network via autoencoder with adversarial loss, embedding the unpaired 2D rendered image domain with the hand-drawn sketch domain to a shared latent vector space. Then from the embedding latent space, for each testing sketch image, we retrieve a few (e.g. five) nearest neighbors from the training 3D data set as prior knowledge for a 3D Generative Adversarial Network. Our experiments verify our network's robust and superior performance in handling 3D volumetric object generation from single hand-drawn sketch without requiring any 3D ground truth labels."
"Marek Dvoroznák, Wilmot Li, Vladimir G. Kim, D. Sýkora",d751f77cbdc002dafad9d9610d10bd56a4cfa0b6,Toonsynth: example-based synthesis of hand-colored cartoon animations,ACM Trans. Graph.,2018.0,11,"We present a new example-based approach for synthesizing hand-colored cartoon animations. Our method produces results that preserve the specific visual appearance and stylized motion of manually authored animations without requiring artists to draw every frame from scratch. In our framework, the artist first stylizes a limited set of known source skeletal animations from which we extract a style-aware puppet that encodes the appearance and motion characteristics of the artwork. Given a new target skeletal motion, our method automatically transfers the style from the source examples to create a hand-colored target animation. Compared to previous work, our technique is the first to preserve both the detailed visual appearance and stylized motion of the original hand-drawn content. Our approach has numerous practical applications including traditional animation production and content creation for games."
"Deng-Ping Fan, Shengchuan Zhang, Yu-Huan Wu, Ming-Ming Cheng, Bo Ren, R. Ji, Paul L. Rosin",5ea4a066263b282a8571198330c459e53e319e3d,Face Sketch Synthesis Style Similarity: A New Structure Co-occurrence Texture Measure,ArXiv,2018.0,11,"Existing face sketch synthesis (FSS) similarity measures are sensitive to slight image degradation (e.g., noise, blur). However, human perception of the similarity of two sketches will consider both structure and texture as essential factors and is not sensitive to slight (""pixel-level"") mismatches. Consequently, the use of existing similarity measures can lead to better algorithms receiving a lower score than worse algorithms. This unreliable evaluation has significantly hindered the development of the FSS field. To solve this problem, we propose a novel and robust style similarity measure called Scoot-measure (Structure CO-Occurrence Texture Measure), which simultaneously evaluates ""block-level"" spatial structure and co-occurrence texture statistics. In addition, we further propose 4 new meta-measures and create 2 new datasets to perform a comprehensive evaluation of several widely-used FSS measures on two large databases. Experimental results demonstrate that our measure not only provides a reliable evaluation but also achieves significantly improved performance. Specifically, the study indicated a higher degree (78.8%) of correlation between our measure and human judgment than the best prior measure (58.6%). Our code will be made available."
"H. Pham, Yuting Wang, V. Pavlovic",263ad0264a19ac58905804715f14fb53fe2f181a,End-to-end Learning for 3D Facial Animation from Speech,ICMI,2018.0,11,"We present a deep learning framework for real-time speech-driven 3D facial animation from speech audio. Our deep neural network directly maps an input sequence of speech spectrograms to a series of micro facial action unit intensities to drive a 3D blendshape face model. In particular, our deep model is able to learn the latent representations of time-varying contextual information and affective states within the speech. Hence, our model not only activates appropriate facial action units at inference to depict different utterance generating actions, in the form of lip movements, but also, without any assumption, automatically estimates emotional intensity of the speaker and reproduces her ever-changing affective states by adjusting strength of related facial unit activations. For example, in a happy speech, the mouth opens wider than normal, while other facial units are relaxed; or both eyebrows raise higher in a surprised state. Experiments on diverse audiovisual corpora of different actors across a wide range of facial actions and emotional states show promising results of our approach. Being speaker-independent, our generalized model is readily applicable to various tasks in human-machine interaction and animation."
"Mingjin Zhang, N. Wang, Xinbo Gao, Yunsong Li",bd4edba22a914175bfc1d238e19fe374e54a9395,Markov Random Neural Fields for Face Sketch Synthesis,IJCAI,2018.0,10,"Synthesizing face sketches with both common and specific information from photos has been recently attracting considerable attentions in digital entertainment. However, the existing approaches either make the strict similarity assumption on face sketches and photos, leading to lose some identity-specific information, or learn the direct mapping relationship from face photos to sketches by the simple neural network, resulting in the lack of some common information. In this paper, we propose a novel face sketch synthesis based on the Markov random neural fields including two structures. In the first structure, we utilize the neural network to learn the non-linear photo-sketch relationship and obtain the identity-specific information of the test photo, such as glasses, hairpins and hairstyles. In the second structure, we choose the nearest neighbors of the test photo patch and the sketch pixel synthesized in the first structure from the training data which ensure the common information of Miss or Mr Average. Experimental results on the Chinese University of Hong Kong face sketch database illustrate that our proposed framework can preserve the common structure and capture the characteristic features. Compared with the state-of-the-art methods, our method achieves better results in terms of both quantitative and qualitative experimental evaluations."
"Fei Huang, Cheng Jin, Yuejie Zhang, Kangnian Weng, T. Zhang, W. Fan",55a0e26803514d0d2be19731a477c12a6c01c642,Sketch-based image retrieval with deep visual semantic descriptor,Pattern Recognit.,2018.0,10,"Abstract Sketch-based Image Retrieval (SBIR) has received a lot of attentions recently. In this paper we aim to enhance SBIR with deep visual semantic descriptor and related optimization mechanisms. Our scheme significantly differs from other earlier work in: 1) A feature representation via deep visual semantic descriptor is established to bridge the gap between sketches and images, which can encode both low-level local features and high-level semantic features; 2) A clustering-based re-ranking optimization is introduced to further improve SBIR by dynamically adjusting the correlations of images in the ranking list. The main contribution of our work is that we effectively apply the deep visual semantic descriptor to enable deep sketch-image matching, which has provided a more reasonable base for us to fuse local low-level visual features with high-level semantic features by determining an optimal correlated mapping. Our experiments on a large number of public data have obtained very positive results."
"D. Xu, Xavier Alameda-Pineda, Jingkuan Song, E. Ricci, N. Sebe",cd0bcb3e527862963bd703e2ca391f18f5eb5b38,Cross-Paced Representation Learning With Partial Curricula for Sketch-Based Image Retrieval,IEEE Transactions on Image Processing,2018.0,10,"In this paper, we address the problem of learning robust cross-domain representations for sketch-based image retrieval (SBIR). While, most SBIR approaches focus on extracting low- and mid-level descriptors for direct feature matching, recent works have shown the benefit of learning coupled feature representations to describe data from two related sources. However, cross-domain representation learning methods are typically cast into non-convex minimization problems that are difficult to optimize, leading to unsatisfactory performance. Inspired by self-paced learning (SPL), a learning methodology designed to overcome convergence issues related to local optima by exploiting the samples in a meaningful order (i.e., easy to hard), we introduce the cross-paced partial curriculum learning (CPPCL) framework. Compared with existing SPL methods which only consider a single modality and cannot deal with prior knowledge, CPPCL is specifically designed to assess the learning pace by jointly handling data from dual sources and modality-specific prior information provided in the form of partial curricula. In addition, thanks to the learned dictionaries, we demonstrate that the proposed CPPCL embeds robust coupled representations for SBIR. Our approach is extensively evaluated on four publicly available datasets (i.e., CUFS, Flickr15K, QueenMary SBIR, and TU-Berlin Extension datasets), showing superior performance over competing SBIR methods."
"Lei Li, C. Zou, Youyi Zheng, Q. Su, Hongbo Fu, C. Tai",5619152331d49bde96ae9f51fffac931ca37a500,Sketch-R2CNN: An Attentive Network for Vector Sketch Recognition,ArXiv,2018.0,10,"Freehand sketching is a dynamic process where points are sequentially sampled and grouped as strokes for sketch acquisition on electronic devices. To recognize a sketched object, most existing methods discard such important temporal ordering and grouping information from human and simply rasterize sketches into binary images for classification. In this paper, we propose a novel single-branch attentive network architecture RNN-Rasterization-CNN (Sketch-R2CNN for short) to fully leverage the dynamics in sketches for recognition. Sketch-R2CNN takes as input only a vector sketch with grouped sequences of points, and uses an RNN for stroke attention estimation in the vector space and a CNN for 2D feature extraction in the pixel space respectively. To bridge the gap between these two spaces in neural networks, we propose a neural line rasterization module to convert the vector sketch along with the attention estimated by RNN into a bitmap image, which is subsequently consumed by CNN. The neural line rasterization module is designed in a differentiable way to yield a unified pipeline for end-to-end learning. We perform experiments on existing large-scale sketch recognition benchmarks and show that by exploiting the sketch dynamics with the attention mechanism, our method is more robust and achieves better performance than the state-of-the-art methods."
"Anran Qi, Yi-Zhe Song, Tao Xiang",9bd705b9521fc5a2ade911e167f0f27365e70143,Semantic Embedding for Sketch-Based 3D Shape Retrieval,BMVC,2018.0,10,"The main challenge for sketch-based 3D shape retrieval lies with the large domain gap between 2D sketch and 3D shape. Most existing works attempt to overcome the domain gap by learning a joint feature embedding space to align the two domains. In this work we argue that the large domain gap cannot be effectively bridged in a shared feature space. Instead, we propose to align them in their common class label space. To this end, a novel deep cross-domain semantic embedding model is proposed. Extensive experiments are carried out on two large benchmarking datasets, SHREC’13 and SHREC’14. The results show that the proposed model drastically improves over the state-of-the-art alternatives."
"Deng Yu, Yujie Liu, Y. Pang, Zongmin Li, Hua Li",8fbe67f77f1088376269a7f3138c6eead2fcd5c7,A multi-layer deep fusion convolutional neural network for sketch based image retrieval,Neurocomputing,2018.0,9,"Abstract The purpose of this paper is to introduce a new approach for the free-hand sketch representation in the sketch based image retrieval (SBIR), where the sketches are treated as the queries to search for the natural photos in the natural image dataset. This task is known as an extremely challenging work for 3 main reasons: (i) sketches show a highly abstract visual appearance versus natural photos, fewer context can be extracted as descriptors using the existing methods, (ii) for the same object, different people provide widely different sketches, making sketch-photo matching harder, (iii) mapping the sketches and photos into a common domain is also a challenging task. In this paper, we address the cross-domain question using a strategy of mapping sketches and natural photos in multiple layers. For the first time, we introduce a multi-layer deep CNNs framework to train the multi-layer representation of free hand sketches and natural photos. We use Flickr15k dataset as benchmark for the retrieval and show that our learned representation significantly outperformances both hand-crafted features as well as deep features trained by sketches or photos."
"Justin Liang, R. Urtasun",9f7f96e985e8cf9d13591a15a2ad7ff910260ed8,End-to-End Deep Structured Models for Drawing Crosswalks,ECCV,2018.0,9,"In this paper we address the problem of detecting crosswalks from LiDAR and camera imagery. Towards this goal, given multiple LiDAR sweeps and the corresponding imagery, we project both inputs onto the ground surface to produce a top down view of the scene. We then leverage convolutional neural networks to extract semantic cues about the location of the crosswalks. These are then used in combination with road centerlines from freely available maps (e.g., OpenStreetMaps) to solve a structured optimization problem which draws the final crosswalk boundaries. Our experiments over crosswalks in a large city area show that 96.6% automation can be achieved."
"Tao Zhou, Chen Fang, Zhaowen Wang, Jimei Yang, Byungmoon Kim, Zhili Chen, Jonathan Brandt, Demetri Terzopoulos",066403a65583bcfe2d18c9b84dc4bad371fb4cb3,Learning to Sketch with Deep Q Networks and Demonstrated Strokes,ArXiv,2018.0,9,"Doodling is a useful and common intelligent skill that people can learn and master. In this work, we propose a two-stage learning framework to teach a machine to doodle in a simulated painting environment via Stroke Demonstration and deep Q-learning (SDQ). The developed system, Doodle-SDQ, generates a sequence of pen actions to reproduce a reference drawing and mimics the behavior of human painters. In the first stage, it learns to draw simple strokes by imitating in supervised fashion from a set of strokeaction pairs collected from artist paintings. In the second stage, it is challenged to draw real and more complex doodles without ground truth actions; thus, it is trained with Qlearning. Our experiments confirm that (1) doodling can be learned without direct stepby- step action supervision and (2) pretraining with stroke demonstration via supervised learning is important to improve performance. We further show that Doodle-SDQ is effective at producing plausible drawings in different media types, including sketch and watercolor."
"Ravi Kiran Sarvadevabhatla, Shiv Surya, Trisha Mittal, V. Radhakrishnan",b081d11a8d19048c65b34c520357a82efcc91856,Game of Sketches: Deep Recurrent Models of Pictionary-style Word Guessing,AAAI,2018.0,9,"The ability of intelligent agents to play games in human-like fashion is popularly considered a benchmark of progress in Artificial Intelligence. Similarly, performance on multi-disciplinary tasks such as Visual Question Answering (VQA) is considered a marker for gauging progress in Computer Vision. In our work, we bring games and VQA together. Specifically, we introduce the first computational model aimed at Pictionary, the popular word-guessing social game. We first introduce Sketch-QA, an elementary version of Visual Question Answering task. Styled after Pictionary, Sketch-QA uses incrementally accumulated sketch stroke sequences as visual data. Notably, Sketch-QA involves asking a fixed question (""What object is being drawn?"") and gathering open-ended guess-words from human guessers. We analyze the resulting dataset and present many interesting findings therein. To mimic Pictionary-style guessing, we subsequently propose a deep neural model which generates guess-words in response to temporally evolving human-drawn sketches. Our model even makes human-like mistakes while guessing, thus amplifying the human mimicry factor. We evaluate our model on the large-scale guess-word dataset generated via Sketch-QA task and compare with various baselines. We also conduct a Visual Turing Test to obtain human impressions of the guess-words generated by humans and our model. Experimental results demonstrate the promise of our approach for Pictionary and similarly themed games."
"Matthew Q. Hill, Connor J. Parde, C. Castillo, Y. Colon, Rajeev Ranjan, Jun-Cheng Chen, V. Blanz, A. O'Toole",3beb1528ce4770ed5b63e424202acc981aeaf149,Deep convolutional neural networks in the face of caricature,,2018.0,9,"Real-world face recognition requires us to perceive the uniqueness of a face across variable images. Deep convolutional neural networks (DCNNs) accomplish this feat by generating robust face representations that can be analysed in a multidimensional ‘face space’. We examined the organization of viewpoint, illumination, gender and identity in this space. We found that DCNNs create a highly organized face similarity structure in which identities and images coexist. Natural image variation is organized hierarchically, with face identity nested under gender, and illumination and viewpoint nested under identity. To examine identity, we caricatured faces and found that identification accuracy increased with the strength of identity information in a face, and caricature representations ‘resembled’ their veridical counterparts—mimicking human perception. DCNNs therefore offer a theoretical framework for reconciling decades of behavioural and neural results that emphasized either the image or the face in representations, without understanding how a neural code could seamlessly accommodate both.Human face recognition is robust to changes in viewpoint, illumination, facial expression and appearance. The authors investigated face recognition in deep convolutional neural networks by manipulating the strength of identity information in a face by caricaturing. They found that networks create a highly organized face similarity structure in which identities and images coexist."
"S. M. Iranmanesh, Hadi Kazemi, Sobhan Soleymani, Ali Dabouei, N. Nasrabadi",88d7a287ec25d41823ba312d1edbcc23874b22b5,Deep Sketch-Photo Face Recognition Assisted by Facial Attributes,"2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS)",2018.0,9,"In this paper, we present a deep coupled framework to address the problem of matching sketch image against a gallery of mugshots. Face sketches have the essential information about the spatial topology and geometric details of faces while missing some important facial attributes such as ethnicity, hair, eye, and skin color. We propose a coupled deep neural network architecture which utilizes facial attributes in order to improve the sketch-photo recognition performance. The proposed Attribute-Assisted Deep Convolutional Neural Network (AADCNN) method exploits the facial attributes and leverages the loss functions from the facial attributes identification and face verification tasks in order to learn rich discriminative features in a common embedding subspace. The facial attribute identification task increases the inter-personal variations by pushing apart the embedded features extracted from individuals with different facial attributes, while the verification task reduces the intra-personal variations by pulling together all the features that are related to one person. The learned discriminative features can be well generalized to new identities not seen in the training data. The proposed architecture is able to make full use of the sketch and complementary facial attribute information to train a deep model compared to the conventional sketch-photo recognition methods. Extensive experiments are performed on composite (E-PRIP) and semi-forensic (IIIT-D semi-forensic) datasets. The results show the superiority of our method compared to the state-of-the-art models in sketch-photo recognition algorithms."
"Jiazhou Chen, Mengqi Du, Xujia Qin, Yongwei Miao",ee2b62ec20a75d682878b723b7ad59243c7ab4c5,An improved topology extraction approach for vectorization of sketchy line drawings,The Visual Computer,2018.0,8,"Vectorization converts raster scans of line drawings into vector graphics; it breaks the barrier between line drawing generation and postprocessing. Prior work on line drawing vectorization considerably succeeded in revealing artists’ drawing intention driven by structural topologies. However, none of them is able to extract simplified topologies for sketchy line drawings consisted by many unwanted lines. In this paper, we propose an improved topology extraction approach based on artists’ sketching customs. Redundant regions and open curves are discriminated from artists’ deliberate ones and further removed progressively through an iterative optimization mechanism. We demonstrate that our improved topology benefits our vectorization method as well as existing topology-driven ones and allows them to vectorize rough sketchy line drawings robustly and efficiently."
"P. Kindermann, Wouter Meulemans, André Schulz",f721c447323a9a3775db8cde42f98687c7dd9ce7,Experimental analysis of the accessibility of drawings with few segments,J. Graph Algorithms Appl.,2018.0,8,"The visual complexity of a graph drawing is defined as the number of geometric objects needed to represent all its edges. In particular, one object may represent multiple edges, e.g., one needs only one line segment to draw two collinear incident edges. We study the question if drawings with few segments have a better aesthetic appeal and help the user to asses the underlying graph. We design an experiment that investigates two different graph types (trees and sparse graphs), three different layout algorithms for trees, and two different layout algorithms for sparse graphs. We asked the users to give an aesthetic ranking on the layouts and to perform a furthest-pair or shortest-path task on the drawings."
"Y. Li, Wenzhao Li",48922520e6de0954a83f26977b2b50b7fbfdcf61,A survey of sketch-based image retrieval,Machine Vision and Applications,2018.0,7,"Sketch-based image retrieval (SBIR) has been studied since the early 1990s and has drawn more and more interest recently. Yet, a comprehensive review of the SBIR field is still absent. This survey tries to fill in this gap by reviewing the representative papers studying the SBIR problem. More importantly, this survey tries to answer two important questions which are generally not well discussed: what are the objectives of SBIR, and what is the general methodology of SBIR? The reviewed papers are organized in a chronological way and analyzed by answering these two important questions. As a novel trend, fine-grained SBIR has become the main topic for the recent research. The discussion on it is also integrated. From this survey, we hope that different perspectives can be observed, common values can be discovered and new ideas can be inspired."
"Adeel Akram, N. Wang, J. Li, Xinbo Gao",482b389c3d8598028644179f2396c26007355625,A Comparative Study on Face Sketch Synthesis,IEEE Access,2018.0,7,"The purpose of face sketch synthesis technique is to generate a sketch from an input face image given a set of face sketch-photo images as the training set. Since face sketch synthesis is attracting huge attentions, an experimental study to existing methods is nontrivial. This paper provides a comprehensive review and comparative study to representative face sketch synthesis methods. These methods are further sub-divided into two main categories: data-driven methods, also known as exemplar-based methods, and model-driven methods. Generally, exemplar-based face sketch synthesis consists of four parts: patch representation; neighbor selection; weight computation; and patch assembling. Model-driven methods explicitly learn the mapping from face photos to face sketches. We have drawn some promising conclusions in this paper which have not been investigated before."
"Young-Sun Yun, Jinman Jung, Seongbae Eun, S. So, Junyoung Heo",cbec2077707809848ccec3d1dfdd16d66ace3232,Detection of GUI Elements on Sketch Images Using Object Detector Based on Deep Neural Networks,,2018.0,7,"Graphical user interface (GUI) is very important to interact with software users. In many studies, therefore, they are trying to convert GUI elements (or widgets) to code or to describe formally its structure by help of domain knowledge or machine learning based algorithms. In this paper, we adopted object detection based on deep neural networks that finds GUI elements by integration of localization and classification. After the successfully detection of GUI components, we will describe the objects as the hierarchical structure and transform those to appropriate codes by synthetic or machine learning algorithms."
"Zheqi He, Yafeng Zhou, Yongtao Wang, Siwei Wang, X. Lu, Zhi Tang, Lingyi Cai",fe0edc34d9bdf51c1544a3f70e83917e5d917681,An End-to-End Quadrilateral Regression Network for Comic Panel Extraction,ACM Multimedia,2018.0,7,"Comic panel extraction, i.e., decomposing a comic page image into panels, has become a fundamental technique for meeting many practical needs of mobile comic reading such as comic content adaptation and comic animating. Most of existing approaches are based on handcrafted low-level visual patterns and heuristics rules, thus having limited ability to deal with irregular comic panels. Only one existing method is based on deep learning and achieves better experimental results, but its architecture is redundant and its time efficiency is not good. To address these problems, we propose an end-to-end, two-stage quadrilateral regressing network architecture for comic panel detection, which inherits the architecture of Faster R-CNN. At the first stage, we propose a quadrilateral region proposal network for generating panel proposals, based on a newly proposed quadrilateral regression method. At the second stage, we classify the proposals and refine their shapes with the proposed quadrilateral regression method again. Extensive experimental results demonstrate that the proposed method significantly outperforms the existing comic panel detection methods on multiple datasets by F1-score and page accuracy."
"K. Sasaki, S. Iizuka, Edgar Simo-Serra, H. Ishikawa",7719536f6e06cf2b39aa522ee5de4e38d4ef7002,Learning to restore deteriorated line drawing,The Visual Computer,2018.0,7,"We propose a fully automatic approach to restore aged old line drawings. We decompose the task into two subtasks: the line extraction subtask, which aims to extract line fragments and remove the paper texture background, and the restoration subtask, which fills in possible gaps and deterioration of the lines to produce a clean line drawing. Our approach is based on a convolutional neural network that consists of two sub-networks corresponding to the two subtasks. They are trained as part of a single framework in an end-to-end fashion. We also introduce a new dataset consisting of manually annotated sketches by Leonardo da Vinci which, in combination with a synthetic data generation approach, allows training the network to restore deteriorated line drawings. We evaluate our method on challenging 500-year-old sketches and compare with existing approaches with a user study, in which it is found that our approach is preferred 72.7% of the time."
"Yi-Ling Qiao, Lin Gao, Yu-Kun Lai, Shi-hong Xia",b8ecce1d8c055f8bd05711471b16642c33412b45,Learning Bidirectional LSTM Networks for Synthesizing 3D Mesh Animation Sequences,ArXiv,2018.0,7,"In this paper, we present a novel method for learning to synthesize 3D mesh animation sequences with long short-term memory (LSTM) blocks and mesh-based convolutional neural networks (CNNs). Synthesizing realistic 3D mesh animation sequences is a challenging and important task in computer animation. To achieve this, researchers have long been focusing on shape analysis to develop new interpolation and extrapolation techniques. However, such techniques have limited learning capabilities and therefore can produce unrealistic animation. Deep architectures that operate directly on mesh sequences remain unexplored, due to the following major barriers: meshes with irregular triangles, sequences containing rich temporal information and flexible deformations. To address these, we utilize convolutional neural networks defined on triangular meshes along with a shape deformation representation to extract useful features, followed by LSTM cells that iteratively process the features. To allow completion of a missing mesh sequence from given endpoints, we propose a new weight-shared bidirectional structure. The bidirectional generation loss also helps mitigate error accumulation over iterations. Benefiting from all these technical advances, our approach outperforms existing methods in sequence prediction and completion both qualitatively and quantitatively. Moreover, this network can also generate follow-up frames conditioned on initial shapes and improve the accuracy as more bootstrap models are provided, which other works in the geometry processing domain cannot achieve."
"D. Giunchi, Stuart James, A. Steed",401edfd13e70547b966d59c4c2e88c1a1759f158,Model Retrieval by 3D Sketching in Immersive Virtual Reality,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),2018.0,6,"We describe a novel method for searching 3D model collections using free-form sketches within a virtual environment as queries. As opposed to traditional Sketch Retrieval, our queries are drawn directly onto an example model. Using immersive virtual reality the user can express their query through a sketch that demonstrates the desired structure, color and texture. Unlike previous sketch-based retrieval methods, users remain immersed within the environment without relying on textual queries or 2D projections which can disconnect the user from the environment. We show how a convolutional neural network (CNN) can create multi-view representations of colored 3D sketches. Using such a descriptor representation, our system is able to rapidly retrieve models and in this way, we provide the user with an interactive method of navigating large object datasets. Through a preliminary user study we demonstrate that by using our VR 3D model retrieval system, users can perform quick and intuitive search. Using our system users can rapidly populate a virtual environment with specific models from a very large database, and thus the technique has the potential to be broadly applicable in immersive editing systems."
"Hussein Samma, S. A. Suandi, J. Mohamad-Saleh",4b6591c87b08131d8c1e4fe9588e6e347b047133,Face sketch recognition using a hybrid optimization model,Neural Computing and Applications,2018.0,6,"In this work, a hybrid optimization-based model is introduced to handle the problem of face sketch recognition. The proposed model comprises a total of three layers that are global search layer, control layer, and fine-tuning layer. The global layer contains a set of search operations from particle swarm optimization (PSO) algorithm to perform the task of global search. However, the control layer is responsible about controlling the execution of the implemented search operations at run time. Finally, the fine-tuning layer is aimed at performing search refinement to enhance the search ability. For sketch recognition, the proposed hybrid model is applied on the input face sketch to locate the internal sketch facial components. Three types of texture features extraction techniques are adopted in this study including Histogram Of Gradient (HOG), Local Binary Pattern (LBP), and Gabor wavelet. To assess the performances of the proposed model, a total of three face sketch databases have been used which are LFW, AR, and CUHK. The reported results indicate that the proposed hybrid model was able to achieve a competitive performance with 96% on AR, 87.68% on CUHK, and 50.00% on LFW. Additionally, the outcomes reveal that the proposed model statistically outperforms others PSO-based models as well as the state-of-the-art meta-heuristic optimization models."
"Saya Fujino, N. Mori, Keinosuke Matsumoto",8205759c3b421dbe4c6dacbbb1c06e32e965457d,Recognizing the Order of Four-Scene Comics by Evolutionary Deep Learning,DCAI,2018.0,6,"In recent years, comic analysis has become an attractive research topic in the field of artificial intelligence. In this study, we focused on the four-scene comics and applied deep convolutional neural networks (DCNNs) to the data for understanding the order structure. The tuning of the DCNN hyperparameters requires considerable effort. To solve this problem, we propose a novel method called evolutionary deep learning (evoDL) by means of genetic algorithms. The effectiveness of evoDL is confirmed by an experiment conducted to identify structural problems in actual four-scene comics."
"Marco Stricker, Olivier Augereau, K. Kise, M. Iwata",64cac22210861d4e9afb00b781da90cf99f9d19c,Facial Landmark Detection for Manga Images,ArXiv,2018.0,6,"The topic of facial landmark detection has been widely covered for pictures of human faces, but it is still a challenge for drawings. Indeed, the proportions and symmetry of standard human faces are not always used for comics or mangas. The personal style of the author, the limitation of colors, etc. makes the landmark detection on faces in drawings a difficult task. Detecting the landmarks on manga images will be useful to provide new services for easily editing the character faces, estimating the character emotions, or generating automatically some animations such as lip or eye movements. 
This paper contains two main contributions: 1) a new landmark annotation model for manga faces, and 2) a deep learning approach to detect these landmarks. We use the ""Deep Alignment Network"", a multi stage architecture where the first stage makes an initial estimation which gets refined in further stages. The first results show that the proposed method succeed to accurately find the landmarks in more than 80% of the cases."
"Jatin Garg, S. Peri, Himanshu Tolani, N. C. Krishnan",adf4d5986495bbe3f8375aaed0b667961df8a542,Deep Cross Modal Learning for Caricature Verification and Identification (CaVINet),ACM Multimedia,2018.0,6,"Learning from different modalities is a challenging task. In this paper, we look at the challenging problem of cross modal face verification and recognition between caricature and visual image modalities. Caricature have exaggerations of facial features of a person. Due to the significant variations in the caricatures, building vision models for recognizing and verifying data from this modality is an extremely challenging task. Visual images with significantly lesser amount of distortions can act as a bridge for the analysis of caricature modality. We introduce a publicly available large Caricature-VIsual dataset [CaVI] with images from both the modalities that captures the rich variations in the caricature of an identity. This paper presents the first cross modal architecture that handles extreme distortions of caricatures using a deep learning network that learns similar representations across the modalities. We use two convolutional networks along with transformations that are subjected to orthogonality constraints to capture the shared and modality specific representations. In contrast to prior research, our approach neither depends on manually extracted facial landmarks for learning the representations, nor on the identities of the person for performing verification. The learned shared representation achieves 91% accuracy for verifying unseen images and 75% accuracy on unseen identities. Further, recognizing the identity in the image by knowledge transfer using a combination of shared and modality specific representations, resulted in an unprecedented performance of 85% rank-1 accuracy for caricatures and 95% rank-1 accuracy for visual images."
Lei Li,8f2d70342c20cb1c738dc0dca76ce97870b641f7,Fast Sketch Segmentation and Labeling with Deep Learning,,2018.0,6,"We present a simple and efficient method based on deep learning to automatically decompose sketched objects into semantically valid parts. We train a deep neural network to transfer existing segmentations and labelings from 3D models to freehand sketches without requiring numerous well-annotated sketches as training data. The network takes the binary image of a sketched object as input and produces a corresponding segmentation map with per-pixel labelings as output. A subsequent post-process procedure with multi-label graph cuts further refines the segmentation and labeling result. We validate our proposed method on two sketch datasets. Experiments show that our method outperforms the state-of-the-art method in terms of segmentation and labeling accuracy and is significantly faster, enabling further integration in interactive drawing systems. We demonstrate the efficiency of our method in a sketch-based modeling application that automatically transforms input sketches into 3D models by part assembly."
"Pegah Karimi, N. Davis, Kazjon Grace, M. Maher",1a87341fdcb4f8018064ef6cfa173ab6eecd5849,Deep Learning for Identifying Potential Conceptual Shifts for Co-creative Drawing,ArXiv,2018.0,6,"We present a system for identifying conceptual shifts between visual categories, which will form the basis for a co-creative drawing system to help users draw more creative sketches. The system recognizes human sketches and matches them to structurally similar sketches from categories to which they do not belong. This would allow a co-creative drawing system to produce an ambiguous sketch that blends features from both categories."
"J. Lu, H. Yang",67de347518123376bb1da832fc3889987ebb2925,Phase-Space Sketching for Crystal Image Analysis Based on Synchrosqueezed Transforms,SIAM J. Imaging Sci.,2018.0,6,"Recent developments of imaging techniques enable researchers to visualize materials at the atomic resolution to better understand the microscopic structures of materials. This paper aims at automatic and quantitative characterization of potentially complicated microscopic crystal images, providing feedback to tweak theories and improve synthesis in materials science. As such, an efficient phase-space sketching method is proposed to encode microscopic crystal images in a translation, rotation, illumination, and scale invariant representation, which is also stable with respect to small deformations. Based on the phase-space sketching, we generalize our previous analysis framework for crystal images with simple structures to those with complicated geometry."
"Hwan Heo, Youngbae Hwang",3f8744bf227901f5d02c2f14399d5011fcf1b5e9,Automatic Sketch Colorization using DCGAN,"2018 18th International Conference on Control, Automation and Systems (ICCAS)",2018.0,6,"In general, the manual coloring task from the black-white sketch is complicated and time-consuming. Furthermore, in the case of coloring which is a repetition of a similar pattern, it can be seen that manual coloring is less efficient. Therefore, the technique of automatically coloring from black-white sketch can become a practical application. We propose automatic sketch colorization by using U-Net and deep convolutional generative adversarial network (DCGAN) in the generative model. Experimental results on test set show various results including errors depend on test images."
"Saurav Jha, Nikhil Agarwal, S. Agarwal",bb52a8c4b47ba12ca698d406a803a2f341ed3c49,Towards Improved Cartoon Face Detection and Recognition Systems,ArXiv,2018.0,5,"Given the significant advancement in face detection and recognition techniques for human faces over recent years, we questioned how well would they work for cartoon faces - a domain that remains largely unexplored yet, mainly due to the unavailability of abundant data sets and failure of traditional methods on these. In the present article, we employ various state-of-the-art deep learning frameworks for detecting and recognizing faces of cartoon characters along with proposing a novel approach to cartoon face recognition. For face detection, our work demonstrates the effectiveness of the Multi-task Cascaded Convolutional Network (MTCNN) architecture and contrasts it with other benchmark methods. For face recognition, we present two feature-based techniques: (i) an Inductive transfer approach combining the feature learning capability of the Inception v3 network and feature recognizing capability of Support Vector Machines (SVM), (ii) a proposed Hybrid Convolutional Neural Network (HCNN) based recognition framework trained over a fusion of pixel values and 15 manually located facial key points. All the methods are evaluated on the Cartoon Faces in the Wild (IIIT-CFW) database. We show a detailed analysis of the performance of the models using several metrics over a number of input constraints. Experiments show that the MTCNN based model results in a respective gain of 3.97%, 1.19% and 2.78% on the True positive rate, False positive rate and False negative rate over the state-of-the-art detection method while both the recognition models surpass the state-of-the-art in terms of F-score. The Inception v3+SVM recognition model also establishes a new benchmark F-score of 0.910 on the task of cartoon gender recognition. We also introduce a small sized database containing location coordinates of 15 key points of the cartoon faces belonging to 50 public figures included in the IIIT-CFW database."
"Yongzhe Xu, Jiangchuan Hu, K. Zeng, Y. Gong",44dd332f81decef29c833a4de1b4899bd3aa94c3,Sketch-Based Shape Retrieval via Multi-view Attention and Generalized Similarity,2018 7th International Conference on Digital Home (ICDH),2018.0,5,"Sketch-based shape retrieval has received increasing attention in computer vision and computer graphics. It suffers from the challenge gap between 2D sketches and 3D shapes. In this paper, we propose a generalized similarity matching framework based on a multi-view attention network (MVAN), which can retrieve 3D shape that is most similar to the query sketch. In proposed approach, firstly we compute 2D projections of 3D shapes from multiple viewpoints and utilize a convolutional neural network to extract low level feature maps of these 2D projections. Secondly a multi-view attention network is designed to fuse the feature maps and forms a more accurate 3D shape representation. Meanwhile we use a CNN to extract the feature of sketches. Thirdly the similarity between sketches and 3D shapes is estimated via a generalized similarity model, which fuses some traditional similarity model into a generalized form and optimizes its parameters using a data-driven method. Finally we combine the MVAN and generalized similarity model into a unified network and train the model in an end-to-end manner. The experimental results on SHREC'13 and SHREC'14 sketch track benchmark datasets demonstrate that the proposed method can outperform state-of-the-art methods."
"Natasha Jaques, J. McCleary, Jesse Engel, David Ha, Fred Bertsch, Rosalind W. Picard, D. Eck",c959449bf29cc35efee566d7e6bb6daba4ac119d,Learning via Social Awareness: Improving a Deep Generative Sketching Model with Facial Feedback,AffComp@IJCAI,2018.0,5,"In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, by optimizing the model to produce sketches that it predicts will lead to more positive facial expressions. We show in multiple independent evaluations that the model trained with facial feedback produced sketches that are more highly rated, and induce significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model."
"Jialun Jiang, Casey Fiesler, J. Brubaker",858fa61acc213549d0468ef91ff4cab9f4fb11a2,'The Perfect One',Proc. ACM Hum. Comput. Interact.,2018.0,5,"Animated GIFs are increasingly popular in text-based communication. Finding the perfect GIF can make conversations funny, interesting, and engaging, but GIFs also introduce potentials for miscommunication. Through 24 in-depth qualitative interviews, this empirical, exploratory study examines the nuances of communication practices with animated GIFs to better understand why and how GIFs can send unintentional messages. We find participants leverage contexts like source material and interpersonal relationship to find the perfect GIFs for different communication scenarios, while these contexts are also the primary reason for miscommunication and some technical usability issues. This paper concludes with a discussion of the important role that different types of context play in the use and interpretations of GIFs, and argues that nonverbal communication tools should account for complex contexts and common ground that communication media rely on."
"F. Avram, D. Goreac",c6d4d46e00c4f0618b7e75ab22853d49d9926994,"A pontryaghin maximum principle approach for the optimization of dividends/consumption of spectrally negative markov processes, until a generalized draw-down time",,2018.0,5,"ABSTRACT The first motivation of our paper is to explore further the idea that, in risk control problems, it may be profitable to base decisions both on the position of the underlying process and on its supremum . Strongly connected to Azema-Yor/generalized draw-down/trailing stop time this framework provides a natural unification of draw-down and classic first passage times. We illustrate here the potential of this unified framework by solving a variation of the De Finetti problem of maximizing expected discounted cumulative dividends/consumption gained under a barrier policy, until an optimally chosen Azema-Yor time, with a general spectrally negative Markov model. While previously studied cases of this problem assumed either Lévy or diffusion models, and the draw-down function to be fixed, we describe, for a general spectrally negative Markov model, not only the optimal barrier but also the optimal draw-down function. This is achieved by solving a variational problem tackled by Pontryaghin's maximum principle. As a by-product we show that in the Lévy case the classic first passage solution is indeed optimal; in the diffusion case, we obtain the optimality equations, but the behavior of associated solutions for further explicit models and the question of whether they do better than the classic solution is left for future work. Instead, we illustrate the novelty by a toy example, with a conveniently chosen scale-like function."
"F. D. Luca, Md. Iqbal Hossain, S. Kobourov, A. Lubiw, Debajyoti Mondal",f92f9b2eeb03424a71a81ac8ae29066556472e45,Recognition and Drawing of Stick Graphs,Graph Drawing,2018.0,5,"A Stick graph is an intersection graph of axis-aligned segments such that the left end-points of the horizontal segments and the bottom end-points of the vertical segments lie on a “ground line”, a line with slope \(-1\). It is an open question to decide in polynomial time whether a given bipartite graph G with bipartition \(A\cup B\) has a Stick representation where the vertices in A and B correspond to horizontal and vertical segments, respectively. We prove that G has a Stick representation if and only if there are orderings of A and B such that G’s bipartite adjacency matrix with rows A and columns B excludes three small ‘forbidden’ submatrices. This is similar to characterizations for other classes of bipartite intersection graphs."
"Denys J. C. Matthies, Laura Milena Daza Parra, B. Urban",e487b02cc3f308ba1001b184b47258bd64deeced,Scaling Notifications Beyond Alerts: From Subtly Drawing Attention up to Forcing the User to Take Action,UIST,2018.0,5,"Research has been done in sophisticated notifications, still, devices today mainly stick to a binary level of information, while they are either attention drawing or silent. We propose scalable notifications, which adjust the intensity level reaching from subtle to obtrusive and even going beyond that level while forcing the user to take action. To illustrate the technical feasibility and validity of this concept, we developed three prototypes. The prototypes provided mechano-pressure, thermal, and electrical feedback, which were evaluated in different lab studies. Our first prototype provides subtle poking through to high and frequent pressure on the user's spine, which significantly improves back posture. In a second scenario, the user is able to perceive the overuse of a drill by an increased temperature on the palm of a hand until the heat is intolerable, forcing the user to eventually put down the tool. The last application comprises of a speed control in a driving simulation, while electric muscle stimulation on the users' legs, conveys information on changing the car's speed by a perceived tingling until the system forces the foot to move involuntarily. In conclusion, all studies' findings support the feasibility of our concept of a scalable notification system, including the system forcing an intervention."
"Z. Bhatti, Ahsanullah Abro, Abdul Rehman Gillal, M. Karbasi",20832d12651c23f3854eac81ad4389b9e14bdbd9,Be-Educated: Multimedia Learning through 3D Animation,ArXiv,2018.0,5,"Multimedia learning tools and techniques are placing its importance with large scale in education sector. With the help of multimedia learning, various complex phenomenon and theories can be explained and taught easily and conveniently. This project aims to teach and spread the importance of education and respecting the tools of education: pen, paper, pencil, rubber. To achieve this cognitive learning, a 3D animated movie has been developed using principles of multimedia learning with 3D cartoon characters resembling the actual educational objects, where the buildings have also been modelled to resemble real books and diaries. For modelling and animation of these characters, polygon mesh tools are used in 3D Studio Max. Additionally, the final composition of video and audio is performed in adobe premiere. This 3D animated video aims to highlight a message of importance for education and stationary. The Moral of movie is that do not waste your stationary material, use your Pen and Paper for the purpose they are made for. To be a good citizen you have to Be-Educated yourself and for that you need to give value to Pen. The final rendered and composited 3D animated video reflects this moral and portrays the intended message with very vibrant visuals"
II. O Verview,172855949a669fd6d5f8049f1a8ec6f7614cbccd,Redundant structure detection in attributed adjacency graphs for character detection in comics books,,2018.0,5,"Graphs are popular data structures used to model pair wise relations between elements from a given collection. In image processing, adjacency graphs are often used to represent the relations between segmented regions. Such graphs can be compared but graph matching strategies are essential to find similar patterns. In this paper, we propose to detect the recurrent characters of a comics book. In this method each panel is represented with an attributed adjacency graph. Then, an inexact graph matching strategy is applied to find redundant structures among this set of graphs. The main idea is that the same character will be represented by similar subgraphs in the different panels where it appears. The two-step matching process consists in a node matching step and an edge validation step. Experiments show that our approach is able to detect redundant structures in the graph and consequently the recurrent characters in a comics book. The originality of our approach is that no model is required, the algorithm detects all by itself all redundant structures. Keywords—Comics, character detection, attributed adjacency graph, graph comparison, graph matching, spatial relation"
"Tu Bui, L. Ribeiro, M. Ponti, J. Collomosse",f8ea16db66904733f8e5dda96cf73f524b13dac2,Deep Manifold Alignment for Mid-Grain Sketch Based Image Retrieval,ACCV,2018.0,4,"We present an algorithm for visually searching image collections using free-hand sketched queries. Prior sketch based image retrieval (SBIR) algorithms adopt either a category-level or fine-grain (instance-level) definition of cross-domain similarity—returning images that match the sketched object class (category-level SBIR), or a specific instance of that object (fine-grain SBIR). In this paper we take the middle-ground; proposing an SBIR algorithm that returns images sharing both the object category and key visual characteristics of the sketched query without assuming photo-approximate sketches from the user. We describe a deeply learned cross-domain embedding in which ‘mid-grain’ sketch-image similarity may be measured, reporting on the efficacy of unsupervised and semi-supervised manifold alignment techniques to encourage better intra-category (mid-grain) discrimination within that embedding. We propose a new mid-grain sketch-image dataset (MidGrain65c) and demonstrate not only mid-grain discrimination, but also improved category-level discrimination using our approach."
"Xianlin Zhang, Xueming Li, Xuewei Li, Mengling Shen",42cf916d7e5547879c4d9b19d0bedb635d793760,Better freehand sketch synthesis for sketch-based image retrieval: Beyond image edges,Neurocomputing,2018.0,4,"Abstract With the rapid development of electronic touch screen and pressure-sensing devices, research on freehand sketches has become a hotspot in recent years. In this paper, we first propose a new freehand sketch generation model (FHS-GAN), which is based on the deep architecture of dual generative adversarial nets (GANs). We construct a model which utilize the deep convolutional neural network (CNN) and GAN to produce freehand sketches. We then propose an improved deep CNN model as a validated network, which is based on Faster R-CNN, to measure the similarity of real sketches and generated freehand sketches by FHS-GAN, and we test the improved model using the produced sketches with two large sketch datasets. The experiments show that the proposed FHS-GAN framework achieves state-of-the-art results in comparison with other baseline models. Furthermore, the generated sketches can be used for other sketch recognition tasks, such as in a pre-processing step for application in sketch-based image retrieval (SBIR) and fine-grained sketch-based image retrieval (FG-SBIR). Overall, our FHS-GAN model is important for the development of freehand sketches."
"W. Chu, Chih-Chi Yu",f5a1eba14297ae3ccb10e1a6df8fb692f2175a9b,"Text Detection in Manga by Deep Region Proposal, Classification, and Regression",2018 IEEE Visual Communications and Image Processing (VCIP),2018.0,4,"Text in manga presents high variations and different contextual information, and existing scene text detection methods are not directly applicable. We propose two approaches based on deep networks to detect text in manga. In the first approach, features extracted from multiple CNNs are joined and then fed to a combination of a classification network and a regression network. In the second approach, region proposal, feature extraction, and classification/regression, are taken together in a single deep network. The evaluation results show that the first approach achieves performance comparable to the current state of the art, while the second approach yields a big performance leap over existing ones."
"Kaiyue Pang, Da Li, Jifei Song, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",d5513092b33717ac60d8ee5b3e8b11b342d6df95,Deep Factorised Inverse-Sketching,ECCV,2018.0,4,"Modelling human free-hand sketches has become topical recently, driven by practical applications such as fine-grained sketch based image retrieval (FG-SBIR). Sketches are clearly related to photo edge-maps, but a human free-hand sketch of a photo is not simply a clean rendering of that photo’s edge map. Instead there is a fundamental process of abstraction and iconic rendering, where overall geometry is warped and salient details are selectively included. In this paper we study this sketching process and attempt to invert it. We model this inversion by translating iconic free-hand sketches to contours that resemble more geometrically realistic projections of object boundaries, and separately factorise out the salient added details. This factorised re-representation makes it easier to match a free-hand sketch to a photo instance of an object. Specifically, we propose a novel unsupervised image style transfer model based on enforcing a cyclic embedding consistency constraint. A deep FG-SBIR model is then formulated to accommodate complementary discriminative detail from each factorised sketch for better matching with the corresponding photo. Our method is evaluated both qualitatively and quantitatively to demonstrate its superiority over a number of state-of-the-art alternatives for style transfer and FG-SBIR."
"Sitao Xiang, Hao Li",f8d1c807960decf887f533b862a16ec2512413e8,Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks,ArXiv,2018.0,4,"Deep learning-based style transfer between images has recently become a popular area of research. A common way of encoding ""style"" is through a feature representation based on the Gram matrix of features extracted by some pre-trained neural network or some other form of feature statistics. Such a definition is based on an arbitrary human decision and may not best capture what a style really is. In trying to gain a better understanding of ""style"", we propose a metric learning-based method to explicitly encode the style of an artwork. In particular, our definition of style captures the differences between artists, as shown by classification performances, and such that the style representation can be interpreted, manipulated and visualized through style-conditioned image generation through a Generative Adversarial Network. We employ this method to explore the style space of anime portrait illustrations."
"Vatsal Sharan, P. Gopalan, U. Wieder",281d048689bad12d8dce8316a61c31b15c6f50de,Efficient Anomaly Detection via Matrix Sketching,NeurIPS,2018.0,4,"We consider the problem of finding anomalies in high-dimensional data using popular PCA based anomaly scores. The naive algorithms for computing these scores explicitly compute the PCA of the covariance matrix which uses space quadratic in the dimensionality of the data. We give the first streaming algorithms that use space that is linear or sublinear in the dimension. We prove general results showing that \emph{any} sketch of a matrix that satisfies a certain operator norm guarantee can be used to approximate these scores. We instantiate these results with powerful matrix sketching techniques such as Frequent Directions and random projections to derive efficient and practical algorithms for these problems, which we validate over real-world data sets. Our main technical contribution is to prove matrix perturbation inequalities for operators arising in the computation of these measures."
"F. Mémoli, Anastasios Sidiropoulos, Kritika Singhal",0470570b663520ab4914fe2dbcb211bf30106e25,Sketching and Clustering Metric Measure Spaces,ArXiv,2018.0,4,"Two important optimization problems in the analysis of geometric data sets are clustering and sketching. Here, clustering refers to the problem of partitioning some input metric measure space (mm-space) into $k$ clusters, minimizing some objective function $f$. Sketching, on the other hand, is the problem of approximating some mm-space by a smaller one supported on a set of $k$ points. Specifically, we define the $k$-sketch of some mm-space $M$ to be the nearest neighbor of $M$ in the set of $k$-point mm-spaces, under some distance function $\rho$ on the set of mm-spaces. 
In this paper, we demonstrate a duality between general classes of clustering and sketching problems. We present a general method for efficiently transforming a solution for a clustering problem to a solution for a sketching problem, and vice versa, with approximately equal cost. More specifically, we obtain the following results. We define the sketching/clustering gap to be the supremum over all mm-spaces of the ratio of the sketching and clustering objectives. 
1. For metric spaces, we consider the case where $f$ is the maximum cluster diameter, and $\rho$ is the Gromov-Hausdorff distance. We show that the gap is constant for any compact metric space. 
2. We extend the above results to obtain constant gaps for the case of mm-spaces, where $\rho$ is the $p$-Gromov-Wasserstein distance and the clustering objective involves minimizing various notions of the $\ell_p$-diameters of the clusters. 
3. We consider two competing notions of sketching for mm-spaces, with one of them being more demanding than the other. These notions arise from two different definitions of $p$-Gromov-Wasserstein distance that have appeared in the literature. We then prove that whereas the gap between these can be arbitrarily large, in the case of doubling metric spaces the resulting sketching objectives are polynomially related."
"G. Liu, Xin Chen, Y. Hu",4a44a2924ecdfc6ca4c5e6813a88e18e2d163493,Anime Sketch Coloring with Swish-Gated Residual U-Net,,2018.0,4,"Anime sketch coloring is to fill the color into the anime sketches to obtain the colorful anime images and it is a new research direction in deep learning technology. Currently, generative adversarial networks (GANs) have been used for anime sketch coloring and achieved some results. However, the colorful images generated by the anime sketch coloring methods based on GANs generally have poor coloring effects. In this paper, an efficient anime sketch coloring method based on swish-gated residual U-net (SGRU) is proposed to solve the above problems. In SGRU, the proposed swish layer and swish-gated residual blocks (SGRBs) effectively filter the information transmitted by each level and speed up the convergence of the network. The perceptual loss and the per-pixel loss are used to constitute the final loss of SGRU. The final loss function reflects the coloring results more realistically and can control the effect of coloring more effectively. SGRU can automatically color the sketch without providing any coloring hints in advance and can be trained end-to-end with the sketch and the corresponding color image. Experimental results show that our method performs better than other state-of-the-art coloring methods, and can achieve the colorful images with higher visual quality."
"Zhenxue Chen, Saisai Yao, Yunyi Jia, Chengyun Liu",91c4fdc7e4a3a4a0160ab939f9db76b0ec0e8fe0,Face sketch-photo synthesis and recognition: Dual-scale Markov Network and multi-information fusion,J. Vis. Commun. Image Represent.,2018.0,3,"Abstract Sketch face recognition (SFR) has been widely and successfully applied in law enforcement, which attracts a growing number of researchers. In this paper, a face sketch-photo synthesis and recognition method is proposed. Our method has two parts: Firstly, according to the different synthesis results for different scales, a cascade sketch-photo synthesis method via dual-scale Markov Network is utilized for image synthesis; Secondly, structural information and feature information-based data fusion method has been presented for face recognition. It is inspired by the Face Recognition Cognitive Theory, which applies both structural information and feature information for recognition. The experimental results on different databases based on the proposed method, demonstrate the outperformance of our method compared with state-of-the-art methods both in synthesis and recognition processes."
"Junhong Huang, Mingkui Tan, Yuguang Yan, C. Qing, Qingyao Wu, Zhu Liang Yu",4f10a7697fb2a2c626d1190db2afba83c4ffe856,Cartoon-to-Photo Facial Translation with Generative Adversarial Networks,ACML,2018.0,3,"Cartoon-to-photo facial translation could be widely used in different applications, such as law enforcement and anime remaking. Nevertheless, current general-purpose imageto-image models usually produce blurry or unrelated results in this task. In this paper, we propose a Cartoon-to-Photo facial translation with Generative Adversarial Networks (CP-GAN) for inverting cartoon faces to generate photo-realistic and related face images. In order to produce convincing faces with intact facial parts, we exploit global and local discriminators to capture global facial features and three local facial regions, respectively. Moreover, we use a specific content network to capture and preserve face characteristic and identity between cartoons and photos. As a result, the proposed approach can generate convincing high-quality faces that satisfy both the characteristic and identity constraints of input cartoon faces. Compared with recent works on unpaired image-to-image translation, our proposed method is able to generate more realistic and correlative images."
"Ameya Prabhu, Vishal Batchu, Sri Aurobindo Munagala, Rohit Gajawada, A. Namboodiri",cb7b53518eae06163716253421c1f40e07367613,Distribution-Aware Binarization of Neural Networks for Sketch Recognition,2018 IEEE Winter Conference on Applications of Computer Vision (WACV),2018.0,3,"Deep neural networks are highly effective at a range of computational tasks. However, they tend to be computationally expensive, especially in vision-related problems, and also have large memory requirements. One of the most effective methods to achieve significant improvements in computational/spatial efficiency is to binarize the weights and activations in a network. However, naive binarization results in accuracy drops when applied to networks for most tasks. In this work, we present a highly generalized, distribution-aware approach to binarizing deep networks that allows us to retain the advantages of a binarized network, while reducing accuracy drops. We also develop efficient implementations for our proposed approach across different architectures. We present a theoretical analysis of the technique to show the effective representational power of the resulting layers, and explore the forms of data they model best. Experiments on popular datasets show that our technique offers better accuracies than naive binarization, while retaining the same benefits that binarization provides - with respect to run-time compression, reduction of computational costs, and power consumption."
"Mahrukh Khan, M. Tahir, Zeeshan Ahmed",b15f32556ae12012cc47e8c0b7bcaed069b5cc3c,Detection of Violent Content in Cartoon Videos Using Multimedia Content Detection Techniques,2018 IEEE 21st International Multi-Topic Conference (INMIC),2018.0,3,"Children are the most vulnerable to ideas presented in Cartoon videos and TV. Cartoons have become one of the most important source of entertainment, but it also introduce a lot of ideas that are not suitable for them. Violence is one of the unwanted feature that is prevalent in cartoons to put element of fantasy and enchantment. In order to stop children from viewing violent intense cartoons, the best strategy is to make them inaccessible. Therefore, some sort of filters should be placed at certain hubs to perform this task. The challenge is that how a filter will know that a particular cartoon video has violent content in it. The meta-data telling the world about the video does not inform that the video consists of violent material. Certain frames/snapshots/images of video, if analyzed using image processing techniques, can help in concluding that a particular video has intense material in it. The aim of this work is to classify social media videos especially related to animated cartoons with violent / nonviolent behaviors. It addresses the problem of content based image matching algorithms based on key point descriptors. The basic goal is to extract general information from an image without any specific query. First SIFT-descriptors are extracted from a large set of images. This set of descriptors are then defined as a means of providing fast and accurate comparisons between images and distinguish between violent and nonviolent images in combination with Machine Learning algorithms. The results are then compared for each classifier with varying parameters."
"D. Stark, K. Bundy, K. Westfall, M. Bershady, A. Weijmans, K. Masters, S. Kruk, J. Brinchmann, J. Soler, R. Abraham, E. Cheung, D. Bizyaev, N. Drory, A. R. Lopes, D. Law",cbfbec9c0d6160d34c2b27fec642491f85d5a1b2,SDSS IV MaNGA: characterizing non-axisymmetric motions in galaxy velocity fields using the radon transform,,2018.0,3,"We show how the Radon transform (defined as a series of line integrals through an image at different orientations and offsets from the origin) can be used as a simple, non-parametric tool to characterize galaxy velocity fields, specifically their global kinematic position angles (PA_k) and any radial variation or asymmetry in PA_k. This method is fast and easily automated, making it particularly beneficial in an era where IFU and interferometric surveys are yielding samples of thousands of galaxies. We demonstrate the Radon transform by applying it to gas and stellar velocity fields from the first ~2800 galaxies of the SDSS-IV MaNGA IFU survey. We separately classify gas and stellar velocity fields into five categories based on the shape of their radial PA_k profiles. At least half of stellar velocity fields and two-thirds of gas velocity fields are found to show detectable deviations from uniform coplanar circular motion, although most of these variations are symmetric about the center of the galaxy. The behavior of gas and stellar velocity fields is largely independent, even when PA_k profiles for both components are measured over the same radii. We present evidence that one class of symmetric PA_k variations is likely associated with bars and/or oval distortions, while another class is more consistent with warped disks. This analysis sets the stage for more in-depth future studies which explore the origin of diverse kinematic behavior in the galaxy population."
N. Keriven,8ad17a40587021cd250890135d54defb33c70534,SketchMLbox -- A MATLAB toolbox for large-scale mixture learning,,2018.0,2,"The SketchMLbox is a Matlab toolbox for fitting mixture models to large databases using sketching techniques. 
The database is first compressed into a vector called sketch, then a mixture model (e.g. a Gaussian Mixture Model) is estimated from this sketch using greedy algorithms typical of sparse recovery. 
The size of the sketch does not depend on the number of elements in the database, but rather on the complexity of the problem at hand [2,3]. Its computation can be massively parallelized and distributed over several units. It can also be maintained in an online setting at low cost. 
 
Mixtures of Diracs (""K-means"") and Gaussian Mixture Models with diagonal covariance are currently available, the toolbox is structured so that new mixture models can be easily implemented. 
 
 Details can be found in the following papers: 
[1] Keriven N., Bourrier A., Gribonval R., Perez P., ""Sketching for Large-Scale Learning of Mixture Models"", ICASSP 2016. 
[2] Keriven N., Bourrier A., Gribonval R., Perez P., ""Sketching for Large-Scale Learning of Mixture Models"", 2016. arXiv:1606.02838 (extended version) 
[3] Keriven N., Tremblay N., Traonmilin Y., Gribonval R., ""Compressive K-means"", ICASSP 2017. 
[4] Gribonval R., Blanchard G., Keriven N., Traonmilin Y., ""Compressive Statistical Learning with Random Feature Moments"", 2017. arXiv:1706.07180."
"Yi Han, Jun He, Qiwen Dong",03c2948ed2591c35b92325485a79120e5ec1d9ac,CSSSketch2Code: An Automatic Method to Generate Web Pages with CSS Style,ICAAI 2018,2018.0,2,"With the constantly increasing scale of the Internet and the users, the Internet applications have higher demands on the front-end web pages. Some web pages have single lattice structure and a relatively fixed HTML code template, which can be automatically generated. There have been research abroad using the deep learning on the task of automatically generating the web pages. However due to the basic encoder-decoder model adopted, the generalization ability of the model is not very robust. In this paper, we propose a novel method based on object detection and attention mechanism to automatically generate a web page with CSS style information. We use object detection to extend the original problem, which makes the model possible to detect the CSS style contents in the web page. Meanwhile we use attention mechanism to strengthen the model. Finally we propose our own dataset, based on which the experiment results show that method we proposed outperforms other existing methods."
"Fevziye Irem Eyiokur, Dogucan Yaman, H. K. Ekenel",b8e92e5f9482cf9296e5728462d444ebd01d186c,Sketch classification with deep learning models,2018 26th Signal Processing and Communications Applications Conference (SIU),2018.0,2,"Sketch classification problem is challenging due to several reasons, such as absence of color and texture information, lack of detailed information of objects, and the quality, which depends on drawing ability of the person. In this study, sketch classification problem is addressed by using deep convolutional neural network models. Specifically, the effect of domain adaptation is examined, when fine-tuning the convolutional neural networks for sketch classification. By employing domain adaptation, the classification accuracy is increased by around 3%. The proposed system, which utilizes VGG-16 network model and performs two-stage fine-tuning, outperforms the previous state-of-the-art approaches on the TU Berlin sketch dataset by reaching 79,72% accuracy."
"Anand Mishra, A. Singh",6175dd4ffe47e3b95658a6f7a0c49e914de4d4c2,Deep Embedding using Bayesian Risk Minimization with Application to Sketch Recognition,ACCV,2018.0,2,"In this paper, we address the problem of hand-drawn sketch recognition. Inspired by the Bayesian decision theory, we present a deep metric learning loss with the objective to minimize the Bayesian risk of misclassification. We estimate this risk for every mini-batch during training, and learn robust deep embeddings by backpropagating it to a deep neural network in an end-to-end trainable paradigm. Our learnt embeddings are discriminative and robust despite of intra-class variations and inter-class similarities naturally present in hand-drawn sketch images. Outperforming the state of the art on sketch recognition, our method achieves 82.2% and 88.7% on TU-Berlin-250 and TU-Berlin-160 benchmarks respectively."
"Anne Morvan, Krzysztof Choromanski, C. Gouy-Pailler, J. Atif",de486bf96bc1af73bac1cb8abd49e38c5c598a52,Graph sketching-based Space-efficient Data Clustering,SDM,2018.0,2,"In this paper, we address the problem of recovering arbitrary-shaped data clusters from datasets while facing \emph{high space constraints}, as this is for instance the case in many real-world applications when analysis algorithms are directly deployed on resources-limited mobile devices collecting the data. We present DBMSTClu a new space-efficient density-based \emph{non-parametric} method working on a Minimum Spanning Tree (MST) recovered from a limited number of linear measurements i.e. a \emph{sketched} version of the dissimilarity graph $\mathcal{G}$ between the $N$ objects to cluster. Unlike $k$-means, $k$-medians or $k$-medoids algorithms, it does not fail at distinguishing clusters with particular forms thanks to the property of the MST for expressing the underlying structure of a graph. No input parameter is needed contrarily to DBSCAN or the Spectral Clustering method. An approximate MST is retrieved by following the dynamic \emph{semi-streaming} model in handling the dissimilarity graph $\mathcal{G}$ as a stream of edge weight updates which is sketched in one pass over the data into a compact structure requiring $O(N \operatorname{polylog}(N))$ space, far better than the theoretical memory cost $O(N^2)$ of $\mathcal{G}$. The recovered approximate MST $\mathcal{T}$ as input, DBMSTClu then successfully detects the right number of nonconvex clusters by performing relevant cuts on $\mathcal{T}$ in a time linear in $N$. We provide theoretical guarantees on the quality of the clustering partition and also demonstrate its advantage over the existing state-of-the-art on several datasets."
"P. Chikontwe, H. J. Lee",5123b32cde11a2a784c8789676652545adc6aee3,Towards Robust Face Sketch Synthesis with Style Transfer Algorithms,,2018.0,1,"We propose an approach for face sketch synthesis by employing deep image transformations using an artistic style transfer algorithm. Face sketch synthesis remains an area of great interest in the research community as well as its applications in law enforcement towards face recognition. Recent methods for this problem typically employ traditional approaches to synthesize face sketches to digital images. However, most approaches are gradually shifting towards convolutional neural networks for robust feature learning and image transformations. In this paper, we propose an approach that uses recent artistic style transfer algorithms for face sketch synthesis. Additionally, we show that poorly synthesized images can be improved with a denoising autoencoder for better facial feature reconstruction. Further, the approach is extended to perform face verification of heterogeneous image samples to assess the effectiveness of the proposed approach and gives a better view into the potential applications for styling algorithms for face image synthesis and transformation problems alike."
"Peng Lu, Hangyu Lin, Yanwei Fu, S. Gong, Yugang Jiang, X. Xue",4893ce89df7afde71534af9b9fd5becb947f112e,Instance-level Sketch-based Retrieval by Deep Triplet Classification Siamese Network,ArXiv,2018.0,1,"Sketch has been employed as an effective communicative tool to express the abstract and intuitive meanings of object. Recognizing the free-hand sketch drawing is extremely useful in many real-world applications. While content-based sketch recognition has been studied for several decades, the instance-level Sketch-Based Image Retrieval (SBIR) tasks have attracted significant research attention recently. The existing datasets such as QMUL-Chair and QMUL-Shoe, focus on the retrieval tasks of chairs and shoes. However, there are several key limitations in previous instance-level SBIR works. The state-of-the-art works have to heavily rely on the pre-training process, quality of edge maps, multi-cropping testing strategy, and augmenting sketch images. To efficiently solve the instance-level SBIR, we propose a new Deep Triplet Classification Siamese Network (DeepTCNet) which employs DenseNet-169 as the basic feature extractor and is optimized by the triplet loss and classification loss. Critically, our proposed DeepTCNet can break the limitations existed in previous works. The extensive experiments on five benchmark sketch datasets validate the effectiveness of the proposed model. Additionally, to study the tasks of sketch-based hairstyle retrieval, this paper contributes a new instance-level photo-sketch dataset - Hairstyle Photo-Sketch dataset, which is composed of 3600 sketches and photos, and 2400 sketch-photo pairs."
"Di Sun, Jiawan Zhang, Rui Zhan, Shichao Jia",6c15140654c934fe87483e6e8fa94c83e8d90c71,Line Drawing Extraction and Computer Aided Copying for Dunhuang Frescoes,,2018.0,1,
"Ting Han, Sina Zarrieß, Kazunori Komatani, D. Schlangen",76d6db0986ac0d68f21960835c3da9ab38367e07,Learning to Describe Multimodally from Parallel Unimodal Data ? A Pilot Study on Verbal and Sketched Object Descriptions,,2018.0,1,"Previous work on multimodality in interaction has mostly focussed on integrating models for verbal utterances and embodied modalities like gestures. In this paper, we take a first step towards investigating multimodal interaction that combines verbal utterances and hand-drawn sketches which can be essential, for instance, for conveying explanation in dialogue. While there is a lot of theoretical work on how drawing and sketching convey iconic meaning, there is no realistic data set that pairs language and sketch as integrated modalities. Recently, the Draw-and-Tell corpus enriched a pre-existing dataset (the “Sketchy Dataset”) with verbal descriptions of the sketched images. We base our study on this corpus and implement two models that learn to generate simple verbal and sketched object descriptions in a parallel fashion. We evaluated our models in unimodal and multimodal object identification tasks with human listeners via crowd-sourcing experiments. The results show that partial hand-drawn sketches clearly improve the effectiveness of verbal descriptions, even if the generator did not coordinate their meanings. Interestingly, we also find that unimodal sketched object descriptions outperform multimodal descriptions. We argue that this highlights the great potential of sketched explanations for multimodal interaction, but at the same time, shows the need for more natural data sets that provide insights into the orchestration of verbal and sketched elements in multimodal descriptions."
"Jinning Li, Siqi Liu, Mengyao Cao",2e4b56eea27c8fb7ab5bf777a653d38a2b7b35b8,Line Artist: A Multiple Style Sketch to Painting Synthesis Scheme,ArXiv,2018.0,1,"Drawing a beautiful painting is a dream of many people since childhood. In this paper, we propose a novel scheme, Line Artist, to synthesize artistic style paintings with freehand sketch images, leveraging the power of deep learning and advanced algorithms. Our scheme includes three models. The Sketch Image Extraction (SIE) model is applied to generate the training data. It includes smoothing reality images and pencil sketch extraction. The Detailed Image Synthesis (DIS) model trains a conditional generative adversarial network to generate detailed real-world information. The Adaptively Weighted Artistic Style Transfer (AWAST) model is capable to combine multiple style images with a content with the VGG19 network and PageRank algorithm. The appealing artistic images are then generated by optimization iterations. Experiments are operated on the Kaggle Cats dataset and The Oxford Buildings Dataset. Our synthesis results are proved to be artistic, beautiful and robust."
"L. Anderlucci, Roberta Falcone, A. Montanari",c4ce01c03f946ce2988fe04f6e55939611684520,Supervised Classification with Matrix Sketching,,2018.0,1,"Matrix sketching is a recently developed data compression technique. An input matrix A is efficiently approximated with a smaller matrix B, so that B preserves most of the properties of A up to some guaranteed approximation ratio. In so doing numerical operations on big data sets become faster. Sketching algorithms generally use random projections to compress the original dataset and this stochastic generation process makes them amenable to statistical analysis. The statistical properties of sketched regression algorithms have been widely studied previously. We study the performances of sketching algorithms in the supervised classification context, both in terms of misclassification rate and of boundary approximation, as the degree of sketching increases. We also address, through sketching, the issue of unbalanced classes, which hampers most of the common classification methods."
"Yue Zhong, Honggang Zhang, Jun Guo, Yi-Zhe Song",0b6d2f68ef9530dce0529beac64904da52282476,Directional Element HOG for Sketch Recognition,2018 International Conference on Network Infrastructure and Digital Content (IC-NIDC),2018.0,1,"We propose a novel Directional Element Histogram of Oriented Gradient (DE-HOG) feature to human free-hand sketch recognition task that achieves superior performance to traditional HOG feature, originally designed for photographic objects. As a result of modeling the unique characteristics of free-hand sketch, i.e. consisting only a set of strokes omitting visual information such as color and brightness, being highly iconic and abstract. Specifically, we encode sketching strokes as a form of regularized directional vectors from the skeleton of a sketch, whilst still leveraging the HOG feature to meet the local deformation-invariant demands. Such a representation combines the best of two features by encoding necessary and discriminative stroke-level information, but can still robustly deal with various levels of sketching variations. Extensive experiments conducted on two large benchmark sketch recognition datasets demonstrate the performance of our proposed method."
"Maciej Pesko, T. Trzciński",26fa3d9b589ca1d8c5dc5a10a5766bb172b096ab,Neural Comic Style Transfer: Case Study,ArXiv,2018.0,1,"The work by Gatys et al. [1] recently showed a neural style algorithm that can produce an image in the style of another image. Some further works introduced various improvements regarding generalization, quality and efficiency, but each of them was mostly focused on styles such as paintings, abstract images or photo-realistic style. In this paper, we present a comparison of how state-of-the-art style transfer methods cope with transferring various comic styles on different images. We select different combinations of Adaptive Instance Normalization [11] and Universal Style Transfer [16] models and confront them to find their advantages and disadvantages in terms of qualitative and quantitative analysis. Finally, we present the results of a survey conducted on over 100 people that aims at validating the evaluation results in a real-life application of comic style transfer."
"K. M. A. Sultan, Labiba Rupty, Nahidul Islam Pranto, Sayed Khan Shuvo, M. Jubair",04deae25fc49ed3cbe1a36faef8c0e5bcb5d9a35,Cartoon-to-real: An Approach to Translate Cartoon to Realistic Images using GAN,ArXiv,2018.0,1,"We propose a method to translate cartoon images to real world images using Generative Aderserial Network (GAN). Existing GAN-based image-to-image translation methods which are trained on paired datasets are impractical as the data is difficult to accumulate. Therefore, in this paper we exploit the Cycle-Consistent Adversarial Networks (CycleGAN) method for images translation which needs an unpaired dataset. By applying CycleGAN we show that our model is able to generate meaningful real world images from cartoon images. However, we implement another state of the art technique $-$ Deep Analogy $-$ to compare the performance of our approach."
"Jessica De Silva, Brady Gales, Bryson Kagy, David Offner",63e12638ed05fe2c67dae0ce7a11be89b2e80458,An analysis of a fair division protocol for drawing legislative districts,,2018.0,1,"Landau, Reid, and Yershov [A Fair Division Solution to the Problem of Redistricting, \textit{Social Choice and Welfare}, 2008] propose a protocol for drawing legislative districts based on a two player fair division process, where each player is entitled to draw the districts for a portion of the state. We call this the \textit{LRY protocol}. Landau and Su [Fair Division and Redistricting, arXiv:1402.0862, 2014] propose a measure of the fairness of a state's districts called the \textit{geometric target}. In this paper we prove that the number of districts a party can win under the LRY protocol can be at most two fewer than their geometric target, assuming no geometric constraints on the districts, and provide examples to prove this bound is tight. We also show that if the LRY protocol is applied on a state with geometric constraints, the result can be arbitrarily far from the geometric target."
"P. Eades, P. Healy, Nikola S. Nikolov",b52e97108fad3f2e3f80e4701246ff09941572ea,The Weighted Barycenter Drawing Recognition Problem,Graph Drawing,2018.0,1,"We consider the question of whether a given graph drawing \(\varGamma \) of a triconnected planar graph G is a weighted barycenter drawing. We answer the question with an elegant arithmetic characterisation using the faces of \(\varGamma \). This leads to positive answers when the graph is a Halin graph, and to a polynomial time recognition algorithm when the graph is cubic."
"Sanghyun Choi, Nikita Ivkin, Vladimir Braverman, M. Jacobs",8535b1076a8991bb23df467cf09ac467538f7e28,DreamNLP: Novel NLP System for Clinical Report Metadata Extraction using Count Sketch Data Streaming Algorithm: Preliminary Results,ArXiv,2018.0,1,"Extracting information from electronic health records (EHR) is a challenging task since it requires prior knowledge of the reports and some natural language processing algorithm (NLP). With the growing number of EHR implementations, such knowledge is increasingly challenging to obtain in an efficient manner. We address this challenge by proposing a novel methodology to analyze large sets of EHRs using a modified Count Sketch data streaming algorithm termed DreamNLP. By using DreamNLP, we generate a dictionary of frequently occurring terms or heavy hitters in the EHRs using low computational memory compared to conventional counting approach other NLP programs use. We demonstrate the extraction of the most important breast diagnosis features from the EHRs in a set of patients that underwent breast imaging. Based on the analysis, extraction of these terms would be useful for defining important features for downstream tasks such as machine learning for precision medicine."
"Wenbin Li, Jing Huo, Y. Shi, Y. Gao, Lei Wang, Jiebo Luo",bb43b707612d55e888052ba5b787a19f5c0fa602,A Joint Local and Global Deep Metric Learning Method for Caricature Recognition,ACCV,2018.0,1,"Caricature recognition is a novel, interesting, yet challenging problem. Due to the exaggeration and distortion, there is a large cross-modal gap between photographs and caricatures, making it nontrivial to match the features of photographs and caricatures. To address the problem, a joint local and global metric learning method (LGDML) is proposed. First, joint local and global feature representation is learnt with convolutional neural networks to find both discriminant features of local facial parts and global distinctive features of the whole face. Next, in order to fuse the local and global similarities of features, a unified feature representation and similarity measure learning framework is proposed. Various methods are evaluated on the caricature recognition task. We have verified that both local and global features are crucial for caricature recognition. Moreover, experimental results show that, compared with the state-of-the-art methods, LGDML can obtain superior performance in terms of Rank-1 and Rank-10."
"Levi Offen, M. Werman",5ed29a8d37e82c78285256eea2ba481d1df347b5,Sketch Based Reduced Memory Hough Transform,2018 25th IEEE International Conference on Image Processing (ICIP),2018.0,0,"This paper proposes using sketch algorithms to represent the votes in Hough transforms. Replacing the accumulator array with a sketch (Sketch Hough Transform - SHT) significantly reduces the memory needed to compute a Hough transform. We also present a new sketch, Count Median Update, which works better than known sketch methods for replacing the accumulator array in the Hough Transform."
"Jinwei Lin, Aimin Zhou",3a6b17dafe37635f1b6cd782c18cfb4f407ad5af,PyDraw: a GUI drawing generator based on Tkinter and its design concept,ArXiv,2018.0,0,"The emergence of GUI is a great progress in the history of computer science and software design. GUI makes human computer interaction more simple and interesting. Python, as a popular programming language in recent years, has not been realized in GUI design. Tkinter has the advantage of native support for Python, but there are too few visual GUI generators supporting Tkinter. This article presents a GUI generator based on Tkinter framework, PyDraw. The design principle of PyDraw and the powerful design concept behind it are introduced in detail. With PyDraw's GUI design philosophy, it can easily design a visual GUI rendering generator for any GUI framework with canvas functionality or programming language with screen display control. This article is committed to conveying PyDraw's GUI free design concept. Through experiments, we have proved the practicability and efficiency of PyDrawd. In order to better convey the design concept of PyDraw, let more enthusiasts join PyDraw update and evolution, we have the source code of PyDraw. At the end of the article, we summarize our experience and express our vision for future GUI design. We believe that the future GUI will play an important role in graphical software programming, the future of less code or even no code programming software design methods must become a focus and hot, free, like drawing GUI will be worth pursuing."
"M. Rahmani, Adel Karimian, Andre Beckus, George K. Atia",79d83006d2865047b66565b5dd42e3ca102f7366,Randomized Robust matrix Completion for the Community Detection Problem,"2018 52nd Asilomar Conference on Signals, Systems, and Computers",2018.0,0,"This paper focuses on the unsupervised clustering of large partially observed graphs. We propose a provable randomized framework in which a clustering algorithm is applied to a graph’s adjacency matrix generated from a stochastic block model. A sub-matrix is constructed using random sampling, and the low rank component is found using a convex-optimization-based matrix completion algorithm. The clusters are then identified based on this low rank component using a correlation-based retrieval step. Additionally, a new random node sampling algorithm is presented which significantly improves upon the performance of the clustering algorithm with unbalanced data. Given a partially observed graph with adjacency matrix $\mathrm{A} \in \mathbb{R}^{N\times N},$ the proposed approach can reduce the computational complexity from $\mathrm{O}(N^{2})$ to $\mathrm{O}(N)$."
Thom W. Frühwirth,9ef88b43336d4bca73df60170cf4ab369a7eeb1d,"Rule-Based Drawing, Analysis and Generation of Graphs for Mason's Mark Design",ArXiv,2018.0,0,"We are developing a rule-based implementation of a tool to analyse and generate graphs. It is currently used in the domain of mason's marks. For thousands of years, stonemasons have been inscribing these symbolic signs on dressed stone. Geometrically, mason's marks are line drawings. They consist of a pattern of straight lines, sometimes circles and arcs. We represent mason's marks by connected planar graphs. Our prototype tool for analysis and generation of graphs is written in the rule-based declarative language Constraint Handling Rules. It features - a vertex-centric logical graph representation as constraints, - derivation of properties and statistics from graphs, - recognition of (sub)graphs and patterns in a graph, - automatic generation of graphs from given constrained subgraphs, - drawing graphs by visualization using svg graphics. In particular, we started to use the tool to classify and to invent mason's marks. In principe, our tool can be applied to any problem domain that admits a modeling as graphs."
"Patsorn Sangkloy, Jingwan Lu, Chen Fang, F. Yu, James Hays",4cf8e4dd94bf9f08d1d1c370ef05c0c0865c2858,Scribbler: Controlling Deep Image Synthesis with Sketch and Color,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,307,"Several recent works have used deep convolutional networks to generate realistic imagery. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos (e.g. faces or bedrooms). However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach generates more realistic, diverse, and controllable outputs. The architecture is also effective at user-guided colorization of grayscale images."
"Jacob Andreas, D. Klein, Sergey Levine",3a13f7c43b767b1fb72ef107ef62a4ddd48dd2a7,Modular Multitask Reinforcement Learning with Policy Sketches,ICML,2017.0,216,"We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them—specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level sub-goals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks."
"L. Liu, Fumin Shen, Yuming Shen, Xianglong Liu, L. Shao",69569f5d9fa03f410f5e83299e974ad683523cdc,Deep Sketch Hashing: Fast Free-Hand Sketch-Based Image Retrieval,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,150,"Free-hand sketch-based image retrieval (SBIR) is a specific cross-view retrieval task, in which queries are abstract and ambiguous sketches while the retrieval database is formed with natural images. Work in this area mainly focuses on extracting representative and shared features for sketches and natural images. However, these can neither cope well with the geometric distortion between sketches and images nor be feasible for large-scale SBIR due to the heavy continuous-valued distance computation. In this paper, we speed up SBIR by introducing a novel binary coding method, named Deep Sketch Hashing (DSH), where a semi-heterogeneous deep architecture is proposed and incorporated into an end-to-end binary coding framework. Specifically, three convolutional neural networks are utilized to encode free-hand sketches, natural images and, especially, the auxiliary sketch-tokens which are adopted as bridges to mitigate the sketch-image geometric distortion. The learned DSH codes can effectively capture the cross-view similarities as well as the intrinsic semantic correlations between different categories. To the best of our knowledge, DSH is the first hashing work specifically designed for category-level SBIR with an end-to-end deep architecture. The proposed DSH is comprehensively evaluated on two large-scale datasets of TU-Berlin Extension and Sketchy, and the experiments consistently show DSHs superior SBIR accuracies over several state-of-the-art methods, while achieving significantly reduced retrieval time and memory footprint."
"Tero Karras, Timo Aila, S. Laine, Antti Herva, J. Lehtinen",95b803d07c37e8349bd7b1318367d8237c76cbc0,Audio-driven facial animation by joint end-to-end learning of pose and emotion,ACM Trans. Graph.,2017.0,145,"We present a machine learning technique for driving 3D facial animation by audio input in real time and with low latency. Our deep neural network learns a mapping from input waveforms to the 3D vertex coordinates of a face model, and simultaneously discovers a compact, latent code that disambiguates the variations in facial expression that cannot be explained by the audio alone. During inference, the latent code can be used as an intuitive control for the emotional state of the face puppet. We train our network with 3--5 minutes of high-quality animation data obtained using traditional, vision-based performance capture methods. Even though our primary goal is to model the speaking style of a single actor, our model yields reasonable results even when driven with audio from other speakers with different gender, accent, or language, as we demonstrate with a user study. The results are applicable to in-game dialogue, low-cost localization, virtual reality avatars, and telepresence."
"Sarah L. Taylor, Taehwan Kim, Yisong Yue, Moshe Mahler, James Krahe, Anastasio Garcia Rodriguez, J. Hodgins, I. Matthews",cc63b9cf84b1fb0b3eca84372919f74a40b7c132,A deep learning approach for generalized speech animation,ACM Trans. Graph.,2017.0,136,"We introduce a simple and effective deep learning approach to automatically generate natural looking speech animation that synchronizes to input speech. Our approach uses a sliding window predictor that learns arbitrary nonlinear mappings from phoneme label input sequences to mouth movements in a way that accurately captures natural motion and visual coarticulation effects. Our deep learning approach enjoys several attractive properties: it runs in real-time, requires minimal parameter tuning, generalizes well to novel input speech sequences, is easily edited to create stylized and emotional speech, and is compatible with existing animation retargeting approaches. One important focus of our work is to develop an effective approach for speech animation that can be easily integrated into existing production pipelines. We provide a detailed description of our end-to-end approach, including machine learning design decisions. Generalized speech animation results are demonstrated over a wide range of animation clips on a variety of characters and voices, including singing and foreign language input. Our approach can also generate on-demand speech animation in real-time from user speech input."
"Jiajun Wu, Erika Lu, P. Kohli, B. Freeman, J. Tenenbaum",eb597cceec6e0889d1423ae688e8854bfa6f822d,Learning to See Physics via Visual De-animation,NIPS,2017.0,122,"We introduce a paradigm for understanding physical scenes without human annotations. At the core of our system is a physical world representation that is first recovered by a perception module and then utilized by physics and graphics engines. During training, the perception module and the generative models learn by visual de-animation --- interpreting and reconstructing the visual information stream. During testing, the system first recovers the physical world state, and then uses the generative models for reasoning and future prediction. Even more so than forward simulation, inverting a physics or graphics engine is a computationally hard problem; we overcome this challenge by using a convolutional inversion network. Our system quickly recognizes the physical world state from appearance and motion cues, and has the flexibility to incorporate both differentiable and non-differentiable physics and graphics engines. We evaluate our system on both synthetic and real datasets involving multiple physical scenes, and demonstrate that our system performs well on both physical state estimation and reasoning problems. We further show that the knowledge learned on the synthetic dataset generalizes to constrained real images."
"N. Wang, Xinbo Gao, Leiyu Sun, J. Li",b033a4a543cfbd6a1032ed2f0b109a4327124d2f,Bayesian Face Sketch Synthesis,IEEE Transactions on Image Processing,2017.0,102,"Exemplar-based face sketch synthesis has been widely applied to both digital entertainment and law enforcement. In this paper, we propose a Bayesian framework for face sketch synthesis, which provides a systematic interpretation for understanding the common properties and intrinsic difference in different methods from the perspective of probabilistic graphical models. The proposed Bayesian framework consists of two parts: the neighbor selection model and the weight computation model. Within the proposed framework, we further propose a Bayesian face sketch synthesis method. The essential rationale behind the proposed Bayesian method is that we take the spatial neighboring constraint between adjacent image patches into consideration for both aforementioned models, while the state-of-the-art methods neglect the constraint either in the neighbor selection model or in the weight computation model. Extensive experiments on the Chinese University of Hong Kong face sketch database demonstrate that the proposed Bayesian method could achieve superior performance compared with the state-of-the-art methods in terms of both subjective perceptions and objective evaluations."
"Yanghua Jin, Jiakai Zhang, Minjun Li, Yingtao Tian, Huachun Zhu, Zhihao Fang",2759179c786f5eec95b4552910e2cace1899890e,Towards the Automatic Anime Characters Creation with Generative Adversarial Networks,ArXiv,2017.0,97,"Automatic generation of facial images has been well studied after the Generative Adversarial Network (GAN) came out. There exists some attempts applying the GAN model to the problem of generating facial images of anime characters, but none of the existing work gives a promising result. In this work, we explore the training of GAN models specialized on an anime facial image dataset. We address the issue from both the data and the model aspect, by collecting a more clean, well-suited dataset and leverage proper, empirical application of DRAGAN. With quantitative analysis and case studies we demonstrate that our efforts lead to a stable and high-quality model. Moreover, to assist people with anime character design, we build a website (this http URL) with our pre-trained model available online, which makes the model easily accessible to general public."
"Jifei Song, Qian Yu, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",f1c808ed24684b734f137f8bb76524ddc5ed1b36,Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval,2017 IEEE International Conference on Computer Vision (ICCV),2017.0,96,"Human sketches are unique in being able to capture both the spatial topology of a visual object, as well as its subtle appearance details. Fine-grained sketch-based image retrieval (FG-SBIR) importantly leverages on such fine-grained characteristics of sketches to conduct instance-level retrieval of photos. Nevertheless, human sketches are often highly abstract and iconic, resulting in severe misalignments with candidate photos which in turn make subtle visual detail matching difficult. Existing FG-SBIR approaches focus only on coarse holistic matching via deep cross-domain representation learning, yet ignore explicitly accounting for fine-grained details and their spatial context. In this paper, a novel deep FG-SBIR model is proposed which differs significantly from the existing models in that: (1) It is spatially aware, achieved by introducing an attention module that is sensitive to the spatial position of visual details: (2) It combines coarse and fine semantic information via a shortcut connection fusion block: and (3) It models feature correlation and is robust to misalignments between the extracted features across the two domains by introducing a novel higher-order learnable energy function (HOLEF) based loss. Extensive experiments show that the proposed deep spatial-semantic attention model significantly outperforms the state-of-the-art."
"Lvmin Zhang, Y. Ji, Xin Lin",d634ec5eed78f6411ea774cc99b068c539a44a6a,Style Transfer for Anime Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN,2017 4th IAPR Asian Conference on Pattern Recognition (ACPR),2017.0,81,"Recently, with the revolutionary neural style transferring methods, creditable paintings can be synthesized automatically from content images and style images. However, when it comes to the task of applying a painting's style to an anime sketch, these methods will just randomly colorize sketch lines as outputs and fail in the main task: specific style transfer. In this paper, we integrated residual U-net to apply the style to the gray-scale sketch with auxiliary classifier generative adversarial network (AC-GAN). The whole process is automatic and fast. Generated results are creditable in the quality of art style as well as colorization."
"Xiaoguang Han, Chang Gao, Y. Yu",1af6d95486db5e7b5b61ac5425df9d1540f7a182,DeepSketch2Face: A Deep Learning Based Sketching System for 3D Face and Caricature Modeling,ACM Trans. Graph.,2017.0,75,"Face modeling has been paid much attention in the field of visual computing. There exist many scenarios, including cartoon characters, avatars for social media, 3D face caricatures as well as face-related art and design, where low-cost interactive face modeling is a popular approach especially among amateur users. In this paper, we propose a deep learning based sketching system for 3D face and caricature modeling. This system has a labor-efficient sketching interface, that allows the user to draw freehand imprecise yet expressive 2D lines representing the contours of facial features. A novel CNN based deep regression network is designed for inferring 3D face models from 2D sketches. Our network fuses both CNN and shape based features of the input sketch, and has two independent branches of fully connected layers generating independent subsets of coefficients for a bilinear face representation. Our system also supports gesture based interactions for users to further manipulate initial face models. Both user studies and numerical results indicate that our sketching system can help users create face models quickly and effectively. A significantly expanded face database with diverse identities, expressions and levels of exaggeration is constructed to promote further research and evaluation of face modeling techniques."
"Yiwen Guo, Anbang Yao, Hao Zhao, Yurong Chen",40fbb2a926e46f59341b8aa7c4359a9602a9f5b5,Network Sketching: Exploiting Binary Structure in Deep CNNs,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,64,"Convolutional neural networks (CNNs) with deep architectures have substantially advanced the state-of-the-art in computer vision tasks. However, deep networks are typically resource-intensive and thus difficult to be deployed on mobile devices. Recently, CNNs with binary weights have shown compelling efficiency to the community, whereas the accuracy of such models is usually unsatisfactory in practice. In this paper, we introduce network sketching as a novel technique of pursuing binary-weight CNNs, targeting at more faithful inference and better trade-off for practical applications. Our basic idea is to exploit binary structure directly in pre-trained filter banks and to produce binary-weight models via tensor expansion. The whole process can be treated as a coarse-to-fine model approximation, akin to the pencil drawing steps of outlining and shading. To further speedup the generated models, namely the sketches, we also propose an associative implementation of binary tensor convolutions. Experimental results demonstrate that a proper sketch of AlexNet (or ResNet) outperforms the existing binary-weight models by large margins on the ImageNet large scale classification task, while the committed memory for network parameters only exceeds a little."
"Yifan Liu, Zengchang Qin, Zhenbo Luo, Hua Wang",a071a97357a2a8f15acd21adb4ecbba659ca188c,Auto-painter: Cartoon Image Generation from Sketch by Using Conditional Generative Adversarial Networks,ArXiv,2017.0,58,"Recently, realistic image generation using deep neural networks has become a hot topic in machine learning and computer vision. Images can be generated at the pixel level by learning from a large collection of images. Learning to generate colorful cartoon images from black-and-white sketches is not only an interesting research problem, but also a potential application in digital entertainment. In this paper, we investigate the sketch-to-image synthesis problem by using conditional generative adversarial networks (cGAN). We propose the auto-painter model which can automatically generate compatible colors for a sketch. The new model is not only capable of painting hand-draw sketch with proper colors, but also allowing users to indicate preferred colors. Experimental results on two sketch datasets show that the auto-painter performs better that existing image-to-image methods."
"Yihao Feng, Dilin Wang, Qiang Liu",00b0857f2d072ca968387f57b63513ff48202070,Learning to Draw Samples with Amortized Stein Variational Gradient Descent,UAI,2017.0,54,"We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient direction (Liu & Wang, 2016) that maximally decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. We demonstrate our method with a number of applications, including variational autoencoder (VAE) with expressive encoders to model complex latent space structures, and hyper-parameter learning of MCMC samplers that allows Bayesian inference to adaptively improve itself when seeing more data."
"Fabien Baradel, C. Wolf, J. Mille",4ff6faa490819687b703f175dd3db6e7c2d618ae,Human Action Recognition: Pose-Based Attention Draws Focus to Hands,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),2017.0,51,"We propose a new spatio-temporal attention based mechanism for human action recognition able to automatically attend to most important human hands and detect the most discriminative moments in an action. Attention is handled in a recurrent manner employing Recurrent Neural Network (RNN) and is fully-differentiable. In contrast to standard soft-attention based mechanisms, our approach does not use the hidden RNN state as input to the attention model. Instead, attention distributions are drawn using external information: human articulated pose. We performed an extensive ablation study to show the strengths of this approach and we particularly studied the conditioning aspect of the attention mechanism. We evaluate the method on the largest currently available human action recognition dataset, NTU-RGB+D, and report state-of-the-art results. Another advantage of our model are certains aspects of explanability, as the spatial and temporal attention distributions at test time allow to study and verify on which parts of the input data the method focuses."
"Haibin Huang, E. Kalogerakis, Ersin Yumer, R. Mech",124bf7e986e534e339b3020c4387413f82296bb4,Shape Synthesis from Sketches via Procedural Models and Convolutional Networks,IEEE Transactions on Visualization and Computer Graphics,2017.0,50,"Procedural modeling techniques can produce high quality visual content through complex rule sets. However, controlling the outputs of these techniques for design purposes is often notoriously difficult for users due to the large number of parameters involved in these rule sets and also their non-linear relationship to the resulting content. To circumvent this problem, we present a sketch-based approach to procedural modeling. Given an approximate and abstract hand-drawn 2D sketch provided by a user, our algorithm automatically computes a set of procedural model parameters, which in turn yield multiple, detailed output shapes that resemble the user's input sketch. The user can then select an output shape, or further modify the sketch to explore alternative ones. At the heart of our approach is a deep Convolutional Neural Network (CNN) that is trained to map sketches to procedural model parameters. The network is trained by large amounts of automatically generated synthetic line drawings. By using an intuitive medium, i.e., freehand sketching as input, users are set free from manually adjusting procedural model parameters, yet they are still able to create high quality content. We demonstrate the accuracy and efficacy of our method in a variety of procedural modeling scenarios including design of man-made and organic shapes."
"J. Fiser, Ondrej Jamriska, David Simons, E. Shechtman, Jingwan Lu, Paul Asente, M. Lukác, D. Sýkora",6ad5d67fa3f772c8538d14617febcbf5413babf0,Example-based synthesis of stylized facial animations,ACM Trans. Graph.,2017.0,48,"We introduce a novel approach to example-based stylization of portrait videos that preserves both the subject's identity and the visual richness of the input style exemplar. Unlike the current state-of-the-art based on neural style transfer [Selim et al. 2016], our method performs non-parametric texture synthesis that retains more of the local textural details of the artistic exemplar and does not suffer from image warping artifacts caused by aligning the style exemplar with the target face. Our method allows the creation of videos with less than full temporal coherence [Ruder et al. 2016]. By introducing a controllable amount of temporal dynamics, it more closely approximates the appearance of real hand-painted animation in which every frame was created independently. We demonstrate the practical utility of the proposed solution on a variety of style exemplars and target videos."
"Chie Furusawa, Kazuyuki Hiroshiba, K. Ogaki, Yuri Odagiri",cb099882a728914aeee7f2b2a2f80cd8be758d08,Comicolorization: semi-automatic manga colorization,SIGGRAPH Asia Technical Briefs,2017.0,45,"We developed Comicolorization, a semi-automatic colorization system for manga images. Given a monochrome manga and reference images as inputs, our system generates a plausible color version of the manga. This is the first work to address the colorization of an entire manga title (a set of manga pages). Our method colorizes a whole page (not a single panel) semi-automatically, with the same color for the same character across multiple panels. To colorize the target character by the color from the reference image, we extract a color feature from the reference and feed it to the colorization network to help the colorization. Our approach employs adversarial loss to encourage the effect of the color features. Optionally, our tool allows users to revise the colorization result interactively. By feeding the color features to our deep colorization network, we accomplish colorization of the entire manga using the desired colors for each panel."
"Tu Bui, Leo Sampaio Ferraz Ribeiro, M. Ponti, J. Collomosse",d8a46154e061e617118cbdfc7684e36fc0379e4f,Compact descriptors for sketch-based image retrieval using a triplet loss convolutional neural network,Comput. Vis. Image Underst.,2017.0,41,"Abstract We present an efficient representation for sketch based image retrieval (SBIR) derived from a triplet loss convolutional neural network (CNN). We treat SBIR as a cross-domain modelling problem, in which a depiction invariant embedding of sketch and photo data is learned by regression over a siamese CNN architecture with half-shared weights and modified triplet loss function. Uniquely, we demonstrate the ability of our learned image descriptor to generalise beyond the categories of object present in our training data, forming a basis for general cross-category SBIR. We explore appropriate strategies for training, and for deriving a compact image descriptor from the learned representation suitable for indexing data on resource constrained e. g. mobile devices. We show the learned descriptors to outperform state of the art SBIR on the defacto standard Flickr15k dataset using a significantly more compact (56 bits per image, i. e. ≈ 105KB total) search index than previous methods. Datasets and models are available from the CVSSP datasets server at www.cvssp.org ."
"Chunlei Peng, Xinbo Gao, Nannan Wang, J. Li",54be36792f90365609dd800d49acdadade5f142a,Superpixel-Based Face Sketch–Photo Synthesis,IEEE Transactions on Circuits and Systems for Video Technology,2017.0,40,"Face sketch–photo synthesis technique has attracted growing attention in many computer vision applications, such as law enforcement and digital entertainment. Existing methods either simply perform the face sketch–photo synthesis on the holistic image or divide the face image into regular rectangular patches ignoring the inherent structure of the face image. In view of such situations, this paper presents a novel superpixel-based face sketch–photo synthesis method by estimating the face structures through image segmentation. In our proposed method, face images are first segmented into superpixels, which are then dilated to enhance the compatibility of neighboring superpixels. Each input face image induces a specific graphical structure modeled by Markov networks. We employ a two-stage synthesis process to learn the face structures through Markov networks constructed from two scales of dilation, respectively. Experiments on several public databases demonstrate that our proposed face sketch–photo synthesis method achieves superior performance compared with the state-of-the-art methods."
"Christian Galea, R. Farrugia",e387db84cd31f14e468bb329ac008a80e645400e,Forensic Face Photo-Sketch Recognition Using a Deep Learning-Based Architecture,IEEE Signal Processing Letters,2017.0,38,"Numerous methods that automatically identify subjects depicted in sketches as described by eyewitnesses have been implemented, but their performance often degrades when using real-world forensic sketches and extended galleries that mimic law enforcement mug-shot galleries. Moreover, little work has been done to apply deep learning for face photo-sketch recognition despite its success in numerous application domains including traditional face recognition. This is primarily due to the limited number of sketch images available, which are insufficient to robustly train large networks. This letter aims to tackle these issues with the following contributions: 1) a state-of-the-art model pre-trained for face photo recognition is tuned for face photo-sketch recognition by applying transfer learning, 2) a three-dimensional morphable model is used to synthesise new images and artificially expand the training data, allowing the network to prevent over-fitting and learn better features, 3) multiple synthetic sketches are also used in the testing stage to improve performance, and 4) fusion of the proposed method with a state-of-the-art algorithm is shown to further boost performance. An extensive evaluation of several popular and state-of-the-art algorithms is also performed using publicly available datasets, thereby serving as a benchmark for future algorithms. Compared to a leading method, the proposed framework is shown to reduce the error rate by 80.7% for viewed sketches and lowers the mean retrieval rank by 32.5% for real-world forensic sketches."
"V. Murali, Swarat Chaudhuri, C. Jermaine",fa6f30c397ebe9f61525b4aecef8a884c7dbee84,Bayesian Sketch Learning for Program Synthesis,ArXiv,2017.0,34,"We present a Bayesian statistical approach to the problem of automatic program synthesis. Our synthesizer starts by learning, offline and from an existing corpus, a probabilistic model of real-world programs. During synthesis, it is provided some ambiguous and incomplete evidence about the nature of the programming task that the user wants automated, for example sets of API calls or data types that are relevant for the task. Given this input, the synthesizer infers a posterior distribution over type-safe programs that assigns higher likelihood to programs that, according to the learned model, are more likely to match the evidence. We realize this approach using two key ideas. First, our learning techniques operate not over code but syntactic abstractions, or sketches, of programs. During synthesis, we infer a posterior distribution over sketches, then concretize samples from this distribution into type-safe programs using combinatorial techniques. Second, our statistical model explicitly models the full intent behind a synthesis task as a latent variable. To infer sketches, we first estimate a posterior distribution on the intent, then use samples from this posterior to generate a distribution over possible sketches. We show that our model can be implemented effectively using the new neural architecture of Bayesian encoder-decoders, which can be trained with stochastic gradient descent and yields a simple inference procedure. We implement our ideas in a system, called BAYOU, for the synthesis of API-heavy Java methods. We train BAYOU on a large corpus of Android apps, and find that the trained system can often synthesize complex methods given just a few API method names or data types as evidence. The experiments also justify the design choice of using a latent intent variable and the levels of abstraction at which sketches and evidence are defined."
"J. Xie, Guoxian Dai, F. Zhu, Yi Fang",251456909cd8e322118c6e50333e61ee167b2601,Learning Barycentric Representations of 3D Shapes for Sketch-Based 3D Shape Retrieval,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,33,"Retrieving 3D shapes with sketches is a challenging problem since 2D sketches and 3D shapes are from two heterogeneous domains, which results in large discrepancy between them. In this paper, we propose to learn barycenters of 2D projections of 3D shapes for sketch-based 3D shape retrieval. Specifically, we first use two deep convolutional neural networks (CNNs) to extract deep features of sketches and 2D projections of 3D shapes. For 3D shapes, we then compute the Wasserstein barycenters of deep features of multiple projections to form a barycentric representation. Finally, by constructing a metric network, a discriminative loss is formulated on the Wasserstein barycenters of 3D shapes and sketches in the deep feature space to learn discriminative and compact 3D shape and sketch features for retrieval. The proposed method is evaluated on the SHREC13 and SHREC14 sketch track benchmark datasets. Compared to the state-of-the-art methods, our proposed method can significantly improve the retrieval performance."
"N. Wang, Mingrui Zhu, J. Li, Bin Song, Zan Li",aaa3cb5e907bfc6cb3a9fe22ed2b7807614c4523,Data-driven vs. model-driven: Fast face sketch synthesis,Neurocomputing,2017.0,32,"Abstract Face sketch synthesis refers to the technique generating a sketch from an input photo. Existing methods are data-driven, which synthesize a sketch by linearly combining K candidate sketch patches which are purposely selected from the training data. However, these methods have large computation cost due to neighbor selection process that perform neighbor searching on a large scale of training image patches. Instead of the aforementioned commonly used data-driven strategy, we propose to learn some models from training photos to training sketches which could speed the synthesis process a lot while preserving comparable or even better synthesis performance. Specially, we learn some ridge regressors from training photo patch intensities to training sketch patch intensities. An initial estimation is obtained from these regressors. Simultaneously, a high-frequency image is hallucinated from some ridge regressors which are learned from the high-frequency information of training photos and sketches. The high-frequency image is superimposed to the initial estimation to compensate the filtered details due to the dense average in the initial estimation process. Extensive experiments on public face sketch database illustrate the effectiveness of proposed model-driven strategy."
"Yajing Chen, Shikui Tu, Yuqi Yi, Lei Xu",8a00974396c92745498d790412e7ace932704c9c,Sketch-pix2seq: a Model to Generate Sketches of Multiple Categories,ArXiv,2017.0,32,"Sketch is an important media for human to communicate ideas, which reflects the superiority of human intelligence. Studies on sketch can be roughly summarized into recognition and generation. Existing models on image recognition failed to obtain satisfying performance on sketch classification. But for sketch generation, a recent study proposed a sequence-to-sequence variational-auto-encoder (VAE) model called sketch-rnn which was able to generate sketches based on human inputs. The model achieved amazing results when asked to learn one category of object, such as an animal or a vehicle. However, the performance dropped when multiple categories were fed into the model. Here, we proposed a model called sketch-pix2seq which could learn and draw multiple categories of sketches. Two modifications were made to improve the sketch-rnn model: one is to replace the bidirectional recurrent neural network (BRNN) encoder with a convolutional neural network(CNN); the other is to remove the Kullback-Leibler divergence from the objective function of VAE. Experimental results showed that models with CNN encoders outperformed those with RNN encoders in generating human-style sketches. Visualization of the latent space illustrated that the removal of KL-divergence made the encoder learn a posterior of latent space that reflected the features of different categories. Moreover, the combination of CNN encoder and removal of KL-divergence, i.e., the sketch-pix2seq model, had better performance in learning and generating sketches of multiple categories and showed promising results in creativity tasks."
"Paulina Hensman, K. Aizawa",cb50d3080ab198741aa7ee87d285b984ea289100,cGAN-Based Manga Colorization Using a Single Training Image,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,32,"The Japanese comic format known as Manga is popular all over the world. It is traditionally produced in black and white, and colorization is time consuming and costly. Automatic colorization methods generally rely on greyscale values, which are not present in manga. Furthermore, due to copyright protection, colorized manga available for training is scarce. We propose a manga colorization method based on conditional Generative Adversarial Networks (cGAN). Unlike previous cGAN approaches that use many hundreds or thousands of training images, our method requires only a single colorized reference image for training, avoiding the need of a large dataset. Colorizing manga using cGANs can produce blurry results with artifacts, and the resolution is limited. We therefore also propose a method of segmentation and color-correction to mitigate these issues. The final results are sharp, clear, and in high resolution, and stay true to the character's original color scheme."
"C. Li, Xueting Liu, T. Wong",42c6513804a4f85476e5060aaf174f504c1c41f9,Deep extraction of manga structural lines,ACM Trans. Graph.,2017.0,32,"Extraction of structural lines from pattern-rich manga is a crucial step for migrating legacy manga to digital domain. Unfortunately, it is very challenging to distinguish structural lines from arbitrary, highly-structured, and black-and-white screen patterns. In this paper, we present a novel data-driven approach to identify structural lines out of pattern-rich manga, with no assumption on the patterns. The method is based on convolutional neural networks. To suit our purpose, we propose a deep network model to handle the large variety of screen patterns and raise output accuracy. We also develop an efficient and effective way to generate a rich set of training data pairs. Our method suppresses arbitrary screen patterns no matter whether these patterns are regular, irregular, tone-varying, or even pictorial, and regardless of their scales. It outputs clear and smooth structural lines even if these lines are contaminated by and immersed in complex patterns. We have evaluated our method on a large number of mangas of various drawing styles. Our method substantially outperforms state-of-the-art methods in terms of visual quality. We also demonstrate its potential in various manga applications, including manga colorization, manga retargeting, and 2.5D manga generation."
"Guoxian Dai, J. Xie, F. Zhu, Yi Fang",a6a579d38f6e69d5d289c21ed94de5afe812e2eb,Deep Correlated Metric Learning for Sketch-based 3D Shape Retrieval,AAAI,2017.0,31,"The explosive growth of 3D models has led to the pressing demand for an efficient searching system. Traditional modelbased search is usually not convenient, since people don’t always have 3D model available by side. The sketch-based 3D shape retrieval is a promising candidate due to its simpleness and efficiency. The main challenge for sketch-based 3D shape retrieval is the discrepancy across different domains. In the paper, we propose a novel deep correlated metric learning (DCML) method to mitigate the discrepancy between sketch and 3D shape domains. The proposed DCML trains two distinct deep neural networks (one for each domain) jointly with one loss, which learns two deep nonlinear transformations to map features from both domains into a nonlinear feature space. The proposed loss, including discriminative loss and correlation loss, aims to increase the discrimination of features within each domain as well as the correlation between different domains. In the transfered space, the discriminative loss minimizes the intra-class distance of the deep transformed features and maximizes the inter-class distance of the deep transformed features at least a predefined margin within each domain, while the correlation loss focuses on minimizing the distribution discrepancy across different domains. Our proposed method is evaluated on SHREC 2013 and 2014 benchmarks, and the experimental results demonstrate the superiority of our proposed method over the state-of-the-art methods."
"Paritosh Mittal, Aishwarya Jain, Gaurav Goswami, Mayank Vatsa, Richa Singh",454621e3e678bc61043a5f18d0bf9f6148824928,Composite sketch recognition using saliency and attribute feedback,Inf. Fusion,2017.0,31,"Propose composite sketch to photo matching algorithm using visual saliency and combination of texture features.Attributes such as gender and ethnicity information is used to improve recognition performance.Multiple experts such as sketches from different artists are combined for further increasing accuracy. Recent interest and requirement of law enforcement agencies in matching composite sketches with digital images has instigated research in this important face recognition problem. In this paper, we propose feature extraction and matching algorithm using visual saliency and combination of texture features for matching composite sketches with digital photos. The attributes such as gender, ethnicity, and skin color are utilized for re-ordering the ranked list. Further, information from multiple experts such as multiple composite sketch generation tools or artists is combined for improving the matching performance. The results obtained on the extended PRIP database show that the proposed algorithm improves the state-of-art in matching composite sketch and digital face images and yields the rank 50 identification accuracy of 70.3% on a database of 1500 subjects."
"Bingke Zhu, Yingying Chen, Jinqiao Wang, Si Liu, Bo Zhang, Ming Tang",deda6de1552e69c2320dfd322a4dfd4cdfb1f68b,Fast Deep Matting for Portrait Animation on Mobile Phone,ACM Multimedia,2017.0,29,"Image matting plays an important role in image and video editing. However, the formulation of image matting is inherently ill-posed. Traditional methods usually employ interaction to deal with the image matting problem with trimaps and strokes, and cannot run on the mobile phone in real-time. In this paper, we propose a real-time automatic deep matting approach for mobile devices. By leveraging the densely connected blocks and the dilated convolution, a light full convolutional network is designed to predict a coarse binary mask for portrait image. And a feathering block, which is edge-preserving and matting adaptive, is further developed to learn the guided filter and transform the binary mask into alpha matte. Finally, an automatic portrait animation system based on fast deep matting is built on mobile devices, which does not need any interaction and can realize real-time matting with 15 fps. The experiments show that the proposed approach achieves comparable results with the state-of-the-art matting solvers."
"Kaiyue Pang, Yi-Zhe Song, Tony Xiang, Timothy M. Hospedales",148824668e2e769380833cd00762853d272aadcb,Cross-domain Generative Learning for Fine-Grained Sketch-Based Image Retrieval,BMVC,2017.0,28,"The key challenge for learning a fine-grained sketch-based image retrieval (FG-SBIR) model is to bridge the domain gap between photo and sketch. Existing models learn a deep joint embedding space with discriminative losses where a photo and a sketch can be compared. In this paper, we propose a novel discriminative-generative hybrid model by introducing a generative task of cross-domain image synthesis. This task enforces the learned embedding space to preserve all the domain invariant information that is useful for cross-domain reconstruction, thus explicitly reducing the domain gap as opposed to existing models. Extensive experiments on the largest FG-SBIR dataset Sketchy [19] show that the proposed model significantly outperforms state-of-the-art discriminative FG-SBIR models."
"Dongyu Zhang, Liang Lin, Tianshui Chen, X. Wu, Wenwei Tan, E. Izquierdo",d9b975bc6fd18b584923844548485611ce13d82c,Content-Adaptive Sketch Portrait Generation by Decompositional Representation Learning,IEEE Transactions on Image Processing,2017.0,26,"Sketch portrait generation benefits a wide range of applications such as digital entertainment and law enforcement. Although plenty of efforts have been dedicated to this task, several issues still remain unsolved for generating vivid and detail-preserving personal sketch portraits. For example, quite a few artifacts may exist in synthesizing hairpins and glasses, and textural details may be lost in the regions of hair or mustache. Moreover, the generalization ability of current systems is somewhat limited since they usually require elaborately collecting a dictionary of examples or carefully tuning features/components. In this paper, we present a novel representation learning framework that generates an end-to-end photo-sketch mapping through structure and texture decomposition. In the training stage, we first decompose the input face photo into different components according to their representational contents (i.e., structural and textural parts) by using a pre-trained convolutional neural network (CNN). Then, we utilize a branched fully CNN for learning structural and textural representations, respectively. In addition, we design a sorted matching mean square error metric to measure texture patterns in the loss function. In the stage of sketch rendering, our approach automatically generates structural and textural representations for the input photo and produces the final result via a probabilistic fusion scheme. Extensive experiments on several challenging benchmarks suggest that our approach outperforms example-based synthesis algorithms in terms of both perceptual and objective metrics. In addition, the proposed method also has better generalization ability across data set without additional training."
"H. Pham, Samuel Cheung, V. Pavlovic",cb7cf162fb44ef06abd6aa30026c99ded8cbcdf8,Speech-Driven 3D Facial Animation with Implicit Emotional Awareness: A Deep Learning Approach,2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2017.0,26,"We introduce a long short-term memory recurrent neural network (LSTM-RNN) approach for real-time facial animation, which automatically estimates head rotation and facial action unit activations of a speaker from just her speech. Specifically, the time-varying contextual non-linear mapping between audio stream and visual facial movements is realized by training a LSTM neural network on a large audio-visual data corpus. In this work, we extract a set of acoustic features from input audio, including Mel-scaled spectrogram, Mel frequency cepstral coefficients and chromagram that can effectively represent both contextual progression and emotional intensity of the speech. Output facial movements are characterized by 3D rotation and blending expression weights of a blendshape model, which can be used directly for animation. Thus, even though our model does not explicitly predict the affective states of the target speaker, her emotional manifestation is recreated via expression weights of the face model. Experiments on an evaluation dataset of different speakers across a wide range of affective states demonstrate promising results of our approach in real-time speech-driven facial animation."
"Mingrui Zhu, N. Wang, Xinbo Gao, J. Li",cbef6ee44bb87f54d80ea2ca7d1266bc624d9d07,Deep Graphical Feature Learning for Face Sketch Synthesis,IJCAI,2017.0,23,"The exemplar-based face sketch synthesis method generally contains two steps: neighbor selection and reconstruction weight representation. Pixel intensities are widely used as features by most of the existing exemplar-based methods, which lacks of representation ability and robustness to light variations and clutter backgrounds. We present a novel face sketch synthesis method combining generative exemplar-based method and discriminatively trained deep convolutional neural networks (dCNNs) via a deep graphical feature learning framework. Our method works in both two steps by using deep discriminative representations derived from dCNNs. Instead of using it directly, we boost its representation capability by a deep graphical feature learning framework. Finally, the optimal weights of deep representations and optimal reconstruction weights for face sketch synthesis can be obtained simultaneously. With the optimal reconstruction weights, we can synthesize high quality sketches which is robust against light variations and clutter backgrounds. Extensive experiments on public face sketch databases show that our method outperforms state-of-the-art methods, in terms of both synthesis quality and recognition ability."
"W. Chu, Wei-Wei Li",39b642f9470d04ca4b26b7fdae760178f879541b,Manga FaceNet: Face Detection in Manga based on Deep Neural Network,ICMR,2017.0,23,"Among various elements of manga, character's face plays one of the most important role in access and retrieval. We propose a DNN-based method to do manga face detection, which is a challenging but relatively unexplored topic. Given a manga page, we first find candidate regions based on the selective search scheme. A deep neural network is then proposed to detect manga faces of various appearance. We evaluate the proposed method based on a large-scale benchmark, and show performance comparison and convincing evaluation results that have rarely done before."
"Giorgos Tolias, O. Chum",3d29d61eed1284ab73c5466b1337a95b029c0088,Asymmetric Feature Maps with Application to Sketch Based Retrieval,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,22,"We propose a novel concept of asymmetric feature maps (AFM), which allows to evaluate multiple kernels between a query and database entries without increasing the memory requirements. To demonstrate the advantages of the AFM method, we derive a short vector image representation that, due to asymmetric feature maps, supports efficient scale and translation invariant sketch-based image retrieval. Unlike most of the short-code based retrieval systems, the proposed method provides the query localization in the retrieved image. The efficiency of the search is boosted by approximating a 2D translation search via trigonometric polynomial of scores by 1D projections. The projections are a special case of AFM. An order of magnitude speed-up is achieved compared to traditional trigonometric polynomials. The results are boosted by an image-based average query expansion, exceeding significantly the state of the art on standard benchmarks."
"Shengchuan Zhang, Xinbo Gao, N. Wang, J. Li",4f76b9eb6d27971f65c6a1c6cbef7e8b670688c6,Face Sketch Synthesis From a Single Photo–Sketch Pair,IEEE Transactions on Circuits and Systems for Video Technology,2017.0,20,"Face sketch synthesis is crucial in many practical applications, such as digital entertainment and law enforcement. Previous methods relying on many photo–sketch pairs have made great progress. State-of-the-art face sketch synthesis algorithms adopt Bayesian inference (BI) (e.g., Markov random fields) to select local sketch patches around corresponding position from a set of training data. However, these methods have two limitations: 1) they depend on many training photo–sketch pairs and 2) they cannot tackle nonfacial factors (e.g., hairpins, glasses, backgrounds, and image size) if these factors are excluded in training data. In this paper, we propose a novel face sketch synthesis method that is capable of handling nonfacial factors only using a single photo–sketch pair from coarse to fine. Our method proposes a cascaded image synthesis (CIS) strategy and integrates sparse representation-based greedy search (SRGS) and BI for face sketch synthesis. We first apply SRGS to select candidate sketch patches from the whole training photo–sketch pairs sampled from the only photo–sketch pair. We then employ BI to estimate an initial sketch. Afterward, the input photo and the estimated initial sketch are taken as an additional photo–sketch pair for training. Finally, we adopt CIS with the given two photo–sketch pairs to further improve the quality of the initial sketch. The experimental results on several databases demonstrate that our algorithm outperforms state-of-the-art methods."
"Ravi Kiran Sarvadevabhatla, Isht Dwivedi, A. Biswas, Sahil Manocha, R. VenkateshBabu",37a8c7f5e5a1a3a108a2dbefdb952eb1837b9934,SketchParse: Towards Rich Descriptions for Poorly Drawn Sketches using Multi-Task Hierarchical Deep Networks,ACM Multimedia,2017.0,20,"The ability to semantically interpret hand-drawn line sketches, although very challenging, can pave way for novel applications in multimedia. We propose SKETCHPARSE, the first deep-network architecture for fully automatic parsing of freehand object sketches. SKETCHPARSE is configured as a two-level fully convolutional network. The first level contains shared layers common to all object categories. The second level contains a number of expert sub-networks. Each expert specializes in parsing sketches from object categories which contain structurally similar parts. Effectively, the two-level configuration enables our architecture to scale up efficiently as additional categories are added. We introduce a router layer which (i) relays sketch features from shared layers to the correct expert (ii) eliminates the need to manually specify object category during inference. To bypass laborious part-level annotation, we sketchify photos from semantic object-part image datasets and use them for training. Our architecture also incorporates object pose prediction as a novel auxiliary task which boosts overall performance while providing supplementary information regarding the sketch. We demonstrate SKETCHPARSE's abilities (i) on two challenging large-scale sketch datasets (ii) in parsing unseen, semantically related object categories (iii) in improving fine-grained sketch-based image retrieval. As a novel application, we also outline how SKETCHPARSE's output can be used to generate caption-style descriptions for hand-drawn sketches."
"Jun-Yan He, Xiao Wu, Yugang Jiang, Bo Zhao, Qiang Peng",4ae33d64f8515a023f10e20af20f62a2a5a76f13,Sketch Recognition with Deep Visual-Sequential Fusion Model,ACM Multimedia,2017.0,20,"In this paper, a deep end-to-end network for sketch recognition, named Deep Visual-Sequential Fusion model (DVSF) is proposed to model the visual and sequential patterns of the strokes. To capture the intermediate states of sketches, a three-way representation learner is first utilized to extract the visual features. These deep features are simultaneously fed into the visual and sequential networks to capture spatial and temporal properties, respectively. More specifically, visual networks are novelly proposed to learn the stroke patterns by stacking the Residual Fully-Connected (R-FC) layers, which integrate ReLU and Tanh activation functions to achieve the sparsity and generalization ability. To learn the patterns of stroke order, sequential networks are constructed by Residual Long Short-Term Memory (R-LSTM) units, which optimize the network architecture by skip connection. Finally, the visual and sequential representations of the sketches are seamlessly integrated with a fusion layer to obtain the final results. Experiments conducted on the benchmark sketch dataset TU-Berlin demonstrate the effectiveness of the proposed method, which outperforms the state-of-the-art approaches."
"Nhu-Van Nguyen, Christophe Rigaud, J. Burie",6bf9c86f8d93e50b26874d07c33bfd5bd508e1aa,Comic Characters Detection Using Deep Learning,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,19,"Comic characters detection has been an interesting area in comic analysis as it not only allows more efficient indexation and retrieval for comic books but also yields an adequate understanding of comics so as to help better creating the digital form of comic books. In recent years, several methods that have been proposed to extract/detect characters from comics, have given reasonable performance. However, they always use their datasets to evaluate the methods without comparing with other works or experimenting on a standard dataset. In this work, we take advantage of the recent and significant development of deep learning to apply it to comic character detection. We use the latest object detection deep networks to train the comic characters detector based on our proposed dataset. By experimenting on our proposed dataset and also on available datasets from previous works, we have found that this method significantly outperforms existing methods. We believe that this state-of-the-art approach can be considered as a reliable baseline method to compare and better understand future detection techniques."
"R. Dwivedi, G. Agnihotri",a2148f786f102ba07993ff6eba81eea617b43979,Study of Deep Drawing Process Parameters,,2017.0,19,"Abstract Deep drawing is a common sheet metal forming process used to manufacture complicated 3-D parts from thin sheet metals.In many industries, Deep Drawing is a very important metal forming process. Deep drawing is complex deformation affected by the geometrical and process parameters. Deep drawing process optimization is a challenging task. This paper presents a review on the deep drawing parameters and identifies directions for future research and the results of present study were showing thesuccessfully produced aluminium alloys cup."
"Ke Li, Kaiyue Pang, Yi-Zhe Song, Timothy M. Hospedales, Tao Xiang, Honggang Zhang",b8f4939f456a3a54d093fdd32c2bb3fe4cbdd65e,Synergistic Instance-Level Subspace Alignment for Fine-Grained Sketch-Based Image Retrieval,IEEE Transactions on Image Processing,2017.0,18,"We study the problem of fine-grained sketch-based image retrieval. By performing instance-level (rather than category-level) retrieval, it embodies a timely and practical application, particularly with the ubiquitous availability of touchscreens. Three factors contribute to the challenging nature of the problem: 1) free-hand sketches are inherently abstract and iconic, making visual comparisons with photos difficult; 2) sketches and photos are in two different visual domains, i.e., black and white lines versus color pixels; and 3) fine-grained distinctions are especially challenging when executed across domain and abstraction-level. To address these challenges, we propose to bridge the image-sketch gap both at the high level via parts and attributes, as well as at the low level via introducing a new domain alignment method. More specifically, first, we contribute a data set with 304 photos and 912 sketches, where each sketch and image is annotated with its semantic parts and associated part-level attributes. With the help of this data set, second, we investigate how strongly supervised deformable part-based models can be learned that subsequently enable automatic detection of part-level attributes, and provide pose-aligned sketch-image comparisons. To reduce the sketch-image gap when comparing low-level features, third, we also propose a novel method for instance-level domain-alignment that exploits both subspace and instance-level cues to better align the domains. Finally, fourth, these are combined in a matching framework integrating aligned low-level features, mid-level geometric structure, and high-level semantic attributes. Extensive experiments conducted on our new data set demonstrate effectiveness of the proposed method."
"Xiaoran Qin, Yafeng Zhou, Zheqi He, Yongtao Wang, Zhi Tang",015b8b966baae37b36d8fbf33a4be6f4c30c6116,A Faster R-CNN Based Method for Comic Characters Face Detection,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,18,"Face detection of comic characters is a necessary step in most applications, such as comic character retrieval, automatic character classification and comic analysis. However, the existing methods were developed for simple cartoon images or small size comic datasets, and detection performance remains to be improved. In this paper, we propose a Faster R-CNN based method for face detection of comic characters. Our contribution is twofold. First, for the binary classification task of face detection, we empirically find that the sigmoid classifier shows a slightly better performance than the softmax classifier. Second, we build two comic datasets, JC2463 and AEC912, consisting of 3375 comic pages in total for characters face detection evaluation. Experimental results have demonstrated that the proposed method not only performs better than existing methods, but also works for comic images with different drawing styles."
"N. Wang, Shengchuan Zhang, Xinbo Gao, J. Li, Bin Song, Zan Li",355cf0799bba51f324f1e8370327e51cd5b358d8,Unified framework for face sketch synthesis,Signal Process.,2017.0,17,"Face sketch synthesis (FSS) has great significance to sketch based face retrieval or recognition and digital entertainment. Recently, great progress has been made in face sketch synthesis. Most state-of-the-art FSS methods work at patch level. However, these methods only consider either position constraint or global search when selecting candidate image patches. Furthermore, the common used weighting combination in these methods leads to the lost of reasonable high frequency details. We argue that all these factors are necessary for face sketch synthesis. To this end, we propose a simple yet effective unified approach considering position constraint, global search and high frequency compensation to infer pseudosketches from input test photos. Firstly, a nearest-neighbor search is conducted by combining both position constraint and global search. After obtaining the candidate image patches, a Markov network is applied to generate the pseudosketch. Secondly, the residue between an original sketch and the synthesized pseudosketch is modeled by the same Markov network to compensate the high frequency details. The effectiveness of the proposed method is demonstrated on the CUHK face sketch database by comparing with state-of-the-art FSS methods. HighlightsWe designs a unified approach for face sketch synthesis.We proposes a data-driven based high frequency information compensation strategy for face sketch synthesis.The proposed method achieves superior performance in comparison to state-of-the-art face sketch synthesis methods."
"Shruti Nagpal, Maneet Singh, Richa Singh, Mayank Vatsa, A. Noore, A. Majumdar",3cf1f89d73ca4b25399c237ed3e664a55cd273a2,Face Sketch Matching via Coupled Deep Transform Learning,2017 IEEE International Conference on Computer Vision (ICCV),2017.0,17,"Face sketch to digital image matching is an important challenge of face recognition that involves matching across different domains. Current research efforts have primarily focused on extracting domain invariant representations or learning a mapping from one domain to the other. In this research, we propose a novel transform learning based approach termed as DeepTransformer, which learns a transformation and mapping function between the features of two domains. The proposed formulation is independent of the input information and can be applied with any existing learned or hand-crafted feature. Since the mapping function is directional in nature, we propose two variants of DeepTransformer: (i) semi-coupled and (ii) symmetrically-coupled deep transform learning. This research also uses a novel IIIT-D Composite Sketch with Age (CSA) variations database which contains sketch images of 150 subjects along with age-separated digital photos. The performance of the proposed models is evaluated on a novel application of sketch-to-sketch matching, along with sketch-to-digital photo matching. Experimental results demonstrate the robustness of the proposed models in comparison to existing state-of-the-art sketch matching algorithms and a commercial face recognition system."
"Omar Seddati, S. Dupont, S. Mahmoudi",eef5ad2dfb15c9bd866b03242d4be868068e45a8,Quadruplet Networks for Sketch-Based Image Retrieval,ICMR,2017.0,16,"Freehand sketches are a simple and powerful tool for communication. They are easily recognized across cultures and suitable for various applications. In this paper, we use deep convolutional neural networks (ConvNets) to address sketch-based image retrieval (SBIR). We first train our ConvNets on sketch and image object recognition in a large scale benchmark for SBIR (the sketchy database). We then conduct a comprehensive study of ConvNets features for SBIR, using a kNN similarity search paradigm in the ConvNet feature space. In contrast to recent SBIR works, we propose a new architecture the quadruplet networks which enhance ConvNet features for SBIR. This new architecture enables ConvNets to extract more robust global and local features. We evaluate our approach on three large scale datasets. Our quadruplet networks outperform previous state-of-the-art on two of them by a significant margin and gives competitive results on the third. Our system achieves a recall of 42.16% (at k=1) for the sketchy database (more than 5% improvement), a Kendal score of 43.28Τb on the TU-Berlin SBIR benchmark (close to 6Τb improvement) and a mean average precision (MAP) of 32.16% on Flickr15k (a category level SBIR benchmark)."
"M. Kuba, H. Mahmoud",c4d24d63fe51e4b7c77721a945bba6bd2f89c4d2,Two-color balanced affine urn models with multiple drawings,Adv. Appl. Math.,2017.0,16,"This is the second part of a two-part investigation. We continue the study of a class of balanced urn schemes on balls of two colors (white and black). At each drawing, a sample of size $m\ge 1$ is drawn from the urn and ball addition rules are applied; the special case $m=1$ of sampling only a single ball coincides with ordinary balanced urn models. We consider these multiple drawings under sampling with or without replacement. For the class of affine conditional expected value, we study the number of white balls after $n$ steps. The affine class is parametrized by $\Lambda$, specified by the ratio of the two eigenvalues of a reduced ball replacement matrix and the sample size, leading to three different cases: small-index urns ($\Lambda \le \frac 1 2$, and the case $\Lambda= \frac 1 2$ is critical), large-index urns ($\Lambda > \frac 1 2$), and triangular urns. In Part I we derived a central limit theorem for small index urns, and proved almost-sure convergence for large index and triangular urn models. In the present paper (Part II), we continue the study of affiance urn schemes and study the moments of large-index urns and triangular urn models. We show moment convergence under suitable scaling and we also provide expressions for the moments."
"Yibing Song, Jiawei Zhang, Linchao Bao, Q. Yang",cdc66310c0f93c370dd3f86be3a1a837eafa0e16,Fast Preprocessing for Robust Face Sketch Synthesis,IJCAI,2017.0,15,"Exemplar-based face sketch synthesis methods usually meet the challenging problem that input photos are captured in different lighting conditions from training photos. The critical step causing the failure is the search of similar patch candidates for an input photo patch. Conventional illumination invariant patch distances are adopted rather than directly relying on pixel intensity difference, but they will fail when local contrast within a patch changes. In this paper, we propose a fast preprocessing method named Bidirectional Luminance Remapping (BLR), which interactively adjust the lighting of training and input photos. Our method can be directly integrated into state-of-the-art exemplar-based methods to improve their robustness with ignorable computational cost."
"Jifei Song, Yi-Zhe Song, Tony Xiang, Timothy M. Hospedales",c52f30ef7fbef659994dc195bcce16fa85bd6f41,Fine-Grained Image Retrieval: the Text/Sketch Input Dilemma,BMVC,2017.0,15,"Fine-grained image retrieval (FGIR) enables a user to search for a photo of an object instance based on a mental picture. Depending on how the object is described by the user, two general approaches exist: sketch-based FGIR or text-based FGIR, each of which has its own pros and cons. However, no attempt has been made to systematically investigate how informative each of these two input modalities is, and more importantly whether they are complementary to each thus should be modelled jointly. In this work, for the first time we introduce a multi-modal FGIR dataset with both sketches and sentences description provided as query modalities. A multi-modal quadruplet deep network is formulated to jointly model the sketch and text input modalities as well as the photo output modality. We show that on its own the sketch modality is much more informative than text and each modality can benefit the other when they are modelled jointly."
"Longteng Guo, Jing Liu, Yuhang Wang, Zhonghua Luo, Wei Wen, Hanqing Lu",ec96af15a74b99ee349ba87f9064e4e8ae04ac2a,Sketch-based Image Retrieval using Generative Adversarial Networks,ACM Multimedia,2017.0,15,"For sketch-based image retrieval (SBIR), we propose a generative adversarial network trained on a large number of sketches and their corresponding real images. To imitate human search process, we attempt to match candidate images with theimaginary image in user single s mind instead of the sketch query, i.e., not only the shape information of sketches but their possible content information are considered in SBIR. Specifically, a conditional generative adversarial network (cGAN) is employed to enrich the content information of sketches and recover the imaginary images, and two VGG-based encoders, which work on real and imaginary images respectively, are used to constrain their perceptual consistency from the view of feature representations. During SBIR, we first generate an imaginary image from a given sketch via cGAN, and then take the output of the learned encoder for imaginary images as the feature of the query sketch. Finally, we build an interactive SBIR system that shows encouraging performance."
"Christophe Rigaud, J. Burie, J. Ogier",19951933f0bbebe730c95a908ad2c4409615dde1,Segmentation-Free Speech Text Recognition for Comic Books,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,14,"Speech text in comic books is written in a particular manner by the scriptwriter which raises unusual challenges for text recognition. We first detail these challenges and present different approaches to solve them. We compare the performances of pre-trained OCR and segmentation-free approach for speech text of comic books written in Latin script. We demonstrate that few good quality pre-trained OCR output samples, associated with other unlabeled data with the same writing style, can feed a segmentation-free OCR and improve text recognition. Thanks to the help of the lexicality measure that automatically accept or reject the pretrained OCR output as pseudo ground truth for a subsequent segmentation-free OCR training and recognition."
"K. Sasaki, S. Iizuka, Edgar Simo-Serra, H. Ishikawa",645e531b098dcdf5ceee30292949f91aace3236c,Joint Gap Detection and Inpainting of Line Drawings,2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017.0,14,"We propose a novel data-driven approach for automatically detecting and completing gaps in line drawings with a Convolutional Neural Network. In the case of existing inpainting approaches for natural images, masks indicating the missing regions are generally required as input. Here, we show that line drawings have enough structures that can be learned by the CNN to allow automatic detection and completion of the gaps without any such input. Thus, our method can find the gaps in line drawings and complete them without user interaction. Furthermore, the completion realistically conserves thickness and curvature of the line segments. All the necessary heuristics for such realistic line completion are learned naturally from a dataset of line drawings, where various patterns of line completion are generated on the fly as training pairs to improve the model generalization. We evaluate our method qualitatively on a diverse set of challenging line drawings and also provide quantitative results with a user study, where it significantly outperforms the state of the art."
"T. Chugh, Maneet Singh, Shruti Nagpal, Richa Singh, Mayank Vatsa",6efb18dd98469ff3c4c7d82932ed459f5a0a2e1b,Transfer Learning Based Evolutionary Algorithm for Composite Face Sketch Recognition,2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),2017.0,14,"Matching facial sketches to digital face images has widespread application in law enforcement scenarios. Recent advancements in technology have led to the availability of sketch generation tools, minimizing the requirement of a sketch artist. While these sketches have helped in manual authentication, matching composite sketches with digital mugshot photos automatically show high modality gap. This research aims to address the task of matching a composite face sketch image to digital images by proposing a transfer learning based evolutionary algorithm. A new feature descriptor, Histogram of Image Moments, has also been presented for encoding features across modalities. Moreover, IIITD Composite Face Sketch Database of 150 subjects is presented to fill the gap due to limited availability of databases in this problem domain. Experimental evaluation and analysis on the proposed dataset show the effectiveness of the transfer learning approach for performing cross-modality recognition."
"H. Pham, Yuting Wang, V. Pavlovic",446974157c1f94a1fc78dfd3254a7a075d4610f0,End-to-end Learning for 3D Facial Animation from Raw Waveforms of Speech,ArXiv,2017.0,14,"We present a deep learning framework for real-time speech-driven 3D facial animation from just raw waveforms. Our deep neural network directly maps an input sequence of speech audio to a series of micro facial action unit activations and head rotations to drive a 3D blendshape face model. In particular, our deep model is able to learn the latent representations of time-varying contextual information and affective states within the speech. Hence, our model not only activates appropriate facial action units at inference to depict different utterance generating actions, in the form of lip movements, but also, without any assumption, automatically estimates emotional intensity of the speaker and reproduces her ever-changing affective states by adjusting strength of facial unit activations. For example, in a happy speech, the mouth opens wider than normal, while other facial units are relaxed; or in a surprised state, both eyebrows raise higher. Experiments on a diverse audiovisual corpus of different actors across a wide range of emotional states show interesting and promising results of our approach. Being speaker-independent, our generalized model is readily applicable to various tasks in human-machine interaction and animation."
"Yanning Shen, M. Mardani, G. Giannakis",c73be41d605fa58aea8df5379d85724f2e5d77e1,Online Categorical Subspace Learning for Sketching Big Data with Misses,IEEE Transactions on Signal Processing,2017.0,14,"With the scale of data growing every day, reducing the dimensionality (a.k.a. sketching) of high-dimensional data has emerged as a task of paramount importance. Relevant issues to address in this context include the sheer volume of data that may consist of categorical observations, the typically streaming  format of acquisition, and the possibly missing entries. To cope with these challenges, this paper develops a novel categorical subspace learning approach to unravel the latent structure for three prominent categorical (bilinear) models, namely, Probit, Tobit, and Logit. The deterministic Probit and Tobit models treat data as quantized values of an analog-valued process lying in a low-dimensional subspace, while the probabilistic Logit model relies on low dimensionality of the data log-likelihood ratios. Leveraging the low intrinsic dimensionality of the sought models, a rank regularized maximum-likelihood estimator is devised, which is then solved recursively via alternating majorization-minimization to sketch high-dimensional categorical data “on the fly.” The resultant lightweight first-order algorithms entail highly parallelizable tasks per iteration. In addition, the quantization thresholds are also learned jointly with the subspace to enhance the predictive power of the sought models. Performance of the subspace iterates is analyzed for both infinite and finite data streams, where for the former asymptotic convergence to the stationary point set of the batch estimator is established, while for the latter sublinear regret bounds are derived for the empirical cost. Simulated tests with both synthetic and real-world datasets corroborate the merits of the novel schemes for real-time movie recommendation and chess-game classification."
"Yanghua Jin, Jiakai Zhang, Minjun Li, Yingtao Tian, Huachun Zhu",d1c72730b979ebc5df67b91ac2b481a8742b7e6c,Towards the High-quality Anime Characters Generation with Generative Adversarial Networks,,2017.0,13,"The automatic generation of anime characters offers an opportunity to bring a custom character into existence without professional skill. Besides, professionals may also take advantages of the automatic generation for inspiration on animation and game character design. however results from existing models [15, 18, 8, 22, 12] on anime image generation are blurred and distorted on an non-trivial frequency, thus generating industry-standard facial images for anime characters remains a challenge. In this paper, we propose a model that produces anime faces at high quality with promising rate of success with three-fold contributions: A clean dataset from Getchu, a suitable DRAGAN[10]-based SRResNet[11]like GAN model, and our general approach to training conditional model from image with estimated tags as conditions. We also make available a public accessible web interface."
"A. Jones, G. Kauffmann, R. D’Souza, D. Bizyaev, D. Law, L. Haffner, Y. Bah'e, B. Andrews, M. Bershady, J. Brownstein, K. Bundy, B. Cherinka, A. Diamond-Stanic, N. Drory, R. Riffel, S. Thomas, D. Wake, R. Yan, K. Zhang",ba8492388d7136511e7494022e282bb04c3d084c,"SDSS IV MaNGA: deep observations of extra-planar, diffuse ionized gas around late-type galaxies from stacked IFU spectra",,2017.0,13,"We have conducted a study of extra-planar diffuse ionized gas using the first year data from the MaNGA IFU survey. We have stacked spectra from 49 edge-on, late-type galaxies as a function of distance from the midplane of the galaxy. With this technique we can detect the bright emission lines Hα, Hβ, [O ii]λλ3726, 3729, [O iii]λ5007, [N ii]λλ6549, 6584, and [S ii]λλ6717, 6731 out to about 4 kpc above the midplane. With 16 galaxies we can extend this analysis out to about 9 kpc, i.e. a distance of ∼ 2 Re, vertically from the midplane. In the halo, the surface brightnesses of the [O ii] and Hα emission lines are comparable, unlike in the disk where Hα dominates. When we split the sample by specific star-formation rate, concentration index, and stellar mass, each subsample’s emission line surface brightness profiles and ratios differ, indicating that extra-planar gas properties can vary. The emission line surface brightnesses of the gas around high specific star-formation rate galaxies are higher at all distances, and the line ratios are closer to ratios characteristic of H ii regions compared with low specific star-formation rate galaxies. The less concentrated and lower stellar mass samples exhibit line ratios that are more like H ii regions at larger distances than their more concentrated and higher stellar mass counterparts. The largest difference between different subsamples occurs when the galaxies are split by stellar mass. We additionally infer that gas far from the midplane in more massive galaxies has the highest temperatures and steepest radial temperature gradients based on their [N ii]/Hα and [O ii]/Hα ratios between the disk and the halo."
"Tianbi Jiang, Gui-Song Xia, Qikai Lu, Weiming Shen",955844abfbf9d69d86e585e3e87ee1fd6e3e8c89,Retrieving Aerial Scene Images with Learned Deep Image-Sketch Features,Journal of Computer Science and Technology,2017.0,12,"This paper investigates the problem of retrieving aerial scene images by using semantic sketches, since the state-of-the-art retrieval systems turn out to be invalid when there is no exemplar query aerial image available. However, due to the complex surface structures and huge variations of resolutions of aerial images, it is very challenging to retrieve aerial images with sketches and few studies have been devoted to this task. In this article, for the first time to our knowledge, we propose a framework to bridge the gap between sketches and aerial images. First, an aerial sketch-image database is collected, and the images and sketches it contains are augmented to various levels of details. We then train a multi-scale deep model by the new dataset. The fully-connected layers of the network in each scale are finally connected and used as cross-domain features, and the Euclidean distance is used to measure the cross-domain similarity between aerial images and sketches. Experiments on several commonly used aerial image datasets demonstrate the superiority of the proposed method compared with the traditional approaches."
"Jing Huo, Wenbin Li, Y. Shi, Yang Gao, Hujun Yin",e8293b3be11cfa7b544a3c183d92a74a2c1c73ef,WebCaricature: a benchmark for caricature face recognition,ArXiv,2017.0,12,"Caricatures are facial drawings by artists with exaggeration on certain facial parts. The exaggerations are often beyond realism and yet the caricatures are still recognizable by humans. With the advent of deep learning, recognition performances by computers on real-world faces has become comparable to human performance even under unconstrained situations. However, there is still a gap in caricature recognition performance between computer and human. This is mainly due to the lack of publicly available caricature datasets of large scale. To facilitate the research in caricature recognition, a new caricature dataset is built. All the caricature images and face images were collected from the web.Compared with two existing datasets, this dataset is of larger size and has various artistic styles. We also offer evaluation protocols and present baseline performances on the dataset. Specifically, four evaluation protocols are provided: restricted and unrestricted caricature verifications, caricature to photo and photo to caricature face identifications. Based on the evaluation protocols, three face alignment methods together with five kinds of features and nine subspace and metric learning algorithms have been applied to provide the baseline performances on this dataset. Main conclusion is that there is still a space for improvement in caricature face recognition."
"Y. Zhang, Weiming Dong, Chongyang Ma, X. Mei, Ke Li, Feiyue Huang, Bao-Gang Hu, O. Deussen",dbf0d091d664119d63cdd5735d8880d0efb21d04,Data-Driven Synthesis of Cartoon Faces Using Different Styles,IEEE Transactions on Image Processing,2017.0,12,"This paper presents a data-driven approach for automatically generating cartoon faces in different styles from a given portrait image. Our stylization pipeline consists of two steps: an offline analysis step to learn about how to select and compose facial components from the databases; a runtime synthesis step to generate the cartoon face by assembling parts from a database of stylized facial components. We propose an optimization framework that, for a given artistic style, simultaneously considers the desired image-cartoon relationships of the facial components and a proper adjustment of the image composition. We measure the similarity between facial components of the input image and our cartoon database via image feature matching, and introduce a probabilistic framework for modeling the relationships between cartoon facial components. We incorporate prior knowledge about image-cartoon relationships and the optimal composition of facial components extracted from a set of cartoon faces to maintain a natural, consistent, and attractive look of the results. We demonstrate generality and robustness of our approach by applying it to a variety of portrait images and compare our output with stylized results created by artists via a comprehensive user study."
"M. Kuba, H. Sulzbach",b37bd9adb89369387290a4f477e1d51ced56588c,On martingale tail sums in affine two-color urn models with multiple drawings,J. Appl. Probab.,2017.0,12,"In two recent works, Kuba and Mahmoud (arXiv:1503.090691 and arXiv:1509.09053) introduced the family of two-color affine balanced Polya urn schemes with multiple drawings. We show that, in large-index urns (urn index between $1/2$ and $1$) and triangular urns, the martingale tail sum for the number of balls of a given color admits both a Gaussian central limit theorem as well as a law of the iterated logarithm. The laws of the iterated logarithm are new even in the standard model when only one ball is drawn from the urn in each step (except for the classical Polya urn model). Finally, we prove that the martingale limits exhibit densities (bounded under suitable assumptions) and exponentially decaying tails. Applications are given in the context of node degrees in random linear recursive trees and random circuits."
"James W. Hennessey, H. Liu, H. Winnemöller, Mira Dontcheva, N. Mitra",66bb520f7b96f1f624a9af919ee4e2c24175ec30,How2Sketch: generating easy-to-follow tutorials for sketching 3D objects,I3D,2017.0,12,"Accurately drawing 3D objects is difficult for untrained individuals, as it requires an understanding of perspective and its effects on geometry and proportions. Step-by-step tutorials break the complex task of sketching an entire object down into easy-to-follow steps that even a novice can follow. However, creating such tutorials requires expert knowledge and is time-consuming. As a result, the availability of tutorials for a given object or viewpoint is limited. How2Sketch (H2S) addresses this problem by automatically generating easy-to-follow tutorials for arbitrary 3D objects. Given a segmented 3D model and a camera viewpoint, H2S computes a sequence of steps for constructing a drawing scaffold comprised of geometric primitives, which helps the user draw the final contours in correct perspective and proportion. To make the drawing scaffold easy to construct, the algorithm solves for an ordering among the scaffolding primitives and explicitly makes small geometric modifications to the size and location of the object parts to simplify relative positioning. Technically, we formulate this scaffold construction as a single selection problem that simultaneously solves for the ordering and geometric changes of the primitives. We generate different tutorials on man-made objects using our method and evaluate how easily the tutorials can be followed with a user study."
"Kemal Tugrul Yesilbek, T. M. Sezgin",865e66cef980821824284964846c7d96c8e7cec6,Sketch recognition with few examples,Comput. Graph.,2017.0,11,"Abstract Sketch recognition is the task of converting hand-drawn digital ink into symbolic computer representations. Since the early days of sketch recognition, the bulk of the work in the field focused on building accurate recognition algorithms for specific domains, and well defined data sets. Recognition methods explored so far have been developed and evaluated using standard machine learning pipelines and have consequently been built over many simplifying assumptions. For example, existing frameworks assume the presence of a fixed set of symbol classes, and the availability of plenty of annotated examples. However, in practice, these assumptions do not hold. In reality, the designer of a sketch recognition system starts with no labeled data at all, and faces the burden of data annotation. In this work, we propose to alleviate the burden of annotation by building systems that can learn from very few labeled examples, and large amounts of unlabeled data. Our systems perform self-learning by automatically extending a very small set of labeled examples with new examples extracted from unlabeled sketches. The end result is a sufficiently large set of labeled training data, which can subsequently be used to train classifiers. We present four self-learning methods with varying levels of implementation difficulty and runtime complexities. One of these methods leverages contextual co-occurrence patterns to build verifiably more diverse set of training instances. Rigorous experiments with large sets of data demonstrate that this novel approach based on exploiting contextual information leads to significant leaps in recognition performance. As a side contribution, we also demonstrate the utility of bagging for sketch recognition in imbalanced data sets with few positive examples and many outliers."
"Rei Narita, Koki Tsubota, T. Yamasaki, K. Aizawa",5a1772b31e2ce7d28064f577d41f738552bc182e,Sketch-Based Manga Retrieval Using Deep Features,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,10,"Manga, Japanese comics, are globally popular, and the digital manga (e-manga) market is growing year by year. E-manga has a limitation in its search methodology: it is currently restricted to a keyword search of authors and titles. In this paper, we present an intuitive sketch-based manga retrieval method using deep features. We propose a framework to extract feature vectors from sketches and manga images by two differently trained CNNs: The two CNNs are trained on a large number of manga face images with and without screentone. The deep features are switched according to a query, that is, a sketch drawing or a crop of a manga image. We built an interactive retrieval system that has a browser interface. We evaluated its retrieval accuracy by using sketches and manga images. The proposed method significantly outperformed state-of-the art sketch-based manga retrieval using handcrafted features."
"Yongyi Lu, Shangzhe Wu, Yu-Wing Tai, C. Tang",af6af58ba12920762638e1d0b8310a0d9961b7be,Sketch-to-Image Generation Using Deep Contextual Completion,ArXiv,2017.0,10,"When the input to pix2pix translation is a badly drawn sketch, the output follows the input edges due to the strict alignment imposed by the translation process. In this paper we propose sketch-to-image generation, where the output edges do not necessarily follow the input edges. We address the image generation problem using a novel joint image completion approach, where the sketch provides the image context for completing, or generating the output image. We train a deep generative model to learn the joint distribution of sketch and the corresponding image by using joint images. Our deep contextual completion approach has several advantages. First, the simple joint image representation allows for simple and effective definition of losses in the same joint image-sketch space, which avoids complicated issues in cross-domain learning. Second, while the output is related to its input overall, the generated features exhibit more freedom in appearance and do not strictly align with the input features. Third, from the joint image's point of view, image and sketch are of no difference, thus exactly the same deep joint image completion network can be used for image-to-sketch generation. Experiments evaluated on three different datasets show that the proposed approach can generate more realistic images than the state-ofthe- arts on challenging inputs and generalize well on common categories."
"Y. Chen, Yu-Kun Lai, Yongjin Liu",a329c2ef83674487fdaff7fd6513098bc3505537,Transforming photos to comics using convolutional neural networks,2017 IEEE International Conference on Image Processing (ICIP),2017.0,10,"In this paper, inspired by Gatys's recent work, we propose a novel approach that transforms photos to comics using deep convolutional neural networks (CNNs). While Gatys's method that uses a pre-trained VGG network generally works well for transferring artistic styles such as painting from a style image to a content image, for more minimalist styles such as comics, the method often fails to produce satisfactory results. To address this, we further introduce a dedicated comic style CNN, which is trained for classifying comic images and photos. This new network is effective in capturing various comic styles and thus helps to produce better comic stylization results. Even with a grayscale style image, Gatys's method can still produce colored output, which is not desirable for comics. We develop a modified optimization framework such that a grayscale image is guaranteed to be synthesized. To avoid converging to poor local minima, we further initialize the output image using grayscale version of the content image. Various examples show that our method synthesizes better comic images than the state-of-the-art method."
"Jianjun Lei, Kaifu Zheng, Hua Zhang, Xiaochun Cao, N. Ling, Y. Hou",edfa8dbe19ca6605b516612dddee123606743ccb,Sketch based image retrieval via image-aided cross domain learning,2017 IEEE International Conference on Image Processing (ICIP),2017.0,9,"Existing methods on sketch based image retrieval (SBIR) are usually based on the hand-crafted features whose ability of representation is limited. In this paper, we propose a sketch based image retrieval method via image-aided cross domain learning. First, the deep learning model is introduced to learn the discriminative features. However, it needs a large number of images to train the deep model, which is not suitable for the sketch images. Thus, we propose to extend the sketch training images via introducing the real images. Specifically, we initialize the deep models with extra image data, and then extract the generalized boundary from real images as the sketch approximation. The using of generalized boundary is under the assumption that their domain is similar with sketch domain. Finally, the neural network is fine-tuned with the sketch approximation data. Experimental results on Flicker15 show that the proposed method has a strong ability to link the associated image-sketch pairs and the results outperform state-of-the-arts methods."
"Tianbi Jiang, Gui-Song Xia, Qikai Lu",673bd00caccb10a7e91f35d9d5f4ded1c6bcad95,Sketch-based aerial image retrieval,2017 IEEE International Conference on Image Processing (ICIP),2017.0,9,"Notwithstanding aerial image retrieval is an important and obligatory task, existing retrieval systems lose their efficiency when there is no available aerial image used as the exemplar query. In this paper, we take free-hand sketches into consideration and address the problem of sketch-based aerial image retrieval. This is an extremely challenging task due to the complex surface structures and huge variations of resolutions of aerial images, and few works have been devoted to it. For the first time to our knowledge, we propose a framework to bridge the gap between sketches and aerial images. Specifically, an aerial sketch-image dataset is first collected. Sketches and aerial images are augmented to varied levels of details and used to train a multi-scale deep hierarchical model. The fully-connected layers of the deep model are used as cross-domain features, and the similarity between aerial images and sketches is measured by the Euclidean distance. Experiments on several public aerial image datasets demonstrate the efficiency and superiority of the proposed method."
"Q. Guo, Ce Zhu, Zhiqiang Xia, Z. Wang, Y. Liu",ccffab56bfb563b87b6e1ec11cfbac9c24207590,Attribute-controlled face photo synthesis from simple line drawing,2017 IEEE International Conference on Image Processing (ICIP),2017.0,9,"Face photo synthesis from simple line drawing is a one-to-many task as simple line drawing merely contains the contour of human face. Previous exemplar-based methods are over-dependent on the datasets and are hard to generalize to complicated natural scenes. Recently, several works utilize deep neural networks to increase the generalization, but they are still limited in the controllability of the users. In this paper, we propose a deep generative model to synthesize face photo from simple line drawing controlled by face attributes such as hair color and complexion. In order to maximize the controllability of face attributes, an attribute-disentangled variational auto-encoder (AD-VAE) is firstly introduced to learn latent representations disentangled with respect to specified attributes. Then we conduct photo synthesis from simple line drawing based on AD-VAE. Experiments show that our model can well disentangle the variations of attributes from other variations of face photos and synthesize detailed photorealistic face images with desired attributes. Regarding background and illumination as the style and human face as the content, we can also synthesize face photos with the target style of a style photo."
"J. Coër, H. Laurent, M. C. Oliveira, P. Manach, L. Menezes",3efde2ab2065ded122b5b49afd689f5890c5d7eb,Detailed experimental and numerical analysis of a cylindrical cup deep drawing: Pros and cons of using solid-shell elements,,2017.0,9,"The Swift test was originally proposed as a formability test to reproduce the conditions observed in deep drawing operations. This test consists on forming a cylindrical cup from a circular blank, using a flat bottom cylindrical punch and has been extensively studied using both analytical and numerical methods. This test can also be combined with the Demeri test, which consists in cutting a ring from the wall of a cylindrical cup, in order to open it afterwards to measure the springback. This combination allows their use as benchmark test, in order to improve the knowledge concerning the numerical simulation models, through the comparison between experimental and numerical results. The focus of this study is the experimental and numerical analyses of the Swift cup test, followed by the Demeri test, performed with an AA5754-O alloy at room temperature. In this context, a detailed analysis of the punch force evolution, the thickness evolution along the cup wall, the earing profile, the strain paths and their evolution and the ring opening is performed. The numerical simulation is performed using the finite element code ABAQUS, with solid and solid-shell elements, in order to compare the computational efficiency of these type of elements. The results show that the solid-shell element is more cost-effective than the solid, presenting global accurate predictions, excepted for the thinning zones. Both the von Mises and the Hill48 yield criteria predict the strain distributions in the final cup quite accurately. However, improved knowledge concerning the stress states is still required, because the Hill48 criterion showed difficulties in the correct prediction of the springback, whatever the type of finite element adopted."
"Gangjoon Yoon, S. Yoon",6f366326ac400ad388c205394f2c176fdc58a2bb,Sketch-based 3D object recognition from locally optimized sparse features,Neurocomputing,2017.0,8,"We propose a user-drawn sketch image-based three-dimensional (3D) object recognition method, which automatically learns and optimizes features by using unsupervised algorithm to overcome the difficulty of extracting robust features from the black and white sketch image. As a preprocessing task, both the sketch image database and the projected image database of the 3D objects are built by learning with various user-drawn sketch images and suggestive contour images of the 3D objects respectively, and each sketch image is mapped to the most similar projected database image by measuring the similarity. This enables us to avoid a direct comparison of the sketch query and the projected images of the 3D objects and to use the learned robust sparse features of the trained sketch images in the sketch database, compensating for the difference between the user-drawn sketch image and synthesized images of the 3D mesh model. The locally-enforced feature optimization of the local and global features of the database images reduces the error and retains the feature properties. Furthermore, we quantitatively compared the proposed method to previous remarkable object recognition approaches. Numerous experiments on various challenging 3D objects and sketch images demonstrate that the proposed methodology performs favorably against several state-of-the-art algorithms."
"Jing Huo, Yang Gao, Y. Shi, Hujun Yin",0d40a5118987c260934a2b7fb4a70c8aaba2e9c3,Variation Robust Cross-Modal Metric Learning for Caricature Recognition,ACM Multimedia,2017.0,8,"In this paper, a variation robust cross-modal metric learning (VR-CM2L) method is proposed for caricature recognition. The goal of caricature recognition is to match a caricature with a photo. This recognition process needs to deal with all kind of variations including different modalities, facial appearance exaggerations, changes in viewpoint, expression, and illumination, etc. All these variations lead to severe misalignment between features of caricatures and photos. To deal with these problems, a specifically designed facial landmark based feature extraction scheme is proposed, where features of caricatures and photos are extracted using different feature extraction steps. At each facial landmark, features of photos are extracted with fixed viewing angle and scale, while features of caricatures are extracted with different scales and viewing angles. To measure the similarity of these features, multiple cross-modal metrics are learned at different facial landmarks in one optimization framework to guarantee global optimum. As the measured features are from two modalities (caricature and photo), cross-modal metric is used to remove modality variations. Pooling at distance level is used during metric optimization to further align the features of caricatures and photos. The introduced pooling step makes the learning method more robust to variations. Experimental results demonstrate the effectiveness of the proposed method on two caricature datasets with various variations."
"F. Gao, Shengjie Shi, Jun Yu, Qingming Huang",7b6aadee5d287962e788598361cd02f8292b1e3e,Composition-aided Sketch-realistic Portrait Generation,ArXiv,2017.0,8,"Sketch portrait generation is of wide applications including digital entertainment and law enforcement. Despite the great progress achieved by existing face sketch generation methods, they mostly yield blurred effects and great deformation over various facial parts. In order to tackle this challenge, we propose a novel composition-aided generative adversarial network (CA-GAN) for sketch portrait generation. First, we utilize paired inputs including a face photo and the corresponding pixel-wise face labels for generating the portrait. Second, we propose an improved pixel loss, termed compositional loss, to focus training on hard-generated components and delicate facial structures. Moreover, we use stacked CA-GANs (stack-CA-GAN) to further rectify defects and add compelling details. Experimental results show that our method is capable of generating identity-preserving, sketch-realistic, and visually comfortable sketch portraits over a wide range of challenging data, and outperforms existing methods. Besides, our methods show considerable generalization ability."
"Evan Byrne, R. Gribonval, Philip Schniter",b7f4c123b3fbb01259a5d05a08dfae634cd5ae46,Sketched clustering via hybrid approximate message passing,"2017 51st Asilomar Conference on Signals, Systems, and Computers",2017.0,7,"In sketched clustering, the dataset is first sketched down to a vector of modest size, from which the cluster centers are subsequently extracted. The goal is to perform clustering more efficiently than with methods that operate on the full training data, such as k-means++. For the sketching methodology recently proposed by Keriven, Gribonval, et al., which can be interpreted as a random sampling of the empirical characteristic function, we propose a cluster recovery algorithm based on simplified hybrid generalized approximate message passing (SHyGAMP). Numerical experiments suggest that our approach is more efficient than the state-of-the-art sketched clustering algorithms (in both computational and sample complexity) and more efficient than k-means++ in certain regimes."
"Fei Huang, Yong Cheng, Cheng Jin, Yuejie Zhang, T. Zhang",9a5af8af77c32068ad590de11a44b01fe9ce5e39,Deep Multimodal Embedding Model for Fine-grained Sketch-based Image Retrieval,SIGIR,2017.0,7,"Fine-grained Sketch-based Image Retrieval (Fine-grained SBIR), which uses hand-drawn sketches to search the target object images, has been an emerging topic over the last few years. The difficulties of this task not only come from the ambiguous and abstract characteristics of sketches with less useful information, but also the cross-modal gap at both visual and semantic level. However, images on the web are always exhibited with multimodal contents. In this paper, we consider Fine-grained SBIR as a cross-modal retrieval problem and propose a deep multimodal embedding model that exploits all the beneficial multimodal information sources in sketches and images. In our experiment with large quantity of public data, we show that the proposed method outperforms the state-of-the-art methods for Fine-grained SBIR."
"D. Varga, C. Szabó, T. Szirányi",4673e98fe03f969f9cc110b40405b1d25ed21ea4,Automatic Cartoon Colorization Based on Convolutional Neural Network,CBMI,2017.0,7,"This paper deals with automatic cartoon colorization. This is a hard issue, since it is an ill-posed problem that usually requires user intervention to achieve high quality. Motivated by the recent successes in natural image colorization based on deep learning techniques, we investigate the colorization problem at the cartoon domain using Convolutional Neural Network. To our best knowledge, no existing papers or research studies address this problem using deep learning techniques. Here we investigate a deep Convolutional Neural Network based automatic color filling method for cartoons."
"H. Li, Hefeng Wu, Xiangjian He, Shujin Lin, Ruomei Wang, Xiaonan Luo",c98b4c9a952a4be1ffceb98fdcef66f004a74eba,Multi-view pairwise relationship learning for sketch based 3D shape retrieval,2017 IEEE International Conference on Multimedia and Expo (ICME),2017.0,7,"Recent progress in sketch-based 3D shape retrieval creates a novel and user-friendly way to explore massive 3D shapes on the Internet. However, current methods on this topic rely on designing invariant features for both sketches and 3D shapes, or complex matching strategies. Therefore, they suffer from problems like arbitrary drawings and inconsistent viewpoints. To tackle this problem, we propose a probabilistic framework based on Multi-View Pairwise Relationship (MVPR) learning. Our framework includes multiple views of 3D shapes as the intermediate layer between sketches and 3D shapes, and transforms the original retrieval problem into the form of inferring pairwise relationship between sketches and views. We accomplish pairwise relationship inference by a novel MVPR net, which can automatically predict and merge the pairwise relationships between a sketch and multiple views, thus freeing us from exhaustively selecting the best view of 3D shapes. We also propose to learn robust features for sketches and views via fine-tuning pre-trained networks. Extensive experiments on a large dataset demonstrate that the proposed method can outperform state-of-the-art methods significantly."
"Shuang Wu, Hua Yang, Shibao Zheng, Hang Su, Qin Zhou, X. Lu",ca3ff5775a5e63249850ea3b20585b1faa857c72,Motion sketch based crowd video retrieval,Multimedia Tools and Applications,2017.0,7,"Crowd video retrieval with desired motion flow segmentation is an important problem in surveillance video management, e.g., video indexing and browsing, especially in the age of big data. In this paper, we address this issue from the motion-level perspective by using hand-drawn sketches as queries. Motion sketch based crowd video retrieval naturally suffers from challenges in crowd motion representation and similarity measurement. To tackle them, we propose to (1) leverage the motion structure coding algorithm for motion-level video indexing and hand-drawn sketch representation and (2) exploit distance metric fusion strategy incorporated with Ranking SVM for measuring the relevant degree between a sketch query and crowd videos. Specifically, for video indexing, motion decomposition is utilized to separate sub-motion vector fields with typical patterns from a set of optical flows. Then, the motion-level descriptors of the vector fields are computed and stored in an index database. To represent motion sketches, we propose a mechanism by vectorizing the sketches followed by motion structure coding. In the retrieval stage, we first compute the pairwise distance with different metrics between a new sketch query and crowd videos, and then stack them into a feature vector as the input of the Ranking SVM algorithm. Finally, we use the learned retrieval model to predict the ranking score of each crowd video in the database. Experimental results on the publicly available crowd datasets show the robustness and effectiveness of the proposed sketch based crowd video retrieval system."
"Conghui Hu, Da Li, Yi-Zhe Song, Timothy M. Hospedales",4ef4cfe5a74b4f2d1eab880367b296275566764f,Now You See Me: Deep Face Hallucination for Unviewed Sketches,BMVC,2017.0,7,"Face hallucination has been well studied in the last decade because of its useful applications in law enforcement and entertainment. Promising results on the problem of sketch-photo face hallucination have been achieved with classic, and increasingly deep learning-based methods. However, synthesized photos still lack the crisp fidelity of real photos. More importantly, good results have primarily been demonstrated on very constrained datasets where the style variability is very low, and crucially the sketches are perfectly align-able traces of the ground-truth photos. However, realistic applications in entertainment or law enforcement require working with more unconstrained sketches drawn from memory or description, which are not rigidly align-able. In this paper, we develop a new deep learning approach to address these settings. Our image-image regression network is trained with a combination of content and adversarial losses to generate crisp photorealistic images, and it contains an integrated spatial transformer network to deal with non-rigid alignment between the domains. We evaluate face synthesis on classic constrained, as well as unviewed, benchmarks namely CUHK, MGDB, and FSMD. The results qualitatively and quantitatively outperform existing approaches."
"Qi Jia, Meiyu Yu, Xin Fan, Haojie Li",579fe3f57c75ffb64ea6e611f1665b9d774b0e38,Sequential Dual Deep Learning with Shape and Texture Features for Sketch Recognition,ArXiv,2017.0,7,"Recognizing freehand sketches with high arbitrariness is greatly challenging. Most existing methods either ignore the geometric characteristics or treat sketches as handwritten characters with fixed structural ordering. Consequently, they can hardly yield high recognition performance even though sophisticated learning techniques are employed. In this paper, we propose a sequential deep learning strategy that combines both shape and texture features. A coded shape descriptor is exploited to characterize the geometry of sketch strokes with high flexibility, while the outputs of constitutional neural networks (CNN) are taken as the abstract texture feature. We develop dual deep networks with memorable gated recurrent units (GRUs), and sequentially feed these two types of features into the dual networks, respectively. These dual networks enable the feature fusion by another gated recurrent unit (GRU), and thus accurately recognize sketches invariant to stroke ordering. The experiments on the TU-Berlin data set show that our method outperforms the average of human and state-of-the-art algorithms even when significant shape and appearance variations occur."
"Samet Hicsonmez, Nermin Samet, Fadime Sener, P. D. Sahin",dd0b9f98ff795db45fe951734c73f5628322afc0,DRAW: Deep Networks for Recognizing Styles of Artists Who Illustrate Children's Books,ICMR,2017.0,7,"This paper is motivated from a young boy's capability to recognize an illustrator's style in a totally different context. In the book ""We are All Born Free"" [1], composed of selected rights from the Universal Declaration of Human Rights interpreted by different illustrators, the boy was surprised to see a picture similar to the ones in the ""Winnie the Witch"" series drawn by Korky Paul (Figure [1]). The style was noticeable in other characters of the same illustrator in different books as well. The capability of a child to easily spot the style was shown to be valid for other illustrators such as Axel Scheffler and Debi Gliori. The boy's enthusiasm let us to start the journey to explore the capabilities of machines to recognize the style of illustrators. We collected pages from children's books to construct a new illustrations dataset consisting of about 6500 pages from 24 artists. We exploited deep networks for categorizing illustrators and with around 94% classification performance our method over-performed the traditional methods by more than 10%. Going beyond categorization we explored transferring style. The classification performance on the transferred images has shown the ability of our system to capture the style. Furthermore, we discovered representative illustrations and discriminative stylistic elements."
"Jun Yu, Shengjie Shi, F. Gao, D. Tao, Qingming Huang",1c4e70a7ed70cb068d69191e43356ed8969ccb00,Composition-Aided Face Photo-Sketch Synthesis,,2017.0,6,
"Yuusuke Kataoka, Takashi Matsubara, K. Uehara",e671983bb6fef8509a35ee897e50d632bcf95c56,Automatic manga colorization with color style by generative adversarial nets,"2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",2017.0,6,"Many comic books are now published as digital books, which easily provide color contents compared to the physical books. The motivation of automatic colorization of comic books now arises. Previous studies colorize sketches without other clues or with spatial color annotations. They are expected to reduce workloads of comic artists but still require spatial color annotations for desirable colorizations. This study introduces a color style information and combines it with conditional adversarially learned inference. The experimental results demonstrate that the objects are painted with colors depending on the color style information and that the color style information extracted from a color image supports to painting an object with a desirable color."
"Fei Wang, Shujin Lin, Xiaonan Luo, Hefeng Wu, Ruomei Wang, Fan Zhou",7de9f706863ff95943b0ee857bb646d795726f69,A Data‐Driven Approach for Sketch‐Based 3D Shape Retrieval via Similar Drawing‐Style Recommendation,Comput. Graph. Forum,2017.0,6,"Sketching is a simple and natural way of expression and communication for humans. For this reason, it gains increasing popularity in human computer interaction, with the emergence of multitouch tablets and styluses. In recent years, sketch‐based interactive methods are widely used in many retrieval systems. In particular, a variety of sketch‐based 3D model retrieval works have been presented. However, almost all of these works focus on directly matching sketches with the projection views of 3D models, and they suffer from the large differences between the sketch drawing and the views of 3D models, leading to unsatisfying retrieval results. Therefore, in this paper, during the matching procedure in the retrieval, we propose to match the sketch with each 3D model from historical users instead of projection views. Yet since the sketches between the current user and the historical users can have big difference, we also aim to handle users' personalized deviations and differences. To this end, we leverage recommendation algorithms to estimate the drawing style characteristic similarity between the current user and historical users. Experimental results on the Large Scale Sketch Track Benchmark(SHREC14LSSTB) demonstrate that our method outperforms several state‐of‐the‐art methods."
"S. Kasiviswanathan, Nina Narodytska, Hongxia Jin",fa4d6f83ac667113c636a273175abc1fae2b7819,Deep Neural Network Approximation using Tensor Sketching,ArXiv,2017.0,6,"Deep neural networks are powerful learning models that achieve state-of-the-art performance on many computer vision, speech, and language processing tasks. In this paper, we study a fundamental question that arises when designing deep network architectures: Given a target network architecture can we design a smaller network architecture that approximates the operation of the target network? The question is, in part, motivated by the challenge of parameter reduction (compression) in modern deep neural networks, as the ever increasing storage and memory requirements of these networks pose a problem in resource constrained environments. 
In this work, we focus on deep convolutional neural network architectures, and propose a novel randomized tensor sketching technique that we utilize to develop a unified framework for approximating the operation of both the convolutional and fully connected layers. By applying the sketching technique along different tensor dimensions, we design changes to the convolutional and fully connected layers that substantially reduce the number of effective parameters in a network. We show that the resulting smaller network can be trained directly, and has a classification accuracy that is comparable to the original network."
"J. Vie, F. Yger, Ryan Lahfa, Basile Clément, Kévin Cocchi, Thomas Chalumeau, H. Kashima",8210470966ca5e5c9679cd4d7ca478699c3d3988,Using Posters to Recommend Anime and Mangas in a Cold-Start Scenario,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,6,"Item cold-start is a classical issue in recommender systems that affects anime and manga recommendations as well. This problem can be framed as follows: how to predict whether a user will like a manga that received few ratings from the community? Content-based techniques can alleviate this issue but require extra information, that is usually expensive to gather. In this paper, we use a deep learning technique, Illustration2Vec, to easily extract tag information from the manga and anime posters (e.g., sword, or ponytail). We propose BALSE (Blended Alternate Least Squares with Explanation), a new model for collaborative filtering, that benefits from this extra information to recommend mangas. We show, using real data from an online manga recommender system called Mangaki, that our model improves substantially the quality of recommendations, especially for less-known manga, and is able to provide an interpretation of the taste of the users."
"Ting Han, David Schlangen",ce08c90190a592e2f45ca3ab80c50865c39e1607,Draw and Tell: Multimodal Descriptions Outperform Verbal- or Sketch-Only Descriptions in an Image Retrieval Task,IJCNLP,2017.0,5,"While language conveys meaning largely symbolically, actual communication acts typically contain iconic elements as well: People gesture while they speak, or may even draw sketches while explaining something. Image retrieval prima facie seems like a task that could profit from combined symbolic and iconic reference, but it is typically set up to work either from language only, or via (iconic) sketches with no verbal contribution. Using a model of grounded language semantics and a model of sketch-to-image mapping, we show that adding even very reduced iconic information to a verbal image description improves recall. Verbal descriptions paired with fully detailed sketches still perform better than these sketches alone. We see these results as supporting the assumption that natural user interfaces should respond to multimodal input, where possible, rather than just language alone."
"Zheqi He, Yafeng Zhou, Yongtao Wang, Zhi Tang",5763c557a2b2c387f4254eb6b588ef8758735476,SReN: Shape Regression Network for Comic Storyboard Extraction,AAAI,2017.0,5,"The goal of storyboard extraction is to decompose the comic image into storyboards, which is the fundamental step of comic image understanding and producing digital comic documents suitable for mobile reading. Most of existing approaches are based on hand crafted low-level visual patters like edge segments and line segments, which do not capture high-level vision information. To overcome this drawback of the existing approaches, we propose a novel architecture based on deep convolutional neural network, named Shape Regression Network (SReN), to detect storyboards within comic images. Firstly, we use Fast R-CNN to generate rectangle bounding boxes as storyboard proposals. Then we train a deep neural network to predict quadrangles for these proposals. Unlike existing object detection methods which only output rectangle bounding boxes, SReN can produce more precise quadrangle bounding boxes. Experimental results on 7382 comic pages, demonstrate that SReN outperforms the state-of-the-art methods by more than 10% in terms of F1score and page correction rate."
"Ravi Kiran Sarvadevabhatla, Sudharshan Suresh, R. Venkatesh Babu",062ebea1c4861cf90f18c369b3d729b79b076f8f,Object Category Understanding via Eye Fixations on Freehand Sketches,IEEE Transactions on Image Processing,2017.0,5,"The study of eye gaze fixations on photographic images is an active research area. In contrast, the image sub-category of freehand sketches has not received as much attention for such studies. In this paper, we analyze the results of a free-viewing gaze fixation study conducted on 3904 freehand sketches distributed across 160 object categories. Our analysis shows that fixation sequences exhibit marked consistency within a sketch, across sketches of a category and even across suitably grouped sets of categories. This multi-level consistency is remarkable given the variability in depiction and extreme image content sparsity that characterizes hand-drawn object sketches. In this paper, we show that the multi-level consistency in the fixation data can be exploited to 1) predict a test sketch’s category given only its fixation sequence and 2) build a computational model which predicts part-labels underlying fixations on objects. We hope that our findings motivate the community to deem sketch-like representations worthy of gaze-based studies vis-a-vis photographic images."
"A. Igamberdiev, Wouter Meulemans, André Schulz",ac9b78349d677666b4f062a0e9999a23e0554e94,Drawing Planar Cubic 3-Connected Graphs with Few Segments: Algorithms & Experiments,J. Graph Algorithms Appl.,2017.0,5,"A drawing of a graph can be understood as an arrangement of geometric objects. In the most natural setting the arrangement is formed by straight-line segments. Every cubic planar 3-connected graph with n n vertices has such a drawing with only n/2+3 n/2+3 segments, matching the lower bound. This result is due to Mondal et al. [J. of Comb. Opt., 25], who gave an algorithm for constructing such drawings. We introduce two new algorithms that also produce drawings with n/2+3 n/2+3 segments. One algorithm is based on a sequence of dual edge contractions, the other is based on a recursion of nested cycles. We also show a flaw in the algorithm of Mondal et al. and present a fix for it. We then compare the performance of these three algorithms by measuring angular resolution, edge length and face aspect ratio of the constructed drawings. We observe that the corrected algorithm of Mondal et al. mostly outperforms the other algorithms, especially in terms of angular resolution. However, the new algorithms perform better in terms of edge length and minimal face aspect ratio."
"Yang Song, Zhifei Zhang, H. Qi",4589d6bbb3186fc001ea2a42ae1ea2718edba915,Recursive Cross-Domain Face/Sketch Generation from Limited Facial Parts,ArXiv,2017.0,5,"We start by asking an interesting yet challenging question, “If a large proportion (e.g., more than 90% as shown in Fig. 1) of the face/sketch is missing, can a realistic whole face sketch/image still be estimated?” Existing face completion and generation methods either do not conduct domain transfer learning or can not handle large missing area. For example, the inpainting approach tends to blur the generated region when the missing area is large (i.e., more than 50%). In this paper, we exploit the potential of deep learning networks in filling large missing region (e.g., as high as 95% missing) and generating realistic faces with high-fidelity in cross domains. We propose the recursive generation by bidirectional transformation networks (rBTN) that recursively generates a whole face/sketch from a small sketch/face patch. The large missing area and the cross domain challenge make it difficult to generate satisfactory results using a unidirectional cross-domain learning structure. On the other hand, a forward and backward bidirectional learning between the face and sketch domains would enable recursive estimation of the missing region in an incremental manner (Fig. 1) and yield appealing results. r-BTN also adopts an adversarial constraint to encourage the generation of realistic faces/sketches. Extensive experiments have been conducted to demonstrate the superior performance from r-BTN as compared to existing potential solutions."
"D. Lee, John Lee, Tarique Siddiqui, Jaewoo Kim, K. Karahalios, Aditya G. Parameswaran",f5b3ab9b64ccc9a704e3de0e5e2c6e5ef2578bef,Accelerating Scientific Data Exploration via Visual Query Systems,ArXiv,2017.0,5,"The increasing availability of rich and complex data in a variety of scientific domains poses a pressing need for tools to enable scientists to rapidly make sense of and gather insights from data. One proposed solution is to design visual query systems (VQSs) that allow scientists to search for desired patterns in their datasets. While many existing VQSs promise to accelerate exploratory data analysis by facilitating this search, they are unfortunately not widely used in practice. Through a year-long collaboration with scientists in three distinct domains---astronomy, genetics, and material science---we study the impact of various features within VQSs that can aid rapid visual data analysis, and how VQSs fit into a scientists' analysis workflow. Our findings offer design guidelines for improving the usability and adoption of next-generation VQSs, paving the way for VQSs to be applied to a variety of scientific domains."
"Bingwen Jin, Songhua Xu, Weidong Geng",89a8e2566ff10a62011b43ccb784e3b751aa29c3,Learning to sketch human facial portraits using personal styles by case-based reasoning,Multimedia Tools and Applications,2017.0,4,"This paper employs case-based reasoning (CBR) to capture the personal styles of individual artists and generate the human facial portraits from photos accordingly. For each human artist to be mimicked, a series of cases are firstly built-up from her/his exemplars of source facial photo and hand-drawn sketch, and then its stylization for facial photo is transformed as a style-transferring process of iterative refinement by looking-for and applying best-fit cases in a sense of style optimization. Two models, fitness evaluation model and parameter estimation model, are learned for case retrieval and adaptation respectively from these cases. The fitness evaluation model is to decide which case is best-fitted to the sketching of current interest, and the parameter estimation model is to automate case adaptation. The resultant sketch is synthesized progressively with an iterative loop of retrieval and adaptation of candidate cases until the desired aesthetic style is achieved. To explore the effectiveness and advantages of the novel approach, we experimentally compare the sketch portraits generated by the proposed method with that of a state-of-the-art example-based facial sketch generation algorithm as well as a couple commercial software packages. The comparisons reveal that our CBR based synthesis method for facial portraits is superior both in capturing and reproducing artists’ personal illustration styles to the peer methods."
"H. Zhang, C. Zhang, Ming Wu",2921dbe59e26ed57eaf65b174dab62457766c5d7,Sketch-based cross-domain image retrieval via heterogeneous network,2017 IEEE Visual Communications and Image Processing (VCIP),2017.0,3,"The development of image diversity has led multiple fields' application of cross-domain image retrieval. In this paper, we propose a heterogeneous dual network (two different networks) based on sketches and images. End-to-end cross-domain image retrieval is realized by limiting the similarity of features extracted from the two networks through the method of combining the contrastive loss with the triplet ranking loss. We also study how the order of drawings affects the sketch retrieval. Compared to the Siamese network, we avoid edge extraction for preprocessing, and the effect of fine-grained retrieval is further enhanced."
"Yen-Cheng Liu, Wei-Chen Chiu, Sheng-De Wang, Yu-Chiang Frank Wang",14a8f79ede14be602b40aa1cba4498e811ab6a9e,Domain-Adaptive generative adversarial networks for sketch-to-photo inversion,2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP),2017.0,3,"Generating photo-realistic images from multiple style sketches is one of challenging tasks in image synthesis with important applications such as facial composite for suspects. While machine learning techniques have been applied for solving this problem, the requirement of collecting sketch and face photo image pairs would limit the use of the learned model for rendering sketches of different styles. In this paper, we propose a novel deep learning model of Domain-adaptive Generative Adversarial Networks (DA-GAN). The design of DA-GAN performs cross-style sketch-to-photo inversion, which mitigates the difference across input sketch styles without the need to collect a large number of sketch and face image pairs for training purposes. In experiments, we show that our method is able to produce satisfactory results as well as performing favorably against state-of-the-art approaches."
"Yuki Daiku, Olivier Augereau, M. Iwata, K. Kise",c30836156326bbabccc928e47fb3cfb74e9fe9ff,Comic Story Analysis Based on Genre Classification,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017.0,3,"People who are reading comics are interested not only by the estheticism of the graphics but also by interesting stories. Therefore, understanding the detail of comic story is an important step to build comic retrieval systems based on readers' interest. As a method of understanding comic story, we propose to convert comic story into a novel formatted narrative structure, which uses comic genres as the representation of the contents of story. Each page of a comic volume is classified into a genre by using convolutional neural network. Generally, in machine learning, labeling ground truth on a large number of training samples is necessary, which costs time and money. In this paper, we propose a story analysis method which can describe a comic story as the sequence of genres with relatively low manual cost. The experimental results show the effectiveness of our proposed method."
"Fei Huang, Cheng Jin, Yuejie Zhang, T. Zhang",c0d9cf2be13788b8e91a3b4ffdc74e33a0ef8216,Towards sketch-based image retrieval with deep cross-modal correlation learning,2017 IEEE International Conference on Multimedia and Expo (ICME),2017.0,3,"A novel scheme with deep cross-modal correlation learning is developed in this paper to facilitate more effective Sketch-based Image Retrieval (SBIR) for large-scale annotated images. It integrates the deep multimodal feature generation, deep cross-modal correlation learning and similarity search optimization through mining all the beneficial multimodal information sources in sketches and images, which can be treated as an inter-related correlation distribution over deep representations of sketches and images. Very positive results were obtained in our experiments using a large quantity of public data."
"Krzysztof Pietroszek, Phuc Pham, Sophia Rose, Liudmila Tahai, I. Humer, C. Eckhardt",86adfddc263b6f6f7c504fa7d4c75cb228f529c1,Real-time avatar animation synthesis from coarse motion input,VRST,2017.0,2,"We present an animation synthesis technique that produces high quality avatar animation from coarse or incomplete motion input by matching, in real-time, the input against thousands of high-quality pre-recorded motion capture templates. The technique uses subsequence multivariate Quaternion Dynamic Time Warping with the angle between quaternions as a distance measure. Our implementation of the technique using compute shaders shows performance gains orders of magnitude greater than the state-of-the-art DTW implementations."
"N. Wang, Shengchuan Zhang, Chunlei Peng, J. Li, Xinbo Gao",9369371172a7fc16517eed519f81e7880a87289f,Face Sketch Recognition via Data-Driven Synthesis,Handbook of Biometrics for Forensic Science,2017.0,2,"In some real-world scenarios, there does not always exist a normal photo for face recognition or retrieval purpose, e.g. suspect searching for law enforcement. Under the circumstances, a sketch drawn by the artist is usually taken as the substitute for matching with the mug shot photos collected by the police office. However, due to the great discrepancy of the texture presentation between sketches and photos, common face recognition methods achieve limited performance on this task. In order to shrink this gap, sketches can be transformed to photos relying on some machine learning techniques and then synthesized photos are utilized to match with mug shot photos. Alternatively, photos can also be transformed to sketches and the probe sketch drawn by the artist is matched with the transformed sketches subsequently. Existing learning-based face sketch–photo synthesis methods are grouped into two major categories: data-driven methods (example-based methods) and model-based methods. This chapter would give a comprehensive analysis and comparison to advances on this topic."
"Sakiko Fujieda, Y. Morimoto, K. Ohzeki",c0d97e4f0ba3f59036135e756e5c3aa35df0ae3d,An image generation system of delicious food in a manga style,SIGGRAPH ASIA,2017.0,2,"While the types of images presented in manga can range from realistic to deformed, foods are generally drawn as realistic, delicious-looking images. However, drawing such pictures requires skill. Thus, we propose a system that emphasizes the gloss of wet and oily foods to generate delicious food pictures in a manga style."
"Yongluan Yan, Xinggang Wang, X. Yang, X. Bai, Wenyu Liu",df082be92aeb1f3c22660b043ede5e71afbbaed4,Joint Classification Loss and Histogram Loss for Sketch-Based Image Retrieval,ICIG,2017.0,2,"We study the problem of content-based image retrieval using hand drawn sketches. The problem is very challenging since the low-level visual features of sketch and image have a large variance. Recent studies show that learning deep features that utilize high-level supervision is a feasible solution of this problem. We propose a new network structure with a joint loss by combining a simple classification loss with a robust histogram loss to learn better deep features for both sketch and image. The joint loss method has nearly no parameters to tune; it can not only learn the difference between image/sketch samples from different semantic class but also capture the fine-grained similarity between image/sketch samples in the same semantic class. In the experiments, we show the proposed method obtains excellent performance in real-time on the standard sketch-based image retrieval benchmark."
"P. Kindermann, Wouter Meulemans, André Schulz",5e939463020b6b5ff10f77a0cb32c96ff0b99bcd,Experimental Analysis of the Accessibility of Drawings with Few Segments,Graph Drawing,2017.0,2,"The visual complexity of a graph drawing is defined as the number of geometric objects needed to represent all its edges. In particular, one object may represent multiple edges, e.g., one needs only one line segment to draw two collinear incident edges. We study the question if drawings with few segments have a better aesthetic appeal and help the user to asses the underlying graph. We design an experiment that investigates two different graph types (trees and sparse graphs), three different layout algorithms for trees, and two different layout algorithms for sparse graphs. We asked the users to give an aesthetic ranking on the layouts and to perform a furthest-pair or shortest-path task on the drawings."
"Sungmin Kang, J. Choo",d1cc53b4458cf8e032f8cede32f6a55338b76b6f,Consistent Comic Colorization with Pixel-wise Background Classification,,2017.0,2,"Comic colorization is a time-consuming task, acting as a bottleneck in comic drawing. We propose an automatic coloring model based on the observation that the background colors of comics are often consistent but random. From this observation, we introduce a novel background detector that learns to segment backgrounds out even without direct human annotation. This allows the generation of background-consistent colorizations, a feat that previous work fails to achieve."
"Syoichiro Ota, Hayaki Kawata, M. Muta, S. Masuko, J. Hoshino",bda8658a00776c3859e2e4eb7fa312113f72f1e0,AniReco: Japanese Anime Recommendation System,ICEC,2017.0,1,"Along with development of animation works and their market, it has become more difficult for users to find out works corresponding to their own preference from among huge number of animation works as well as to recognize the whole picture of contents related to them. Therefore, “AniReco” is proposed in this paper which is an animation work recommendation system capable of recommending animation works and their related contents in a cross-sectional fashion while reflecting users’ potential preference. As a result of evaluation experiment performed aiming at verifying the system usability and contents of recommendation; it has been proved that the recommendation system is capable of recommending animation works which reflect users’ preference."
"H. Pham, Samuel Cheung, V. Pavlovic",cc76f5d348ab6c3a20ab4adb285fc1ad96d3c009,Speech-driven 3 D Facial Animation with Implicit Emotional Awareness : A Deep Learning Approach,,2017.0,1,"We introduce a long short-term memory recurrent neural network (LSTM-RNN) approach for real-time facial animation, which automatically estimates head rotation and facial action unit activations of a speaker from just her speech. Specifically, the time-varying contextual non-linear mapping between audio stream and visual facial movements is realized by training a LSTM neural network on a large audio-visual data corpus. In this work, we extract a set of acoustic features from input audio, including Mel-scaled spectrogram, Mel frequency cepstral coefficients and chromagram that can effectively represent both contextual progression and emotional intensity of the speech. Output facial movements are characterized by 3D rotation and blending expression weights of a blendshape model, which can be used directly for animation. Thus, even though our model does not explicitly predict the affective states of the target speaker, her emotional manifestation is recreated via expression weights of the face model. Experiments on an evaluation dataset of different speakers across a wide range of affective states demonstrate promising results of our approach in real-time speech-driven facial animation."
K. Greene,047461a14da6bdb4547302c660f50fbbdee9cc32,DragonPaint: Rule based bootstrapping for small data with an application to cartoon coloring,PAPIs,2017.0,1,"In this paper, we confront the problem of deep learning's big labeled data requirements, offer a rule based strategy for extreme augmentation of small data sets and apply that strategy with the image to image translation model by Isola et al. (2016) to automate cel style cartoon coloring with very limited training data. While our experimental results using geometric rules and transformations demonstrate the performance of our methods on an image translation task with industry applications in art, design and animation, we also propose the use of rules on partial data sets as a generalizable small data strategy, potentially applicable across data types and domains."
N. Keriven,3296175552f0c424befb1f447255fe736885366e,Sketching for Large-Scale Learning of Mixture Models. (Apprentissage de modèles de mélange à large échelle par Sketching),,2017.0,1,"Learning parameters from voluminous data can be prohibitive in terms of memory and computational requirements. We propose a "" compressive learning "" framework where we estimate model parameters from a sketch of the training data. This sketch is a collection of generalized moments of the underlying probability distribution of the data. It can be computed in a single pass on the training set, and is easily computable on streams or distributed datasets. The proposed framework shares similarities with compressive sensing, which aims at drastically reducing the dimension of high-dimensional signals while preserving the ability to reconstruct them. To perform the estimation task, we derive an iterative algorithm analogous to sparse reconstruction algorithms in the context of linear inverse problems. We exemplify our framework with the compressive estimation of a Gaussian Mixture Model (GMM), providing heuristics on the choice of the sketching procedure and theoretical guarantees of reconstruction. We experimentally show on synthetic data that the proposed algorithm yields results comparable to the classical Expectation-Maximization (EM) technique while requiring significantly less memory and fewer computations when the number of database elements is large. We further demonstrate the potential of the approach on real large-scale data (over 10 8 training samples) for the task of model-based speaker verification. Finally, we draw some connections between the proposed framework and approximate Hilbert space embedding of probability distributions using random features. We show that the proposed sketching operator can be seen as an innovative method to design translation-invariant kernels adapted to the analysis of GMMs. We also use this theoretical framework to derive information preservation guarantees, in the spirit of infinite-dimensional compressive sensing."
"Xiaoguang Han, Chang Gao, Yizhou Yu",6d397cb0259c5fb9d6d47955e6ca920e9eef4563,DeepSketch2Face,,2017.0,1,"Face modeling has been paid much attention in the field of visual computing. There exist many scenarios, including cartoon characters, avatars for social media, 3D face caricatures as well as face-related art and design, where low-cost interactive face modeling is a popular approach especially among amateur users. In this paper, we propose a deep learning based sketching system for 3D face and caricature modeling. This system has a labor-efficient sketching interface, that allows the user to draw freehand imprecise yet expressive 2D lines representing the contours of facial features. A novel CNN based deep regression network is designed for inferring 3D face models from 2D sketches. Our network fuses both CNN and shape based features of the input sketch, and has two independent branches of fully connected layers generating independent subsets of coefficients for a bilinear face representation. Our system also supports gesture based interactions for users to further manipulate initial face models. Both user studies and numerical results indicate that our sketching system can help users create face models quickly and effectively. A significantly expanded face database with diverse identities, expressions and levels of exaggeration is constructed to promote further research and evaluation of face modeling techniques."
"Eman T. Hassan, David J. Crandall",d0802d13d0c381714520084a468be6a521a25be6,A Study of Cross-domain Generative Models applied to Cartoon Series,ArXiv,2017.0,0,"We investigate Generative Adversarial Networks (GANs) to model one particular kind of image: frames from TV cartoons. Cartoons are particularly interesting because their visual appearance emphasizes the important semantic information about a scene while abstracting out the less important details, but each cartoon series has a distinctive artistic style that performs this abstraction in different ways. We consider a dataset consisting of images from two popular television cartoon series, Family Guy and The Simpsons. We examine the ability of GANs to generate images from each of these two domains, when trained independently as well as on both domains jointly. We find that generative models may be capable of finding semantic-level correspondences between these two image domains despite the unsupervised setting, even when the training data does not give labeled alignments between them."
"Scott E. Reed, Zeynep Akata, S. Mohan, Samuel Tenka, B. Schiele, Honglak Lee",cad4ac0d2389a89cf1955dd4788278c1e8ac1af9,Learning What and Where to Draw,NIPS,2016.0,379,"Generative Adversarial Networks (GANs) have recently demonstrated the capability to synthesize compelling real-world images, such as room interiors, album covers, manga, faces, birds, and flowers. While existing models can synthesize images based on global constraints such as a class label or caption, they do not provide control over pose or object location. We propose a new model, the Generative Adversarial What-Where Network (GAWWN), that synthesizes images given instructions describing what content to draw in which location. We show high-quality 128 x 128 image synthesis on the Caltech-UCSD Birds dataset, conditioned on both informal text descriptions and also object location. Our system exposes control over both the bounding box around the bird and its constituent parts. By modeling the conditional distributions over part locations, our system also enables conditioning on arbitrary subsets of parts (e.g. only the beak and tail), yielding an efficient interface for picking part locations."
"Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, T. Yamasaki, K. Aizawa",1fef45786e707e6b9b8517b0403e596ecbdea6a5,Sketch-based manga retrieval using manga109 dataset,Multimedia Tools and Applications,2016.0,316,"Manga (Japanese comics) are popular worldwide. However, current e-manga archives offer very limited search support, i.e., keyword-based search by title or author. To make the manga search experience more intuitive, efficient, and enjoyable, we propose a manga-specific image retrieval system. The proposed system consists of efficient margin labeling, edge orientation histogram feature description with screen tone removal, and approximate nearest-neighbor search using product quantization. For querying, the system provides a sketch-based interface. Based on the interface, two interactive reranking schemes are presented: relevance feedback and query retouch. For evaluation, we built a novel dataset of manga images, Manga109, which consists of 109 comic books of 21,142 pages drawn by professional manga artists. To the best of our knowledge, Manga109 is currently the biggest dataset of manga images available for research. Experimental results showed that the proposed framework is efficient and scalable (70 ms from 21,142 pages using a single computer with 204 MB RAM)."
"Qian Yu, Yongxin Yang, Feng Liu, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales",327d7cddbf139712a32f332d5462bb740f04692d,Sketch-a-Net: A Deep Neural Network that Beats Humans,International Journal of Computer Vision,2016.0,167,"We propose a deep learning approach to free-hand sketch recognition that achieves state-of-the-art performance, significantly surpassing that of humans. Our superior performance is a result of modelling and exploiting the unique characteristics of free-hand sketches, i.e., consisting of an ordered set of strokes but lacking visual cues such as colour and texture, being highly iconic and abstract, and exhibiting extremely large appearance variations due to different levels of abstraction and deformation. Specifically, our deep neural network, termed Sketch-a-Net has the following novel components: (i) we propose a network architecture designed for sketch rather than natural photo statistics. (ii) Two novel data augmentation strategies are developed which exploit the unique sketch-domain properties to modify and synthesise sketch training data at multiple abstraction levels. Based on this idea we are able to both significantly increase the volume and diversity of sketches for training, and address the challenge of varying levels of sketching detail commonplace in free-hand sketches. (iii) We explore different network ensemble fusion strategies, including a re-purposed joint Bayesian scheme, to further improve recognition performance. We show that state-of-the-art deep networks specifically engineered for photos of natural objects fail to perform well on sketch recognition, regardless whether they are trained using photos or sketches. Furthermore, through visualising the learned filters, we offer useful insights in to where the superior performance of our network comes from."
"Yonggang Qi, Yi-Zhe Song, Honggang Zhang, Jun Liu",e8db8b3ae77c09e0b882560b06fbfb4b4690792e,Sketch-based image retrieval via Siamese convolutional neural network,2016 IEEE International Conference on Image Processing (ICIP),2016.0,124,"Sketch-based image retrieval (SBIR) is a challenging task due to the ambiguity inherent in sketches when compared with photos. In this paper, we propose a novel convolutional neural network based on Siamese network for SBIR. The main idea is to pull output feature vectors closer for input sketch-image pairs that are labeled as similar, and push them away if irrelevant. This is achieved by jointly tuning two convolutional neural networks which linked by one loss function. Experimental results on Flickr15K demonstrate that the proposed method offers a better performance when compared with several state-of-the-art approaches."
"Dilin Wang, Qiang Liu",0fa88943665de1176b0fc6de4ed7469b40cdb08c,Learning to Draw Samples: With Application to Amortized MLE for Generative Adversarial Learning,ArXiv,2016.0,90,"We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results."
"Chunlei Peng, Xinbo Gao, N. Wang, D. Tao, Xuelong Li, J. Li",af3f802734ba1326ecd69d6219aed9ab09a1f39f,Multiple Representations-Based Face Sketch–Photo Synthesis,IEEE Transactions on Neural Networks and Learning Systems,2016.0,84,"Face sketch-photo synthesis plays an important role in law enforcement and digital entertainment. Most of the existing methods only use pixel intensities as the feature. Since face images can be described using features from multiple aspects, this paper presents a novel multiple representations-based face sketch-photo-synthesis method that adaptively combines multiple representations to represent an image patch. In particular, it combines multiple features from face images processed using multiple filters and deploys Markov networks to exploit the interacting relationships between the neighboring image patches. The proposed framework could be solved using an alternating optimization strategy and it normally converges in only five outer iterations in the experiments. Our experimental results on the Chinese University of Hong Kong (CUHK) face sketch database, celebrity photos, CUHK Face Sketch FERET Database, IIIT-D Viewed Sketch Database, and forensic sketches demonstrate the effectiveness of our method for face sketch-photo synthesis. In addition, cross-database and database-dependent style-synthesis evaluations demonstrate the generalizability of this novel method and suggest promising solutions for face identification in forensic science."
"Shuxin Ouyang, Timothy M. Hospedales, Yi-Zhe Song, Xueming Li, Chen Change Loy, Xiaogang Wang",02843c9d8f9d8df2dda4ad1208e05b32cbcf6cfb,"A survey on heterogeneous face recognition: Sketch, infra-red, 3D and low-resolution",Image Vis. Comput.,2016.0,82,"Heterogeneous face recognition (HFR) refers to matching face imagery across different domains. It has received much interest from the research community as a result of its profound implications in law enforcement. A wide variety of new invariant features, cross-modality matching models and heterogeneous datasets are being established in recent years. This survey provides a comprehensive review of established techniques and recent developments in HFR. Moreover, we offer a detailed account of datasets and benchmarks commonly used for evaluation. We finish by assessing the state of the field and discussing promising directions for future research. Display Omitted Provide a comprehensive review of established techniques in HFRProvide a thorough review of recent developments in HFROffer a detailed account of datasets and benchmarks commonly used for evaluationAssess the state of the field and discuss promising directions for future research"
"Michael Gygli, Yale Song, L. Cao",28f0e0d3783659bc9adb2cec56f19b1f90cdd2be,Video2GIF: Automatic Generation of Animated GIFs from Video,2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2016.0,76,"We introduce the novel problem of automatically generating animated GIFs from video. GIFs are short looping video with no sound, and a perfect combination between image and video that really capture our attention. GIFs tell a story, express emotion, turn events into humorous moments, and are the new wave of photojournalism. We pose the question: Can we automate the entirely manual and elaborate process of GIF creation by leveraging the plethora of user generated GIF content? We propose a Robust Deep RankNet that, given a video, generates a ranked list of its segments according to their suitability as GIF. We train our model to learn what visual content is often selected for GIFs by using over 100K user generated GIFs and their corresponding video sources. We effectively deal with the noisy web data by proposing a novel adaptive Huber loss in the ranking formulation. We show that our approach is robust to outliers and picks up several patterns that are frequently present in popular animated GIFs. On our new large-scale benchmark dataset, we show the advantage of our approach over several state-of-the-art methods."
"Bret Jackson, Daniel F. Keefe",0c1df623ae6363d4e0219d2e82150705ace1cf76,Lift-Off: Using Reference Imagery and Freehand Sketching to Create 3D Models in VR,IEEE Transactions on Visualization and Computer Graphics,2016.0,73,"Three-dimensional modeling has long been regarded as an ideal application for virtual reality (VR), but current VR-based 3D modeling tools suffer from two problems that limit creativity and applicability: (1) the lack of control for freehand modeling, and (2) the difficulty of starting from scratch. To address these challenges, we present Lift-Off, an immersive 3D interface for creating complex models with a controlled, handcrafted style. Artists start outside of VR with 2D sketches, which are then imported and positioned in VR. Then, using a VR interface built on top of image processing algorithms, 2D curves within the sketches are selected interactively and “lifted” into space to create a 3D scaffolding for the model. Finally, artists sweep surfaces along these curves to create 3D models. Evaluations are presented for both long-term users and for novices who each created a 3D sailboat model from the same starting sketch. Qualitative results are positive, with the visual style of the resulting models of animals and other organic subjects as well as architectural models matching what is possible with traditional fine art media. In addition, quantitative data from logging features built into the software are used to characterize typical tool use and suggest areas for further refinement of the interface."
"Hua Zhang, Si Liu, Changqing Zhang, Wenqi Ren, Rui Wang, Xiaochun Cao",b5b620774304e6245a660b14c1207386d3abad17,SketchNet: Sketch Classification with Web Images,2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2016.0,70,"In this study, we present a weakly supervised approach that discovers the discriminative structures of sketch images, given pairs of sketch images and web images. In contrast to traditional approaches that use global appearance features or relay on keypoint features, our aim is to automatically learn the shared latent structures that exist between sketch images and real images, even when there are significant appearance differences across its relevant real images. To accomplish this, we propose a deep convolutional neural network, named SketchNet. We firstly develop a triplet composed of sketch, positive and negative real image as the input of our neural network. To discover the coherent visual structures between the sketch and its positive pairs, we introduce the softmax as the loss function. Then a ranking mechanism is introduced to make the positive pairs obtain a higher score comparing over negative ones to achieve robust representation. Finally, we formalize above-mentioned constrains into the unified objective function, and create an ensemble feature representation to describe the sketch images. Experiments on the TUBerlin sketch benchmark demonstrate the effectiveness of our model and show that deep feature representation brings substantial improvements over other state-of-the-art methods on sketch classification."
"James Bornholt, E. Torlak, D. Grossman, L. Ceze",011a0f193a4ad6e118abd5a36f705618071891ba,Optimizing synthesis with metasketches,POPL 2016,2016.0,68,"Many advanced programming tools---for both end-users and expert developers---rely on program synthesis to automatically generate implementations from high-level specifications. These tools often need to employ tricky, custom-built synthesis algorithms because they require synthesized programs to be not only correct, but also optimal with respect to a desired cost metric, such as program size. Finding these optimal solutions efficiently requires domain-specific search strategies, but existing synthesizers hard-code the strategy, making them difficult to reuse. This paper presents metasketches, a general framework for specifying and solving optimal synthesis problems. metasketches make the search strategy a part of the problem definition by specifying a fragmentation of the search space into an ordered set of classic sketches. We provide two cooperating search algorithms to effectively solve metasketches. A global optimizing search coordinates the activities of local searches, informing them of the costs of potentially-optimal solutions as they explore different regions of the candidate space in parallel. The local searches execute an incremental form of counterexample-guided inductive synthesis to incorporate information sent from the global search. We present Synapse, an implementation of these algorithms, and show that it effectively solves optimal synthesis problems with a variety of different cost functions. In addition, metasketches can be used to accelerate classic (non-optimal) synthesis by explicitly controlling the search strategy, and we show that Synapse solves classic synthesis problems that state-of-the-art tools cannot."
"Haipeng Luo, Alekh Agarwal, N. Cesa-Bianchi, J. Langford",329012f816422c57ed6ed28c1d8a358dd361d79d,Efficient Second Order Online Learning by Sketching,NIPS,2016.0,59,"We propose Sketched Online Newton (SON), an online second order learning algorithm that enjoys substantially improved regret guarantees for ill-conditioned data. SON is an enhanced version of the Online Newton Step, which, via sketching techniques enjoys a running time linear in the dimension and sketch size. We further develop sparse forms of the sketching methods (such as Oja's rule), making the computation linear in the sparsity of features. Together, the algorithm eliminates all computational obstacles in previous second order online learning approaches."
"N. Keriven, Anthony Bourrier, R. Gribonval, P. Pérez",3c5c7c480c710b062b9feb55ee81fdcd4125c068,Sketching for large-scale learning of mixture models,"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2016.0,49,"Learning parameters from voluminous data can be prohibitive in terms of memory and computational requirements. We propose a ""compressive learning"" framework where we first sketch the data by computing random generalized moments of the underlying probability distribution, then estimate mixture model parameters from the sketch using an iterative algorithm analogous to greedy sparse signal recovery. We exemplify our framework with the sketched estimation of Gaussian Mixture Models (GMMs). We experimentally show that our approach yields results comparable to the classical Expectation-Maximization (EM) technique while requiring significantly less memory and fewer computations when the number of database elements is large. We report large-scale experiments in speaker verification, where our approach makes it possible to fully exploit a corpus of 1000 hours of speech signal to learn a universal background model at scales computationally inaccessible to EM."
"Xueming Qian, Xianglong Tan, Y. Zhang, Richang Hong, M. Wang",5c37d0f64c6ce16147a68f52b53c1c076831603b,Enhancing Sketch-Based Image Retrieval by Re-Ranking and Relevance Feedback,IEEE Transactions on Image Processing,2016.0,46,"A sketch-based image retrieval often needs to optimize the tradeoff between efficiency and precision. Index structures are typically applied to large-scale databases to realize efficient retrievals. However, the performance can be affected by quantization errors. Moreover, the ambiguousness of user-provided examples may also degrade the performance, when compared with traditional image retrieval methods. Sketch-based image retrieval systems that preserve the index structure are challenging. In this paper, we propose an effective sketch-based image retrieval approach with re-ranking and relevance feedback schemes. Our approach makes full use of the semantics in query sketches and the top ranked images of the initial results. We also apply relevance feedback to find more relevant images for the input query sketch. The integration of the two schemes results in mutual benefits and improves the performance of the sketch-based image retrieval."
"Y. Zhang, Xueming Qian, Xianglong Tan, Junwei Han, Yuanyan Tang",234e7ee89cb3c30d852a622a197447f9e7aa1f68,Sketch-Based Image Retrieval by Salient Contour Reinforcement,IEEE Transactions on Multimedia,2016.0,41,"The paper presents a sketch-based image retrieval algorithm. One of the main challenges in sketch-based image retrieval (SBIR) is to measure the similarity between a sketch and an image. To tackle this problem, we propose an SBIR-based approach by salient contour reinforcement. In our approach, we divide the image contour into two types. The first is the global contour map. The second, called the salient contour map, is helpful to find out the object in images similar to the query. In addition, based on the two contour maps, we propose a new descriptor, namely an angular radial orientation partitioning (AROP) feature. It fully utilizes the edge pixels' orientation information in contour maps to identify the spatial relationships. Our AROP feature based on the two candidate contour maps is both efficient and effective to discover false matches of local features between sketches and images, and can greatly improve the retrieval performance. The application of the retrieval system based on this algorithm is established. The experiments on the image dataset with 0.3 million images show the effectiveness of the proposed method and comparisons with other algorithms are also given. Compared to baseline performance, the proposed method achieves 10% higher precision in top 5."
"F. Zhu, J. Xie, Yi Fang",8e785faea2283ab4ebd16b5600564bed5364f2ef,Learning Cross-Domain Neural Networks for Sketch-Based 3D Shape Retrieval,AAAI,2016.0,40,"Sketch-based 3D shape retrieval, which returns a set of relevant 3D shapes based on users' input sketch queries, has been receiving increasing attentions in both graphics community and vision community. In this work, we address the sketch-based 3D shape retrieval problem with a novel Cross-Domain Neural Networks (CDNN) approach, which is further extended to Pyramid Cross-Domain Neural Networks (PCDNN) by cooperating with a hierarchical structure. In order to alleviate the discrepancies between sketch features and 3D shape features, a neural network pair that forces identical representations at the target layer for instances of the same class is trained for sketches and 3D shapes respectively. By constructing cross-domain neural networks at multiple pyramid levels, a many-to-one relationship is established between a 3D shape feature and sketch features extracted from different scales. We evaluate the effectiveness of both CDNN and PCDNN approach on the extended large-scale SHREC 2014 benchmark and compare with some other well established methods. Experimental results suggest that both CDNN and PCDNN can outperform state-of-the-art performance, where PCDNN can further improve CDNN when employing a hierarchical structure."
"Azuma Fujimoto, Toru Ogawa, Kazuyoshi Yamamoto, Yusuke Matsui, T. Yamasaki, K. Aizawa",48320a4be9cc741fdb28ad72f359c449e41309cc,Manga109 dataset and creation of metadata,MANPU@ICPR,2016.0,39,"We have created Manga109, a dataset of a variety of 109 Japanese comic books publicly available for use for academic purposes. This dataset provides numerous comic images but lacks the annotations of elements in the comics that are necessary for use by machine learning algorithms or evaluation of methods. In this paper, we present our ongoing project to build metadata for Manga109. We first define the metadata in terms of frames, texts and characters. We then present our web-based software for efficiently creating the ground truth for these images. In addition, we provide a guideline for the annotation with the intent of improving the quality of the metadata."
"Shengchuan Zhang, Xinbo Gao, N. Wang, J. Li",a8a46c299128ac1823c484337e440bb11abd8c41,Robust Face Sketch Style Synthesis,IEEE Transactions on Image Processing,2016.0,38,"Heterogeneous image conversion is a critical issue in many computer vision tasks, among which example-based face sketch style synthesis provides a convenient way to make artistic effects for photos. However, existing face sketch style synthesis methods generate stylistic sketches depending on many photo-sketch pairs. This requirement limits the generalization ability of these methods to produce arbitrarily stylistic sketches. To handle such a drawback, we propose a robust face sketch style synthesis method, which can convert photos to arbitrarily stylistic sketches based on only one corresponding template sketch. In the proposed method, a sparse representation-based greedy search strategy is first applied to estimate an initial sketch. Then, multi-scale features and Euclidean distance are employed to select candidate image patches from the initial estimated sketch and the template sketch. In order to further refine the obtained candidate image patches, a multi-feature-based optimization model is introduced. Finally, by assembling the refined candidate image patches, the completed face sketch is obtained. To further enhance the quality of synthesized sketches, a cascaded regression strategy is adopted. Compared with the state-of-the-art face sketch synthesis methods, experimental results on several commonly used face sketch databases and celebrity photos demonstrate the effectiveness of the proposed method."
"Rosália G. Schneider, T. Tuytelaars",c9db41624b835278c51cfba669ea19aa4766fd1b,Example-Based Sketch Segmentation and Labeling Using CRFs,ACM Trans. Graph.,2016.0,37,"We introduce a new approach for segmentation and label transfer in sketches that substantially improves the state of the art. We build on successful techniques to find how likely each segment is to belong to a label, and use a Conditional Random Field to find the most probable global configuration. Our method is trained fully on the sketch domain, such that it can handle abstract sketches that are very far from 3D meshes. It also requires a small quantity of annotated data, which makes it easily adaptable to new datasets. The testing phase is completely automatic, and our performance is comparable to state-of-the-art methods that require manual tuning and a considerable amount of previous annotation [Huang et al. 2014]."
"Xinggang Wang, Xiong Duan, X. Bai",05b435174d24b14b17df4ce5af79dc6086a2b16f,Deep sketch feature for cross-domain image retrieval,Neurocomputing,2016.0,33,"Deep learning has been proven to be very effective for various image recognition tasks, e.g., image classification, semantic segmentation, image retrieval, shape classification, etc. However, existing works on deep learning for image recognition mainly focus on either natural image data or binary shape data. In this paper, we show that deep convolutional neural networks (DCNN) is also suitable for cross-domain image recognition, i.e., using sketch as query to retrieve natural images in a large dataset. To solve this kind of cross-domain problem, we propose to train CNN jointly using image data and sketch data in a novel way. The learned deep feature is effective for cross-domain image retrieval - using simple Euclidean distance on the learned feature can significantly outperform the previous state-of-the-arts. In addition, we find that pre-training and a feasible data-argumentation for DCNN can largely surpass human-level performance in the standard sketch classification benchmark."
"Tu Bui, Leo Sampaio Ferraz Ribeiro, M. Ponti, J. Collomosse",b3fb8047675e1dbdef800ce32abbfe1dccb42235,Generalisation and Sharing in Triplet Convnets for Sketch based Visual Search,ArXiv,2016.0,33,"We propose and evaluate several triplet CNN architectures for measuring the similarity between sketches and photographs, within the context of the sketch based image retrieval (SBIR) task. In contrast to recent fine-grained SBIR work, we study the ability of our networks to generalise across diverse object categories from limited training data, and explore in detail strategies for weight sharing, pre-processing, data augmentation and dimensionality reduction. We exceed the performance of pre-existing techniques on both the Flickr15k category level SBIR benchmark by $18\%$, and the TU-Berlin SBIR benchmark by $\sim10 \mathcal{T}_b$, when trained on the 250 category TU-Berlin classification dataset augmented with 25k corresponding photographs harvested from the Internet."
"Ravi Kiran Sarvadevabhatla, Jogendra Nath Kundu, R. Venkatesh Babu",8e8073b238c92c097fd6d84b9f8c86ee2837e9dd,Enabling My Robot To Play Pictionary: Recurrent Neural Networks For Sketch Recognition,ACM Multimedia,2016.0,32,"Freehand sketching is an inherently sequential process. Yet, most approaches for hand-drawn sketch recognition either ignore this sequential aspect or exploit it in an ad-hoc manner. In our work, we propose a recurrent neural network architecture for sketch object recognition which exploits the long-term sequential and structural regularities in stroke data in a scalable manner. Specifically, we introduce a Gated Recurrent Unit based framework which leverages deep sketch features and weighted per-timestep loss to achieve state-of-the-art results on a large database of freehand object sketches across a large number of object categories. The inherently online nature of our framework is especially suited for on-the-fly recognition of objects as they are being drawn. Thus, our framework can enable interesting applications such as camera-equipped robots playing the popular party game Pictionary with human players and generating sparsified yet recognizable sketches of objects."
"Stephen Ranshous, Steve Harenberg, Kshitij Sharma, N. Samatova",b66dbe242c3fa0a5738c7e76004f1f7b655f5ed6,A Scalable Approach for Outlier Detection in Edge Streams Using Sketch-based Approximations,SDM,2016.0,27,"Dynamic graphs are a powerful way to model an evolving set of objects and their ongoing interactions. A broad spectrum of systems, such as information, communication, and social, are naturally represented by dynamic graphs. Outlier (or anomaly) detection in dynamic graphs can provide unique insights into the relationships of objects and identify novel or emerging relationships. To date, outlier detection in dynamic graphs has been studied in the context of graph streams, focusing on the analysis and comparison of entire graph objects. However, the volume and velocity of data are necessitating a transition from outlier detection in the context of graph streams to outlier detection in the context of edge streams–where the stream consists of individual graph edges instead of entire graph objects. In this paper, we propose the first approach for outlier detection in edge streams. We first describe a highlevel model for outlier detection based on global and local structural properties of a stream. We propose a novel application of the Count-Min sketch for approximating these properties, and prove probabilistic error bounds on our edge outlier scoring functions. Our sketch-based implementation provides a scalable solution, having constant time updates and constant space requirements. Experiments on synthetic and real world datasets demonstrate our method’s scalability, effectiveness for discovering outliers, and the effects of approximation."
"Antonia Creswell, A. Bharath",344e8d09cd6144e84a92273d2b5be6c885ce2c22,Adversarial Training for Sketch Retrieval,ECCV Workshops,2016.0,26,"Generative Adversarial Networks (GAN) are able to learn excellent representations for unlabelled data which can be applied to image generation and scene classification. Representations learned by GANs have not yet been applied to retrieval. In this paper, we show that the representations learned by GANs can indeed be used for retrieval. We consider heritage documents that contain unlabelled Merchant Marks, sketch-like symbols that are similar to hieroglyphs. We introduce a novel GAN architecture with design features that make it suitable for sketch retrieval. The performance of this sketch-GAN is compared to a modified version of the original GAN architecture with respect to simple invariance properties. Experiments suggest that sketch-GANs learn representations that are suitable for retrieval and which also have increased stability to rotation, scale and translation compared to the standard GAN architecture."
"Jifei Song, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales, Xiang Ruan",9ea16aeed4cb7664f7b962e52275f31a3bbf846e,Deep Multi-task Attribute-driven Ranking for Fine-grained Sketch-based Image Retrieval,BMVC,2016.0,25,"Fine-grained sketch-based image retrieval (SBIR) aims to go beyond conventional SBIR to perform instance-level cross-domain retrieval: finding the specific photo that matches an input sketch. Existing methods focus on designing/learning good features for cross-domain matching and/or learning cross-domain matching functions. However, they neglect the semantic aspect of retrieval, i.e., what meaningful object properties does a user try encode in her/his sketch? We propose a fine-grained SBIR model that exploits semantic attributes and deep feature learning in a complementary way. Specifically, we perform multi-task deep learning with three objectives, including: retrieval by fine-grained ranking on a learned representation, attribute prediction, and attribute-level ranking. Simultaneously predicting semantic attributes and using such predictions in the ranking procedure help retrieval results to be more semantically relevant. Importantly, the introduction of semantic attribute learning in the model allows for the elimination of the otherwise prohibitive cost of human annotations required for training a fine-grained deep ranking model. Experimental results demonstrate that our method outperforms the state-of-the-art on challenging fine-grained SBIR benchmarks while requiring less annotation."
"Y. Li, Yi-Zhe Song, Timothy M. Hospedales, S. Gong",24f22ca1c609c8fb11f09cd2b9633b14ca3c2cfa,Free-Hand Sketch Synthesis with Deformable Stroke Models,International Journal of Computer Vision,2016.0,25,"We present a generative model which can automatically summarize the stroke composition of free-hand sketches of a given category. When our model is fit to a collection of sketches with similar poses, it discovers and learns the structure and appearance of a set of coherent parts, with each part represented by a group of strokes. It represents both consistent (topology) as well as diverse aspects (structure and appearance variations) of each sketch category. Key to the success of our model are important insights learned from a comprehensive study performed on human stroke data. By fitting this model to images, we are able to synthesize visually similar and pleasant free-hand sketches."
"Yuji Aramaki, Yusuke Matsui, T. Yamasaki, K. Aizawa",2d32aa47bed762b441e043f80c2cc0839b70fbdd,Text detection in manga by combining connected-component-based and region-based classifications,2016 IEEE International Conference on Image Processing (ICIP),2016.0,22,"As manga (Japanese comics) have become common content in many countries, it is necessary to search manga by text query or translate them automatically. For these applications, we must first extract texts from manga. In this paper, we develop a method to detect text regions in manga. Taking motivation from methods used in scene text detection, we propose an approach using classifiers for both connected components and regions. We have also developed a text region dataset of manga, which enables learning and detailed evaluations of methods used to detect text regions. Experiments using the dataset showed that our text detection method performs more effectively than existing methods."
"Jun Guo, C. Wang, Edgar Román-Rangel, Hongyang Chao, Y. Rui",0dce1412c4c49b2e6c88d30456295b40687b186d,Building Hierarchical Representations for Oracle Character and Sketch Recognition,IEEE Transactions on Image Processing,2016.0,21,"In this paper, we study oracle character recognition and general sketch recognition. First, a data set of oracle characters, which are the oldest hieroglyphs in China yet remain a part of modern Chinese characters, is collected for analysis. Second, typical visual representations in shape- and sketch-related works are evaluated. We analyze the problems suffered when addressing these representations and determine several representation design criteria. Based on the analysis, we propose a novel hierarchical representation that combines a Gabor-related low-level representation and a sparse-encoder-related mid-level representation. Extensive experiments show the effectiveness of the proposed representation in both oracle character recognition and general sketch recognition. The proposed representation is also complementary to convolutional neural network (CNN)-based models. We introduce a solution to combine the proposed representation with CNN-based models, and achieve better performances over both approaches. This solution has beaten humans at recognizing general sketches."
"Christian Galea, R. Farrugia",c7252af9fd5e268030d04b6ccc08f1d9ed360467,Face photo-sketch recognition using local and global texture descriptors,2016 24th European Signal Processing Conference (EUSIPCO),2016.0,21,"The automated matching of mug-shot photographs with sketches drawn using eyewitness descriptions of criminals is a problem that has received much attention in recent years. However, most algorithms have been evaluated either on small datasets or using sketches that closely resemble the corresponding photos. In this paper, a method which extracts Multi-scale Local Binary Pattern (MLBP) descriptors from overlapping patches of log-Gabor-filtered images is used to obtain cross-modality templates for each photo and sketch. The Spearman Rank-Order Correlation Coefficient (SROCC) is then used for template matching. Log-Gabor filtering and MLBP provide global and local texture information, respectively, whose combination is shown to be beneficial for face photo-sketch recognition. Experimental results with a large database show that the proposed approach outperforms state-of-the-art methods, with a Rank-1 retrieval rate of 81.4%. Fusion with the intra-modality approach Eigenpatches improves the Rank-1 rate to 85.5%."
"Peng Xu, Qiyue Yin, Yonggang Qi, Yi-Zhe Song, Zhanyu Ma, Liang Wang, Jun Guo",b223474a3b0f2e809f57bf4ed19d97f8cad1183c,Instance-Level Coupled Subspace Learning for Fine-Grained Sketch-Based Image Retrieval,ECCV Workshops,2016.0,20,"Fine-grained sketch-based image retrieval (FG-SBIR) is a newly emerged topic in computer vision. The problem is challenging because in addition to bridging the sketch-photo domain gap, it also asks for instance-level discrimination within object categories. Most prior approaches focused on feature engineering and fine-grained ranking, yet neglected an important and central problem: how to establish a fine-grained cross-domain feature space to conduct retrieval. In this paper, for the first time we formulate a cross-domain framework specifically designed for the task of FG-SBIR that simultaneously conducts instance-level retrieval and attribute prediction. Different to conventional photo-text cross-domain frameworks that performs transfer on category-level data, our joint multi-view space uniquely learns from the instance-level pair-wise annotations of sketch and photo. More specifically, we propose a joint view selection and attribute subspace learning algorithm to learn domain projection matrices for photo and sketch, respectively. It follows that visual attributes can be extracted from such matrices through projection to build a coupled semantic space to conduct retrieval. Experimental results on two recently released fine-grained photo-sketch datasets show that the proposed method is able to perform at a level close to those of deep models, while removing the need for extensive manual annotations."
"Peng Xu, K. Li, Zhanyu Ma, Yi-Zhe Song, Liang Wang, Jun Guo",fd60f46ef9ac01a12162550abfe146b6407edd0f,Cross-modal subspace learning for sketch-based image retrieval: A comparative study,2016 IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC),2016.0,20,"Sketch-based image retrieval (SBIR) has become a prominent research topic in recent years due to the proliferation of touch screens. The problem is however very challenging for that photos and sketches are inherently modeled in different modalities. Photos are accurate (colored and textured) depictions of the real-world, whereas sketches are highly abstract (black and white) renderings often drawn from human memory. This naturally motivates us to study the effectiveness of various cross-modal retrieval methods in SBIR. However, to the best of our knowledge, all established cross-modal algorithms are designed to traverse the more conventional cross-modal gap of image and text, making their general applicableness to SBIR unclear. In this paper, we design a series of experiments to clearly illustrate circumstances under which cross-modal methods can be best utilized to solve the SBIR problem. More specifically, we choose six state-of-the-art cross-modal subspace learning approaches that were shown to work well on image-text and conduct extensive experiments on a recently released SBIR dataset. Finally, we present detailed comparative analysis of the experimental results and offer insights to benefit future research."
"P. Grohs, Thomas Wiatowski, H. Bölcskei",8cce9c0cb1ca869cc818424d22a1091f5f819db3,Deep convolutional neural networks on cartoon functions,2016 IEEE International Symposium on Information Theory (ISIT),2016.0,20,"Wiatowski and Bölcskei, 2015, proved that deformation stability and vertical translation invariance of deep convolutional neural network-based feature extractors are guaranteed by the network structure per se rather than the specific convolution kernels and non-linearities. While the translation invariance result applies to square-integrable functions, the deformation stability bound holds for band-limited functions only. Many signals of practical relevance (such as natural images) exhibit, however, sharp and curved discontinuities and are hence not band-limited. The main contribution of this paper is a deformation stability result that takes these structural properties into account. Specifically, we establish deformation stability bounds for the class of cartoon functions introduced by Donoho, 2001."
"Dragomir R. Radev, Amanda Stent, Joel R. Tetreault, Aasish Pappu, Aikaterini Iliakopoulou, A. Chanfreau, Paloma de Juan, Jordi Vallmitjana, A. Jaimes, Rahul Jha, Robert Mankoff",6a51192f7a2fbc328058b68ff5537b91dbaf023b,Humor in Collective Discourse: Unsupervised Funniness Detection in the New Yorker Cartoon Caption Contest,LREC,2016.0,20,"The New Yorker publishes a weekly captionless cartoon. More than 5,000 readers submit captions for it. The editors select three of them and ask the readers to pick the funniest one. We describe an experiment that compares a dozen automatic methods for selecting the funniest caption. We show that negative sentiment, human-centeredness, and lexical centrality most strongly match the funniest captions, followed by positive sentiment. These results are useful for understanding humor and also in the design of more engaging conversational agents in text and multimodal (vision+text) systems. As part of this work, a large set of cartoons and captions is being made available to the community."
"K. Li, Kaiyue Pang, Yi-Zhe Song, Timothy M. Hospedales, Honggang Zhang, Yichuan Hu",2a8e2a93c48d82452d0f87452355a19376a0eda2,Fine-grained sketch-based image retrieval: The role of part-aware attributes,2016 IEEE Winter Conference on Applications of Computer Vision (WACV),2016.0,19,"We study the problem of fine-grained sketch-based image retrieval. By performing instance-level (rather than category-level) retrieval, it embodies a timely and practical application, particularly with the ubiquitous availability of touchscreens. Three factors contribute to the challenging nature of the problem: (i) free-hand sketches are inherently abstract and iconic, making visual comparisons with photos more difficult, (ii) sketches and photos are in two different visual domains, i.e. black and white lines vs. color pixels, and (iii) fine-grained distinctions are especially challenging when executed across domain and abstraction-level. To address this, we propose to detect visual attributes at part-level, in order to build a new representation that not only captures fine-grained characteristics but also traverses across visual domains. More specifically, (i) we propose a dataset with 304 photos and 912 sketches, where each sketch and photo is annotated with its semantic parts and associated part-level attributes, and with the help of this dataset, we investigate (ii) how strongly-supervised deformable part-based models can be learned that subsequently enable automatic detection of part-level attributes, and (iii) a novel matching framework that synergistically integrates low-level features, mid-level geometric structure and high-level semantic attributes to boost retrieval performance. Extensive experiments conducted on our new dataset demonstrate value of the proposed method."
"K. Sasaki, K. Noda, T. Ogata",35852b1b76037c7a30fa7a6aae75effd53709222,Visual motor integration of robot's drawing behavior using recurrent neural network,Robotics Auton. Syst.,2016.0,19,"Abstract Drawing is a way of visually expressing our feelings, knowledge, and situation. People draw pictures to share information with other human beings. This study investigates visuomotor memory (VM), which is a reusable memory storing drawing behavioral data. We propose a neural network-based model for acquiring a computational memory that can replicate VM through self-organized learning of a robot’s actual drawing experiences. To design the model, we assume that VM has the following two characteristics: (1) it is formed by bottom-up learning and integration of temporal drawn pictures and motion data, and (2) it allows the observers to associate drawing motions from pictures. The proposed model comprises a deep neural network for dimensionally compressing temporal drawn images and a continuous-time recurrent neural network for integration learning of drawing motions and temporal drawn images. Two experiments are conducted on unicursal shape learning to investigate whether the proposed model can learn the function without any shape information for visual processing. Based on the first experiment, the model can learn 15 drawing sequences for three types of pictures, acquiring associative memory for drawing motions through the bottom-up learning process. Thus, it can associate drawing motions from untrained drawn images. In the second experiment, four types of pictures are trained, with four distorted variations per type. In this case, the model can organize the different shapes based on their distortions by utilizing both the image information and the drawing motions, even if visual characteristics are not shared."
"N. Yakovenko, L. Cao, Colin Raffel, James Fan",f0d94eec64ddde55733f3ad04a6e819293db0302,Poker-CNN: A Pattern Learning Strategy for Making Draws and Bets in Poker Games Using Convolutional Networks,AAAI,2016.0,19,"Poker is a family of card games that includes many variations. We hypothesize that most poker games can be solved as a pattern matching problem, and propose creating a strong poker playing system based on a unified poker representation. Our poker player learns through iterative self-play, and improves its understanding of the game by training on the results of its previous actions without sophisticated domain knowledge. We evaluate our system on three poker games: single player video poker, two-player Limit Texas Hold'em, and finally two-player 2-7 triple draw poker. We show that our model can quickly learn patterns in these very different poker games while it improves from zero knowledge to a competitive player against human experts. 
 
The contributions of this paper include: (1) a novel representation for poker games, extendable to different poker variations, (2) a Convolutional Neural Network (CNN) based learning model that can effectively learn the patterns in three different games, and (3) a self-trained system that significantly beats the heuristic-based program on which it is trained, and our system is competitive against human expert players."
"S. Dupont, Omar Seddati, S. Mahmoudi",feac7ae2ce66e6dcc8e8c64223dc5624edea8d08,DeepSketch 2: Deep convolutional neural networks for partial sketch recognition,2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI),2016.0,18,"Freehand sketches are a simple and powerful tool for communication. They are easily recognized across cultures and suitable for various applications. In this paper, we propose a new approach for partial sketch recognition. This could be used to design applications using real-time sketch recognition. We use deep convolutional neural networks (ConvNets), state-of-the-art in the field of sketch recognition. To the best of our knowledge, it is the first ConvNet for partial sketch classification. Our first aim is to build a ConvNet capable of recognizing partial sketches without compromising the accuracy reached for complete sketch recognition. Therefore, we evaluate different approaches and propose an efficient way for partial sketch recognition. Our second aim is improving complete sketch recognition using information about sketching progression. We obtained a ConvNet that outperforms state-of-the-art results in the TU-Berlin sketch benchmark. We reached an accuracy of 77.69%."
"Gabriele Barbagallo, A. Madeo, F. Morestin, P. Boisse",e7fbe43c338abd1bb4db72f12c0508cf9731b563,Modelling the deep drawing of a 3D woven fabric with a second gradient model,,2016.0,18,"Experimental testing on dry woven fabrics exhibits a complex set of evidences that are difficult to completely describe using classical continuum models. The aim of this paper is to show how the introduction of energy terms related to the micro-deformation mechanisms of the fabric, in particular to the bending stiffness of the yarns, helps in the modelling of the mechanical behaviour of this kind of materials. To this aim, a second gradient, hyperelastic, initially orthotropic continuum theory is proposed to model fibrous composite interlocks at finite strains. In particular, the present work explores the relationship between the onset of wrinkling during the simulation of the deep drawing of a woven fabric and the use of a second gradient model. It is shown that the introduction of second gradient terms accounting for the description of in-plane and out-of-plane bending rigidities decreases the onset of wrinkles during the simulation of deep drawing. In this work, a quadratic energy, roughly proportional to the square of the curvature of the fibres, is presented and implemented in the simulations. This simple constitutive assumption allows the effects of the second gradient energy on both the wrinkling description and the numerical stability of the model to be clearly shown. The results obtained in second gradient simulations are descriptive of the experimental evidence of deep drawing whose description is targeted in this work. The present paper provides additional evidence of the fact that first gradient continuum theories alone cannot be considered fully descriptive of the behaviour of dry woven composite reinforcements. On the other hand, the proposed second gradient model for fibrous composite reinforcements opens the way both to the more accurate simulation of complex forming processes and to the possibility of controlling the onset of wrinkles."
"B. Li, Y. Lu, H. Johan, Ribel Fares",6437d423e053bdee1522155c5fc96216c77fb04d,Sketch-based 3D model retrieval utilizing adaptive view clustering and semantic information,Multimedia Tools and Applications,2016.0,17,"Searching for relevant 3D models based on hand-drawn sketches is both intuitive and important for many applications, such as sketch-based 3D modeling and recognition, human computer interaction, 3D animation, game design, and etc. In this paper, our target is to significantly improve the current sketch-based 3D retrieval performance in terms of both accuracy and efficiency. We propose a new sketch-based 3D model retrieval framework by utilizing adaptive view clustering and semantic information. It first utilizes a proposed viewpoint entropy-based 3D information complexity measurement to guide adaptive view clustering of a 3D model to shortlist a set of representative sample views for 2D-3D comparison. To bridge the gap between the query sketches and the target models, we then incorporate a novel semantic sketch-based search approach to further improve the retrieval performance. Experimental results on several latest benchmarks have evidently demonstrated our significant improvement in retrieval performance."
"N. Davis, Chih-Pin Hsiao, Kunwar Yashraj Singh, Brian Magerko",e20da4cff5316c1a62c6afaa2372dedb438b411e,Co-Creative Drawing Agent with Object Recognition,AIIDE,2016.0,17,"This paper describes an updated version of a co-creative drawing system called the Drawing Apprentice. The system collaborates with users by analyzing their drawn input and responding in a real time dialogical and improvisational interaction. The current system includes an object recognition module that employs deep learning to classify sketched objects. The system architecture and implementation are described along with its evaluation during a public demonstration during which artists, non-artists, and designers provided feedback about the experience interacting with the system."
"Chunlei Peng, N. Wang, Xinbo Gao, J. Li",2b695a7ca8d1dc63309f92f914027b69dd9f8d0b,"Face Recognition from Multiple Stylistic Sketches: Scenarios, Datasets, and Evaluation",ECCV Workshops,2016.0,16,"Matching a face sketch against mug shots, which plays an important role in law enforcement and security, is an interesting and challenging topic in face recognition community. Although great progress has been made in recent years, main focus is the face recognition based on SINGLE sketch in existing studies. In this paper, we present a fundamental study of face recognition from multiple stylistic sketches. Three specific scenarios with corresponding datasets are carefully introduced to mimic real-world situations: (1) recognition from multiple hand-drawn sketches; (2) recognition from hand-drawn sketch and composite sketches; (3) recognition from multiple composite sketches. We further provide the evaluation protocols and several benchmarks on these proposed scenarios. Finally, we discuss the plenty of challenges and possible future directions that worth to be further investigated. All the materials will be publicly available online (Available at http://chunleipeng.com/FRMSketches.html.) for comparisons and further study of this problem."
"Xueming Qian, Xianglong Tan, Yuting Zhang, Richang Hong, Meng Wang",de676b582172883b54341f0e2d420f8b375ff367,Enhancing Sketch-Based Image Retrieval by Re-Ranking and Relevance Feedback.,IEEE transactions on image processing : a publication of the IEEE Signal Processing Society,2016.0,16,"A sketch-based image retrieval often needs to optimize the tradeoff between efficiency and precision. Index structures are typically applied to large-scale databases to realize efficient retrievals. However, the performance can be affected by quantization errors. Moreover, the ambiguousness of user-provided examples may also degrade the performance, when compared with traditional image retrieval methods. Sketch-based image retrieval systems that preserve the index structure are challenging. In this paper, we propose an effective sketch-based image retrieval approach with re-ranking and relevance feedback schemes. Our approach makes full use of the semantics in query sketches and the top ranked images of the initial results. We also apply relevance feedback to find more relevant images for the input query sketch. The integration of the two schemes results in mutual benefits and improves the performance of the sketch-based image retrieval."
"Daniel L. Pimentel-Alarcón, L. Balzano, R. Nowak",db4e3943d20204e9e852c03ee5b65f2ecebd5f18,Necessary and sufficient conditions for sketched subspace clustering,"2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)",2016.0,16,"This paper is about an interesting phenomenon: two r-dimensional subspaces, even if they are orthogonal to one an other, can appear identical if they are only observed on a subset of coordinates. Understanding this phenomenon is of particular importance for many modern applications of subspace clustering where one would like to subsample in order to improve computational efficiency. Examples include real-time video surveillance and datasets so large that cannot even be stored in memory. In this paper we introduce a new metric between subspaces, which we call partial coordinate discrepancy. This metric captures a notion of similarity between subsampled subspaces that is not captured by other distance measures between subspaces. With this, we are able to show that subspace clustering is theoretically possible in lieu of coherence assumptions using only r + 1 rows of the dataset at hand. This gives precise information-theoretic necessary and sufficient conditions for sketched subspace clustering. This can greatly improve computational efficiency without compromising performance. We complement our theoretical analysis with synthetic and real data experiments."
"Zahraa Yasseen, Anne Verroust-Blondet, A. Nasri",5ce1e18c82f4e84ce30aacaae9890ca57d790ab8,View selection for sketch-based 3D model retrieval using visual part shape description,The Visual Computer,2016.0,15,"Hand drawings are the imprints of shapes in human’s mind. How a human expresses a shape is a consequence of how he or she visualizes it. A query-by-sketch 3D object retrieval application is closely tied to this concept from two aspects. First, describing sketches must involve elements in a figure that matter most to a human. Second, the representative 2D projection of the target 3D objects should be limited to “the canonical views” from a human cognition perspective. We advocate for these two rules by presenting a new approach for sketch-based 3D object retrieval that describes a 2D shape by the visual protruding parts of its silhouette. Furthermore, we present a list of candidate 2D projections that represent the canonical views of a 3D object. The general rule is that humans would visually avoid part occlusion and symmetry. We quantify the extent of part occlusion of the projected silhouettes of 3D objects by skeletal length computations. Sorting the projected views in the decreasing order of skeletal lengths gives access to a subset of the best representative views. We experimentally show how views that cause misinterpretation and mismatching can be detected according to the part occlusion criteria. We also propose criteria for locating side, off axis, or asymmetric views."
"Christian Galea, R. Farrugia",1e472cf9a290e8f59573628dba426cd6d74411f4,A Large-Scale Software-Generated Face Composite Sketch Database,2016 International Conference of the Biometrics Special Interest Group (BIOSIG),2016.0,14,"Numerous algorithms that can identify suspects depicted in sketches following eyewitness descriptions of criminals are currently being developed because of their potential importance in forensics investigations. Yet, despite the prevalent use of software-generated composite sketches by law enforcement agencies, there still exist few such sketches which can be used by researchers to adequately evaluate face photo- sketch recognition algorithms when using these composites. The main contribution of this paper is the creation of the University of Malta Software- Generated Face Sketch (UoM-SGFS) database that is publicly available and which contains the largest number of viewed software-generated sketches, that also exhibit several deformations and exaggerations to mimic sketches obtained in real- world investigations. Further, in contrast to other databases, all sketches in this new database are represented in colour. {Lastly, state-of-the- art recognition algorithms are found to perform worse on the software-generated composites than on hand-drawn sketches, while recognition accuracies still lag far behind those achieved for traditional photo-to-photo comparisons."
"A. Backurs, P. Indyk, Ilya P. Razenshteyn, David P. Woodruff",7c1884e25a6f88cf9f86cc34f4ac25497a54d018,"Nearly-optimal bounds for sparse recovery in generic norms, with applications to k-median sketching",SODA,2016.0,13,"We initiate the study of trade-offs between sparsity and the number of measurements in sparse recovery schemes for generic norms. Specifically, for a norm $\|\cdot\|$, sparsity parameter $k$, approximation factor $K>0$, and probability of failure $P>0$, we ask: what is the minimal value of $m$ so that there is a distribution over $m \times n$ matrices $A$ with the property that for any $x$, given $Ax$, we can recover a $k$-sparse approximation to $x$ in the given norm with probability at least $1-P$? We give a partial answer to this problem, by showing that for norms that admit efficient linear sketches, the optimal number of measurements $m$ is closely related to the doubling dimension of the metric induced by the norm $\|\cdot\|$ on the set of all $k$-sparse vectors. By applying our result to specific norms, we cast known measurement bounds in our general framework (for the $\ell_p$ norms, $p \in [1,2]$) as well as provide new, measurement-efficient schemes (for the Earth-Mover Distance norm). The latter result directly implies more succinct linear sketches for the well-studied planar $k$-median clustering problem. Finally, our lower bound for the doubling dimension of the EMD norm enables us to address the open question of [Frahling-Sohler, STOC'05] about the space complexity of clustering problems in the dynamic streaming model."
"D. Xu, Xavier Alameda-Pineda, Jingkuan Song, E. Ricci, N. Sebe",9a05dc4a65c5c703f7a825b9c0f8f43a5b27ca1a,Academic Coupled Dictionary Learning for Sketch-based Image Retrieval,ACM Multimedia,2016.0,11,"In the last few years, the query-by-visual-example paradigm gained popularity, specially for content based retrieval systems. As sketches represent a natural way of expressing a synthetic query, recent research efforts focused on developing algorithmic solutions to address the sketch-based image retrieval (SBIR) problem. Within this context, we propose a novel approach for SBIR that, unlike previous methods, is able to exploit the visual complexity inherently present in sketches and images. We introduce academic learning, a paradigm in which the sample learning order is constructed both from the data, as in self-paced learning, and from partial curricula. We propose an instantiation of this paradigm within the framework of coupled dictionary learning to address the SBIR task. We also present an efficient algorithm to learn the dictionaries and the codes, and to pace the learning combining the reconstruction error, the prior knowledge suggested by the partial curricula and the cross-domain code coherence. In order to evaluate the proposed approach, we report an extensive experimental validation showing that the proposed method outperforms the state-of-the-art in coupled dictionary learning and in SBIR on three different publicly available datasets."
"Mingrui Zhu, N. Wang",52638c383f85bf0dadd4a09aacdd89123e126d8c,A Simple and Fast Method for Face Sketch Synthesis,ICIMCS,2016.0,10,"In this paper, we propose a simple and fast model-based face sketch synthesis method using subspace ridge regression. Different from the commonly used data-driven strategy that similar sketch patches are searched from the real sketch database, the proposed simple and fast face sketch synthesis (SF-FSS) method adopts the divide-and-conquer strategy which firstly classify the training photo-sketch patch pairs into a number of classes and then use a simple ridge regression model to learn the mapping between training photo patches and their corresponding sketch patches. We can predict sketch patches directly and fast by multiplying the input test photo patch with some special pre-computed regression matrix. Simultaneously, some high frequency information is also generated to be superposed on the regressed sketch patches. Experimental results show that the proposed method achieves comparable or better performance with least time consuming compared with state-of-the-art methods."
"W. Chu, W. Cheng",fa1487c69814ad630f9434453487efb91eff1fa0,Manga-specific features and latent style model for manga style analysis,"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2016.0,10,"A latent style model describing manga styles based on the proposed manga-specific features is constructed to facilitate novel style-based applications. Two manga-specific features, i.e., screentone features showing texture and shade, and panel features showing panel arrangement, are firstly proposed to describe manga pages. Based on the latent Dirichlet allocation technique, we discover latent style elements embedded in manga documents, which are described by visual words derived from manga-specific features. Distributions of style elements are then used to measure similarity between manga documents, and facilitate the development ofvarious style-based applications. Experimental results show that the features and models especially designed for describing manga styles yield promising performance and could bring many potential extensions."
"Y. Ye, Y. Lu, H. Jiang",b2304f4794075d188d239667639806e418b149a2,Human's Scene Sketch Understanding,ICMR,2016.0,10,"Human's sketch understanding is important. It has many applications in human computer interaction, multimedia, and computer vision. Recognizing human sketches is also challenging. Previous methods focus on single-object sketch recognition. Understanding human's scene sketch that involves multiple objects and their complex interactions has not been explored. In this paper, we tackle this new problem. We create the first scene sketch dataset ""Scene250"" and propose a deep learning method to understand human scene sketches. We propose ""Scene-Net"", a new deep convolutional neural network (CNN) structure, based on which we build a novel scene sketch recognition system. Our system has been tested on the collected scene sketch dataset and compared with other state-of-the-art CNNs and sketch recognition approaches. Our experimental results demonstrate that our method achieves the state of art."
S. Heuer,a52f775f4a99a98d07bc7dab9c07c77161e0e1b7,The influence of image characteristics on image recognition: a comparison of photographs and line drawings,,2016.0,10,"Background: Photographs provide more information including colour, luminance, texture, and shading cues compared to line drawings. There is evidence that these additional cues facilitate image recognition in individuals with and without neurological deficits. Black-and-white line drawings and colour photographs are commonly used with individuals with aphasia in evaluation and treatment. Eye tracking provides an opportunity to assess the influence of these different image types on object recognition processes without relying on verbal responses. Aims: The purpose of this study was to determine whether differences in object recognition of photographs and line drawings were observed using eye-tracking measures. Specific goals were to compare the influence of (a) image type of the same target image presented as colour photograph and black-and-white line drawing and (b) degree of colour diagnosticity (high-colour diagnostic natural objects and low-colour diagnostic human-made objects) in multiple-choice image displays on language-mediated eye movements in language-normal adults. Methods & Procedures: Eye movements of 19 participants were recorded while they viewed 66 multiple-choice image displays of colour photographs and black-and-white line drawings presented with a verbal stimulus. Target images included high-colour diagnostic natural objects and low-colour diagnostic human-made objects. Outcomes & Results: Participants allocated significantly greater proportions of fixation duration and first-pass gaze duration to the photographs compared to line drawings. No significant differences were observed for colour diagnosticity differences within the colour or the black-and-white line drawing displays. Conclusions: Eye tracking indexed significant differences in fixation duration allocated to target images in displays that only differed with respect to image type and colour, and were otherwise carefully controlled for shape, size, orientation, and content conveyed. Results suggest that language-normal participants’ object recognition was facilitated by colour photographs compared to line drawings, highlighting the clinical relevance and the need for research of image design for clinical use with individuals with neurological impairments."
"Chao Ma, Xiaokang Yang, Chongyang Zhang, Xiang Ruan, Ming-Hsuan Yang",e2d37596f1ad4823fe042f37137ff54048231de2,Sketch retrieval via local dense stroke features,Image Vis. Comput.,2016.0,10,"Sketch retrieval aims at retrieving the most similar sketches from a large database based on one hand-drawn query. Successful retrieval hinges on an effective representation of sketch images and an efficient search method. In this paper, we propose a representation scheme which takes sketch strokes into account with local features, thereby facilitating efficient retrieval with codebooks. Stroke features are detected via densely sampled points on stroke lines with crucial corners as anchor points, from which local gradients are enhanced and described by a quantized histogram of gradients. A codebook is organized in a hierarchical vocabulary tree, which maintains structural information of visual words and enables efficient retrieval in sub-linear time. Experimental results on three data sets demonstrate the merits of the proposed algorithm for effective and efficient sketch retrieval. Display Omitted"
"William Souillard-Mandar, Randall Davis, C. Rudin, R. Au, D. Penney",725572a18bc7b90132878568a0fb016581afa8fd,Interpretable Machine Learning Models for the Digital Clock Drawing Test,ArXiv,2016.0,10,"The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular neuropsychological screening tool for cognitive conditions. The Digital Clock Drawing Test (dCDT) uses novel software to analyze data from a digitizing ballpoint pen that reports its position with considerable spatial and temporal precision, making possible the analysis of both the drawing process and final product. We developed methodology to analyze pen stroke data from these drawings, and computed a large collection of features which were then analyzed with a variety of machine learning techniques. The resulting scoring systems were designed to be more accurate than the systems currently used by clinicians, but just as interpretable and easy to use. The systems also allow us to quantify the tradeoff between accuracy and interpretability. We created automated versions of the CDT scoring systems currently used by clinicians, allowing us to benchmark our models, which indicated that our machine learning models substantially outperformed the existing scoring systems."
"Y. Ye, B. Li, Y. Lu",e372032468bd7d2daf333b8416408729633b12e9,3D sketch-based 3D model retrieval with convolutional neural network,2016 23rd International Conference on Pattern Recognition (ICPR),2016.0,9,"3D sketch-based 3D model retrieval is to retrieve similar 3D models using users' hand-drawn 3D sketches as input. Compared with traditional 2D sketch-based retrieval, 3D sketch-based 3D model retrieval is a brand new and challenging research topic. In this paper, we employ advanced deep learning method and propose a novel 3D sketch based 3D model retrieval system. Our system has been comprehensively tested on two benchmark datasets and compared with other existing 3D model retrieval algorithms. The experimental results reveal our approach outperforms other competing state-of-the-arts and demonstrate promising potential of our approach on 3D sketch based applications."
"Amit Daniely, Nevena Lazic, Y. Singer, Kunal Talwar",9ba4942194229417399dab584f9ca1fcad9e45e9,Sketching and Neural Networks,ArXiv,2016.0,9,"High-dimensional sparse data present computational and statistical challenges for supervised learning. We propose compact linear sketches for reducing the dimensionality of the input, followed by a single layer neural network. We show that any sparse polynomial function can be computed, on nearly all sparse binary vectors, by a single layer neural network that takes a compact sketch of the vector as input. Consequently, when a set of sparse binary vectors is approximately separable using a sparse polynomial, there exists a single-layer neural network that takes a short sketch as input and correctly classifies nearly all the points. Previous work has proposed using sketches to reduce dimensionality while preserving the hypothesis class. However, the sketch size has an exponential dependence on the degree in the case of polynomial classifiers. In stark contrast, our approach of using improper learning, using a larger hypothesis class allows the sketch size to have a logarithmic dependence on the degree. Even in the linear case, our approach allows us to improve on the pesky $O({1}/{{\gamma}^2})$ dependence of random projections, on the margin $\gamma$. We empirically show that our approach leads to more compact neural networks than related methods such as feature hashing at equal or better performance."
"Yuqian Zhang, N. Wang, Shengchuan Zhang, J. Li, Xinbo Gao",e914f76b19fe822df6a0a43860da6fc85f96da5f,Fast Face Sketch Synthesis via KD-Tree Search,ECCV Workshops,2016.0,8,"Automatic face sketch synthesis has been widely applied in digital entertainment and law enforcement. Currently, most sketch synthesis algorithms focus on generating face portrait of good quality, but ignoring the time consumption. Existing methods have large time complexity due to dense computation of patch matching in the neighbor selection process. In this paper, we propose a simple yet effective fast face sketch synthesis method based on K dimensional-Tree (KD-Tree). The proposed method employs the idea of divide-and-conquer (i.e. piece-wise linear) to learn the complex nonlinear mapping between facial photos and sketches. In the training phase, all the training images are divided into regions and every region is divided into some small patches, then KD-Tree is built up among training photo patches in each region. In the test phase, the test photo is first divided into some patches as the same way in the training phase. KD-Tree search is conducted for K nearest neighbor selection by matching the test photo patches in each region against the constructed KD-Tree of training photo patches in the same region. The KD-Tree process builds index structure which greatly reduces the time consumption for neighbor selection. Compared with synthesis methods using classical greedy search strategy (i.e. KNN), the proposed method is much less time consuming but with comparable synthesis performance. Experiments on the public CUHK face sketch (CUFS) database illustrate the effectiveness of the proposed method. In addition, the proposed neighbor selection strategy can be further extended to other synthesis algorithms."
"Adalat Jabrayilov, Sven Mallach, Petra Mutzel, U. Rüegg, R. V. Hanxleden",6a5420cd1cd154abff1ee44527273e50577d58b7,Compact Layered Drawings of General Directed Graphs,Graph Drawing,2016.0,8,"We consider the problem of layering general directed graphs under height and possibly also width constraints. Given a directed graph \(G=(V,A)\) and a maximal height, we propose a layering approach that minimizes a weighted sum of the number of reversed arcs, the arc lengths, and the width of the drawing. We call this the Compact Generalized Layering Problem (CGLP). Here, the width of a drawing is defined as the maximum sum of the number of vertices placed on a layer and the number of dummy vertices caused by arcs traversing the layer. The CGLP is \(\mathcal {NP}\)-hard. We present two MIP models for this problem. The first one (EXT) is our extension of a natural formulation for directed acyclic graphs as suggested by Healy and Nikolov. The second one (CGL) is a new formulation based on partial orderings. Our computational experiments on two benchmark sets show that the CGL formulation can be solved much faster than EXT using standard commercial MIP solvers. Moreover, we suggest a variant of CGL, called MML, that can be seen as a heuristic approach. In our experiments, MML clearly improves on CGL in terms of running time while it does not considerably increase the average arc lengths and widths of the layouts although it solves a slightly different problem where the dummy vertices are not taken into account."
"Christophe Rigaud, Thanh-Nam Le, J. Burie, J. Ogier, Shoya Ishimaru, M. Iwata, K. Kise",002aeb3ba00dd34eb52b705af105fcd5e30e53e5,Semi-automatic Text and Graphics Extraction of Manga Using Eye Tracking Information,2016 12th IAPR Workshop on Document Analysis Systems (DAS),2016.0,8,"The popularity of storing, distributing and reading comic books electronically has made the task of comics analysis an interesting research problem. Different work have been carried out aiming at understanding their layout structure and the graphic content. However the results are still far from universally applicable, largely due to the huge variety in expression styles and page arrangement, especially in manga (Japanese comics). In this paper, we propose a comic image analysis approach using eye-tracking data recorded during manga reading sessions. As humans are extremely capable of interpreting the structured drawing content, and show different reading behaviors based on the nature of the content, their eye movements follow distinguishable patterns over text or graphic regions. Therefore, eye gaze data can add rich information to the understanding of the manga content. Experimental results show that the fixations and saccades indeed form consistent patterns among readers, and can be used for manga textual and graphical analysis."
"B. Li, Y. Lu, F. Duan, S. Dong, Yachun Fan, Lu Qian, Hamid Laga, Haisheng Li, Yuxiang Li, Peng Liu, M. Ovsjanikov, H. Tabia, Y. Ye, H. Yin, Ziyu Xue",d8bf26697c68db309967550a75f794f655b0e4ec,3D Sketch-Based 3D Shape Retrieval,3DOR@Eurographics,2016.0,7,"Sketch-based 3D shape retrieval has unique representation availability of the queries and vast applications. Therefore, it has received more and more attentions in the research community of content-based 3D object retrieval. However, sketch-based 3D shape retrieval is a challenging research topic due to the semantic gap existing between the inaccurate representation of sketches and accurate representation of 3D models. In order to enrich and advance the study of sketch-based 3D shape retrieval, we initialize the research on 3D sketch-based 3D model retrieval and collect a 3D sketch dataset based on a developed 3D sketching interface which facilitates us to draw 3D sketches in the air while standing in front of a Microsoft Kinect. 
 
The objective of this track is to evaluate the performance of different 3D sketch-based 3D model retrieval algorithms using the hand-drawn 3D sketch query dataset and a generic 3D model target dataset. The benchmark contains 300 sketches that are evenly divided into 30 classes, as well as 1258 3D models that are classified into 90 classes. In this track, nine runs have been submitted by five groups and their retrieval performance has been evaluated using seven commonly used retrieval performance metrics. We wish this benchmark, the comparative evaluation results and the corresponding evaluation code will further promote sketch-based 3D shape retrieval and its applications."
"Xiao Zhang, X. Chen",f9d5efd2ca678829577c0f2185f5e18006ca2810,Robust Sketch-Based Image Retrieval by Saliency Detection,MMM,2016.0,7,"Sketch-based image retrieval SBIR has been extensively studied for decades because sketch is one of the most intuitive ways to describe ideas. However, the large expressional gap between hand-drawn sketches and natural images with small-scale complex structures is the fundamental challenge for SBIR systems. We present a novel framework to efficiently retrieve images with a query sketch based on saliency detection. In order to extract primary contours of the scene and depress textures, a hierarchical saliency map is computed for each image. Object contours are extracted from the saliency map instead of the original natural image. Histograms of oriented gradients HOG are extracted at multiple scales on a dense gradient field. Using a bag-of-visual-words representation and an inverted index structure, our system efficiently retrieves images by sketches. The experimental results conducted on a dataset of 15i¾?k photographs demonstrate that our method performs well for a wide range of natural scenes."
"Lei Li, Zhe Huang, C. Zou, C. Tai, Rynson W. H. Lau, Hao Zhang, P. Tan, Hongbo Fu",3c56008adf9ff0510116d3f63322e7ad80736fb4,Model-driven sketch reconstruction with structure-oriented retrieval,SIGGRAPH Asia Technical Briefs,2016.0,7,"We propose an interactive system that aims at lifting a 2D sketch into a 3D sketch with the help of existing models in shape collections. The key idea is to exploit part structure for shape retrieval and sketch reconstruction. We adopt sketch-based shape retrieval and develop a novel matching algorithm which considers structure in addition to traditional shape features. From a list of retrieved models, users select one to serve as a 3D proxy, providing abstract 3D information. Then our reconstruction method transforms the sketch into 3D geometry by back-projection, followed by an optimization procedure based on the Laplacian mesh deformation framework. Preliminary evaluations show that our retrieval algorithm is more effective than a state-of-the-art method and users can create interesting 3D forms of sketches without precise drawing skills."
"M. Indu, K. Kavitha",76333b2868a738d41adce72db3579627fbbcf59a,Survey on sketch based image retrieval methods,"2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)",2016.0,7,"In many applications critical roles are played by face sketch-photo synthesis, such as law enforcement and digital entertainment. Several image based retrieval systems are text based, content based and sketch based. Image retrieval methods which use sketch content as input are referred to as Sketch Based Image Retrieval systems. In several ways an image can be retrieved from the database using user queries as input. One of the efficient methods and popular methods for retrieval is as Sketch Based Image Retrieval which is not necessary to have a high skill to draw the query sketch. Paper reviews the various sketch based image retrieval methods used in image processing and a comparison of all these methods is also done. The retrieval system using sketches can be effective and essential in our day to day life such as Medical diagnosis, digital library, search engines, crime prevention, photo sharing sites, geographical information, and sensing remote systems."
"Raviteja Upadrashta, Tarun Choubisa, A. Praneeth, Tony Gracious, V. Aswath, P. V. Kumar, Sripad S. Kowshik, R. HariPrasadGokul, T. V. Prabhakar",60ec45baf6b2c021f736b67c0bddd83c610376f6,Animation and Chirplet-Based Development of a PIR Sensor Array for Intruder Classification in an Outdoor Environment,ArXiv,2016.0,7,"This paper presents the development of a passive infra-red sensor tower platform along with a classification algorithm to distinguish between human intrusion, animal intrusion and clutter arising from wind-blown vegetative movement in an outdoor environment. The research was aimed at exploring the potential use of wireless sensor networks as an early-warning system to help mitigate human-wildlife conflicts occurring at the edge of a forest. There are three important features to the development. Firstly, the sensor platform employs multiple sensors arranged in the form of a two-dimensional array to give it a key spatial-resolution capability that aids in classification. Secondly, given the challenges of collecting data involving animal intrusion, an Animation-based Simulation tool for Passive Infra-Red sEnsor (ASPIRE) was developed that simulates signals corresponding to human and animal intrusion and some limited models of vegetative clutter. This speeded up the process of algorithm development by allowing us to test different hypotheses in a time-efficient manner. Finally, a chirplet-based model for intruder signal was developed that significantly helped boost classification accuracy despite drawing data from a smaller number of sensors. An SVM-based classifier was used which made use of chirplet, energy and signal cross-correlation-based features. The average accuracy obtained for intruder detection and classification on real-world and simulated data sets was in excess of 97%."
"N. Wang, J. Li, Leiyu Sun, Bin Song, Xinbo Gao",fcc76b1762dbeb49cbfa30ca66bd405e015ca331,Training-Free Synthesized Face Sketch Recognition Using Image Quality Assessment Metrics,ArXiv,2016.0,6,"Face sketch synthesis has wide applications ranging from digital entertainments to law enforcements. Objective image quality assessment scores and face recognition accuracy are two mainly used tools to evaluate the synthesis performance. In this paper, we proposed a synthesized face sketch recognition framework based on full-reference image quality assessment metrics. Synthesized sketches generated from four state-of-the-art methods are utilized to test the performance of the proposed recognition framework. For the image quality assessment metrics, we employed the classical structured similarity index metric and other three prevalent metrics: visual information fidelity, feature similarity index metric and gradient magnitude similarity deviation. Extensive experiments compared with baseline methods illustrate the effectiveness of the proposed synthesized face sketch recognition framework. Data and implementation code in this paper are available online at www.ihitworld.com/WNN/IQA_Sketch.zip."
"Xueting Liu, Chengze Li, T. Wong",006b69083ae5be0a2cee3bdb50dfdeea7b2ccf40,Boundary-aware texture region segmentation from manga,Computational Visual Media,2016.0,6,"Due to the lack of color in manga (Japanese comics), black-and-white textures are often used to enrich visual experience. With the rising need to digitize manga, segmenting texture regions from manga has become an indispensable basis for almost all manga processing, from vectorization to colorization. Unfortunately, such texture segmentation is not easy since textures in manga are composed of lines and exhibit similar features to structural lines (contour lines). So currently, texture segmentation is still manually performed, which is labor-intensive and time-consuming. To extract a texture region, various texture features have been proposed for measuring texture similarity, but precise boundaries cannot be achieved since boundary pixels exhibit different features from inner pixels. In this paper, we propose a novel method which also adopts texture features to estimate texture regions. Unlike existing methods, the estimated texture region is only regarded an initial, imprecise texture region. We expand the initial texture region to the precise boundary based on local smoothness via a graph-cut formulation. This allows our method to extract texture regions with precise boundaries. We have applied our method to various manga images and satisfactory results were achieved in all cases."
"Claudiu Tanase, Ivan Giangreco, Luca Rossetto, H. Schuldt, Omar Seddati, S. Dupont, Ozan Can Altiok, T. M. Sezgin",9596ae4b67d68c6e53f4534ceeef9fcf48f26a6a,Semantic Sketch-Based Video Retrieval with Autocompletion,IUI Companion,2016.0,6,"The IMOTION system is a content-based video search engine that provides fast and intuitive known item search in large video collections. User interaction consists mainly of sketching, which the system recognizes in real-time and makes suggestions based on both visual appearance of the sketch (what does the sketch look like in terms of colors, edge distribution, etc.) and semantic content (what object is the user sketching). The latter is enabled by a predictive sketch-based UI that identifies likely candidates for the sketched object via state-of-the-art sketch recognition techniques and offers on-screen completion suggestions. In this demo, we show how the sketch-based video retrieval of the IMOTION system is used in a collection of roughly 30,000 video shots. The system indexes collection data with over 30 visual features describing color, edge, motion, and semantic information. Resulting feature data is stored in ADAM, an efficient database system optimized for fast retrieval."
"Shruti Nagpal, Mayank Vatsa, Richa Singh",0e8d85578ab6d45b851b1e161da566efec3ea7d2,Sketch Recognition: What Lies Ahead?,Image Vis. Comput.,2016.0,6,"Abstract “What is the state-of-the-art in sketch recognition and what are some important future research directions in matching sketches with digital face images?” This opinion paper focuses on answering these questions through proposing three important steps that need to move the field forward: (i) create a large, real world forensic sketch database, (ii) develop fundamental understanding of human cognition of processing sketches, and (iii) develop improved algorithms for matching sketches with mugshot photos."
"Olivier Augereau, Mizuki Matsubara, K. Kise",4411973c8d302330ea09b508e4c453c466e3dd43,Comic visualization on smartphones based on eye tracking,MANPU@ICPR,2016.0,6,"The visualization of comic images on a small screen is a difficult problem as the image is too large to be displayed on the screen and we do not know which areas and in which order the users want to see the image. The basic solution for the user is to look at the image in full screen without being able to see the details, or to zoom and scroll through the image, which can be quite inconvenient if the interactions have to often be repeated. Our idea is to use an eye tracker to record where the users reading a comic on paper books or large screens are looking at, to reproduce their reading behaviors with a comic visualization system and guide the users using a smaller screen through the comic."
"Jifei Song, Yi-Zhe Song, Tao Xiang, Timothy M. Hospedales, Xiang Ruan",aeca8b74c254dc886c4e85f6f8fbbeceaafb92f0,Deep Multitask Attribute-driven Ranking for Fine-grained Sketch-based Image Retrieval,,2016.0,5,"Fine-grained sketch-based image retrieval (SBIR) aims to go beyond conventional SBIR to perform instance-level cross-domain retrieval: finding the specific photo that matches an input sketch. Existing methods focus on designing/learning good features for cross-domain matching and/or learning cross-domain matching functions. However, they neglect the semantic aspect of retrieval, i.e., what meaningful object properties does a user try encode in her/his sketch? We propose a fine-grained SBIR model that exploits semantic attributes and deep feature learning in a complementary way. Specifically, we perform multi-task deep learning with three objectives, including: retrieval by fine-grained ranking on a learned representation, attribute prediction, and attribute-level ranking. Simultaneously predicting semantic attributes and using such predictions in the ranking procedure help retrieval results to be more semantically relevant. Importantly, the introduction of semantic attribute learning in the model allows for the elimination of the otherwise prohibitive cost of human annotations required for training a fine-grained deep ranking model. Experimental results demonstrate that our method outperforms the state-of-the-art on challenging fine-grained SBIR benchmarks while requiring less annotation."
"Ouyang Shuxin, Hospedales Timothy, Song Yi-zhe, Li Xueming, LoyChen Change, W. Xiaogang",18d70481ffef00bd4c38092dac18d69a5215c697,"A survey on heterogeneous face recognition: Sketch, infra-red, 3D and low-resolutionReview Article",,2016.0,5,
"Shuang Wu, Hang Su, Shibao Zheng, Hua Yang, Qin Zhou",4970e0568085e90b98ed6029ebd8f9c1b5750872,Motion sketch based crowd video retrieval via motion structure coding,2016 IEEE International Conference on Image Processing (ICIP),2016.0,5,"Crowd video retrieval is an important problem in surveillance video management in the era of big data, e.g., video indexing and browsing. In this paper, we address this issue from the motion-level perspective by using hand-drawn sketches as queries. Motion sketch based crowd video retrieval naturally suffers from challenges in motion-level video indexing and sketch representation. We tackle them by leveraging the motion structure coding algorithm to extract robust structure-preserved motion descriptors. For video indexing, we use motion decomposition to separate the sub-motion vector fields with typical patterns from a set of optical flows. Then, the motion-level descriptors of the vector fields are computed and stored in the index database. To represent sketch queries, we propose a sketch vectorization algorithm followed by motion structure coding. In the retrieval stage, given a new query, the retrieval function learned by the Ranking SVM algorithm predicts the ranking score of each motion pattern in the index database. Extensive experiments are conducted on the publicly available crowd datasets, which demonstrate the robustness and effectiveness of the proposed sketch based crowd video retrieval system."
"B. Li, Y. Lu, Jian Shen",585d7e06dc424f741144c6d9139aa9a8ddb8fa40,A semantic tree-based approach for sketch-based 3D model retrieval,2016 23rd International Conference on Pattern Recognition (ICPR),2016.0,5,"Sketch-based 3D model retrieval is to retrieve 3D models given a user's hand-drawn sketch. Due to the big semantic gap between rough sketch representation and accurate 3D model coordinates, sketch-based 3D model retrieval (SBR) is one of the most challenging research topics in the field of 3D model retrieval. To bridge the semantic gap, a novel semantic tree-based SBR algorithm is proposed in this paper. Given a 2D sketch query and a collection of 3D models, a 3D semantic tree is built up first based on the ontology structure of WordNet. Every leaf node in the tree contains a set of 3D models assigned to this class according to their semantic classification/label information. Then, sketch components of the 2D query sketch are identified by sketch segmentation and annotation. Finally, by measuring the semantic relatedness between the sketch components' annotations and tree nodes in the 3D semantic tree, the similarities between the 2D sketch and 3D models are computed to find out the most relevant 3D models. Experimental results demonstrate the effectiveness and promising potentials of our approach on sketch-based 3D model retrieval."
"Tahira Khalil, Javed Iqbal, A. Adnan",8fda7dc64ab3d4b2c888118f5d1630e6e46b125c,Low level visio-temporal features for violence detection in cartoon videos,2016 Sixth International Conference on Innovative Computing Technology (INTECH),2016.0,5,Cartoons are an informative way for creating awareness; children take keen interest in watching cartoons and spend leisure time in front of television. Unfortunately there is an inclination towards violence and other objectionable scenes in cartoon videos that have very bad impact on the developing personality of children. Extensive use of such violent scenes is one of the factors of increase of violence in society. Parents rely on cartoons as a mean of amusement for their children without analyzing its content which can pose serious negative impacts on child behavior. To protect children from violent content means are require for automatic detection of violence content in cartoon videos. In this paper different low-level visual features are evaluated for violence detection in cartoon videos using indigenously developed dataset that is categorized as violent and non-violent. From our results it has been observed that low-level visual features could not be used efficiently for the detection of violence. However these features are very helpful in identifying the character and situation that if combined with a knowledgebase capability can be used for detection of violence and other objectionable elements in the cartoon videos.
"Omar Seddati, S. Dupont, S. Mahmoudi",2827c4f6a62493047692d6f023348e087d001719,DeepSketch2Image: Deep Convolutional Neural Networks for Partial Sketch Recognition and Image Retrieval,ACM Multimedia,2016.0,4,"Freehand sketches are an interesting universal form of visual representation. Sketching has become easily accessible with many of the devices that we use on a daily basis. In this paper, we propose a system for real-time sketch recognition and similarity search. Our system is able to recognize partial sketches from 250 object categories. It is then able to retrieve similar sketches but also images/photographs. In this work, we propose to use deep convolutional neural networks (ConvNets) for partial sketch recognition and feature extraction. Features are extracted from sketches and image contours in order to be used as a basis for similarity search using k-Nearest Neighbors (kNN). Our system demonstrates promising results in identifying similar images, and could be integrated in larger content-based search engines."
"J. Zhou, Xin Tong, Zicheng Liu, B. Guo",148effda48ee146f8ad94bd8b598461226a0d94e,3D cartoon face generation by local deformation mapping,The Visual Computer,2016.0,4,"We present a data-driven method for automatically generating a 3D cartoon of a real 3D face. Given a sparse set of 3D real faces and their corresponding cartoon faces modeled by an artist, our method models the face in each subspace as the deformation of its nearby exemplars and learn a mapping between the deformations defined by the real faces and their cartoon counterparts. To reduce the exemplars needed for learning, we regress a collection of linear mappings defined locally in both face geometry and identity spaces and develop a progressive scheme for users to gradually add new exemplars for training. At runtime, our method first finds the nearby exemplars of an input real face and then constructs the result cartoon face from the corresponding cartoon faces of the nearby real face exemplars and the local deformations mapped from the real face subspace. Our method greatly simplifies the cartoon generation process by learning artistic styles from a sparse set of exemplars. We validate the efficiency and effectiveness of our method by applying it to faces of different facial features. Results demonstrate that our method not only preserves the artistic style of the exemplars, but also keeps the unique facial geometric features of different identities."
"Shengchuan Zhang, Xinbo Gao, Nannan Wang, Jie Li",f02b9a63b91d898f3cf9922661d02e0c23f70884,Robust Face Sketch Style Synthesis.,IEEE transactions on image processing : a publication of the IEEE Signal Processing Society,2016.0,4,"Heterogeneous image conversion is a critical issue in many computer vision tasks, among which example-based face sketch style synthesis provides a convenient way to make artistic effects for photos. However, existing face sketch style synthesis methods generate stylistic sketches depending on many photo-sketch pairs. This requirement limits the generalization ability of these methods to produce arbitrarily stylistic sketches. To handle such a drawback, we propose a robust face sketch style synthesis method, which can convert photos to arbitrarily stylistic sketches based on only one corresponding template sketch. In the proposed method, a sparse representation-based greedy search strategy is first applied to estimate an initial sketch. Then, multi-scale features and Euclidean distance are employed to select candidate image patches from the initial estimated sketch and the template sketch. In order to further refine the obtained candidate image patches, a multi-feature-based optimization model is introduced. Finally, by assembling the refined candidate image patches, the completed face sketch is obtained. To further enhance the quality of synthesized sketches, a cascaded regression strategy is adopted. Compared with the state-of-the-art face sketch synthesis methods, experimental results on several commonly used face sketch databases and celebrity photos demonstrate the effectiveness of the proposed method."
"Christophe Rigaud, S. Pal, J. Burie, J. Ogier",6fb9467d75a8ec9f21e0af77e68e5fff4687f989,Toward speech text recognition for comic books,MANPU@ICPR,2016.0,4,"Speech text in comic books is placed and written in a particular manner by the letterers which raises unusual challenges for text recognition. We first detail these challenges and present different approaches to solve them. We compare the performances of generic versus specifically trained OCR systems for typewritten and handwritten text lines from French comic books. This work is evaluated over a subset of public (eBDtheque) and private (Sequencity) datasets. We demonstrate that generic OCR systems perform best on typewritten-like and lowercase fonts while specifically trained OCR can be very powerful on skewed, uppercase and even cursive fonts."
"C. Tu, Yu-Hsien Chan, Yi-Chung Chen",dd03a7f46de119250565cce118a1daafdcc649c7,Facial Sketch Synthesis Using 2D Direct Combined Model-Based Face-Specific Markov Network.,IEEE transactions on image processing : a publication of the IEEE Signal Processing Society,2016.0,3,"A facial sketch synthesis system is proposed, featuring a 2D direct combined model (2DDCM)-based face-specific Markov network. In contrast to the existing facial sketch synthesis systems, the proposed scheme aims to synthesize sketches, which reproduce the unique drawing style of a particular artist, where this drawing style is learned from a data set consisting of a large number of image/sketch pairwise training samples. The synthesis system comprises three modules, namely, a global module, a local module, and an enhancement module. The global module applies a 2DDCM approach to synthesize the global facial geometry and texture of the input image. The detailed texture is then added to the synthesized sketch in a local patch-based manner using a parametric 2DDCM model and a non-parametric Markov random field (MRF) network. Notably, the MRF approach gives the synthesized results an appearance more consistent with the drawing style of the training samples, while the 2DDCM approach enables the synthesis of outcomes with a more derivative style. As a result, the similarity between the synthesized sketches and the input images is greatly improved. Finally, a post-processing operation is performed to enhance the shadowed regions of the synthesized image by adding strong lines or curves to emphasize the lighting conditions. The experimental results confirm that the synthesized facial images are in good qualitative and quantitative agreement with the input images as well as the ground-truth sketches provided by the same artist. The representing power of the proposed framework is demonstrated by synthesizing facial sketches from input images with a wide variety of facial poses, lighting conditions, and races even when such images are not included in the training data set. Moreover, the practical applicability of the proposed framework is demonstrated by means of automatic facial recognition tests."
"Emin Ibili, Sami Sahin",540f1ce0cd96ac1af80bb1ddbd876e511558eace,The use of cartoons in elementary classrooms: An analysis of teachers behavioral intention in terms of gender,,2016.0,3,"Among multimedia researches, contribution of cartoons to teaching process and academic achievement has often been examined. However, these technologies may have a slower and less effect since acceptance of them by users is affected by many factors.  Therefore, it is extremely important to understand and reveal the factors which encourage teachers who are to choose the most appropriate tool and material for students during teaching period to use cartoons for teaching or restrict their use. To this end, teachers’ perceptions, attitudes, intentions and behaviors concerning the use of cartoons for teaching were examined and modeled according to Technology Acceptance Model (TAM). As a result of the analyses, data were obtained from 271 teachers who work in several provinces to test its relationship between the variables of perceived benefit, perceived ease of use, attitude towards use, intention of use and actual behavior stated in TAM. The data obtained were analyzed with Structural Equation Modeling (SEM). The results show that the model gives different results from the ones foreseen in TAM. Moreover, it was seen according to the paired comparisons on the model that the only significant difference between females and males is attitude predicting strength of the perceived benefit 
 
 Key words:  Technology acceptance model, structural equation modeling, educational cartoons."
"David Rim, Sina Honari, Md. Kamrul Hasan, C. Pal",f431d3d7a0323bf1150420c826dade2093a7dfa1,Improving facial analysis and performance driven animation through disentangling identity and expression,Image Vis. Comput.,2016.0,3,"We present techniques for improving performance driven facial animation, emotion recognition, and facial key-point or landmark prediction using learned identity invariant representations. Established approaches to these problems can work well if sufficient examples and labels for a particular identity are available and factors of variation are highly controlled. However, labeled examples of facial expressions, emotions and key-points for new individuals are difficult and costly to obtain. In this paper we improve the ability of techniques to generalize to new and unseen individuals by explicitly modeling previously seen variations related to identity and expression. We use a weakly-supervised approach in which identity labels are used to learn the different factors of variation linked to identity separately from factors related to expression. We show how probabilistic modeling of these sources of variation allows one to learn identity-invariant representations for expressions which can then be used to identity-normalize various procedures for facial expression analysis and animation control. We also show how to extend the widely used techniques of active appearance models and constrained local models through replacing the underlying point distribution models which are typically constructed using principal component analysis with identity-expression factorized representations. We present a wide variety of experiments in which we consistently improve performance on emotion recognition, markerless performance-driven facial animation and facial key-point tracking. Identity-expression disentanglement can improve performance driven facial animation.An identity-expression factorization approach can improve both AAMs and CLMs.Identity-expression disentanglement can improve facial expression recognition."
"Fei Wang, Shujin Lin, Hefeng Wu, Ruomei Wang, Xiaonan Luo",1e8d5f160bf72f7d25440924842468cefe37b170,Data-driven method for sketch-based 3D shape retrieval based on user similar draw-style recommendation,SIGGRAPH Asia Posters,2016.0,2,"Sketching is a simple and natural way of expression and communication for humans. It also gains increasing popularity in human computer interaction, with the emergence of multitouch tablets and styluses. The main characteristics of sketches can be summarized in two aspects: (i) the fuzziness of the sketch information, which can be attributed to that the completeness of the sketch is evolving with the drawing process and there is no fixed mapping between the user expression and the sketch; (ii) the randomness of user input, arising from that users' input is not only associated with their field background, way of thinking, hand-painted habits and preferences, but also affected by types of equipments and environmental factors. These two characteristics make the sketch can express creative thinking, but it is also the two characteristics that make the freehand sketch recognition algorithm must have enough robustness to support user interaction. Neglecting the above two issues in previous studies causes the results to be less satisfactory. In recent years, sketch-based interactive methods are widely used in many retrieval systems. In particular, a variety of sketch-based 3D model retrieval works have been presented. However, almost all these works focus on directly matching sketches with the projection views of 3D models, and they suffer from the large differences between the sketch drawing and the views of 3D models, leading to unsatisfying retrieval results. Therefore, in this article, during the matching procedure in the retrieval, we propose to match the sketch with the ones of each 3D model from historical users instead of projection views. Yet since the sketches between the current user and the historical users can have big difference, we also study appropriate methods to handle users' personalized deviations and differences. To this end, we leverage recommendation algorithms to estimate the drawing style characteristic similarity between the current user and historical users."
"Yuqi Zhang, Y. Zhang, Xueming Qian",e8cbcff26d357f58ee601ed72cffda467271b3d2,Deep Neural Networks for Free-Hand Sketch Recognition,PCM,2016.0,2,"The paper presents a deep Convolutional Neural Network (CNN) framework for free-hand sketch recognition. One of the main challenges in free-hand sketch recognition is to increase the recognition accuracy on sketches drawn by different people. To overcome this problem, we use deep Convolutional Neural Networks (CNNs) that have dominated top results in the field of image recognition. And we use the contours of natural images for training, because sketches drawn by different people may be very different and databases of the sketch images for training are very limited. We propose a CNN training on contours that performs well on sketch recognition over different databases of the sketch images. And we make some adjustments to the contours for training and reach higher recognition accuracy. Experimental results show the effectiveness of the proposed approach."
"Takuya Akiba, Kenko Nakamura, T. Takaguchi",97f7ee6372c3831777e43055b9b343e4f42ce572,Fractality of Massive Graphs: Scalable Analysis with Sketch-Based Box-Covering Algorithm,2016 IEEE 16th International Conference on Data Mining (ICDM),2016.0,2,"Analysis and modeling of networked objects are fundamental pieces of modern data mining. Most real-world networks, from biological to social ones, are known to have common structural properties. These properties allow us to model the growth processes of networks and to develop useful algorithms. One remarkable example is the fractality of networks, which suggests the self-similar organization of global network structure. To determine the fractality of a network, we need to solve the so-called box-covering problem, where preceding algorithms are not feasible for large-scale networks. The lack of an efficient algorithm prevents us from investigating the fractal nature of large-scale networks. To overcome this issue, we propose a new box-covering algorithm based on recently emerging sketching techniques. We theoretically show that it works in near-linear time with a guarantee of solution accuracy. In experiments, we have confirmed that the algorithm enables us to study the fractality of million-scale networks for the first time. We have observed that its outputs are sufficiently accurate and that its time and space requirements are orders of magnitude smaller than those of previous algorithms."
"Mustafa Majeed Abd Zaid Almizragee, Ghadah Al-Khafaji",bedce3daa5abeffc5c11573e1129ff48ba16de56,Content-Based Cartoon Images Retrieval,,2016.0,1,"Cartoon images play essential roles in our everyday lives especially in entertainment, education, and advertisement, that become an increasingly intensive research in the field of multimedia and computer graphics[1-2]. Cartoon image retrieval is bedrock of producer's new cartoon videos, particularly when provides initial planning to be elevated in so as to identify their intention of artistic [3]. Today, a number of researchers have exploited the concepts related to content based images retrieval (CBIR) to search for cartoon images containing particular object(s) of interest [4] This paper aims to design content-based retrieval system for cartoon images. The proposed image retrieval system consists of four basic stages “(image quantization, object extraction, feature extraction and similarity matching). Given a query image, the system extracts features for the query image which is a percentage of each index value (dominant color), cluster values for three bands of quantization image (RGB), and the weight of each index values (weight of each dominant color) depends on its location in the image, then compares it with the images features in database system in similarity matching stage and then the top 10 images are retrieved as the query results."
"Yuting Mai, Wei-Hong Li, Yongyi Tang, Xixi Bi, W. Zheng",b46f6ebe65b32796f180c7c73f5ac6c967fd2381,Sketch metric learning,2016 International Joint Conference on Neural Networks (IJCNN),2016.0,1,"The main theme of this paper is to develop a systematic framework to learn a Mahalanobis distance metric based on matrix sketching. Within this framework, we present a novel sketch metric learning algorithm which sequentially sketches the received samples from training dataset and formulates a new kind of constraint for metric learning. This is in contrast to the traditional constraints that are only consisted of data from training dataset. In this paper, one training instance in the constraint is replaced by a pseudo center, which is generated during the sketching stage. Due to this change, our learning algorithm can focus on pushing every received sample to its corresponding similar pseudo center closer and pulling it far away from the dissimilar one. In addition, it can further achieve better performance of some kinds of time-varying process (e.g. on object tracking) than the compared related competitors. We demonstrate how to implement other methods in our algorithm framework and experiment to show that our method outperforms the competitors and relevant baselines on multiple datasets."
M. Kuba,4fa088b9ce2885735ebe713484bb78cb06c027fd,Classification of urn models with multiple drawings,,2016.0,1,We consider multicolor urn models with multiple drawings. An urn model is called linear if the conditional expected value of the urn composition at time $n$ is a linear function of the composition at time $n-1$. For four different sampling schemes - ordered and unordered samples with or without replacement - we classify urns into linear and non-linear models. We also discuss representations of the expected value and the covariance for linear models.
"Muhammad Jawaherul Alam, M. Dillencourt, M. Goodrich",bab63a16948c6412db55005e69e708b54c155144,Capturing Lombardi Flow in Orthogonal Drawings by Minimizing the Number of Segments,ArXiv,2016.0,1,"Inspired by the artwork of Mark Lombardi, we study the problem of constructing orthogonal drawings where a small number of horizontal and vertical line segments covers all vertices. We study two problems on orthogonal drawings of planar graphs, one that minimizes the total number of line segments and another that minimizes the number of line segments that cover all the vertices. We show that the first problem can be solved by a non-trivial modification of the flow-network orthogonal bend-minimization algorithm of Tamassia, resulting in a polynomial-time algorithm. We show that the second problem is NP-hard even for planar graphs with maximum degree 3. Given this result, we then address this second optimization problem for trees and series-parallel graphs with maximum degree 3. For both graph classes, we give polynomial-time algorithms for upward orthogonal drawings with the minimum number of segments covering the vertices."
"J. Vettel, J. Kantner, Matthew Jaswa, Michael B. Miller",74032e526edb45bc6c79cb5576e69486e72a316d,Animated 3D Human Models for Use in Person Recognition Experiments,ArXiv,2016.0,1,"The development of increasingly realistic experimental stimuli and task environments is important for understanding behavior outside the laboratory. We report a process for generating 3D human model stimuli that combines commonly used graphics software and enables the flexible generation of animated human models while providing parametric control over individualized identity features. Our approach creates novel head models using FaceGen Modeller, attaches them to commercially-purchased 3D avatar bodies in 3D Studio Max, and generates Cal3D human models that are compatible with many virtual 3D environments. Stimuli produced by this method can be embedded as animated 3D avatars in interactive simulations or presented as 2D images embedded in scenes for use in traditional laboratory experiments. The inherent flexibility in this method makes the stimuli applicable to a broad range of basic and applied research questions in the domain of person perception. We describe the steps of the stimulus generation process, provide an example of their use in a recognition memory paradigm, and highlight the adaptability of the method for related avenues of research."
"M. Ashouri, A. Golshani, D. Moazzami, Mandana Ghasemi",241c2afe37fcb903ba819d6a90e35711c918d7f6,Graphs Drawing through Fuzzy Clustering,ArXiv,2016.0,1,"Many problems can be presented in an abstract form through a wide range of binary objects and relations which are defined over problem domain. In these problems, graphical demonstration of defined binary objects and solutions is the most suitable representation approach. In this regard, graph drawing problem discusses the methods for transforming combinatorial graphs to geometrical drawings in order to visualize them. This paper studies the force-directed algorithms and multi-surface techniques for drawing general undirected graphs. Particularly, this research describes force-directed approach to model the drawing of a general graph as a numerical optimization problem. So, it can use rich knowledge which is presented as an established system by the numerical optimization. Moreover, this research proposes the multi-surface approach as an efficient tool for overcoming local minimums in standard force-directed algorithms. Next, we introduce a new method for multi-surface approach based on fuzzy clustering algorithms."
"Pramook Khungurn, Derek Chou",a730e711f703f40a0c5e21854c928ed79df45872,Pose estimation of anime/manga characters: a case for synthetic data,MANPU@ICPR,2016.0,1,"2D articulated pose estimation is the task of locating the body joint positions of a human figure in an image. A pose estimator that works on anime/manga images could be an important component of an automatic system to create 3D animation from existing manga or anime, which could significantly the lower cost of media production. To create an accurate pose estimator, however, a sizable and high-quality dataset is needed, and such a dataset can be expensive to create. To alleviate data scarcity, we propose using a database of 3D character models and poses to generate synthetic training data for 2D pose estimators of anime/manga characters based on convolutional neural networks (CNN). We demonstrate that a high-performing estimator can be obtained by pretraining a network on a large synthetic dataset and then fine-tuning it on a small dataset of drawings. We also show that the approach yields a pose estimator competitive with many previous works when applied to a photograph-based dataset, establishing our synthetic data's usefulness beyond the intended domain."
"Natsumi Kubota, Shinjiro Niino, Satoshi Nakamura, M. Suzuki",dfe3ea5db744de4d6b041e773e355e7d7f8af0ce,A sustainable practice method of hand-drawing by merging user's stroke and model's stroke,MANPU@ICPR,2016.0,1,"Nowadays, people have become able to publish their comics easily because of the spread of Web services featuring their own content. However, it is not easy for them to publish such comics because of the difficulty of improving their hand-drawing skill. One practice method is tracing. However, it is not easy for people to maintain motivation for this practice method. In this paper, we propose a method which enables people to improve their hand-drawing skills and motivation by creating a merging of their hand-drawn character and a corresponding model which is drawn by others automatically. We validate the usefulness of our method by using the system and show how to change the appearance of illustrations."
"N. S. Hirata, I. Montagner, R. Hirata",85db4bf566fa8f61ccda7c4b1314284a263afe07,Comics image processing: learning to segment text,MANPU@ICPR,2016.0,1,"We employ an image operator learning method to segment text in comic images. Since the method is based on learning from pairs of input and corresponding expected output images, it is flexible with respect to alphabet sets and text orientation. The method is applied on both Japanese and European comics. Results indicate that most text regions can be straightforwardly identified from the output images."
"Kota Ito, Yusuke Matsui, T. Yamasaki, K. Aizawa",4d507e9e9e2f8834cf56eb675f5c5e5477cd15b2,Interactive region segmentation for manga,2016 23rd International Conference on Pattern Recognition (ICPR),2016.0,1,"Manga (Japanese comics) are popular all over the world, and are created digitally. In this paper, we propose an interactive segmentation method tailored for manga. The proposed method enables annotators to select areas in manga efficiently. Our experimental results showed that the proposed framework works better than Adobe Photoshop CC, which is the most widely used commercial image editing software."
Radoslav M. Dimitrić,332def24a084388ddda75cd347299802f63339a9,Mathematics: abstraction and reality. A sketch toward deeper analysis,,2016.0,0,"This paper establishes grounds for deeper exploration into the question of dual nature of mathematics as an abstract discipline and as a concrete science. It is argued, as one of the consequences of the discussion, that the division into ""pure"" and ""applied"" mathematics is artificial. The criterion of creativity and applicability outside of the original context is used as a litmus test. It is emphasized that great societies and cultural environments produce great mathematics and individual mathematicians."
"Haishan Ye, Qiaoming Ye, Zhihua Zhang",c3734200c6da25af3fc6dcc955fae3e271b236d3,Tighter bound of Sketched Generalized Matrix Approximation,ArXiv,2016.0,0,"Generalized matrix approximation plays a fundamental role in many machine learning problems, such as CUR decomposition, kernel approximation, and matrix low rank approximation. Especially with today's applications involved in larger and larger dataset, more and more efficient generalized matrix approximation algorithems become a crucially important research issue. In this paper, we find new sketching techniques to reduce the size of the original data matrix to develop new matrix approximation algorithms. Our results derive a much tighter bound for the approximation than previous works: we obtain a $(1+\epsilon)$ approximation ratio with small sketched dimensions which implies a more efficient generalized matrix approximation."
"S. Lee, Y. Yang, Shiyan Yan, Yujin Zhang, Isabelle Wong, Zhengxi Tan, Miles McGruder, Christopher Homan, Walter S. Lasecki",585f5afd0aebd31fbfb34bc9f84358a5bcf7da59,Creating Interactive Behaviors in Early Sketch by Recording and Remixing Crowd Demonstrations,ArXiv,2016.0,0,"In the early stages of designing graphical user interfaces (GUIs), the look (appearance) can be easily presented by sketching, but the feel (interactive behaviors) cannot, and often requires an accompanying description of how it works (Myers et al. 2008). We propose to use crowdsourcing to augment early sketches with interactive behaviors generated, used, and reused by collective ""wizards-of-oz"" as opposed to a single wizard as in prior work (Davis et al. 2007). This demo presents an extension of Apparition (Lasecki et al. 2015), a crowd-powered prototyping tool that allows end users to create functional GUIs using speech and sketch. In Apparition, crowd workers collaborate in real-time on a shared canvas to refine the user-requested sketch interactively, and with the assistance of the end users. Our demo extends this functionality to let crowd workers ""demonstrate"" the canvas changes that are needed for a behavior and refine their demonstrations to improve the fidelity of interactive behaviors. The system then lets workers ""remix"" these behaviors to make creating future behaviors more efficient."
"Hugo Martin, R. Fernandez, Yong Khoo",64f21da8f1587713bd6285175369dcbb80f80376,Large Angle based Skeleton Extraction for 3D Animation,ArXiv,2016.0,0,"In this paper, we present a solution for arbitrary 3D character deformation by investigating rotation angle of decomposition and preserving the mesh topology structure. In computer graphics, skeleton extraction and skeleton-driven animation is an active areas and gains increasing interests from researchers. The accuracy is critical for realistic animation and related applications. There have been extensive studies on skeleton based 3D deformation. However for the scenarios of large angle rotation of different body parts, it has been relatively less addressed by the state-of-the-art, which often yield unsatisfactory results. Besides 3D animation problems, we also notice for many 3D skeleton detection or tracking applications from a video or depth streams, large angle rotation is also a critical factor in the regression accuracy and robustness. We introduced a distortion metric function to quantify the surface curviness before and after deformation, which is a major clue for large angle rotation detection. The intensive experimental results show that our method is suitable for 3D modeling, animation, skeleton based tracking applications."
"M. Nosrati, F. Rahimi, Ronak Karimi",71c901dea74925282693b94c2edb97e7f823c0a3,Language free character recognition using character sketch and center of gravity shifting,ArXiv,2016.0,0,"In this research, we present a heuristic method for character recognition. For this purpose, a sketch is constructed from the image that contains the character to be recognized. This sketch contains the most important pixels of image that are representatives of original image. These points are the most probable points in pixel-by-pixel matching of image that adapt to target image. Furthermore, a technique called gravity shifting is utilized for taking over the problem of elongation of characters. The consequence of combining sketch and gravity techniques leaded to a language free character recognition method. This method can be implemented independently for real-time uses or in combination of other classifiers as a feature extraction algorithm. Low complexity and acceptable performance are the most impressive features of this method that let it to be simply implemented in mobile and battery-limited computing devices. Results show that in the best case 86% of accuracy is obtained and in the worst case 28% of recognized characters are accurate."
"Yukihiro Moriyama, Byeongseon Park, Shinnosuke Iwaoki, M. Matsushita",ca52bdcf27f2dd42905f1eea7a440534dc5c2984,Designing a question-answering system for comic contents,MANPU@ICPR,2016.0,0,"The objective of our research is to create a question answering system for comics. Because a comic has multimodal contents, we have to answer questions about text as well as illustrations. This is different from the conventional question answering system. To solve this problem, in this study, we organized the information to be obtained from comic illustrations and examined the framework of question answering for this content. Then, we built a prototype system and examined the question answering system for comic contents."
"Clément Guérin, J. Burie, J. Ogier",20c5ca0922a85f6c52c7e6e5e85d2a1f5137f929,Detection of comic books twin pages with a non-overlapping stitching method,MANPU@ICPR,2016.0,0,"We address in this paper the issue of stitching non overlapping pairs of real digitized comic books' pages. The main objective is to be able to decide if two pages are meant to be displayed together for their content to be understood. First, the relevant content is separated from the background so the pairing is done over relevant pieces of visual information. We define the different kinds of noise that one can found on the edges of such documents and how to get rid of it. Then we propose a method to decide whether a couple of pages should be paired or not, based on the analysis of the relevant content. Our compatibility methods are evaluated against the methods from the literature, adapted from jigsaw puzzles solvers. Results are discussed over an actual commercial dataset of digitized comic books."
Akihiko Shirai,5fde72da5215d0ef0dd7ca56ac3c15874530a73a,"Manga generator, a future of interactive manga media: invited talk paper",MANPU@ICPR,2016.0,0,"This article contributes to the realization of an immersive role playing manga generating advertising system named ""Manga Generator"". The project began as a student virtual reality project and had underwent various collaborations with professional manga artists and governmental agencies. It was exhibited at many international exhibitions and is currently a permanent exhibition in a museum. The latest version ""MGV"" is a new advertising entertainment system that enables up to two players to engage in role playing interactive manga while allowing other audiences to see advertisement video simultaneously using multiplex hidden image technology ""ExPixel"". In this research, we combined interactive comic generating system with full body motion detection and real time image processing technologies. It can attract non-audiences who are not interested in the video announcements thanks to players playing Manga Generator."
"K. Gregor, Ivo Danihelka, A. Graves, Danilo Jimenez Rezende, Daan Wierstra",a2785f66c20fbdf30ec26c0931584c6d6a0f4fca,DRAW: A Recurrent Neural Network For Image Generation,ICML,2015.0,1473,"This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye."
"Fang Wang, Le Kang, Y. Li",c43986083db2a17f10caf99cda6b227048fa58b7,Sketch-based 3D shape retrieval using Convolutional Neural Networks,2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015.0,269,"Retrieving 3D models from 2D human sketches has received considerable attention in the areas of graphics, image retrieval, and computer vision. Almost always in state of the art approaches a large amount of “best views” are computed for 3D models, with the hope that the query sketch matches one of these 2D projections of 3D models using predefined features. We argue that this two stage approach (view selection - matching) is pragmatic but also problematic because the “best views” are subjective and ambiguous, which makes the matching inputs obscure. This imprecise nature of matching further makes it challenging to choose features manually. Instead of relying on the elusive concept of “best views” and the hand-crafted features, we propose to define our views using a minimalism approach and learn features for both sketches and views. Specifically, we drastically reduce the number of views to only two predefined directions for the whole dataset. Then, we learn two Siamese Convolutional Neural Networks (CNNs), one for the views and one for the sketches. The loss function is defined on the within-domain as well as the cross-domain similarities. Our experiments on three benchmark datasets demonstrate that our method is significantly better than state of the art approaches, and outperforms them in all conventional metrics."
"Liliang Zhang, Liang Lin, X. Wu, Shengyong Ding, Lei Zhang",52189854026300efefc78f7f8afb1d06a6430bd4,End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning,ICMR,2015.0,89,"Sketch-based face recognition is an interesting task in vision and multimedia research, yet it is quite challenging due to the great difference between face photos and sketches. In this paper, we propose a novel approach for photo-sketch generation, aiming to automatically transform face photos into detail-preserving personal sketches. Unlike the traditional models synthesizing sketches based on a dictionary of exemplars, we develop a fully convolutional network to learn the end-to-end photo-sketch mapping. Our approach takes whole face photos as inputs and directly generates the corresponding sketch images with efficient inference and learning, in which the architecture is stacked by only convolutional kernels of very small sizes. To well capture the person identity during the photo-sketch transformation, we define our optimization objective in the form of joint generative discriminative minimization. In particular, a discriminative regularization term is incorporated into the photo-sketch generation, enhancing the discriminability of the generated person sketches against other individuals. Extensive experiments on several standard benchmarks suggest that our approach outperforms other state-of-the-arts in both photo sketch generation and face sketch verification."
"Y. Li, Timothy M. Hospedales, Yi-Zhe Song, S. Gong",b4e78e374f7828c9a6e89d87a3b31f1b8e18a3f2,Free-hand sketch recognition by multi-kernel feature learning,Comput. Vis. Image Underst.,2015.0,79,"Free-hand sketch recognition has become increasingly popular due to the recent expansion of portable touchscreen devices. However, the problem is non-trivial due to the complexity of internal structures that leads to intra-class variations, coupled with the sparsity in visual cues that results in inter-class ambiguities. In order to address the structural complexity, a novel structured representation for sketches is proposed to capture the holistic structure of a sketch. Moreover, to overcome the visual cue sparsity problem and therefore achieve state-of-the-art recognition performance, we propose a Multiple Kernel Learning (MKL) framework for sketch recognition, fusing several features common to sketches. We evaluate the performance of all the proposed techniques on the most diverse sketch dataset to date (Mathias et al., 2012), and offer detailed and systematic analyses of the performance of different features and representations, including a breakdown by sketch-super-category. Finally, we investigate the use of attributes as a high-level feature for sketches and show how this complements low-level features for improving recognition performance under the MKL framework, and consequently explore novel applications such as attribute-based retrieval."
Edith Cohen,d626d58c0fe9ec23d8614da9ac40f99a2c309ec7,"All-Distances Sketches, Revisited: HIP Estimators for Massive Graphs Analysis",IEEE Transactions on Knowledge and Data Engineering,2015.0,74,"Graph datasets with billions of edges, such as social and web graphs, are prevalent, and scalability is critical. All-distances sketches (ADS) [Cohen 1997], are a powerful tool for scalable approximation of statistics. The sketch is a small size sample of the distance relation of a node which emphasizes closer nodes. Sketches for all nodes are computed using a nearly linear computation and estimators are applied to sketches of nodes to estimate their properties. We provide, for the first time, a unified exposition of ADS algorithms and applications. We present the historic inverse probability (HIP) estimators which are applied to the ADS of a node to estimate a large natural class of statistics. For the important special cases of neighborhood cardinalities (the number of nodes within some query distance) and closeness centralities, HIP estimators have at most half the variance of previous estimators and we show that this is essentially optimal. Moreover, HIP obtains a polynomial improvement for more general statistics and the estimators are simple, flexible, unbiased, and elegant. For approximate distinct counting on data streams, HIP outperforms the original estimators for the HyperLogLog MinHash sketches (Flajolet et al. 2007), obtaining significantly improved estimation quality for this state-of-the-art practical algorithm."
"William Souillard-Mandar, Randall Davis, C. Rudin, R. Au, D. Libon, R. Swenson, C. Price, M. Lamar, D. Penney",12f837243ae634623606b37f4d3c6166e37ba6a8,Learning classification models of cognitive conditions from subtle behaviors in the digital Clock Drawing Test,Machine Learning,2015.0,74,"The Clock Drawing Test—a simple pencil and paper test—has been used for more than 50 years as a screening tool to differentiate normal individuals from those with cognitive impairment, and has proven useful in helping to diagnose cognitive dysfunction associated with neurological disorders such as Alzheimer’s disease, Parkinson’s disease, and other dementias and conditions. We have been administering the test using a digitizing ballpoint pen that reports its position with considerable spatial and temporal precision, making available far more detailed data about the subject’s performance. Using pen stroke data from these drawings categorized by our software, we designed and computed a large collection of features, then explored the tradeoffs in performance and interpretability in classifiers built using a number of different subsets of these features and a variety of different machine learning techniques. We used traditional machine learning methods to build prediction models that achieve high accuracy. We operationalized widely used manual scoring systems so that we could use them as benchmarks for our models. We worked with clinicians to define guidelines for model interpretability, and constructed sparse linear models and rule lists designed to be as easy to use as scoring systems currently used by clinicians, but more accurate. While our models will require additional testing for validation, they offer the possibility of substantial improvement in detecting cognitive impairment earlier than currently possible, a development with considerable potential impact in practice."
"H. Laurent, J. Coër, P. Manach, M. Oliveira, L. Menezes",276941d81dc988d874ea92c03342d69375222fd7,Experimental and numerical studies on the warm deep drawing of an Al–Mg alloy,,2015.0,69,"Abstract The warm deep drawing of circular AA5754-O aluminium alloy blanks was investigated both experimentally using specially designed equipment and numerically using a fully coupled thermo-mechanical finite element model. Cylindrical cups were prepared with a heated die and blank-holder. The split-ring test was used to measure the effects of the temperature on the springback process from room temperature to 200 °C. Temperatures above 150 °C were found to greatly affect the force/displacement response during the forming process and the ironing phase, the earing profile and the springback effect. Tensile and shear tests were also performed to study the temperature-dependent mechanical responses. To simulate this process, a temperature-dependent anisotropic model for the material was implemented in the commercial code ABAQUS/Standard, based on the UMAT interface for user-material models. The parameters of a phenomenological Hockett–Sherby hardening model and a power law strain rate dependency were identified using data obtained in uniaxial tensile and shear tests at various temperatures and strain rates, in order to account for both the temperature and the viscous effects in the coupled thermomechanical constitutive law. Von Mises isotropic criterion and Hill׳48 anisotropic yield criterion were also adopted to describe the material mechanical behaviour. The influence of the contact with friction conditions in the forming process (i.e. punch force evolution, thickness distribution along the cup wall and earing profiles) was also analysed. The numerical results obtained with the calibrated parameters generally showed a good match with the experimental temperatures. The results highlighted the importance of the correct choice of the yield criteria. The Hill48 criterion showed difficulties in the correct prediction of the springback process for this aluminium alloy."
"J. M. Saavedra, J. M. Barrios",d6aca3db890ebb617dc3bbd49708c0f16a621f05,Sketch based Image Retrieval using Learned KeyShapes (LKS),BMVC,2015.0,63,"Sketch based image retrieval is a particular case of the image retrieval problem, in which a query is not a regular example image. Instead, the query is a hand-drawn sketch representing what the user is looking for. This kind of problem has a lot of applications, in particular when an example image is not available. For instance, in searching for design pieces in digital catalogs. The natural ambiguity of sketches as well as the poor skills of drawing make the problem very challenging, which is reflected in the low performance achieved by current methods. In this work, we present a novel method for describing sketches based on detecting mid-level patterns called learned keyshapes. Our experiments were performed in two datasets, one with 1326 images and the other with approximately 15k images. Our results show an increase of effectiveness around 17% on the smaller dataset and 98% on the larger one, which represent new state-of-the-art performance in the sketch based image retrieval domain. We also show that our method allows us to achieve good performance even when we use around 20% of the sketch content."
"Shengchuan Zhang, Xinbo Gao, N. Wang, J. Li, Mingjin Zhang",830360f010624ab86576bcf5278035a4bda95b12,Face Sketch Synthesis via Sparse Representation-Based Greedy Search,IEEE Transactions on Image Processing,2015.0,60,"Face sketch synthesis has wide applications in digital entertainment and law enforcement. Although there is much research on face sketch synthesis, most existing algorithms cannot handle some nonfacial factors, such as hair style, hairpins, and glasses if these factors are excluded in the training set. In addition, previous methods only work on well controlled conditions and fail on images with different backgrounds and sizes as the training set. To this end, this paper presents a novel method that combines both the similarity between different image patches and prior knowledge to synthesize face sketches. Given training photo-sketch pairs, the proposed method learns a photo patch feature dictionary from the training photo patches and replaces the photo patches with their sparse coefficients during the searching process. For a test photo patch, we first obtain its sparse coefficient via the learnt dictionary and then search its nearest neighbors (candidate patches) in the whole training photo patches with sparse coefficients. After purifying the nearest neighbors with prior knowledge, the final sketch corresponding to the test photo can be obtained by Bayesian inference. The contributions of this paper are as follows: 1) we relax the nearest neighbor search area from local region to the whole image without too much time consuming and 2) our method can produce nonfacial factors that are not contained in the training set and is robust against image backgrounds and can even ignore the alignment and image size aspects of test photos. Our experimental results show that the proposed method outperforms several state-of-the-arts in terms of perceptual and objective metrics."
"Paritosh Mittal, Mayank Vatsa, Richa Singh",7bf6f9b2bcaf28f71249c637dcf2deebafc1920a,Composite sketch recognition via deep network - a transfer learning approach,2015 International Conference on Biometrics (ICB),2015.0,58,"Sketch recognition is one of the integral components used by law enforcement agencies in solving crime. In recent past, software generated composite sketches are being preferred as they are more consistent and faster to construct than hand drawn sketches. Matching these composite sketches to face photographs is a complex task because the composite sketches are drawn based on the witness description and lack minute details which are present in photographs. This paper presents a novel algorithm for matching composite sketches with photographs using transfer learning with deep learning representation. In the proposed algorithm, first the deep learning architecture based facial representation is learned using large face database of photos and then the representation is updated using small problem-specific training database. Experiments are performed on the extended PRIP database and it is observed that the proposed algorithm outperforms recently proposed approach and a commercial face recognition system."
"Omar Seddati, S. Dupont, S. Mahmoudi",c4f91db667bff4307ab3caa7f91186b547fa9ec0,DeepSketch: Deep convolutional neural networks for sketch recognition and similarity search,2015 13th International Workshop on Content-Based Multimedia Indexing (CBMI),2015.0,47,"In this paper, we present a system for sketch classification and similarity search. We used deep convolution neural networks (ConvNets), state of the art in the field of image recognition. They enable both classification and medium/highlevel features extraction. We make use of ConvNets features as a basis for similarity search using k-Nearest Neighbors (kNN). Evaluation are performed on the TU-Berlin benchmark. Our main contributions are threefold: first, we use ConvNets in contrast to most previous approaches based essentially on hand crafted features. Secondly, we propose a ConvNet that is both more accurate and lighter/faster than the two only previous attempts at making use of ConvNets for handsketch recognition. We reached an accuracy of 75.42%. Third, we shown that similarly to their application on natural images, ConvNets allow the extraction of medium-level and high-level features (depending on the depth) which can be used for similarity search.1"
"Ondrej Jamriska, J. Fiser, Paul Asente, Jingwan Lu, E. Shechtman, D. Sýkora",05d1c3ecfed582a9097cf527870f379946b1eb68,LazyFluids: appearance transfer for fluid animations,ACM Trans. Graph.,2015.0,43,"In this paper we present a novel approach to appearance transfer for fluid animations based on flow-guided texture synthesis. In contrast to common practice where pre-captured sets of fluid elements are combined in order to achieve desired motion and look, we bring the possibility of fine-tuning motion properties in advance using CG techniques, and then transferring the desired look from a selected appearance exemplar. We demonstrate that such a practical work-flow cannot be simply implemented using current state-of-the-art techniques, analyze what the main obstacles are, and propose a solution to resolve them. In addition, we extend the algorithm to allow for synthesis with rich boundary effects and video exemplars. Finally, we present numerous results that demonstrate the versatility of the proposed approach."
"Shu Wang, Jian Zhang, T. Han, Z. Miao",75052729f623c720f8b07113479d5613b8158da0,Sketch-Based Image Retrieval Through Hypothesis-Driven Object Boundary Selection With HLR Descriptor,IEEE Transactions on Multimedia,2015.0,40,"The appearance gap between sketches and photo- realistic images is a fundamental challenge in sketch-based image retrieval (SBIR) systems. The existence of noisy edges on photo- realistic images is a key factor in the enlargement of the appearance gap and significantly degrades retrieval performance . To bridge the gap, we propose a framework consisting of a new line segment -based descriptor named histogram of line relationship (HLR) and a new noise impact reduction algorithm known as object boundary selection . HLR treats sketches and extracted edges of photo- realistic images as a series of piece-wise line segments and captures the relationship between them. Based on the HLR, the object boundary selection algorithm aims to reduce the impact of noisy edges by selecting the shaping edges that best correspond to the object boundaries. Multiple hypotheses are generated for descriptors by hypothetical edge selection. The selection algorithm is formulated to find the best combination of hypotheses to maximize the retrieval score; a fast method is also proposed. To reduce the distraction of false matches in the scoring process, two constraints on spatial and coherent aspects are introduced . We tested the HLR descriptor and the proposed framework on public datasets and a new image dataset of three million images, which we recently collected for SBIR evaluation purposes. We compared the proposed HLR with state-of-the-art descriptors (SHoG, GF-HOG). The experimental results show that our HLR descriptor outperforms them. Combined with the object boundary selection algorithm, our framework significantly improves SBIR performance."
"Yongxin Yang, Timothy M. Hospedales",65342c4d83eb79ecd8cef24da482640d51ce2a38,Deep Neural Networks for Sketch Recognition,ArXiv,2015.0,40,"Deep Neural Networks (DNNs) have recently outperformed traditional object recognition algorithms on multiple largescale datasets, such as ImageNet. However, the model trained on ImageNet fails on recognising the sketches, because the data source is dominated by photos and all kinds of sketches are roughly labelled as ‘cartoon’ rather than their own categorises (e.g., ‘cat’). Most of sketch recognition methods still heavily rely on the hand-craft feature extraction techniques, thus it is interesting to know whether DNNs can eliminate the needs of specific feature engineering in this area, and how the architecture is designed for sketch recognition purpose. To the best of our knowledge, it is the first deep neural network model for sketch classification, and it has outperformed stateof-the-art results in the TU-Berlin sketch benchmark. Based on that, we outline a sketch image retrieval system in a unified neural network framework."
"Tu Bui, J. Collomosse",8c6a4d01eeed2e5ae1b42602e1874361b8e9d40a,Scalable Sketch-Based Image Retrieval Using Color Gradient Features,2015 IEEE International Conference on Computer Vision Workshop (ICCVW),2015.0,40,"We present a scalable system for sketch-based image retrieval (SBIR), extending the state of the art Gradient Field HoG (GF-HoG) retrieval framework through two technical contributions. First, we extend GF-HoG to enable color-shape retrieval and comprehensively evaluate several early-and late-fusion approaches for integrating the modality of color, considering both the accuracy and speed of sketch retrieval. Second, we propose an efficient inverse-index representation for GF-HoG that delivers scalable search with interactive query times over millions of images. A mobile app demo accompanies this paper (Android)."
"H. Huang, S. Kasiviswanathan",d3fb6e1ed4dac0c4b93d76ac60a6e5a73abf7147,Streaming Anomaly Detection Using Randomized Matrix Sketching,Proc. VLDB Endow.,2015.0,40,"Data is continuously being generated from sources such as machines, network traffic, application logs, etc. Timely and accurate detection of anomalies in massive data streams has important applications such as in preventing machine failures, intrusion detection, and dynamic load balancing. In this paper, we introduce a novel (unsupervised) anomaly detection framework which can be used to detect anomalies in a streaming fashion by making only one pass over the data while utilizing limited storage. We adapt ideas from matrix sketching to maintain, in a streaming model, a set of few orthogonal vectors that form a good approximate basis for all the observed data. Using this constructed orthogonal basis, anomalies in new incoming data are detected based on a simple reconstruction error test. We theoretically prove that our algorithm compares favorably with an offline approach based on expensive global singular value decomposition (SVD) updates. Additionally, we apply ideas from randomized low-rank matrix approximations to further speedup the algorithm. The experimental results show the effectiveness and efficiency of our approach over other popular scalable anomaly detection approaches."
"Xueting Liu, T. Wong, P. Heng",549e14748029240b4b6d013e636abe479499f427,Closure-aware sketch simplification,ACM Trans. Graph.,2015.0,40,"In this paper, we propose a novel approach to simplify sketch drawings. The core problem is how to group sketchy strokes meaningfully, and this depends on how humans understand the sketches. The existing methods mainly rely on thresholding low-level geometric properties among the strokes, such as proximity, continuity and parallelism. However, it is not uncommon to have strokes with equal geometric properties but different semantics. The lack of semantic analysis will lead to the inability in differentiating the above semantically different scenarios. In this paper, we point out that, due to the gestalt phenomenon of closure, the grouping of strokes is actually highly influenced by the interpretation of regions. On the other hand, the interpretation of regions is also influenced by the interpretation of strokes since regions are formed and depicted by strokes. This is actually a chicken-or-the-egg dilemma and we solve it by an iterative cyclic refinement approach. Once the formed stroke groups are stabilized, we can simplify the sketchy strokes by replacing each stroke group with a smooth curve. We evaluate our method on a wide range of different sketch styles and semantically meaningful simplification results can be obtained in all test cases."
"A. Rajabi, M. Kadkhodayan, M. Manoochehri, Reza Farjadfar",62a45c221107567f853270a15087ef564ec88b47,"Deep-drawing of thermoplastic metal-composite structures: Experimental investigations, statistical analyses and finite element modeling",,2015.0,39,"Abstract In this article, the influence of process parameters and type of core materials on deep-drawing of two thermoplastic metal-composites is investigated through the experimental tests, statistical analyses and FE simulation. Metal-composite is a general title which can involve fiber–metal laminates (FMLs) and metal–polymer laminates. The metal-composite laminates are produced by polypropylene (PP) and glass-fiber reinforced polypropylene (GFRP) as the cores and aluminum AA1200-O as the skin layers. Statistical analyses based on Taguchi method are used to reduce the number of experiments and to investigate the effect of process variables on the output results. The results show that the two variables of temperature and blank-holder force have the most influence on the output parameters. Furthermore, they demonstrate that a high interaction between the forming temperature and the blank-holder force is required to remove the wrinkling. The results of performed FE simulation predict the experimental punch force–displacement curves and the location of wrinkles with an adequate accuracy."
"Christophe Rigaud, Clément Guérin, Dimosthenis Karatzas, J. Burie, J. Ogier",e664badabfedd75e47508fad52d827287df7cf41,Knowledge-driven understanding of images in comic books,International Journal on Document Analysis and Recognition (IJDAR),2015.0,34,"Document analysis is an active field of research, which can attain a complete understanding of the semantics of a given document. One example of the document understanding process is enabling a computer to identify the key elements of a comic book story and arrange them according to a predefined domain knowledge. In this study, we propose a knowledge-driven system that can interact with bottom-up and top-down information to progressively understand the content of a document. We model the comic book’s and the image processing domains knowledge for information consistency analysis. In addition, different image processing methods are improved or developed to extract panels, balloons, tails, texts, comic characters and their semantic relations in an unsupervised way."
"E. Celledoni, Markus Eslitzbichler",8620ee8367b29af20ecc8f137f37723bcb4a25ae,Shape Analysis on Lie Groups with Applications in Computer Animation,ArXiv,2015.0,30,"Shape analysis methods have in the past few years become very popular, both for theoretical exploration as well as from an application point of view. Originally developed for planar curves, these methods have been expanded to higher dimensional curves, surfaces, activities, character motions and many other objects. In this paper, we develop a framework for shape analysis of curves in Lie groups for problems of computer animations. In particular, we will use these methods to find cyclic approximations of non-cyclic character animations and interpolate between existing animations to generate new ones."
"Ravi Kiran Sarvadevabhatla, R. Venkatesh Babu",7d638b45e71cea3c92ebd19e8b36298a5d0575f0,Freehand Sketch Recognition Using Deep Features,ArXiv,2015.0,28,"Freehand sketches often contain sparse visual detail. In spite of the sparsity, they are easily and consistently recognized by humans across cultures, languages and age groups. Therefore, analyzing such sparse sketches can aid our understanding of the neuro-cognitive processes involved in visual representation and recognition. In the recent past, Convolutional Neural Networks (CNNs) have emerged as a powerful framework for feature representation and recognition for a variety of image domains. However, the domain of sketch images has not been explored. This paper introduces a freehand sketch recognition framework based on ""deep"" features extracted from CNNs. We use two popular CNNs for our experiments -- Imagenet CNN and a modified version of LeNet CNN. We evaluate our recognition framework on a publicly available benchmark database containing thousands of freehand sketches depicting everyday objects. Our results are an improvement over the existing state-of-the-art accuracies by 3% - 11%. The effectiveness and relative compactness of our deep features also make them an ideal candidate for related problems such as sketch-based image retrieval. In addition, we provide a preliminary glimpse of how such features can help identify crucial attributes (e.g. object-parts) of the sketched objects."
"Christophe Rigaud, Nam Le Thanh, J. Burie, J. Ogier, M. Iwata, Eiki Imazu, K. Kise",ab1a9ea7fe98651585490c428270ec89971be03e,Speech balloon and speaker association for comics and manga understanding,2015 13th International Conference on Document Analysis and Recognition (ICDAR),2015.0,24,"Comics and manga are one of the most important forms of publication and play a major role in spreading culture all over the world. In this paper we focus on balloons and their association to comic characters or more generally text and graphic links retrieval. This information is not directly encoded in the image, whether scanned or digital-born, it has to be understood according to other information present in the image. Such high level information allows new browsing experience and story understanding (e.g. dialog analysis, situation retrieval). We propose a speech balloon and comic character association method able to retrieve which character is emitting which speech balloon. The proposed method is based on geometric graph analysis and anchor point selection. This work has been evaluated over various comic book styles from the eBDtheque dataset and also a volume of the Kingdom manga series."
"Panagiotis A. Traganitis, K. Slavakis, G. Giannakis",1c400dcd6c3e54498d9a7bd5aa4c456079a9d236,Sketch and Validate for Big Data Clustering,IEEE Journal of Selected Topics in Signal Processing,2015.0,24,"In response to the need for learning tools tuned to big data analytics, the present paper introduces a framework for efficient clustering of huge sets of (possibly high-dimensional) data. Building on random sampling and consensus (RANSAC) ideas pursued earlier in a different (computer vision) context for robust regression, a suite of novel dimensionality- and set-reduction algorithms is developed. The advocated sketch-and-validate (SkeVa) family includes two algorithms that rely on K-means clustering per iteration on reduced number of dimensions and/or feature vectors: The first operates in a batch fashion, while the second sequential one offers computational efficiency and suitability with streaming modes of operation. For clustering even nonlinearly separable vectors, the SkeVa family offers also a member based on user-selected kernel functions. Further trading off performance for reduced complexity, a fourth member of the SkeVa family is based on a divergence criterion for selecting proper minimal subsets of feature variables and vectors, thus bypassing the need for K-means clustering per iteration. Extensive numerical tests on synthetic and real data sets highlight the potential of the proposed algorithms, and demonstrate their competitive performance relative to state-of-the-art random projection alternatives."
"Changcheng Xiao, C. Wang, Liqing Zhang, Lei Zhang",1519f7329bab906ebe0c1c6a516826c211cc0ac6,Sketch-based Image Retrieval via Shape Words,ICMR,2015.0,24,"The explosive growth of touch screens has provided a good platform for sketch-based image retrieval. However, most previous works focused on low level descriptors of shapes and sketches. In this paper, we try to step forward and propose to leverage shape words descriptor for sketch-based image retrieval. First, the shape words are defined and an efficient algorithm is designed for shape words extraction. Then we generalize the classic Chamfer Matching algorithm to address the shape words matching problem. Finally, a novel inverted index structure is proposed to make shape words representation scalable to large scale image databases. Experimental results show that our method achieves competitive accuracy but requires much less memory, e.g., less than 3% of memory storage of MindFinder. Due to its competitive accuracy and low memory cost, our method can scale up to much larger database."
Michał Borodo,c9a6db7aae878f3288da2e5b3d707afcc2169619,"Multimodality, translation and comics",,2015.0,22,"Although several noteworthy studies concerning the translation of comic books have been published to date (notably Kaindl, 1999; Zanettin, 2008), it still remains an under-investigated topic within Translation Studies. The present article adopts a multimodal perspective on the translation of comics, demonstrating how the relationship between the verbal and the visual modes may be exploited in the translation process. It focuses on the ways in which the two modes interact and contribute to the creation of meaning on a multimodal page, and on the transformations their relationship may undergo in translation. The article is illustrated with examples from a classic, Franco-Belgian comic book series, Thorgal, and the Polish translations of it. The multimodal approach to investigating translated comics may be another step towards a more complete understanding of the character of this still largely unexplored sphere of translation."
"Yonggang Qi, Jun Guo, Yi-Zhe Song, Tao Xiang, Honggang Zhang, Z. Tan",c8699c5766c13b7a39b363074597f7e5d8193753,Im2Sketch: Sketch generation by unconflicted perceptual grouping,Neurocomputing,2015.0,20,"Abstract Effectively solving the problem of sketch generation, which aims to produce human-drawing-like sketches from real photographs, opens the door for many vision applications such as sketch-based image retrieval and non-photorealistic rendering. In this paper, we approach automatic sketch generation from a human visual perception perspective. Instead of gathering insights from photographs, for the first time, we extract information from a large pool of human sketches. In particular, we study how multiple Gestalt rules can be encapsulated into a unified perceptual grouping framework for sketch generation. We further show that by solving the problem of Gestalt confliction, i.e., encoding the relative importance of each rule, more similar to human-made sketches can be generated. For that, we release a manually labeled sketch dataset of 96 object categories and 7680 sketches. A novel evaluation framework is proposed to quantify human likeness of machine-generated sketches by examining how well they can be classified using models trained from human data. Finally, we demonstrate the superiority of our sketches under the practical application of sketch-based image retrieval."
"Florian Perteneder, Martin Bresler, Eva-Maria Grossauer, Joanne Leong, M. Haller",f3d99a38031218244246843e2882ca0655920471,cLuster: Smart Clustering of Free-Hand Sketches on Large Interactive Surfaces,UIST,2015.0,19,"Structuring and rearranging free-hand sketches on large interactive surfaces typically requires making multiple stroke selections. This can be both time-consuming and fatiguing in the absence of well-designed selection tools. Investigating the concept of automated clustering, we conducted a background study which highlighted the fact that people have varying perspectives on how elements in sketches can and should be grouped. In response to these diverse user expectations, we present cLuster, a flexible, domain-independent clustering approach for free-hand sketches. Our approach is designed to accept an initial user selection, which is then used to calculate a linear combination of pre-trained perspectives in real-time. The remaining elements are then clustered. An initial evaluation revealed that in many cases, only a few corrections were necessary to achieve the desired clustering results. Finally, we demonstrate the utility of our approach in a variety of application scenarios."
"Christophe Rigaud, J. Burie, J. Ogier",990064b34dfa9b486dd182d182ff46cb0c5c9444,Text-Independent Speech Balloon Segmentation for Comics and Manga,GREC,2015.0,17,"Comics and manga are one of the most popular and familiar forms of graphic content over the world and play a major role in spreading country’s culture. Nowadays, massive digitization and digital-born materials allow page-per-page mobile reading but we believe that other usages may be released in the near future. In this paper, we focus on speech balloon segmentation which is a key issue for text/graphic association in scanned and digital-born comic book images. Speech balloons are at the interface between text and comic characters, they inform the reader about speech tone and the position of the speakers. We present a generic and text-independent speech balloon segmentation method based on color, shape and topological organization of the connected-components. The method has been evaluated at pixel-level on two public datasets (eBDtheque and Manga109) and the F-measure results are 78.24% and 80.04% respectively."
"Erelcan Yanik, T. M. Sezgin",bc707141abe8a8c1081575eca65f571b9afa8269,Active learning for sketch recognition,Comput. Graph.,2015.0,17,"The increasing availability of pen-based tablets, and pen-based interfaces opened the avenue for computer graphics applications that can utilize sketch recognition technologies for natural interaction. This has led to an increasing interest in sketch recognition algorithms within the computer graphics community. However, a key problem getting in the way of building accurate sketch recognizers has been the necessity of creating large amounts of annotated training data. Several authors have attempted to address this issue by creating synthetic data, or by building easy-to-use annotation tools. In this paper, we take a different approach, and demonstrate that the active learning technology can be used to reduce the amount of manual annotation required to achieve a target recognition accuracy. In particular, we show that by annotating few, but carefully selected examples, we can surpass accuracies achievable with equal number of arbitrarily selected examples. This work is the first comprehensive study on the use of active learning for sketch recognition. We present results of extensive analyses and show that the utility of active learning depends on a number of practical factors that require careful consideration. These factors include the choices of informativeness measures, batch selection strategies, seed size, and domain-specific factors such as feature representation and the choice of database. Our results imply that the Margin based informativeness measure consistently outperforms other measures. We also show that active learning brings definitive advantages in challenging databases when accompanied with powerful feature representations. Graphical abstractDisplay Omitted HighlightsWe present a set of carefully designed experiments and a battery of accompanying statistical tests, which will serve as a roadmap to follow for practitioners of active learning who wish to perform factor analysis.We present the first extensive empirical analysis on active learning for sketch recognition, and provide a detailed discussion of the analysis results.We determine the best performing and reliable informativeness measure for sketch recognition.We show that starting with a large seed set yields better active learning performance for the single classifier approach.We show that the use of active learning brings definitive advantages in challenging databases when accompanied with powerful feature representations."
"Qun Huang, Patrick P. C. Lee",b670caf8a78f2a797da0ddc691093223fa17227d,A hybrid local and distributed sketching design for accurate and scalable heavy key detection in network data streams,Comput. Networks,2015.0,16,"Real-time characterization of network traffic anomalies, such as heavy hitters and heavy changers, is critical for the robustness of operational networks, but its accuracy and scalability are challenged by the ever-increasing volume and diversity of network traffic. We address this problem by leveraging parallelization. We propose LD-Sketch, a data structure designed for accurate and scalable traffic anomaly detection using distributed architectures. LD-Sketch combines the classical counter-based and sketch-based techniques, and performs detection in two phases: local detection, which guarantees zero false negatives, and distributed detection, which reduces false positives by aggregating multiple detection results. We derive the error bounds and the space and time complexity for LD-Sketch. We further analyze the impact of ordering of data items on the memory usage and accuracy of LD-Sketch. We compare LD-Sketch with state-of-the-art sketch-based techniques by conducting experiments on traffic traces from a real-life 3G cellular data network. Our results demonstrate the accuracy and scalability of LD-Sketch over prior approaches."
"K. Sasaki, Hadi Tjandra, K. Noda, K. Takahashi, T. Ogata",dd96628bb83e71719fc8e7f7500959e4c48f9c77,Neural network based model for visual-motor integration learning of robot's drawing behavior: Association of a drawing motion from a drawn image,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2015.0,15,"In this study, we propose a neural network based model for learning a robot's drawing sequences in an unsupervised manner. We focus on the ability to learn visual-motor relationships, which can work as a reusable memory in association of drawing motion from a picture image. Assuming that a humanoid robot can draw a shape on a pen tablet, the proposed model learns drawing sequences, which comprises drawing motion and drawn picture image frames. To learn raw pixel data without any given specific features, we utilized a deep neural network for compressing large dimensional picture images and a continuous time recurrent neural network for integration of motion and picture images. To confirm the ability of the proposed model, we performed an experiment for learning 15 sequences comprising three types of shapes. The model successfully learns all the sequences and can associate a drawing motion from a not trained picture image and a trained picture with similar success. We also show that the proposed model self-organizes its behavior according to types shapes."
"Xueting Liu, C. Li, Haichao Zhu, T. Wong, Xuemiao Xu",914997197ebc05e2cccae6ddc231efa4201eacbc,Text-aware balloon extraction from manga,The Visual Computer,2015.0,14,"Manga, a Japanese word for comics, is a worldwide popular visual entertainment. Nowadays, electronic devices boost the fast development of motion manga for the purpose of visual richness and manga promotion. To convert static manga images into motion mangas, text balloons are usually animated individually for better story telling. This needs the artists to cut out each text balloon meticulously, and therefore it is quite labor-intensive and time-consuming. In this paper, we propose an automatic approach that can extract text balloons from manga images both accurately and effectively. Our approach starts by extracting white areas that contain texts as text blobs. Different from existing text blob extraction methods that only rely on shape properties, we incorporate text properties in order to differentiate text blobs from texture blobs. Instead of heuristic parameter thresholding, we achieve text blob classification via learning-based classifiers. Along with the novel text blob classification method, we also make the first attempt in trying to tackle the boundary issue in balloon extraction. We apply our method on various styles of mangas and comics with texts in different languages, and convincing results are obtained in all cases."
"Katrin Lang, M. Alexa",80d65d06a4196464e9c50d844ca9f45714b27ee5,The Markov pen: online synthesis of free-hand drawing styles,NPAR '15,2015.0,14,"Learning expressive curve styles from example is crucial for interactive or computer-based narrative illustrations. We propose a method for online synthesis of free-hand drawing styles along arbitrary base paths by means of an autoregressive Markov Model. Choice on further curve progression is made while drawing, by sampling from a series of previously learned feature distributions subject to local curvature. The algorithm requires no user-adjustable parameters other than one short example style. It may be used as a custom ""random brush"" designer in any task that requires rapid placement of a large number of detail-rich shapes that are tedious to create manually."
"Long Zhao, Shuang Liang, Jinyuan Jia, Yichen Wei",06db93357a94b2a4a53a1b3f0fc05e20e24d2bba,Learning best views of 3D shapes from sketch contour,The Visual Computer,2015.0,12,"In this paper, we introduce a novel learning-based approach to automatically select the best views of 3D shapes using a new prior. We think that a viewpoint of the 3D shape is reasonable if a human usually draws the shape from it. Hand-drawn sketches collected from relevant datasets are used to model this concept. We reveal the connection between sketches and viewpoints by taking context information of their contours into account. Furthermore, a learning framework is proposed to generalize this connection which aims to learn an automatic best view selector for different kinds of 3D shapes. Experiments on the Princeton Shape Benchmark dataset are conducted to demonstrate the superiority of our approach. The results show that compared with other state-of-the-art methods, our approach is not only robust but also efficient when applied to shape retrieval tasks."
J. M. Saavedra,6ddff4bc115d8369fcda548f8273315682badb70,RST-SHELO: sketch-based image retrieval using sketch tokens and square root normalization,Multimedia Tools and Applications,2015.0,11,"Sketch-based image retrieval (SBIR) is an emergent research area with a variety of applications, specially when an example image is not available for querying. Moreover, making a sketch has become a very attractive and simple task due to the already ubiquitous touch-screen and mobile technologies. Although a sketch is a natural way for representing the structure of a thought object, it may easily get confused in a dataset with high variability turning the retrieval task a quite challenging problem. Indeed, the state-of-the-art methods still show low performance on diverse evaluation datasets. Thereby, a robust sketch descriptor together with a better strategy for representing regular images as sketches are demanded. In this work, we present RST-SHELO, and improved version of SHELO (Soft Histogram of Edge Logal Orientations), an efficient state-of-the-art method for describing sketches. The proposed improvements comes from two aspects: a better technique for obtaining sketch-like representations and a better normalization strategy of SHELO. For the first case, we propose to use the sketch token approach [21], aiming to detect image contours by means of mid-level features. For the second case, we demonstrate that a square root normalization positively affect the effectiveness on the retrieval task. Based on our improvements, we present new state-of-the-art performance. To validate our achievements, we have conducted diverse experiments using two public datasets, Flickr15K and Saavedra’s. Our results show an effectiveness gain of 62 % in the first and 5 % in the second dataset."
"Yongtao Wang, Yafeng Zhou, Zhi Tang",de9bfb633f578c236413ac956179a24ca872a88f,Comic frame extraction via line segments combination,2015 13th International Conference on Document Analysis and Recognition (ICDAR),2015.0,11,"Automatic comic frame extraction is the core technique for comic content adaptation. Typical algorithms segment a comic page into a set of frames using connected components or division lines, but they cannot produce frames without blank margins and there is still room for improvement for complex comic images. We present a method that identifies frame polygons via connected component labeling and line segments combination. We analyze lines within each component and preliminarily judge the frame type, and then we optimize an energy-like score function constrained by several rules to choose frames. Experimental results indicate an increase of both accuracy and F-score compared with previous methods."
"Mingjin Zhang, J. Li, N. Wang, Xinbo Gao",fdca30b3591c3f4fe79757931d72b1888dec61d2,Recognition of facial sketch styles,Neurocomputing,2015.0,10,"Abstract The style recognition of facial sketches drawn by artists contributes great to the painting authentication, digital entertainment and law enforcement. This paper presents a framework to automatically classify different styles of facial sketches based on support vector machines (SVM) and selective ensemble (SE) strategy. Some handwritten features are deployed to feed into SVM classifiers. The framework proceeds as follows: firstly, each geometrically normalized image is divided into five important parts: the whole image, left eye, right eye, nose, and mouth; Secondly, based on the analysis to the technique of the facial sketch artists, gray histogram, gray moment, speeded up robust feature and multiscale local binary patterns are explored to extract handwritten features from each part; Thirdly, SVM is explored to learn the mapping relationship from handwritten features of each part to the style of the artist and thus we obtain multiple classification scores; Finally, we combine these complementary classification scores via SE scheme. Our model is able to achieve the recognition rates of 94% and 96% respectively on two groups of sketches drawn by five artists which would be available on the website."
"Raviteja Upadrashta, Tarun Choubisa, V. Aswath, A. Praneeth, Ajit Prabhu, S. Raman, Tony Gracious, P. V. Kumar, Sripad S. Kowshik, Madhuri Iyer, T. V. Prabhakar",f60cacfc0b2e0dd9713f53981913747f51812b51,An animation-and-chirplet based approach to intruder classification using PIR sensing,"2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)",2015.0,10,"The development of a Passive Infra-Red (PIR) sensing based intrusion detection system is presented here having the ability to reject vegetative clutter and distinguish between human and animal intrusions. This has potential application to reducing human-animal conflicts in the vicinity of a wildlife park. The system takes on the form of a sensor-tower platform (STP) and was developed in-house. It employs a sensor array that endows the platform with a spatial-resolution capability. Given the difficulty of collecting data involving animal motion, a simulation tool was created with the aid of Blender and OpenGL software that is capable of quickly generating streams of human and animal-intrusion data. The generated data was then examined to identify a suitable collection of features that are useful in classification. The features selected corresponded to parameters that model the received signal as the super-imposition of a fixed number of chirplets, an energy signature and a cross-correlation parameter. The resultant feature vector was then passed on to a Support Vector Machine (SVM) for classification. This approach to classification was validated by making use of real-world data collected by the STP which showed both STP design as well as classification technique employed to be quite effective. The average classification accuracy with both real and simulated data was in excess of 94%."
"Thanh-Nam Le, Muhammad Muzzamil Luqman, J. Burie, J. Ogier",dbea17cfa8aad9a820cd9c80c4024ef11ef80d4f,Content-based comic retrieval using multilayer graph representation and frequent graph mining,2015 13th International Conference on Document Analysis and Recognition (ICDAR),2015.0,9,"Comics has its large audience and market throughout the world, yet despite the huge research interest given to content-based image retrieval (CBIR) systems, the question of how to effectively retrieve comic images has been little studied. In this paper, we propose a scheme to represent and retrieve comic-page images using attributed Region Adjacency Graphs (RAGs) and their frequent subgraphs. We first extract the graphical structures and local features of each panel of the whole comic volume, then separate different categories of local features to different layers of attributed RAGs. After that, a list of frequent subgraphs for each layer is obtained by using frequent subgraph mining (FSM) technique. For indexing and CBIR purpose, the recognition and ranking are done by checking for isomorphism between the graphs representing the query versus the discovered frequent subgraphs. Our experimental results show that the proposed approach can achieve reliable retrieval results of comic images using query-by-example (QBE) model."
"A. Igamberdiev, Wouter Meulemans, André Schulz",98f94229a2043e05f81d6a4a57f7a7b0b05367f3,Drawing Planar Cubic 3-Connected Graphs with Few Segments: Algorithms and Experiments,Graph Drawing,2015.0,9,"A drawing of a graph can be understood as an arrangement of geometric objects. In the most natural setting the arrangement is formed by straight-line segments. Every cubic planar 3-connected graph with n vertices has such a drawing with only $$n/2 + 3$$ segments, matching the lower bound. This result is due to Mondal et al. [J. of Comb. Opt., 25], who gave an algorithm for constructing such drawings. 
 
We introduce two new algorithms that also produce drawings with $$n/2 + 3$$ segments. One algorithm is based on a sequence of dual edge contractions, the other is based on a recursion of nested cycles. We also show a flaw in the algorithm of Mondal et al. and present a fix for it. We then compare the performance of these three algorithms by measuring angular resolution, edge length and face aspect ratio of the constructed drawings. We observe that the corrected algorithm of Mondal et al. mostly outperforms the other algorithms, especially in terms of angular resolution. However, the new algorithms perform better in terms of edge length and minimal face aspect ratio."
"Daniyar Turmukhambetov, N. Campbell, Dan B. Goldman, J. Kautz",fc1d9b3df1dbf318c3b9c559c8b65d6cb431a8ba,Interactive Sketch‐Driven Image Synthesis,Comput. Graph. Forum,2015.0,9,"We present an interactive system for composing realistic images of an object under arbitrary pose and appearance specified by sketching. Our system draws inspiration from a traditional illustration workflow: The user first sketches rough ‘masses’ of the object, as ellipses, to define an initial abstract pose that can then be refined with more detailed contours as desired. The system is made robust to partial or inaccurate sketches using a reduced‐dimensionality model of pose space learnt from a labelled collection of photos. Throughout the composition process, interactive visual feedback is provided to guide the user. Finally, the user's partial or complete sketch, complemented with appearance requirements, is used to constrain the automatic synthesis of a novel, high‐quality, realistic image."
"Yao Xie, M. Wang, Andrew Thompson",2cc342f9284589407a1e29e7fd1e3313baeddbf3,Sketching for sequential change-point detection,2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP),2015.0,9,"We study sequential change-point detection using sketches (or linear projections) of the high-dimensional data vectors, and present a new sketching procedure, which is based on the generalized likelihood ratio statistic. We derive theoretical approximations to two fundamental performance metrics for the sketching procedures: the average run length (ARL) and the expected detection delay (EDD), and these approximations are shown to be highly accurate by numerical simulations. We also analyze the ratio of EDD between the sketching procedure and a procedure using the original data, when the sketching matrix A is a random Gaussian matrix and a sparse 0-1 matrix (in particular, a expander graph), respectively. Finally, numerical examples demonstrate that the sketching procedure can approach the performance of a procedure that uses the original data, even when the post-change mean vector is not sparse."
"Christian Galea, R. Farrugia",34cb88af5e8f8f7ea1b1536a934d3053b582c091,Fusion of Intra- and Inter-modality Algorithms for Face-Sketch Recognition,CAIP,2015.0,9,"Identifying and apprehending suspects by matching sketches created from eyewitness and victim descriptions to mugshot photos is a slow process since law enforcement agencies lack automated methods to perform this task. This paper attempts to tackle this problem by combining Eigentransformation, a global intra-modality approach, with the Eigenpatches local intra-modality technique. These algorithms are then fused with an inter-modality method called Histogram of Averaged Orientation Gradients HAOG. Simulation results reveal that the intra- and inter- modality algorithms considered in this work provide complementary information since not only does fusion of the global and local intra-modality methods yield better performance than either of the algorithms individually, but fusion with the inter-modality approach yields further improvement to achieve retrieval rates of 94.05% at Rank-100 on 420 photo-sketch pairs. This performance is achieved at Rank-25 when filtering of the gallery using demographic information is carried out."
"Thanh-Nam Le, Muhammad Muzzamil Luqman, J. Burie, J. Ogier",359a33d8d40f050106302a5cc8644ab72ea94638,A Comic Retrieval System Based on Multilayer Graph Representation and Graph Mining,GbRPR,2015.0,8,"Comics analysis offers a lot of interesting Content-based Image Retrieval (CBIR) applications focusing in this special type of document images. In this paper, we propose a scheme to represent and to retrieve comic-page images using attributed Region Adjacency Graphs (RAGs) and their frequent subgraphs. We first extract the graphical structures and local features of each panel in the whole comic volume, then separate different categories of local features to different layers of attributed RAGs. After that, a list of frequent subgraphs is obtained using Frequent Subgraph Mining (FSM) techniques. For CBIR purpose, the recognition and ranking are done by checking for isomorphism between the graphs representing the query image versus the list of discovered frequent subgraphs. Our experimental results show that the proposed approach can achieve reliable retrieval results for comic images browsing using query-by-example (QBE) model."
"Cheng Jin, Zhemin Wang, T. Zhang, Qinen Zhu, Yuejie Zhang",df84cf593e7e20ac0fab44b647db08d2398cdb13,A Novel Visual-Region-Descriptor-based Approach to Sketch-based Image Retrieval,ICMR,2015.0,8,"A novel Visual-Region-Descriptor-based approach is developed in this paper to facilitate more effective Sketch-based Image Retrieval (SBIR), which can be treated as a problem of bilateral visual mapping and modeled as an inter-related correlation distribution over visual semantic representations of sketches and images. For crossing the matching barrier between binary query sketches and full color natural images, we focus on constructing a visual pre-analysis via the sketch-like representation transformation to improve the general sketch-image resemblance, creating a special visual region descriptor to obtain better visual feature generation for sketches and images, and a dynamic sketch-image matching scheme to achieve more precise characterization of the correlations between sketches and images. Such a visual-region-descriptor-based SBIR pattern can not only enable users to present whatever they imagine in their mind on the sketch query panel but also return the most similar images to the picture in users' mind. Very positive results were obtained in our experiments using a large quantity of public data."
"Ju Shen, Jianjun Yang",9caba491515ed9f64e5f8aa9e154add596f39a80,Automatic Human Animation for Non-Humanoid 3D Characters,2015 14th International Conference on Computer-Aided Design and Computer Graphics (CAD/Graphics),2015.0,8,"In this paper, we propose a system, that automatically transfers human body motion captured from an ordinary video camera to an unknown 3D character mesh. In our system, no manual intervention is required for specifying the internal skeletal structure or defining how the mesh surfaces deform. A sparse graph is generated from the input polygons based on their connectivity and geometric distributions. To estimate articulated body parts in the video, a progressive particle filter is used for identifying correspondences. We anticipate our proposed system can bring animation to a new audience with a more intuitive user interface."
"Ching-Hsuan Liu, Yen-Liang Lin, Wen-Feng Cheng, Winston H. Hsu",cf1e896bbea171cc00fa5da27c49845aae2de332,Exploiting Word and Visual Word Co-occurrence for Sketch-based Clipart Image Retrieval,ACM Multimedia,2015.0,6,"As the increasing popularity of touch-screen devices, retrieving images by hand-drawn sketch has become a trend. Human sketch can easily express some complex user intention such as the object shape. However, sketches are sometimes ambiguous due to different drawing styles and inter-class object shape ambiguity. Although adding text queries as semantic information can help removing the ambiguity of sketch, it requires a huge amount of efforts to annotate text tags to all database clipart images. We propose a method directly model the relationship between text and clipart images by the co-occurrence relationship between words and visual words, which improves traditional sketch-based image retrieval (SBIR), provides a baseline performance and obtains more relevant results in the condition that all images in database do not have any text tag. Experimental results show that our method really can help SBIR to get better retrieval result since it indeed learned semantic meaning from the ``word-visual word"" (W-VW) co-occurrence relationship."
"X. Mao, Xueting Liu, T. Wong, Xuemiao Xu",4888a681586dc696b5f9dd265d197f99ff79edc7,Region-based structure line detection for cartoons,Computational Visual Media,2015.0,6,"Cartoons are a worldwide popular visual entertainment medium with a long history. Nowadays, with the boom of electronic devices, there is an increasing need to digitize old classic cartoons as a basis for further editing, including deformation, colorization, etc. To perform such editing, it is essential to extract the structure lines within cartoon images. Traditional edge detection methods are mainly based on gradients. These methods perform poorly in the face of compression artifacts and spatially-varying line colors, which cause gradient values to become unreliable. This paper presents the first approach to extract structure lines in cartoons based on regions. Our method starts by segmenting an image into regions, and then classifies them as edge regions and non-edge regions. Our second main contribution comprises three measures to estimate the likelihood of a region being a non-edge region. These measure darkness, local contrast, and shape. Since the likelihoods become unreliable as regions become smaller, we further classify regions using both likelihoods and the relationships to neighboring regions via a graph-cut formulation. Our method has been evaluated on a wide variety of cartoon images, and convincing results are obtained in all cases."
"Kemal Tugrul Yesilbek, Cansu Sen, S. Cakmak, T. M. Sezgin",03ebe1aea74ad4e7e354b866e2db0a10a24ec48e,SVM-based sketch recognition: which hyperparameter interval to try?,SBIM '15,2015.0,6,"Hyperparameters are among the most crucial factors that affect the performance of machine learning algorithms. In general, there is no direct method for determining a set of satisfactory parameters, so hyperparameter search needs to be conducted each time a model is to be trained. In this work, we analyze how similar hyperparameters perform across various datasets from the sketch recognition domain. Results show that hyperparameter search space can be reduced to a subspace despite differences in characteristics of datasets."
"S. Bhattacharjee, Anurag Mittal",b03f81c0461e649124ce5b88b44786bb1f8d24e0,Part-based deformable object detection with a single sketch,Comput. Vis. Image Underst.,2015.0,6,"Contour-based object detection scheme uses a single sketch as input model.An automatic part decomposition method segments the given model sketch into partsMulti-stage coarse-to-fine locally affine-invariant part-based matching strategyFirst, a PS-based framework is used to roughly identify some candidate locations.A detailed Contour Tracing then evaluates these initial detections more thoroughly. Object detection using shape is interesting since it is well known that humans can recognize an object simply from its shape. Thus, shape-based methods have great promise to handle a large amount of shape variation using a compact representation. In this paper, we present a new algorithm for object detection that uses a single reasonably good sketch as a reference to build a model for the object. The method hierarchically segments a given sketch into parts using an automatic algorithm and estimates a different affine transformation for each part while matching. A Hough-style voting scheme collects evidence for the object from the leaves to the root in the part decomposition tree for robust detection. Missing edge segments, clutter and generic object deformations are handled by flexibly following the contour paths in the edge image that resemble the model contours. Efficient data-structures and a two-stage matching approach assist in yielding an efficient and robust system. Results on ETHZ and several other popular image datasets yield promising results compared to the state-of-the-art. A new dataset of real-life hand-drawn sketches for all the object categories in the ETHZ dataset is also used for evaluation."
"Raissa dos Santos Vieira, H. A. D. Nascimento, Wanderson Barcelos da Silva",b10e013145eb59c058720d34ffc6507f45f5cd27,The Application of Machine Learning to Problems in Graph Drawing - A Literature Review,,2015.0,5,"Graph drawing, as a research field, is concerned with the visualization of information modeled in the form of graphs. The present paper is a literature review that identifies the state- of-the-art in applying machine learning techniques to problems in graph drawing. We focused on machine learning strategies that build up and represent knowledge about how to draw a graph. Surprisingly, only a few pieces of research can be found about this subject. We classified them in two main groups: the ones that extract knowledge from the user by human-computer interaction and those that are not based on data directly gathered from users. The study of these methods shows that there is still much to research and to develop regarding the application of machine learning to graph drawing. We suggest directions for future research on this area."
"Wei Yang, M. Toyoura, Jiayi Xu, Fumio Ohnuma, Xiaoyang Mao",b58faaf54f09d876873a126286a08ea45e6c4bb2,Example-based caricature generation with exaggeration control,The Visual Computer,2015.0,5,"Caricature is a popular artistic media widely used for effective communications. The fascination of caricature lies in its expressive depiction of a person’s prominent features, which is usually realized through the so-called exaggeration technique. This paper proposes a new example-based automatic caricature generation system supporting the exaggeration of both the shape of facial components and the spatial relationships among the components. Given the photograph of a face, the system automatically computes the feature vectors representing the shape of facial components as well as the spatial relationship among the components. Those features are exaggerated and then used to search the learning database for the corresponding caricature components and for arranging the retrieved components to create the caricature. Experimental results show that our system can generate the caricatures of the example style capturing the prominent features of the subjects."
Yusuke Matsui,b179973fb7b3990e4e9b377500ebcfacafb738ff,Challenge for Manga Processing: Sketch-based Manga Retrieval,ACM Multimedia,2015.0,5,"We propose a sketch-based system for manga image retrieval. In the system, users simply draw sketches, and similar images are retrieved in real time from a manga database. The results are updated every time the user draws a stroke and therefore users can intuitively interact with the system. The proposed method consists of a simple and efficient sliding window-based feature description framework and interactive re-ranking schemes, which are introduced because the characteristics of manga images are different from those of naturalistic images, and thus, traditional image retrieval methods are not effective. Additionally, the future directions of improving the current retrieval system, including by using a combination of text features and image features, and the construction of a large database are discussed."
"Jun Guo, C. Wang, Hongyang Chao",0a84ac0f090b67df5f21af9c1029b75162e420b3,Building Effective Representations for Sketch Recognition,AAAI,2015.0,5,"As the popularity of touch-screen devices, understanding a user's hand-drawn sketch has become an increasingly important research topic in artificial intelligence and computer vision. However, different from natural images, the hand-drawn sketches are often highly abstract, with sparse visual information and large intra-class variance, making the problem more challenging. In this work, we study how to build effective representations for sketch recognition. First, to capture saliency patterns of different scales and spatial arrangements, a Gabor-based low-level representation is proposed. Then, based on this representation, to discovery more complex patterns in a sketch, a Hybrid Multilayer Sparse Coding (HMSC) model is proposed to learn mid-level representations. An improved dictionary learning algorithm is also leveraged in HMSC to reduce over-fitting to common but trivial patterns. Extensive experiments show that the proposed representations are highly discriminative and lead to large improvements over the state of the arts."
"Y. Zhang, Xueming Qian, Xianglong Tan",2b57d4c9baa8da9aff842a11f41eefff1b7a2a30,Sketch-based image retrieval using contour segments,2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP),2015.0,5,"The paper presents a sketch-based image retrieval algorithm. One of the main challenges in sketch-based image retrieval (SBIR) is to measure the similarity between a sketch and an image in contour with high precision. To tackle this problem, we divided the contour of image into two types: the first is global contour, suggesting that we can use it to reduce the similarity between the images with complex background. The second, called salient contour, is helpful to retrieve images with objects similar to the query. Besides, we propose a new descriptor, namely angular radial orientation partitioning (AROP) feature, which makes full use of the gradient orientation information to decrease the gap between sketch and image. Using the two contours as candidate contours for feature extraction could increase the retrieval rate dramatically. Finally an application of retrieval system based on this algorithm is established. The experiment on 0.42 million image dataset shows excellent retrieval performance of the proposed method and comparisons with other algorithms are also given."
"K. T. A. Siddiqui, Abu Wasif",e22f66b78883e63fe0803e757830f1a855af9b90,Skin Detection of Animation Characters,ArXiv,2015.0,5,"The increasing popularity of animes makes it vulnerable to unwanted usages like copyright violations and pornography. That is why, we need to develop a method to detect and recognize animation characters. Skin detection is one of the most important steps in this way. Though there are some methods to detect human skin color, but those methods do not work properly for anime characters. Anime skin varies greatly from human skin in color, texture, tone and in different kinds of lighting. They also vary greatly among themselves. Moreover, many other things (for example leather, shirt, hair etc.), which are not skin, can have color similar to skin. In this paper, we have proposed three methods that can identify an anime character skin more successfully as compared with Kovac, Swift, Saleh and Osman methods, which are primarily designed for human skin detection. Our methods are based on RGB values and their comparative relations."
"C. Zou, Zhe Huang, Rynson W. H. Lau, Jianzhuang Liu, Hongbo Fu",913b2372663988e923098471c42f1e4f08de3c3e,Sketch-based Shape Retrieval using Pyramid-of-Parts,ArXiv,2015.0,5,"We present a multi-scale approach to sketch-based shape retrieval. It is based on a novel multi-scale shape descriptor called Pyramidof- Parts, which encodes the features and spatial relationship of the semantic parts of query sketches. The same descriptor can also be used to represent 2D projected views of 3D shapes, allowing effective matching of query sketches with 3D shapes across multiple scales. Experimental results show that the proposed method outperforms the state-of-the-art method, whether the sketch segmentation information is obtained manually or automatically by considering each stroke as a semantic part."
"S. Parui, Anurag Mittal",87f469be64c832333e8e0e30e935490b7621279c,"Sketch-based Image Retrieval from Millions of Images under Rotation, Translation and Scale Variations",ArXiv,2015.0,4,"Proliferation of touch-based devices has made sketch-based image retrieval practical. While many methods exist for sketch-based object detection/image retrieval on small datasets, relatively less work has been done on large (web)-scale image retrieval. In this paper, we present an efficient approach for image retrieval from millions of images based on user-drawn sketches. Unlike existing methods for this problem which are sensitive to even translation or scale variations, our method handles rotation, translation, scale (i.e. a similarity transformation) and small deformations. The object boundaries are represented as chains of connected segments and the database images are pre-processed to obtain such chains that have a high chance of containing the object. This is accomplished using two approaches in this work: a) extracting long chains in contour segment networks and b) extracting boundaries of segmented object proposals. These chains are then represented by similarity-invariant variable length descriptors. Descriptor similarities are computed by a fast Dynamic Programming-based partial matching algorithm. This matching mechanism is used to generate a hierarchical k-medoids based indexing structure for the extracted chains of all database images in an offline process which is used to efficiently retrieve a small set of possible matched images for query chains. Finally, a geometric verification step is employed to test geometric consistency of multiple chain matches to improve results. Qualitative and quantitative results clearly demonstrate superiority of the approach over existing methods."
"S. Sadimon, H. Haron",02c612b91590ff273086c745b0a19fd8e8ab9905,Neural network model for prediction of facial caricature landmark configuration using modified procrustes superimposition method,SOCO 2015,2015.0,3,"Artificial Neural Network which possessing self-learning ability has shown great promise in addressing problem of learning an artist style in generating facial caricatures. This paper presents Artificial Neural Network model to imitate a particular artist style and to predict a facial caricature configuration for a given original face image (photo). This paper also describes the data preparing process that proposes a modified procrustes superimposition method in deriving the datasets for the neural network model. The experiment is carried out to compare the modified procrustes superimposition method with the original one and to find the appropriate neural network structure that would yield the most accurate prediction results. Different datasets (N1, N2, and N3) derived from the same raw data but using the different method in preparing the dataset and different numbers of hidden nodes (6, 12, 18 and 24) are tested. The experimental result and its detail analysis are given and discussed. It proves that neural network has an ability to predict how the artist exaggerates the original facial feature point. Dataset N2 which use Modified Procrustes Superimposition method and the simple structure of a single hidden layer neural network, in which 6 is the number of hidden node, give the best accuracy of the prediction."
"Salah Eddine Lahlali, A. Sadiq, S. Mbarki",7189d5584416ef2a39d6ab16929dfecdddc10081,A REVIEW OF FACE SKETCH RECOGNITION SYSTEMS,,2015.0,3,"Police sketching techniques are nevertheless a routine part of law enforcement investigation and often used to identify suspects from an eye witness memory. This classic technique of identifying is generally slow and fastidious and may not conduct to arrest the right offender. Therefore an automatic face sketch recognition systems that determine efficiently the perpetrator’s appearance from gallery of face images is required. Such technology design is open challenging research because faces and sketches are generated from distinct sources and have different gaps to overcome in low and high levels. Although many methods have been proposed, we are unaware of any surveys on this particular topic. For this reason we wrote this paper for reviewing the different researches on recognizing face from forensic sketch by analyzing their approaches and identifying their limitations. We also discuss relevant issues such as benchmarking datasets and evaluation protocols. After, we conclude with several promising directions for future research. +"
"Sara Beatriz Nunes, V. Martins",06654efb4d290b3239c37c795504b6d8be52c4e1,Air-Sketching for Object Retrieval,,2015.0,2,"With the development of several modeling and capturing tools, the creation of 3D objects has increased. Hence, the retrieval area of 3D models has been widely explored, as an answer to the resulting challenges from storing and searching for objects. However, the latest works on this subject do not use natural interaction nor an immersive environment to search and explore 3D objects. By executing this work, our purpose was to create a query specification for 3D object retrieval system, in an immersive environment. Our goal was to explore a new approach to search methods using sketching retrieval, that would allow a natural interaction. The users are immersed in a virtual reality environment and define a sketch query that retrieves similar objects using search mechanisms. To validate our prototype we performed tests with users, comparing it to an query specification system that uses 2D sketches. The results obtained with the performed tests allow us to conclude the validity of our approach, and understand that this route of investigation will allow to discover viable solutions on the 3D object retrieval context."
Chih-Pin Hsiao,b57dde97240aacc973d0e56487f3715136d4529e,SolidSketch: Toward Enactive Interactions for Semantic Model Creation,Creativity & Cognition,2015.0,2,"SolidSketch is a solid and parametric modeling program that enables users to rapidly construct 3D parametric and semantic models through sketch and multi-touch input. The interaction design principles of SolidSketch are based on the cognitive science theory of enaction. We argue enactive interactions would support design creativity by enabling rapid iteration and continuous feedback throughout a flexible design exploration. SolidSketch infers the intention of the user by continuously analyzing the surrounding context and user's behavior. This paper briefly introduces the enaction theory, the interaction designs as well as the implementations of SolidSketch."
"Panagiotis A. Traganitis, K. Slavakis, G. Giannakis",a0b631cb891caf19b9817be515b315506235d37b,Large-scale subspace clustering using sketching and validation,ArXiv,2015.0,2,"The nowadays massive amounts of generated and communicated data present major challenges in their processing. While capable of successfully classifying nonlinearly separable objects in various settings, subspace clustering (SC) methods incur prohibitively high computational complexity when processing large-scale data. Inspired by the random sampling and consensus (RANSAC) approach to robust regression, the present paper introduces a randomized scheme for SC, termed sketching and validation (SkeVa-)SC, tailored for large-scale data. At the heart of SkeVa-SC lies a randomized scheme for approximating the underlying probability density function of the observed data by kernel smoothing arguments. Sparsity in data representations is also exploited to reduce the computational burden of SC, while achieving high clustering accuracy. Performance analysis as well as extensive numerical tests on synthetic and real data corroborate the potential of SkeVa-SC and its competitive performance relative to state-of-the-art scalable SC approaches. Keywords: Subspace clustering, big data, kernel smoothing, randomization, sketching, validation, sparsity."
"Z. Bhatti, Asadullah Shah, A. Waqas, Nadeem Mahmood",66bd803cf8dddbdf41099a814f59070918c5f46a,Analysis of Design Principles and Requirements for Procedural Rigging of Bipeds and Quadrupeds Characters with Custom Manipulators for Animation,ArXiv,2015.0,2,"Character rigging is a process of endowing a character with a set of custom manipulators and controls making it easy to animate by an animators. These controls consists of simple joints, handles, or even separate character selection window. This research paper presents an automated rigging system for quadruped characters with custom controls and manipulators for animation. The full character rigging mechanism is procedurally driven based on various principles and requirements used by the riggers and animators. The automation is achieved initially by creating widgets according to the character type. These widgets then can be customized by the rigger according to the character shape, height and proportion. Then joint locations for each body parts are calculated and widgets are replaced programmatically. Finally a complete and fully operational procedurally generated character control rig is created and attached with the underlying skeletal joints. The functionality and feasibility of the rig was analyzed from various sources of actual character motion and a requirements criterion was met. The final rigged character provides an efficient and easy to manipulate control rig with no lagging and at high frame rate."
"T. K. Monserrat, J. P. Pabico, E. Albacea",edf7254e7455b23e8366dca8cf0430657114ce1b,"A Hybrid Graph-drawing Algorithm for Large, Naturally-clustered, Disconnected Graphs",ArXiv,2015.0,1,"In this paper, we present a hybrid graph-drawing algorithm (GDA) for laying out large, naturally-clustered, disconnected graphs. We call it a hybrid algorithm because it is an implementation of a series of already known graph-drawing and graph-theoretic procedures. We remedy in this hybrid the problematic nature of the current force-based GDA which has the inability to scale to large, naturally- clustered, and disconnected graphs. These kinds of graphs usually model the complex inter-relationships among entities in social, biological, natural, and artificial networks. Obviously, the hybrid runs longer than the current GDAs. By using two extreme cases of graphs as inputs, we present the derivation of the time complexity of the hybrid which we found to be O(|V| 3 ), where V is the set of nodes in the graph."
X. Yang,fe7a0485bb7098b2c754699ca9cdc6524d5fe628,Face Photo Sketch Synthesis via Larger Patch and Multiresolution Spline,ArXiv,2015.0,0,"Face photo sketch synthesis has got some researchers' attention in recent years because of its potential applications in digital entertainment and law enforcement. Some patches based methods have been proposed to solve this problem. These methods usually focus more on how to get a sketch patch for a given photo patch than how to blend these generated patches. However, without appropriately blending method, some jagged parts and mottled points will appear in the entire face sketch. In order to get a smoother sketch, we propose a new method to reduce such jagged parts and mottled points. In our system, we resort to an existed method, which is Markov Random Fields (MRF), to train a crude face sketch firstly. Then this crude sketch face sketch will be divided into some larger patches again and retrained by Non-Negative Matrix Factorization (NMF). At last, we use Multiresolution Spline and a blend trick named full-coverage trick to blend these retrained patches. The experiment results show that compared with some previous method, we can get a smoother face sketch."
"Rosália G. Schneider, T. Tuytelaars",45c57017ee8f55208d0c91905ec95b89dd73ba6d,Sketch classification and classification-driven analysis using Fisher vectors,ACM Trans. Graph.,2014.0,139,"We introduce an approach for sketch classification based on Fisher vectors that significantly outperforms existing techniques. For the TU-Berlin sketch benchmark [Eitz et al. 2012a], our recognition rate is close to human performance on the same task. Motivated by these results, we propose a different benchmark for the evaluation of sketch classification algorithms. Our key idea is that the relevant aspect when recognizing a sketch is not the intention of the person who made the drawing, but the information that was effectively expressed. We modify the original benchmark to capture this concept more precisely and, as such, to provide a more adequate tool for the evaluation of sketch classification techniques. Finally, we perform a classification-driven analysis which is able to recover semantic aspects of the individual sketches, such as the quality of the drawing and the importance of each part of the sketch for the recognition."
"Yibing Song, Linchao Bao, Q. Yang, Ming-Hsuan Yang",a866c243488d95564efa909f9a9aecaad4d468dd,Real-Time Exemplar-Based Face Sketch Synthesis,ECCV,2014.0,99,"This paper proposes a simple yet effective face sketch synthesis method. Similar to existing exemplar-based methods, a training dataset containing photo-sketch pairs is required, and a K-NN photo patch search is performed between a test photo and every training exemplar for sketch patch selection. Instead of using the Markov Random Field to optimize global sketch patch selection, this paper formulates face sketch synthesis as an image denoising problem which can be solved efficiently using the proposed method. Real-time performance can be obtained on a state-of-the-art GPU. Meanwhile quantitative evaluations on face sketch recognition and user study demonstrate the effectiveness of the proposed method. In addition, the proposed method can be directly extended to the temporal domain for consistent video sketch synthesis, which is of great importance in digital entertainment."
"B. Li, Y. Lu, A. Godil, T. Schreck, B. Bustos, Alfredo Ferreira, T. Furuya, Manuel J. Fonseca, H. Johan, Takahiro Matsuda, Ryutarou Ohbuchi, P. Pascoal, J. M. Saavedra",3888a4814606e725ec86938156166068c0aea79c,A comparison of methods for sketch-based 3D shape retrieval,Comput. Vis. Image Underst.,2014.0,92,"Sketch-based 3D shape retrieval has become an important research topic in content-based 3D object retrieval. To foster this research area, two Shape Retrieval Contest (SHREC) tracks on this topic have been organized by us in 2012 and 2013 based on a small-scale and large-scale benchmarks, respectively. Six and five (nine in total) distinct sketch-based 3D shape retrieval methods have competed each other in these two contests, respectively. To measure and compare the performance of the top participating and other existing promising sketch-based 3D shape retrieval methods and solicit the state-of-the-art approaches, we perform a more comprehensive comparison of fifteen best (four top participating algorithms and eleven additional state-of-the-art methods) retrieval methods by completing the evaluation of each method on both benchmarks. The benchmarks, results, and evaluation tools for the two tracks are publicly available on our websites [1,2]."
"B. Li, Y. Lu, C. Li, A. Godil, T. Schreck, Masaki Aono, Martin Burtscher, Hongbo Fu, T. Furuya, H. Johan, Jianzhuang Liu, Ryutarou Ohbuchi, A. Tatsuma, C. Zou",660e4e84f8123801b8ebb474d0cf19f71f10a0da,Extended Large Scale Sketch-Based 3D Shape Retrieval,3DOR@Eurographics,2014.0,59,"Large scale sketch-based 3D shape retrieval has received more and more attentions in the community of content-based 3D object retrieval. The objective of this track is to evaluate the performance of different sketch-based 3D model retrieval algorithms using a large scale hand-drawn sketch query dataset on a comprehensive 3D model dataset. The benchmark contains 12,680 sketches and 8,987 3D models, divided into 171 distinct classes. In this track, 12 runs were submitted by 4 groups and their retrieval performance was evaluated using 7 commonly used retrieval performance metrics. We hope that this benchmark, the comparative evaluation results and the corresponding evaluation code will further promote the progress of this research direction for the 3D model retrieval community."
"Z. Huang, Hongbo Fu, Rynson W. H. Lau",924462af4f90643a91327a9c466d2cfa905c6fef,Data-driven segmentation and labeling of freehand sketches,ACM Trans. Graph.,2014.0,59,"We present a data-driven approach to derive part-level segmentation and labeling of free-hand sketches, which depict single objects with multiple parts. Our method performs segmentation and labeling simultaneously, by inferring a structure that best fits the input sketch, through selecting and connecting 3D components in the database. The problem is formulated using Mixed Integer Programming, which optimizes over both the local fitness of the selected components and the global plausibility of the connected structure. Evaluations show that our algorithm is significantly better than the straightforward approaches based on direct retrieval or part assembly, and can effectively handle challenging variations in the sketch."
J. M. Saavedra,d96585b5d9eb2bf503d0c34c3a3decd287228ca7,Sketch based image retrieval using a soft computation of the histogram of edge local orientations (S-HELO),2014 IEEE International Conference on Image Processing (ICIP),2014.0,50,"This paper introduces S-HELO (Soft-Histogram of Edge Local Orientations), an outperforming method for describing images in the context of sketch based image retrieval (SBIR). This proposal exploits the advantages provided by the HELO descriptor for describing sketches, and improves significantly its performance by using a soft computation of local orientations and taking into account spatial information. We experimentally demonstrate that a soft computation process together with a local estimation of orientations are very suitable for describing sketches in the context of image retrieval. Indeed, our results show that S-HELO significantly outperforms not only HELO but also classical orientation-based descriptors as HOG. We also show that S-HELO performs very close to the optimal when what we want to retrieve are target images. Moreover, our proposal also shows an outstanding performance for similarity search, i.e., retrieving images that belong to the same category of the query sketch."
"D. Neto, M. Oliveira, J. Alves, L. Menezes",9b43a62d9ada82e69aeeef2dcdb3b1dfd9da8b1b,Influence of the plastic anisotropy modelling in the reverse deep drawing process simulation,,2014.0,49,"This study deals with the description of the anisotropic behaviour of the mild steel sheet used in the reverse deep drawing process of a cylindrical cup, which was proposed as benchmark at the Numisheet’99 conference. The effect of the yield criterion on the numerical results is analysed using three yield functions, von Mises, Hill’48 and Barlat Yld’91, combined with the Swift hardening law. The anisotropy parameters of the Hill’48 model are identified using either the yield stresses or r-values, obtained from the uniaxial tensile test at three different directions. On the other hand, the anisotropy parameters of the Yld’91 are determined taking into account both the yield stresses and r-values, minimizing an objective function. The comparison between experimental and numerical results is presented, being the punch force evolution and the thickness distribution along the cup wall the principal variables under study. In both forming stages, the predicted punch force evolution is close to the experimental one, whatever the yield criterion adopted. Nevertheless, the cup wall thickness distribution is strongly influenced by the yield criteria, being clearly overestimated by the von Mises yield criterion. On the other hand, the Yld’91 yield criterion provides a thickness distribution closer to the experimental one, for both forming stages. The strain paths during both forming stages ranges from uniaxial compression, when the material flows between the die and blank-holder, to plane strain in the cup wall, whereas the important strain path changes occurs in the die radius."
"H. Zein, M. Sherbiny, M. Abd-Rabou, M. Shazly",88ac74d75914fcdea4c79047b8b282986973ccd5,Thinning and spring back prediction of sheet metal in the deep drawing process,,2014.0,46,"The spring back simulation helps to get the required tolerance of the punch travel distance. This tolerance is needed in getting the required height of the final drawn part. Prediction of the forming results as spring back, determination of the thickness distribution and of the thinning of the sheet metal blank reduces the production cost of the material and time. In this paper, A Finite Element (FE) model is developed for the 3D numerical simulation of sheet metal deep drawing process (Parametric Analysis) by using ABAQUS/ EXPLICIT FEA program with the proper material properties (anisotropic material) and simplified boundary conditions. The FE results are compared with experimental results for validation. The developed model predicts the spring back, the thickness distribution and thinning of the blank as affected by the die design parameters (geometrical parameters and physical parameters). Furthermore, with numerical simulation, working parameters such as punch force, the blank holder force, and the lubrication requirements can be determined without expensive shop trials."
"M. Ghosh, A. Miroux, R. Werkhoven, P. Bolt, L. Kestens",ea2c9aeca5e47b3e514b7053b47b35f69afcea21,Warm deep-drawing and post drawing analysis of two Al-Mg-Si alloys,,2014.0,45,"The increasing use of aluminium alloys in light weight structural applications is restricted mainly due to their lower room temperature formability compared to steels. Forming at higher temperature is seen as a promising solution to this problem. In the present investigation two Al-Mg-Si alloys (EN AW-6016 and EN AW-6061) were deep-drawn at room temperature and 250 C and their behaviour during drawing were compared. The effect of ram speed, drawing ratio, holding time, and temper was also investigated. Among the parameters investigated temperature was found to have the most significant effect on the force-displacement response. Because anisotropy has been an important concern during the deep-drawing process, this parameter was also investigated by looking at the earing profile. With increasing temperature the amplitude of earing decreased while the number of ears remained the same, indicating that there is no change in anisotropy with temperature. The cup thickness increases from the bottom of the cup to the flange with a local minimum around the mid-height of the wall. © 2013 Elsevier B.V."
"S. Parui, Anurag Mittal",a4d95b0d6307b6ce48d56c4456ef2475554268df,Similarity-Invariant Sketch-Based Image Retrieval in Large Databases,ECCV,2014.0,44,"Proliferation of touch-based devices has made the idea of sketch-based image retrieval practical. While many methods exist for sketch-based image retrieval on small datasets, little work has been done on large (web)-scale image retrieval. In this paper, we present an efficient approach for image retrieval from millions of images based on user-drawn sketches. Unlike existing methods which are sensitive to even translation or scale variations, our method handles translation, scale, rotation (similarity) and small deformations. To make online retrieval fast, each database image is preprocessed to extract sequences of contour segments (chains) that capture sufficient shape information which are represented by succinct variable length descriptors. Chain similarities are computed by a fast Dynamic Programming-based approximate substring matching algorithm, which enables partial matching of chains. Finally, hierarchical k-medoids based indexing is used for very fast retrieval in a few seconds on databases with millions of images. Qualitative and quantitative results clearly demonstrate superiority of the approach over existing methods."
"Siong Thye Goh, C. Rudin",5860b3004ce08216f4cf360012ba32a5c7b668a7,Box drawings for learning with imbalanced data,KDD,2014.0,38,"The vast majority of real world classification problems are imbalanced, meaning there are far fewer data from the class of interest (the positive class) than from other classes. We propose two machine learning algorithms to handle highly imbalanced classification problems. The classifiers are disjunctions of conjunctions, and are created as unions of parallel axis rectangles around the positive examples, and thus have the benefit of being interpretable. The first algorithm uses mixed integer programming to optimize a weighted balance between positive and negative class accuracies. Regularization is introduced to improve generalization performance. The second method uses an approximation in order to assist with scalability. Specifically, it follows a \textit{characterize then discriminate} approach, where the positive class is characterized first by boxes, and then each box boundary becomes a separate discriminative classifier. This method has the computational advantages that it can be easily parallelized, and considers only the relevant regions of feature space."
Li,7509d69e6a69ebad5e32f443cf3483d0b7a8237c,Fine-grained sketch-based image retrieval by matching deformable part models,,2014.0,37,"(c) 2014. The copyright of this document resides with its authors. 
It may be distributed unchanged freely in print or electronic forms."
"X. Pang, Ying Cao, Rynson W. H. Lau, Antoni B. Chan",1ffdec500d847dc702cdf84e8fe826a71c3c4340,A Robust Panel Extraction Method for Manga,ACM Multimedia,2014.0,31,"Automatically extracting frames/panels from digital comic pages is crucial for techniques that facilitate comic reading on mobile devices with limited display areas. However, automatic panel extraction for manga, i.e., Japanese comics, can be especially challenging, largely because of its complex panel layout design mixed with various visual symbols throughout the page. In this paper, we propose a robust method for automatically extracting panels from digital manga pages. Our method first extracts the panel block by closing open panels and identifying a page background mask. It then performs a recursive binary splitting to partition the panel block into a set of sub-blocks, where an optimal splitting line at each recursive level is determined adaptively."
"Qun Huang, Patrick P. C. Lee",390875c66f1382379f42b9ea5a7476c5998783fd,LD-Sketch: A distributed sketching design for accurate and scalable anomaly detection in network data streams,IEEE INFOCOM 2014 - IEEE Conference on Computer Communications,2014.0,31,"Real-time characterization of traffic anomalies, such as heavy hitters and heavy changers, is critical for the robustness of operational networks, but its accuracy and scalability are challenged by the ever-increasing volume and diversity of network traffic. We address this problem by leveraging parallelization. We propose LD-Sketch, a data structure designed for accurate and scalable traffic anomaly detection using distributed architectures. LD-Sketch combines the classical counter-based and sketch-based techniques, and performs detection in two phases: local detection, which guarantees zero false negatives, and distributed detection, which reduces false positives by aggregating multiple detection results. We derive the error bounds and the space and time complexity for LD-Sketch. We compare LD-Sketch with state-of-the-art sketch-based techniques by conducting experiments on traffic traces from a real-life 3G cellular data network. Our results demonstrate the accuracy and scalability of LD-Sketch over prior approaches."
"M. Sherbiny, H. Zein, M. Abd-Rabou, M. Shazly",ea2f385dee1464b38c67dada323c4475dbb006cd,Thinning and residual stresses of sheet metal in the deep drawing process,,2014.0,28,"Abstract This paper presents a Finite Element (FE) model developed for the 3-D numerical simulation of sheet metal deep drawing process (Parametric Analysis) by using ABAQUS/EXPLICIT Finite Element Analysis (FEA) program with anisotropic material properties and simplified boundary conditions. The FE results are compared with experimental results for validation. The developed model can predict the thickness distribution, thinning, and the maximum residual stresses of the blank at different die design parameters, including both geometrical and physical parameters. Furthermore, it is used for predicting reliable, working parameters without expensive shop trials. Predictions of the thickness distribution, thinning and the maximum residual stresses of the sheet metal blank with different design parameters are reported. Frictional limitations and requirements at the different interfaces are also investigated."
"J. Fiser, M. Lukác, Ondrej Jamriska, Martin Cadík, Yotam I. Gingold, Paul Asente, D. Sýkora",53d241926c860efa0d8ed712ed999cdf3012259f,Color Me Noisy: Example‐based Rendering of Hand‐colored Animations with Temporal Noise Control,Comput. Graph. Forum,2014.0,25,"We present an example‐based approach to rendering hand‐colored animations which delivers visual richness comparable to real artwork while enabling control over the amount of perceived temporal noise. This is important both for artistic purposes and viewing comfort, but is tedious or even intractable to achieve manually. We analyse typical features of real hand‐colored animations and propose an algorithm that tries to mimic them using only static examples of drawing media. We apply the algorithm to various animations using different drawing media and compare the quality of synthetic results with real artwork. To verify our method perceptually, we conducted experiments confirming that our method delivers distinguishable noise levels and reduces eye strain. Finally, we demonstrate the capabilities of our method to mask imperfections such as shower‐door artifacts."
"Y. Li, Timothy M. Hospedales, Yi-Zhe Song, S. Gong",583ab977a80778e74aad5e3200c534635611b89e,Intra-category sketch-based image retrieval by matching deformable part models,BMVC,2014.0,24,
"Feng Wang, Lanfen Lin, Min Tang",9ea8d41109bac3736778b407e6c3ff324c9d7581,A new sketch-based 3D model retrieval approach by using global and local features,Graph. Model.,2014.0,23,"Abstract With the rapid growth of available 3D models, fast retrieval of suitable 3D models has become a crucial task for industrial applications. This paper proposes a novel sketch-based 3D model retrieval approach which utilizes both global feature-based and local feature-based techniques. Unlike current approaches which use either global or local features, as well as do not take into account semantic relations between local features, we extract these two kinds of feature information from the representative 2D views of 3D models that can facilitate semantic description and retrieval for 3D models. Global features represent the gross exterior boundary shape information, and local features describe the interior details by compact visual words. Specifically, an improved bag-of-features method is provided to extract local features and their latent semantic relations. In addition, an efficient two-stage matching strategy is used to measure the distance between the query sketch and 3D models for selection and refinement. Experiment results demonstrate that our approach which combines these two kinds of complementary features significantly outperforms several state-of-the-art approaches."
"W. Chu, Ying-Chieh Chao",8a5ca4a0d84d355784c57dbe817b75da0acad58a,Line-Based Drawing Style Description for Manga Classification,ACM Multimedia,2014.0,19,"Diversity of drawing styles of mangas can be easily perceived by humans, but are hard to be described in text. We design computational features derived from line segments to describe drawing styles, enabling style classification such as discriminating mangas targeting youth boys and youth girls, and discriminating artworks produced by different artists. With statistical analysis, we found that drawing styles can be effectively characterized by the proposed features such that explicit (e.g., density of line segments) or implicit (e.g., included angles between lines) observations can be made to facilitate various manga style classification."
"T. Pham, Mathieu Delalandre, S. Barrat, Jean-Yves Ramel",5726cdf982acc133ad87963df47d95b724a01676,Accurate junction detection and characterization in line-drawing images,Pattern Recognit.,2014.0,19,"In this paper, we present a new approach for junction detection and characterization in line-drawing images. We formulate this problem as searching for optimal meeting points of median lines. In this context, the main contribution of the proposed approach is three-fold. First, a new algorithm for the determination of the support region is presented using the linear least squares technique, making it robust to digitization effects. Second, an efficient algorithm is proposed to detect and conceptually remove all distorted zones, retaining reliable line segments only. These line segments are then locally characterized to form a local structure representation of each crossing zone. Finally, a novel optimization algorithm is presented to reconstruct the junctions. Junction characterization is then simply derived. The proposed approach is very highly robust to common geometry transformations and can resist a satisfactory level of noise/degradation. Furthermore, it works very efficiently in terms of time complexity and requires no prior knowledge of the document content. Extensive evaluations have been performed to validate the proposed approach using other baseline methods. An application of symbol spotting is also provided, demonstrating quite good results. HighlightsWe present a new approach for junction detection in line-drawing documents.We present a novel algorithm to deal with the problem of junction distortion.We present an efficient junction optimization algorithm.The characterization of the detected junctions is presented.We obtained very good results relative to the baseline methods."
"Kazuhiro Sato, Yusuke Matsui, T. Yamasaki, K. Aizawa",3680603b70132e1efa6e08ead838f03ece6b6305,Reference-based manga colorization by graph correspondence using quadratic programming,SIGGRAPH ASIA Technical Briefs,2014.0,18,"Manga (Japanese comics) are popular all over the world. However, most existing manga are monochrome. If such monochrome manga can be colorized, readers can enjoy the richer representations. In this paper, we propose a semiautomatic colorization method for manga. Given a previously colored reference manga image and target monochrome manga images, we propagate the colors of the reference manga to the target manga by representing images as graphs and matching graphs. The proposed method enables coloring of manga images without time-consuming manual colorization. We show results in which the colors of characters were correctly transferred to target characters, even those with complex structures."
"Jiazhou Chen, Qi Lei, Yongwei Miao, Qunsheng Peng",d63f4021d044ee46096af13bafe9e2cd114ff2c6,Vectorization of line drawing image based on junction analysis,Science China Information Sciences,2014.0,16,"Converting a scanned or shot line drawing image into a vector graph can facilitate further editand reuse, making it a hot research topic in computer animation and image processing. Besides avoiding noiseinfluence, its main challenge is to preserve the topological structures of the original line drawings, such as linejunctions, in the procedure of obtaining a smooth vector graph from a rough line drawing. In this paper, wepropose a vectorization method of line drawings based on junction analysis, which retains the original structureunlike done by existing methods. We first combine central line tracking and contour tracking, which allowsus to detect the encounter of line junctions when tracing a single path. Then, a junction analysis approachbased on intensity polar mapping is proposed to compute the number and orientations of junction branches.Finally, we make use of bending degrees of contour paths to compute the smoothness between adjacent branches,which allows us to obtain the topological structures corresponding to the respective ones in the input image.We also introduce a correction mechanism for line tracking based on a quadratic surface fitting, which avoidsaccumulating errors of traditional line tracking and improves the robustness for vectorizing rough line drawings.We demonstrate the validity of our method through comparisons with existing methods, and a large amount ofexperiments on both professional and amateurish line drawing images.创新点本文提出一种基于交叉点分析的线条矢量化方法, 克服了现有方法难以保持拓扑结构的不足。通过中心路径跟踪和轮廓路径跟踪相结合的方式, 准确检测交叉点的出现提出一种基于极坐标亮度映射的交叉点分析方法, 计算交叉点的分支数量和朝向; 利用轮廓路径的弯曲角度判断交叉点相邻分支间的光顺度, 从而获得与原图一致的拓扑结构。"
"P. Talukdar, William W. Cohen",41e49fd3af628f1c8201942a659769f7cc21d812,Scaling Graph-based Semi Supervised Learning to Large Number of Labels Using Count-Min Sketch,AISTATS,2014.0,15,"Graph-based Semi-supervised learning (SSL) algorithms have been successfully used in a large number of applications. These methods classify initially unlabeled nodes by propagating label information over the structure of graph starting from seed nodes. Graph-based SSL algorithms usually scale linearly with the number of distinct labels (m), and require O(m) space on each node. Unfortunately, there exist many applications of practical signicance with very large m over large graphs, demanding better space and time complexity. In this paper, we propose MAD-Sketch, a novel graph-based SSL algorithm which compactly stores label distribution on each node using Count-min Sketch, a randomized data structure. We present theoretical analysis showing that under mild conditions, MAD-Sketch can reduce space complexity at each node from O(m) to O(logm), and achieve similar savings in time complexity as well. We support our analysis through experiments on multiple real world datasets. We observe that MAD-Sketch achieves similar performance as existing state-of-the-art graph-based SSL algorithms, while requiring smaller memory footprint and at the same time achieving up to 10x speedup. We nd that MAD-Sketch is able to scale to datasets with one million labels, which is beyond the scope of existing graph-based SSL algorithms."
"Christophe Rigaud, Dimosthenis Karatzas, J. Burie, J. Ogier",e4ec6acd44b01eb354bcda300efea443ce667620,Color Descriptor for Content-Based Drawing Retrieval,2014 11th IAPR International Workshop on Document Analysis Systems,2014.0,14,"Human detection in computer vision field is an active field of research. Extending this to human-like drawings such as the main characters in comic book stories is not trivial. Comics analysis is a very recent field of research at the intersection of graphics, texts, objects and people recognition. The detection of the main comic characters is an essential step towards a fully automatic comic book understanding. This paper presents a color-based approach for comics character retrieval using content-based drawing retrieval and color palette."
"Yusuke Matsui, K. Aizawa, Yushi Jing",c751085c7cf3b2a4a4b1b2a88323a3dd143c82a1,Sketch2Manga: Sketch-based manga retrieval,2014 IEEE International Conference on Image Processing (ICIP),2014.0,13,"We propose a sketch-based method for manga image retrieval, in which users draw sketches via a Web browser that enables the automatic retrieval of similar images from a database of manga titles. The characteristics of manga images are different from those of naturalistic images. Despite the widespread attention given to content-based image retrieval systems, the question of how to retrieve manga images effectively has been little studied. We propose a fine multi-scale edge orientation histogram (FMEOH) whereby a number of differently sized squares on a page can be indexed efficiently. Our experimental results show that FMEOH can achieve greater accuracy than a state-of-the-art sketch-based retrieval method [1]."
"C. Zou, C. Wang, Yafei Wen, Lei Zhang, Jianzhuang Liu",f9c0c81669909b80546520bbb99b4677175e240b,Viewpoint-Aware Representation for Sketch-Based 3D Model Retrieval,IEEE Signal Processing Letters,2014.0,12,"We study the problem of sketch-based 3D model retrieval, and propose a solution powered by a new query-to-model distance metric and a powerful feature descriptor based on the bag-of-features framework. The main idea of the proposed query-to-model distance metric is to represent a query sketch using a compact set of sample views (called basic views) of each model, and to rank the models in ascending order of the representation errors. To better differentiate between relevant and irrelevant models, the representation is constrained to be essentially a combination of basic views with similar viewpoints. In another aspect, we propose a mid-level descriptor (called BOF-JESC) which robustly characterizes the edge information within junction-centered patches, to extract the salient shape features from sketches or model views. The combination of the query-to-model distance metric and the BOF-JESC descriptor achieves effective results on two latest benchmark datasets."
"M. Kocaoglu, Karthikeyan Shanmugam, A. Dimakis, Adam R. Klivans",1dc6b9a74e155abf49e837d7a4868aa7c315cccf,Sparse Polynomial Learning and Graph Sketching,NIPS,2014.0,12,"Let f : {-1, 1}n - ℝ be a polynomial with at most s non-zero real coefficients. We give an algorithm for exactly reconstructing f given random examples from the uniform distribution on {- 1,1}n that runs in time polynomial in n and 2s and succeeds if the function satisfies the unique sign property: there is one output value which corresponds to a unique set of values of the participating parities. This sufficient condition is satisfied when every coefficient of f is perturbed by a small random noise, or satisfied with high probability when s parity functions are chosen randomly or when all the coefficients are positive. Learning sparse polynomials over the Boolean domain in time polynomial in n and 2s is considered notoriously hard in the worst-case. Our result shows that the problem is tractable for almost all sparse polynomials. 
 
Then, we show an application of this result to hypergraph sketching which is the problem of learning a sparse (both in the number of hyperedges and the size of the hyperedges) hypergraph from uniformly drawn random cuts. We also provide experimental results on a real world dataset."
"Huda Abdulaali Abdulbaqi, G. Sulong, S. Hashem",8f97fb4bb9214e4596787ca791ee1e86f4ce6ced,A SKETCH BASED IMAGE RETRIEVAL: A REVIEW OF LITERATURE,,2014.0,11,"This survey paper reviews the development of Content Based Image Retrieval (CBIR) field and especially the sketch based image retrieval (SBIR) as a core issue. An image is retrieved from the database in several ways in user queries. SBIR is one of the efficient and important methods which are not necessary to have a high skill to draw the query sketch. First, we review the feature extraction, features based matching, and indexing which represents the base of recall images. We also present in the concluding section general limitations of how the methods deal with the image retrieval and our views in image retrieval based on sketch query, which is also the future direction."
"Evmorfia N. Argyriou, A. Symvonis, V. Vassiliou",a69888c636554f811bc71bdbc1ef0e0eae99cd56,A fraud detection visualization system utilizing radial drawings and heat-maps,2014 International Conference on Information Visualization Theory and Applications (IVAPP),2014.0,10,We present a prototype system developed in cooperation with a business organization that combines information visualization and pattern-matching techniques to detect fraudulent activity by employees. The system is built upon common fraud patterns searched while trying to detect occupational fraud suggested by internal auditors of a business company. The main visualization of the system consists of a multi-layer radial drawing that represents the activity of the employees and clients. Each layer represents a different examined pattern whereas heat-maps indicating suspicious activity are incorporated in the visualization. The data are first preprocessed based on a decision tree generated by the examined patterns and each employee is assigned a value indicating whether or not there exist indications of fraud. The visualization is presented as an animation and the employees are visualized one by one according to their severity values together with their related clients.
Christophe Rigaud,fe34ad6026c5c4b91316620d2f67f412c9e35935,Segmentation and indexation of complex objects in comic book images. (Segmentation et indexation d'objets complexes dans les images de bandes dessinées),,2014.0,10,"Born in the 19th century, comics is a visual medium used to express ideas via images, often combined with text or visual information. It is an art form that uses images deployed in sequence for graphic storytelling (sequential art), spread worldwide initially using newspapers, books and magazines. Nowadays, the development of the new technologies and the World Wide Web is giving birth to a new form of paperless comics that takes advantage of the virtual world freedom. However, traditional comics still represent an important cultural heritage in many countries. They have not yet received the same level of attention as music, cinema or literature about their adaptation to the digital format. Using information technologies with digitized comic books would facilitate the exploration of digital libraries, accelerate their translation, allow augmented reading, speech playback for the visually impaired etc. Heritage museums such as the CIBDI (French acronym for International City of Comic books and Images), the Kyoto International Manga Museum and The Digital Comic Museum have already digitized several thousands of comic albums that some are now in the public domain. Despite the growing market place of digital comics, few research has been carried out to take advantage of the added value provided by these new media. A particularity of documents is their dependence on the type of document that often requires specific processing. The challenge of document analysis systems is to propose generic solutions for specific problems. The design process of comics is so specific that their automated analysis may be seen as a niche research field within document analysis, at the intersection of complex background, semi-structured and mixed content documents. Being at the intersection of several fields combines their difficulties. In this thesis, we review, highlight and illustrate the challenges related to comic book image analysis in order to provide a good overview about the last research progress in this field and the current issues. In order to cover the widest possible scope of study, we propose three different approaches for comic book image analysis. The three approaches aim to provide an automatic description of the image content. Different levels of description are discussed, from spacial positions (low level) to semantic information (high level). The first approach describes the image in an intuitive way, from simple to complex elements using previously extracted elements to guide further processing. Simple elements such as panel, text and balloon regions are extracted first, followed by balloon tails and comic character positions from the direction indicated by the tails. The second approach addresses independent information extraction to recover the main drawback of the first approach: error propagation. This second method is composed by several specific extractors for each type of content, independent from each other. Those extractors can be used in parallel, without needing previous information which cancels the error propagation effect. Extra processing such as balloon type classification and text recognition are also covered. The third approach introduces a knowledge-driven system that combines low and high level processing to build a scalable system for comics image understanding. This approach is intended to improve the overall precision of content extraction methods. We built an expert system composed by an inference engine and two models, one for comics domain and another one for image processing, stored in an ontology. The first model embeds the knowledge about comic books and the second models the image processing related part. These two models allow consistency analysis of extracted information and inference of the relationships between all the extracted elements such as the reading order, the type of text (e.g. spoken, onomatopoeic, illustrative) and the relations between speech balloons and speaking characters. The expert system combines the benefits of the two first approaches and enables high level semantic description such as the reading order, the semantic of the balloon shapes, the relations between the speech balloons and their speakers, and the interaction between the comic characters. Apart from that, in this thesis we have provided the first public comic book image dataset and ground truth to the community along with an overall experimental comparison of all the proposed methods and some of the state-of-the-art methods"
"M. Iwata, Atsushi Ito, K. Kise",7605cb2d5db991d70783f5fb91397ab03d3f0c92,A Study to Achieve Manga Character Retrieval Method for Manga Images,2014 11th IAPR International Workshop on Document Analysis Systems,2014.0,10,"Manga (Japanese style comics) is one of the most popular publications. Nowadays manga is often handled as digital images not only in consumers' use but also in digital media. However, they hardly handle manga as content-based materials. Some digital media use tags or text data for retrieval, where the tags and text data are produced by handmade input. Therefore our goal is achieving content-based retrieval method for manga images. As the first step to the goal, we investigate the performance of Sun's method applying to manga character retrieval. Manga character retrieval means a image retrieval of which the input and output are a character image and page images where the input character appears respectively. It is useful for convenient use of manga images, for example, character retrieval or auto-tagging. We modify Sun's method so as to be applicable to manga character retrieval and then investigate the performance."
"Yuji Aramaki, Yusuke Matsui, T. Yamasaki, K. Aizawa",6b5144d804c7ec3b1e5cba2ea460598542a0ce15,Interactive segmentation for manga,SIGGRAPH '14,2014.0,9,"There are only a few effective segmentation methods designed for line drawings. Smart Scribbles [Noris et al. 2012] is one of the state-of-the-art interactive segmentation methods for line drawings. However, it can accept only a vector image composed of a relatively small number of strokes with temporal information. Therefore it is hard to apply Smart Scribbles directly to manga images because they are raster images with a lot of strokes and without temporal information. We propose a method for interactively segmenting manga images. The proposed method consists of (1) vectorization, (2) labeling and (3) rasterization, and it enables users to segment a complicated manga images by simpler operations than Smart Scribbles and Adobe Photoshop R ⃝."
"Stuart James, J. Collomosse",7a2bfa99616a8a34562bc61dcfda5249322427c4,Interactive video asset retrieval using sketched queries,CVMP,2014.0,9,"We present a new algorithm for searching video repositories using free-hand sketches. Our queries express both appearance (color, shape) and motion attributes, as well as semantic properties (object labels) enabling hybrid queries to be specified. Unlike existing sketch based video retrieval (SBVR) systems that enable hybrid queries of this form, we do not adopt a model fitting/optimization approach to match at query-time. Rather, we create an efficiently searchable index via a novel space-time descriptor that encapsulates all these properties. The real-time performance yielded by our indexing approach enables interactive refinement of search results within a relevance feedback (RF) framework; a unique contribution to SBVR. We evaluate our system over 700 sports footage clips exhibiting a variety of clutter and motion conditions, demonstrating significant accuracy and speed gains over the state of the art."
"T. Furuya, Ryutarou Ohbuchi",4f5d754f8ba569c741bfb597090df4b4b979bde3,Hashing Cross-Modal Manifold for Scalable Sketch-Based 3D Model Retrieval,2014 2nd International Conference on 3D Vision,2014.0,9,"This paper proposes a novel sketch-based 3D model retrieval algorithm that is scalable as well as accurate. Accuracy is achieved by a combination of (1) a set of state-of-the-art visual features for comparing sketches and 3D models, and (2) an efficient algorithm to learn data-driven similarity across heterogeneous domains of sketches and 3D models. For the latter, we adopted the algorithm [18] by Furuya et al., which fuses, for more accurate similarity computation, three kinds of similarities, i.e., Those among sketches, those among 3D models, and those between sketches and 3D models. While the algorithm by Furuya et al. [18] does improve accuracy, it does not scale. We accelerate, without loss of accuracy, retrieval result ranking stage of [18] by embedding its cross-modal similarity graph into Hamming space. The embedding is performed by a combination of spectral embedding and hashing into compact binary codes. Experiments show that our proposed algorithm is more accurate and much faster than previous sketch-based 3D model retrieval algorithms."
"S. L. D. Silva, Rodrigo L. da Silva, Judismar T. Guaitolini Junior, Elias Gonccalves, Emilson. R. Viana, J. L. Wyatt",45ddf548e6d03e71956a954451028c2e98a34ddc,Animation with Algodoo: a simple tool for teaching and learning physics,,2014.0,9,"In the present work we have made use of the animation freeware Algodoo, as an easy handling tool to teach and learn physics. The animation is based on the oblique motion model and we have described the movement qualitatively, showing changes in the trajectory of an object as we modify the control parameters, such as speed and launch angle. Exploring the software graphical tools, the consistency between the results obtained by the animation and the literature is maintained, for example the maximum height and the rise time of the disc. This tool can be applied to students from different education levels, and also to undergraduate and high school students. The aim this paper is to use Algodoo for didactic purposes."
"Shuang Liang, Long Zhao, Yichen Wei, Jinyuan Jia",dcd78a081294a34125c69a0d180741773e31465b,Sketch-Based Retrieval Using Content-Aware Hashing,PCM,2014.0,8,"In this paper, we introduce a generic hashing-based approach. It aims to facilitate sketch-based retrieval on large datasets of visual shapes. Unlike previous methods where visual descriptors are extracted from overlapping grids, a content-aware selection scheme is proposed to generate candidate patches instead. Meanwhile, the saliency of each patch is efficiently estimated. Locality-sensitive hashing LSH is employed to integrate and capture both the content and saliency of patches, as well as the spatial information of visual shapes. Furthermore, hash codes are indexed so that a query can be processed in sub-linear time. Experiments on three standard datasets in terms of hand drawn shapes, images and 3D models demonstrate the superiority of our approach."
"Hideaki Yanagisawa, Daisuke Ishii, Hiroshi Watanabe",fdd5ffa5e448d19a81afc7b3938f0d8074828983,FACE DETECTION FOR COMIC IMAGES WITH DEFORMABLE PART MODEL,,2014.0,8,"Comic images include several kinds of picture elements, such as lines, dots, characters and sound effects. Therefore, they form quite complex structure compared with natural images. We have been trying to improve the convenience of e-comics by retrieving metadata elements, such as names of characters and positions of the characters. To extract characters from comic images, a method detecting characters’ face using the Histograms of Oriented Gradients (HOG) features and discriminating them has been proposed. However, this method does not provide stable face detection. In this paper, Deformable Part Model (DMP), which is originally proposed to detect natural objects, is applied to comic images in order to improve accuracy of face detection. As a consequence, it is turned out that we can obtain 85.5 % detection rate for unknown images. Thus, DPM can be regarded an effective method to detect objects in comic images."
"Shin-ichiro Kondo, M. Toyoura, Xiaoyang Mao",73cdbe73a8f8fcd2a6ecf4d4aa9c7726f6b20b2c,Sketch based skirt image retrieval,SBIM '14,2014.0,7,"Although many online shops allow users to search for clothes by categories or keywords, it is usually impossible to specify the details of the design. This paper presents a new technology for retrieving skirt images based on sketches. We first conducted a user study to investigate the typical features illustrated in a sketch. Then algorithms have been developed for automatically extracting those features from both the skirt images and the sketches. A prototype system has been implemented to retrieve and present the best matched skirts in real time when a user interactively sketches her imagined skirt on the canvas."
"J. Wu, C. Wang, Liqing Zhang, Y. Rui",2330805936da78453f403ae30212fa3308257e70,Sketch Recognition with Natural Correction and Editing,AAAI,2014.0,7,"In this paper, we target at the problem of sketch recognition. We systematically study how to incorporate users' correction and editing into isolated and full sketch recognition. This is a natural and necessary interaction in real systems such as Visio where very similar shapes exist. First, a novel algorithm is proposed to mine the prior shape knowledge for three editing modes. Second, to differentiate visually similar shapes, a novel symbol recognition algorithm is introduced by leveraging the learnt shape knowledge. Then, a novel editing detection algorithm is proposed to facilitate symbol recognition. Furthermore, both of the symbol recognizer and the editing detector are systematically incorporated into the full sketch recognition. Finally, based on the proposed algorithms, a realtime sketch recognition system is built to recognize handdrawn flowcharts and diagrams with flexible interactions. Extensive experiments show the effectiveness of the proposed algorithms."
"Hayko Riemenschneider, M. Donoser, H. Bischof",1db4919d0f1b3c6fa4ea88cf4b3f7cbcf04723ca,Image retrieval by shape-focused sketching of objects,,2014.0,7,"Content-based image retrieval deals with retrieval in large databases using the actual visual content. In this paper we propose to use hand-drawn object sketches highlighting the outline of an object of interest as query. Due to the lack of appearance, the focus lies on the shape of an object. Such a scenario requires a common representation for the sketch and the images. We propose novel shapebased descriptors that are calculated on local contour fragments. The contour descriptors are stored in a hierarchical data structure, which enables efficient retrieval in sub-linear time, potentially handles millions of images, and does not require retraining when inserting new images. We demonstrate superior performance in this query-by-shape-sketch retrieval for our novel features, and efficient retrieval in 50 milliseconds on a standard single core computer."
"Shuai Ren, Cheng Jin, Chang Sun, Yuejie Zhang",f2254294a13946049f217c561a63c0c77f72bd99,Sketch-Based Image Retrieval via Adaptive Weighting,ICMR,2014.0,6,"As touch devices become more and more popular these days, it would be convenient if the user could draw a sketch and then use the sketch as the input for an image retrieval system. Although Sketch-Based Image Retrieval (SBIR) had been studied since 1990s, how to measure the similarity between a sketch and an image with high precision is still a challenging problem. In this paper, a novel adaptive weighting method is proposed for the matching process of SBIR. We integrate a cost aggregation step into the matching process, both the neighborhood and multi-scale information are taken into account. The experiments on the public image dataset show that our method can yield promising results."
"Yun Chien, Wen-Chieh Lin, Tsung-Shian Huang, Jung-Hong Chuang",a5b7a7942725e9fde925a30f40aa475b1cea711d,Line drawing simplification by stroke translation and combination,International Conference on Graphic and Image Processing,2014.0,5,"In this paper, we propose a new algorithm for simplifying line drawing sketches. First, we segment the strokes at the points of large curvature if desired. Then, we perform a low-pass filter and use the result to assign a weight to every stroke. The strokes are moved to the position of the higher weight. After that, we find the stroke pairs and combine them to reduce the total number of the strokes, resulting in a cleaner line drawing art. This system also cuts down the disordered and confusing small strokes and combines them to form long strokes."
"Ben Yang, X. Jin",8dc7e406f8466b9e2022843f8daed00301cd0c04,Turbulence synthesis for shape‐controllable smoke animation,Comput. Animat. Virtual Worlds,2014.0,4,"We present a novel procedural synthesis method to improve small‐scale turbulence details for controllable smoke animation constrained by shapes and paths. In order to enhance fluid details without introducing unpleasing fluid control effects, we propose a spatial–temporal varying synthesis parameter to control turbulence behaviors and compute it from control force and the vorticity velocity. Our approach can control enhanced turbulence behaviors efficiently and produces visually plausible realistic fine‐scale details while reducing artifacts of large‐scale noises on fluid control. We compare our algorithm to existing procedural synthesis ones to validate its efficiency and controllability. Copyright © 2014 John Wiley & Sons, Ltd."
Toshihiro Kuboi,6dbe0868a2e478d6b9cc573058deaa5070ce1123,Element Detection in Japanese Comic Book Panels,,2014.0,4,"iv ABSTRACT Element Detection in Japanese Comic Book Panels Toshihiro Kuboi Comic books are a unique and increasingly popular form of entertainment combining visual and textual elements of communication. This work pertains to making comic books more accessible. Specifically, this paper explains how we detect elements such as speech bubbles present in Japanese comic book panels. Some applications of the work presented in this paper are automatic detection of text and its transformation into audio or into other languages. Automatic detection of elements can also allow reasoning and analysis at a deeper semantic level than what's possible today. Our approach uses an expert system and a machine learning system. The expert system process information from images and inspires feature sets which help train the machine learning system. The expert system detects speech bubbles based on heuristics. The machine learning system uses machine learning algorithms. Specifically, Naive Bayes, Maximum Entropy, and support vector machine are used to detect speech bubbles. The algorithms are trained in a fully-supervised way and a semi-supervised way. Both the expert system and the machine learning system achieved high accuracy. We are able to train the machine learning algorithms to detect speech bubbles just as accurately as the expert system. We also applied the same approach to eye detection of characters in the panels, and are able to detect majority of the eyes but with low precision. However, we are able to improve the performance of our eye detection system significantly by combining the SVM and either the Naive Bayes or the AdaBoost classifiers. v ACKNOWLEDGMENTS This thesis is inspired by Eriq Augustine's original project on the machine translation of Japanese comic books. I would like to thank Eriq for his guidance and assistance on the selection of this thesis topic."
"Swarna Kamlam Ravindran, Anurag Mittal",f916dd87bcaa9ca7142ced529b76ff1acbc965d4,CoMIC: Good features for detection and matching at object boundaries,ArXiv,2014.0,3,"Feature or interest points typically use information aggregation in 2D patches which does not remain stable at object boundaries when there is object motion against a significantly varying background. Level or iso-intensity curves are much more stable under such conditions, especially the longer ones. In this paper, we identify stable portions on long iso-curves and detect corners on them. Further, the iso-curve associated with a corner is used to discard portions from the background and improve matching. Such CoMIC (Corners on Maximally-stable Iso-intensity Curves) points yield superior results at the object boundary regions compared to state-of-the-art detectors while performing comparably at the interior regions as well. This is illustrated in exhaustive matching experiments for both boundary and non-boundary regions in applications such as stereo and point tracking for structure from motion in video sequences."
"P. Jayaraman, Chi-Wing Fu",aa54ace3d525fbac13b690e3562e4406b2c37fcf,Interactive Line Drawing Recognition and Vectorization with Commodity Camera,ACM Multimedia,2014.0,2,"This paper presents a novel method that interactively recognizes and vectorizes hand-drawn strokes in front of a commodity webcam. Compared to existing methods, which recognize strokes on a completed drawing, our method captures both spatial and temporal information of the strokes, and faithfully vectorizes them with timestamps. By this, we can avoid various stroke recognition ambiguities, enhance the vectorization quality, and recover the stroke drawing order. This is a challenging problem, requiring robust tracking of pencil tip, accurate modeling of pen-paper contact, handling pen-paper and hand-paper occlusion, while achieving interactive performance. To address these issues, we develop the following novel techniques. First, we perform robust spatio-temporal tracking of pencil tip by extracting discriminable features, which can be classified with a fast cascade of classifiers. Second, we model the pen-paper contact by analyzing the edge-profile of the acquired trajectory and extracting the portions related to individual strokes. Lastly, we propose a spatio-temporal method to reconstruct meaningful strokes, which are coherent to the stroke drawing continuity and drawing order. By integrating these techniques, our method can support interactive recognition and vectorization of drawn strokes that are faithful to the actual strokes drawn by the user, and facilitate the development of various multimedia applications such as video scribing, cartoon production, and pen input interface."
"S. L. D. Silva, Judismar T. Guaitolini Junior, Rodrigo L. da Silva, Emilson. R. Viana, F. F. Leal",9ed31e2a05f8bd0bc0940e0fdd0adc2486b8ea3b,An alternative for teaching and learning the simple diffusion process using Algodoo animations,,2014.0,2,"In this work animations of the random walk movement using a freeware Algodoo were done in order to support teaching the concepts of Brownian Motion. The random walk movement were simulate considering elastic collision between the particles in suspension in a fluid, and the particles which constitute the fluid. The intensity of velocities where defined in an arbitrary range, and we have a random distribution of the velocity directions. Using two methods, the distribution histogram of displacements (DHD) and the mean-square-displacement ${\langle{\Delta r^{2}}\rangle}$ (MSD), it was possible to measure the diffusion coefficient of the system, and determine the regions where the system presents ballistic regime or diffusive transport regime. The ballistic regime was observed graphically when the MSD has a parabolic dependence with time, which differing from the typical diffusive regime where MSD has a linear dependence. The didactical strategy for combining analytical approaches as graphic analysis, and animations in software's with easy implementation supports the teaching and learning processes, especially in Physics were we want to explain experimental results within theoretical models."
"Mohamed A. El-Sayed, S. Abdel-Khalek, Hanan H. Amin",7d0612a9eb9641d68c83431690863e331c8b11ca,Study of Neural Network Algorithm for Straight-Line Drawings of Planar Graphs,ArXiv,2014.0,2,"Graph drawing addresses the problem of finding a layout of a graph that satisfies given aesthetic and understandability objectives. The most important objective in graph drawing is minimization of the number of crossings in the drawing, as the aesthetics and readability of graph drawings depend on the number of edge crossings. VLSI layouts with fewer crossings are more easily realizable and consequently cheaper. A straight-line drawing of a planar graph G of n vertices is a drawing of G such that each edge is drawn as a straight-line segment without edge crossings. However, a problem with current graph layout methods which are capable of producing satisfactory results for a wide range of graphs is that they often put an extremely high demand on computational resources. This paper introduces a new layout method, which nicely draws internally convex of planar graph that consumes only little computational resources and does not need any heavy duty preprocessing. Here, we use two methods: The first is self organizing map known from unsupervised neural networks which is known as (SOM) and the second method is Inverse Self Organized Map (ISOM)."
"M. Rivière, Makoto Okabe",57764710f4401aed919e13d7e5ea3856f1cc2636,Extraction of a cartoon's topology,SIGGRAPH '14,2014.0,1,"The vectorization process transforms an image in the algebraic representation of if its contours. In the case of hand-drawn cartoons, the pen stroke made by the artist defines such a contour. That's why drawing can be interpreted as a series of junctions between nodes, or, in other words, as a topological graph.
 Many softwares tackle this subject (Adobe Live Trace, Win-Topo...). We will focus here on a program developed in 2013 by a team of researchers from the ETH Zurich and Disney Studios [Noris et al. 2013]. Their method was very efficient for solving ambiguous cases in the drawing, however their implementation was very slow: the vectorization of a 2048x2048 cartoon could need more than 3 minutes of computation. We have improved their method achieving interactive speeds."
"Joseph J. Lim, C. L. Zitnick, Piotr Dollár",6b71a01be65d5040809b409105b77f0da810d057,Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection,2013 IEEE Conference on Computer Vision and Pattern Recognition,2013.0,353,"We propose a novel approach to both learning and detecting local contour-based representations for mid-level features. Our features, called sketch tokens, are learned using supervised mid-level information in the form of hand drawn contours in images. Patches of human generated contours are clustered to form sketch token classes and a random forest classifier is used for efficient detection in novel images. We demonstrate our approach on both top-down and bottom-up tasks. We show state-of-the-art results on the top-down task of contour detection while being over 200x faster than competing methods. We also achieve large improvements in detection accuracy for the bottom-up tasks of pedestrian and object detection as measured on INRIA and PASCAL, respectively. These gains are due to the complementary information provided by sketch tokens to low-level features such as gradient histograms."
"Rui Hu, J. Collomosse",f4268671d089b90cb52fe10bc77499cceb66d00e,A performance evaluation of gradient field HOG descriptor for sketch based image retrieval,Comput. Vis. Image Underst.,2013.0,292,"We present an image retrieval system for the interactive search of photo collections using free-hand sketches depicting shape. We describe Gradient Field HOG (GF-HOG); an adapted form of the HOG descriptor suitable for Sketch Based Image Retrieval (SBIR). We incorporate GF-HOG into a Bag of Visual Words (BoVW) retrieval framework, and demonstrate how this combination may be harnessed both for robust SBIR, and for localizing sketched objects within an image. We evaluate over a large Flickr sourced dataset comprising 33 shape categories, using queries from 10 non-expert sketchers. We compare GF-HOG against state-of-the-art descriptors with common distance measures and language models for image retrieval, and explore how affine deformation of the sketch impacts search performance. GF-HOG is shown to consistently outperform retrieval versus SIFT, multi-resolution HOG, Self Similarity, Shape Context and Structure Tensor. Further, we incorporate semantic keywords into our GF-HOG system to enable the use of annotated sketches for image search. A novel graph-based measure of semantic similarity is proposed and two applications explored: semantic sketch based image retrieval and a semantic photo montage."
"Kun Xu, K. Chen, Hongbo Fu, Wei-Lun Sun, S. Hu",7dee33e1c61625e8a0e8537836e7c58f3ffd4263,Sketch2Scene: sketch-based co-retrieval and co-placement of 3D models,ACM Trans. Graph.,2013.0,174,"This work presents Sketch2Scene, a framework that automatically turns a freehand sketch drawing inferring multiple scene objects to semantically valid, well arranged scenes of 3D models. Unlike the existing works on sketch-based search and composition of 3D models, which typically process individual sketched objects one by one, our technique performs co-retrieval and co-placement of 3D relevant models by jointly processing the sketched objects. This is enabled by summarizing functional and spatial relationships among models in a large collection of 3D scenes as structural groups. Our technique greatly reduces the amount of user intervention needed for sketch-based modeling of 3D scenes and fits well into the traditional production pipeline involving concept design followed by 3D modeling. A pilot study indicates that it is promising to use our technique as an alternative but more efficient tool of standard 3D modeling for 3D scene construction."
"N. Wang, D. Tao, Xinbo Gao, Xuelong Li, J. Li",01854d7cdc63ed89e35d435fc796bc49c3a8148d,Transductive Face Sketch-Photo Synthesis,IEEE Transactions on Neural Networks and Learning Systems,2013.0,124,"Face sketch-photo synthesis plays a critical role in many applications, such as law enforcement and digital entertainment. Recently, many face sketch-photo synthesis methods have been proposed under the framework of inductive learning, and these have obtained promising performance. However, these inductive learning-based face sketch-photo synthesis methods may result in high losses for test samples, because inductive learning minimizes the empirical loss for training samples. This paper presents a novel transductive face sketch-photo synthesis method that incorporates the given test samples into the learning process and optimizes the performance on these test samples. In particular, it defines a probabilistic model to optimize both the reconstruction fidelity of the input photo (sketch) and the synthesis fidelity of the target output sketch (photo), and efficiently optimizes this probabilistic model by alternating optimization. The proposed transductive method significantly reduces the expected high loss and improves the synthesis performance for test samples. Experimental results on the Chinese University of Hong Kong face sketch data set demonstrate the effectiveness of the proposed method by comparing it with representative inductive learning-based face sketch-photo synthesis methods."
"B. Li, Y. Lu, A. Godil, T. Schreck, Masaki Aono, H. Johan, J. M. Saavedra, S. Tashiro",fb7c1b22723746acf6b33733bfed0ac667288be1,SHREC'13 Track: Large Scale Sketch-Based 3D Shape Retrieval,3DOR@Eurographics,2013.0,89,"Sketch-based 3D shape retrieval has become an important research topic in content-based 3D object retrieval. The aim of this track is to measure and compare the performance of sketch-based 3D shape retrieval methods based on a large scale hand-drawn sketch query dataset which has 7200 sketches and a generic 3D model target dataset containing 1258 3D models. The sketches and models are divided into 80 distinct classes. In this track, 5 runs have been submitted by 3 groups and their retrieval accuracies were evaluated using 7 commonly used retrieval performance metrics. We hope that this benchmark, its corresponding evaluation code, and the comparative evaluation results will contribute to the progress of this research direction for the 3D model retrieval community."
"S. Klum, Hu Han, Anil K. Jain, B. Klare",30a2f552402049ac5c0bf7fca62a53ab19081395,Sketch based face recognition: Forensic vs. composite sketches,2013 International Conference on Biometrics (ICB),2013.0,69,"Facial sketches are widely used by law enforcement agencies to assist in the identification and apprehension of suspects involved in criminal activities. Sketches used in forensic investigations are either drawn by forensic artists (forensic sketches) or created with computer software (composite sketches) following the verbal description provided by an eyewitness or the victim. These sketches are posted in public places and in media in hopes that some viewers will provide tips about the identity of the suspect. This method of identifying suspects is slow and tedious and may not lead to apprehension of the suspect. Hence, there is a need for a method that can automatically and quickly match facial sketches to large police mugshot databases. We address the problem of automatic facial sketch to mugshot matching and, for the first time, compare the effectiveness of forensic sketches and composite sketches. The contributions of this paper include: (i) a database containing mugshots and corresponding forensic and composite sketches that will be made available to interested researchers; (ii) a comparison of holistic facial representations versus component based representations for sketch to mugshot matching; and (iii) an analysis of the effect of filtering a mugshot gallery using three sources of demographic information (age, gender and race/ethnicity). Our experimental results show that composite sketches are matched with higher accuracy than forensic sketches to the corresponding mugshots. Both of the face representations studied here yield higher sketch to photo matching accuracy compared to a commercial face matcher."
"Y. Li, Yi-Zhe Song, S. Gong",8d87a0b6da29ab0f7c4c3fbf42575459ee7123fe,Sketch Recognition by Ensemble Matching of Structured Features,BMVC,2013.0,66,"Sketch recognition aims to automatically classify human hand sketches of objects into known categories. This has become increasingly a desirable capability due to recent advances in human computer interaction on portable devices. The problem is nontrivial because of the sparse and abstract nature of hand drawings as compared to photographic images of objects, compounded by a highly variable degree of details in human sketches. To this end, we present a method for the representation and matching of sketches by exploiting not only local features but also global structures of sketches, through a star graph based ensemble matching strategy. Different local feature representations were evaluated using the star graph model to demonstrate the effectiveness of the ensemble matching of structured features. We further show that by encapsulating holistic structure matching and learned bag-of-features models into a single framework, notable recognition performance improvement over the state-of-the-art can be observed. Extensive comparative experiments were carried out using the currently largest sketch dataset released by Eitz et al. [15], with over 20,000 sketches of 250 object categories generated by AMT (Amazon Mechanical Turk) crowd-sourcing."
"Xing Sun, C. Wang, Chao Xu, Lei Zhang",d5ba8232284335dec782e472a93d0e8a868b33ff,Indexing billions of images for sketch-based retrieval,MM '13,2013.0,56,"Because of the popularity of touch-screen devices, it has become a highly desirable feature to retrieve images from a huge repository by matching with a hand-drawn sketch. Although searching images via keywords or an example image has been successfully launched in some commercial search engines of billions of images, it is still very challenging for both academia and industry to develop a sketch-based image retrieval system on a billion-level database. In this work, we systematically study this problem and try to build a system to support query-by-sketch for two billion images. The raw edge pixel and Chamfer matching are selected as the basic representation and matching in this system, owning to the superior performance compared with other methods in extensive experiments. To get a more compact feature and a faster matching, a vector-like Chamfer feature pair is introduced, based on which the complex matching is reformulated as the crossover dot-product of feature pairs. Based on this new formulation, a compact shape code is developed to represent each image/sketch by projecting the Chamfer features to a linear subspace followed by a non-linear source coding. Finally, the multi-probe Kmedoids-LSH is leveraged to index database images, and the compact shape codes are further used for fast reranking. Extensive experiments show the effectiveness of the proposed features and algorithms in building such a sketch-based image search system."
"T. Furuya, Ryutarou Ohbuchi",053dcd22da268144bb99840aed71a02eb87e29e0,Ranking on Cross-Domain Manifold for Sketch-Based 3D Model Retrieval,2013 International Conference on Cyberworlds,2013.0,47,"Sketch-based 3D model retrieval algorithms compare a query, a line drawing sketch, and 3D models for similarity by rendering the 3D models into line drawing-like images. Still, retrieval accuracies of previous algorithms remained low, as sets of features, one of sketches and the other of rendered images of 3D models, are quite different, they are said to lie in different domains. A previous approach used semantic labels to establish correspondence between features across inter-domain gap. This approach, however, is prone to over learning if dataset is difficult to learn, i.e., if labeling is sparse and/or if only a small subset of each class is labeled. This paper proposes Cross-Domain Manifold Ranking (CDMR), an algorithm that effectively compares two sets of features that lie in different domains. The proposed algorithm first establishes feature subspace, or manifold, separately in each of the domains. Then, the two feature manifolds are interrelated to form a unified Cross-Domain Manifold (CDM) by using both feature similarity and semantic label correspondence across the domains. Given a query sketch, similarity ranks of 3D models are computed by diffusing relevance value from the sketch over the CDM. Experimental evaluation by using sketch-based 3D model retrieval benchmarks showed that the CDMR is more accurate than state-of-the-art sketch-based 3D model retrieval algorithms."
"J. M. Saavedra, B. Bustos",efdaf2b9c4b56a6366c8a2f92f2e47e6268933dd,Sketch-based image retrieval using keyshapes,Multimedia Tools and Applications,2013.0,40,"Although sketch based image retrieval (SBIR) is still a young research area, there are many applications capable of exploiting this retrieval paradigm, such as web searching and pattern detection. Moreover, nowadays drawing a simple sketch query turns very simple since touch screen based technology is being expanded. In this work, we propose a novel local approach for SBIR based on detecting simple shapes which are named keyshapes. Our method works as a local strategy, but instead of detecting keypoints, it detects keyshapes over which local descriptors are computed. Our proposal based on keyshapes allow us to represent the structure of the objects in an image which could be used to increase the effectiveness in the retrieval task. Indeed, our results show an improvement in the retrieval effectiveness with respect to the state of the art. Furthermore, we demonstrate that combining our keyshape approach with a Bag of Feature approach allows us to achieve significant improvement with respect to the effectiveness of the retrieval task."
"B. Li, Y. Lu, H. Johan",c22d658353d78b481b6f37d6fe06f742f572c349,Sketch-Based 3D Model Retrieval by Viewpoint Entropy-Based Adaptive View Clustering,3DOR@Eurographics,2013.0,38,"Searching for relevant 3D models based on hand-drawn sketches is both intuitive and important for many applications, such as sketch-based 3D modeling and recognition. We propose a sketch-based 3D model retrieval algorithm by utilizing viewpoint entropy-based adaptive view clustering and shape context matching. Different models have different visual complexities, thus there is no need to keep the same number of representative views for each model. Motivated by this, we propose to measure the visual complexity of a 3D model by utilizing viewpoint entropy distribution of a set of sample views and based on the complexity value, we can adaptively decide the number of representative views. Finally, we perform Fuzzy C-Means based view clustering on the sample views based on their viewpoint entropy values. We test our algorithm on two latest sketch-based 3D model retrieval benchmarks and compare it with other four state-of-the-art approaches. The results demonstrate the superior performance and advantages of our algorithm."
"Christophe Rigaud, J. Burie, J. Ogier, Dimosthenis Karatzas, Joost van de Weijer",799e17efaaa20e2a4d5762aeda2c53dc51686543,An Active Contour Model for Speech Balloon Detection in Comics,2013 12th International Conference on Document Analysis and Recognition,2013.0,36,"Comic books constitute an important cultural heritage asset in many countries. Digitization combined with subsequent comic book understanding would enable a variety of new applications, including content-based retrieval and content retargeting. Document understanding in this domain is challenging as comics are semi-structured documents, combining semantically important graphical and textual parts. Few studies have been done in this direction. In this work we detail a novel approach for closed and non-closed speech balloon localization in scanned comic book pages, an essential step towards a fully automatic comic book understanding. The approach is compared with existing methods for closed balloon localization found in the literature and results are presented."
"Kei Mochizuki, S. Nishide, H. Okuno, T. Ogata",5ae06a746cc635edcd5f7801b81c592609a6b6ed,Developmental Human-Robot Imitation Learning of Drawing with a Neuro Dynamical System,"2013 IEEE International Conference on Systems, Man, and Cybernetics",2013.0,30,"This paper mainly deals with robot developmental learning on drawing and discusses the influences of physical embodiment to the task. Humans are said to develop their drawing skills through five phases: 1) Scribbling, 2) Fortuitous Realism, 3) Failed Realism, 4) Intellectual Realism, 5) Visual Realism. We implement phases 1) and 3) into the humanoid robot NAO, holding a pen, using a neuro dynamical model, namely Multiple Timescales Recurrent Neural Network (MTRNN). For phase 1), we used random arm motion of the robot as body babbling to associate motor dynamics with pen position dynamics. For phase 3), we developed incremental imitation learning to imitate and develop the robot's drawing skill using basic shapes: circle, triangle, and rectangle. We confirmed two notable features from the experiment. First, the drawing was better performed for shapes requiring arm motions used in babbling. Second, performance of clockwise drawing of circle was good from beginning, which is a similar phenomenon that can be observed in human development. The results imply the capability of the model to create a developmental robot relating to human development."
"Christophe Rigaud, Dimosthenis Karatzas, Joost van de Weijer, J. Burie, J. Ogier",645619cd9b8c1a32ff74782d4f6fe96099c6f315,Automatic Text Localisation in Scanned Comic Books,VISAPP,2013.0,28,"Comic books constitute an important cultural heritage asset in many countries. Digitization combined with subsequent document understanding enable direct content-based search as opposed to metadata only search (e.g. album title or author name). Few studies have been done in this direction. In this work we detail a novel approach for the automatic text localization in scanned comics book pages, an essential step towards a fully automatic comics book understanding. We focus on speech text as it is semantically important and represents the majority of the text present in comics. The approach is compared with existing methods of text localization found in the literature and results are presented."
"W. Sun, J. Burie, J. Ogier, K. Kise",0b33bbda1a4e46e334e49e3b726b02f2bf42553f,Specific Comic Character Detection Using Local Feature Matching,2013 12th International Conference on Document Analysis and Recognition,2013.0,26,"Comic books are a kind of storytelling graphic publications mainly expressed by abstract line drawings. As a clue of story lines, comic characters play an important role in the story, and their detection is an essential part of comic book analysis. For this purpose, the task includes (1) locating characters in comics pages and (2) identifying them, which is called specific character detection. Corresponding to different scenes of comic books, one specific character can be represented by various expressions coupled with rotations, occlusions, and other perspective drawing effects, which challenge the detection. In this paper, we focus on stable features regarding the possible transformations and proposed a framework to detect them. Specifically, some discriminative features are selected as detectors for characterizing characters, on the basis of a training dataset. Based on the detectors, the drawings of the same characters in different scenes can be detected. The methodology has been experimented and validated on 6 titles of comics. Despite the terrific changes for different scenes, the proposed method achieved detection of 70% comic characters."
"Rui Hu, Stuart James, T. Wang, J. Collomosse",36657aaf5e657b891b5289286235ba54b80c5b84,Markov random fields for sketch based video retrieval,ICMR '13,2013.0,26,"We describe a new system for searching video databases using free-hand sketched queries. Our query sketches depict both object appearance and motion, and are annotated with keywords that indicate the semantic category of each object. We parse space-time volumes from video to form graph representation, which we match to sketches under a Markov Random Field (MRF) optimization. The MRF energy function is used to rank videos for relevance and contains unary, pairwise and higher-order potentials that reflect the colour, shape, motion and type of sketched objects. We evaluate performance over a dataset of 500 sports footage clips."
"Chao Ma, Xiaokang Yang, Chongyang Zhang, Xiang Ruan, Ming-Hsuan Yang",cf1b41ed8ac6f4f9b5b24a211893ac75fc2b0d08,Sketch Retrieval via Dense Stroke Features,BMVC,2013.0,26,"Sketch retrieval aims at retrieving most similar sketches from a large database based on one hand-drawn query. Successful retrieval hinges on an effective representation of sketch images and an efficient search method. In this paper, we propose a representation scheme which takes sketch strokes into account with local features, thereby facilitating efficient retrieval with codebooks. Stroke features are detected via densely sampled points on stroke lines from which local gradients are further enhanced and described by a quantized histogram of gradients. A codebook is organized in a hierarchical vocabulary tree, which maintains structural information of visual words and enables efficient retrieval in sub-linear time. Experimental results on three data sets demonstrate the merits of the proposed algorithm for effective and efficient sketch retrieval."
"Xueting Liu, X. Mao, X. Yang, Linling Zhang, T. Wong",1240e294c54b8db79aae28f9f28f9d219eb0cb22,Stereoscopizing cel animations,ACM Trans. Graph.,2013.0,25,"While hand-drawn cel animation is a world-wide popular form of art and entertainment, introducing stereoscopic effect into it remains difficult and costly, due to the lack of physical clues. In this paper, we propose a method to synthesize convincing stereoscopic cel animations from ordinary 2D inputs, without labor-intensive manual depth assignment nor 3D geometry reconstruction. It is mainly automatic due to the need of producing lengthy animation sequences, but with the option of allowing users to adjust or constrain all intermediate results. The system fits nicely into the existing production flow of cel animation. By utilizing the T-junction cue available in cartoons, we first infer the initial, but not reliable, ordering of regions. One of our major contributions is to resolve the temporal inconsistency of ordering by formulating it as a graph-cut problem. However, the resultant ordering remains insufficient for generating convincing stereoscopic effect, as ordering cannot be directly used for depth assignment due to its discontinuous nature. We further propose to synthesize the depth through an optimization process with the ordering formulated as constraints. This is our second major contribution. The optimized result is the spatiotemporally smooth depth for synthesizing stereoscopic effect. Our method has been evaluated on a wide range of cel animations and convincing stereoscopic effect is obtained in all cases."
"Yen-Liang Lin, Cheng-Yu Huang, Hao-Jen Wang, Winston H. Hsu",6b78beb8083742270d406ac687af2ec19b0eab9c,3D Sub-query Expansion for Improving Sketch-Based Multi-view Image Retrieval,2013 IEEE International Conference on Computer Vision,2013.0,23,"We propose a 3D sub-query expansion approach for boosting sketch-based multi-view image retrieval. The core idea of our method is to automatically convert two (guided) 2D sketches into an approximated 3D sketch model, and then generate multi-view sketches as expanded sub-queries to improve the retrieval performance. To learn the weights among synthesized views (sub-queries), we present a new multi-query feature to model the similarity between sub-queries and dataset images, and formulate it into a convex optimization problem. Our approach shows superior performance compared with the state-of-the-art approach on a public multi-view image dataset. Moreover, we also conduct sensitivity tests to analyze the parameters of our approach based on the gathered user sketches."
"Alex Gittens, P. Kambadur, Christos Boutsidis",041fef52913f0a6a6d48b1cd4781034b61f6dcb8,Approximate Spectral Clustering via Randomized Sketching,ArXiv,2013.0,19,"Spectral clustering is arguably one of the most important algorithms in data mining and machine intelligence; however, its computational complexity makes it a challenge to use it for large scale data analysis. Recently, several approximation algorithms for spectral clustering have been developed in order to alleviate the relevant costs, but theoretical results are lacking. In this paper, we present a novel approximation algorithm for spectral clustering with strong theoretical evidence of its performance. Our algorithm is based on approximating the eigenvectors of the Laplacian matrix using a randomized subspace iteration process, which might be of independent interest."
"W. Sun, K. Kise",1d86874bcff93552c08511666d96f11541800c9e,Detection of exact and similar partial copies for copyright protection of manga,International Journal on Document Analysis and Recognition (IJDAR),2013.0,18,"Manga, a kind of Japanese comic book, is an important genre in the realm of image publications requiring copyright protection. To copy manga, illegal users generally focus on certain interesting parts from which to make partial copies to apply in their own drawings. With respect to their sources, copying of manga can be divided into two types: (1) exact copies, which duplicate specific contents of manga, such as scanned manga publications (printed copies) and traced outlines of manga (hand-drawn copies), and (2) similar partial copies, which infringe the copyright of manga characters based on their features. In this paper, we propose applying content-based image retrieval methods to detect both exact and similar copies based on two kinds of regions of interest (ROIs): generic ROIs and face ROIs. The method is able not only to locate the partial copies from images with complex backgrounds, but also to report the corresponding copied parts of copyrighted manga pages for exact copy detection and copied manga characters for similar copy detection. The experimental results prove high performance of the proposed method for detecting printed partial copies. In addition, 85 % of hand-drawn and 77 % of similar partial copies were detected with relatively high precision using a database containing more than $$10{,}000$$ manga pages."
"M. Kuba, H. Mahmoud, A. Panholzer",72efe180dcfb6ad46711dc488057a7f7c5fbf005,Analysis of a generalized Friedman's urn with multiple drawings,Discret. Appl. Math.,2013.0,16,"We study a generalized Friedman's urn model with multiple drawings of white and blue balls. After a drawing, the replacement follows a policy of opposite reinforcement. We give the exact expected value and variance of the number of white balls after a number of draws, and determine the structure of the moments. Moreover, we obtain a strong law of large numbers, and a central limit theorem for the number of white balls. Interestingly, the central limit theorem is obtained combinatorially via the method of moments and probabilistically via martingales. We briefly discuss the merits of each approach. The connection to a few other related urn models is briefly sketched."
"T. Sawada, M. Toyoura, Xiaoyang Mao",7889728727075887a5dfaae077313b1ebd4f702b,Film Comic Generation with Eye Tracking,MMM,2013.0,15,"Automatic generation of film comic requires solving several challenging problems such as selecting important frames well conveying the whole story, trimming the frames to fit the shape of panels without corrupting the composition of original image and arranging visually pleasing speech balloons without hiding important objects in the panel. We propose a novel approach to the automatic generation of film comic. The key idea is to aggregate eye-tracking data and image features into a computational map, called iMap, for quantitatively measuring the importance of frames in terms of story content and user attention. The transition of iMap in time sequences provides the solution to frame selection. Word balloon arrangement and image trimming are realized as the results of optimizing the energy functions derived from the iMap."
"Luyuan Li, Yongtao Wang, Zhi Tang, Dong Liu",00a153d137783a3814f0f5b224d4dcfdfda72149,Comic image understanding based on polygon detection,Electronic Imaging,2013.0,13,"Comic image understanding aims to automatically decompose scanned comic page images into storyboards and then identify the reading order of them, which is the key technique to produce digital comic documents that are suitable for reading on mobile devices. In this paper, we propose a novel comic image understanding method based on polygon detection. First, we segment a comic page images into storyboards by finding the polygonal enclosing box of each storyboard. Then, each storyboard can be represented by a polygon, and the reading order of them is determined by analyzing the relative geometric relationship between each pair of polygons. The proposed method is tested on 2000 comic images from ten printed comic series, and the experimental results demonstrate that it works well on different types of comic images."
"Debajyoti Mondal, Rahnuma Islam Nishat, Sudip Biswas, Md. Saidur Rahman",b3a74ebfebcd48eaa9ce4d620b9ea68eb6e58043,Minimum-segment convex drawings of 3-connected cubic plane graphs,J. Comb. Optim.,2013.0,13,"A convex drawing of a plane graph G is a plane drawing of G, where each vertex is drawn as a point, each edge is drawn as a straight line segment and each face is drawn as a convex polygon. A maximal segment is a drawing of a maximal set of edges that form a straight line segment. A minimum-segment convex drawing of G is a convex drawing of G where the number of maximal segments is the minimum among all possible convex drawings of G. In this paper, we present a linear-time algorithm to obtain a minimum-segment convex drawing Γ of a 3-connected cubic plane graph G of n vertices, where the drawing is not a grid drawing. We also give a linear-time algorithm to obtain a convex grid drawing of G on an $(\frac{n}{2}+1)\times(\frac {n}{2}+1)$ grid with at most sn+1 maximal segments, where $s_{n}=\frac{n}{2}+3$ is the lower bound on the number of maximal segments in a convex drawing of G."
"P. Das, S. Panda, D. K. Pratihar",d1c89351c1c0fbda8cb789cc6cf8949e831eea99,Modification of Initial Blank Shape to Minimize Earing in Deep Drawing Process,,2013.0,13,"Earing is a common defect that occurs in deep drawing process due to non-uniform material properties within the plane of the sheet that is planar anisotropy. In this study, efforts were made to study the earing problem in deep drawing of cylindrical cups by finite element modeling using HYPERWORKS6.10. Interstitial Free (IF) steel sheet of 1.0 mm thickness has been considered as it has wide application in fabricating critical automobile components. Mechanical properties of IF steel along with tool design parameters were incorporated in the finite element modeling of deep drawing process.Significant earing was observed at rolling and transverse direction in the deformed cup from a circular blank. The cup heights were measured at several points with respect to the rolling direction of the sheet. To minimize earing, flow of material was observed at various steps during the simulation and accordingly initial blank shape had been modified. Modified blanks showed significant reduction in earing and improvement in thickness distribution in simulation."
G. Kutyniok,662f03a1d73da55e2f7d976e3e786f8d93aa5974,Clustered Sparsity and Separation of Cartoon and Texture,SIAM J. Imaging Sci.,2013.0,13,"Natural images are typically a composition of cartoon and texture structures. One common task is to separate such an image into two single images, one containing the cartoon part and the other containing the texture part. Recently, a powerful class of algorithms using sparse approximation and $\ell_1$ minimization has been introduced to resolve this problem, and numerous inspiring empirical results have already been obtained. In this paper we provide a theoretical study of the separation of a combination of cartoon and texture structures in a continuum model situation using this class of algorithms. The methodology we consider expands the image in a combined dictionary consisting of a curvelet frame and a Gabor frame and minimizes the $\ell_1$ norm. Sparse approximation properties then force the cartoon components into the curvelet coefficients and the texture components into the Gabor coefficients, thereby separating the image. Utilizing the fact that the coefficients are clustered geometrically, we prov..."
"Dong Liu, Yongtao Wang, Zhi Tang, Luyuan Li, L. Gao",3f232d562440e3b65cf635f72895b102bbd4ead5,Automatic comic page image understanding based on edge segment analysis,Electronic Imaging,2013.0,9,"Comic page image understanding aims to analyse the layout of the comic page images by detecting the storyboards and identifying the reading order automatically. It is the key technique to produce the digital comic documents suitable for reading on mobile devices. In this paper, we propose a novel comic page image understanding method based on edge segment analysis. First, we propose an efficient edge point chaining method to extract Canny edge segments (i.e., contiguous chains of Canny edge points) from the input comic page image; second, we propose a top-down scheme to detect line segments within each obtained edge segment; third, we develop a novel method to detect the storyboards by selecting the border lines and further identify the reading order of these storyboards. The proposed method is performed on a data set consisting of 2000 comic page images from ten printed comic series. The experimental results demonstrate that the proposed method achieves satisfactory results on different comics and outperforms the existing methods."
"Filter S. Ranjini, M. Sundaresan",338e40f148378e8bb4a97e07ed621165189a0432,Extraction and Recognition of Text From Digital English Comic Image Using Median,,2013.0,9,"Text extraction from image is one of the complicated areas in digital image processing. Text characters entrenched in image represents a rich source of information for text retrieval application. It is a complex process to detect and recognize the text from comic image due to their various size, gray scale values, complex backgrounds and different styles of font. Text extraction process from comic image helps to preserve the text and formatting during conversion process and provide high quality of text from the printed document. Automatic text extraction from comic images receives a growing attention because of prospective application in image retrieval. In existing work, Japanese text is extracted vertically from Manga Comic Image using Blob extraction functions. At the same time, text is extracted from multiple constraints using optical character recognition (OCR) and make translation of Japanese language of Manga into some other languages in conventional way to share the enjoyment of reading Manga through the Internet. This paper talks about English text extraction from blob comic image using various methods."
"Zhijun Song, J. Yu, Changle Zhou, Meng Wang",69a8160298a5580b444591cf3f7fee47ba23cafb,Automatic cartoon matching in computer-assisted animation production,Neurocomputing,2013.0,8,"Abstract Traditional cartoon animation painting has always been a tedious job. In order to improve the efficiency of the process, the development of an automatic cartoon generation system including automatic inbetweening and coloring is required. Automatic matching of cartoon characters in key frames is the prerequisite for the system. This paper provides a novel matching algorithm with iterative maximum a posteriori (MAP) estimation and the maximum likelihood (ML) estimation. Specifically, this algorithm formulate cartoon matching as a many-to-many labeling problem. To refine the results of matching, an optimization approach is adopted to alternatively conduct the MAP estimation and the ML estimation. Besides, we construct the correspondence by using the local shape descriptor, and the rotation and scale invariance in matching can be achieved. The experimental results on real-world datasets demonstrate the effectiveness of the proposed methods for automatic cartoon matching."
"Надежда Львовна Щеголева, Георгий Александрович Кухарев, K. Buda",d74530c3d42021a8c74edd757bf519534ad15ce6,Sketch generation from photo to create test databases,,2013.0,8,"Article proposed novel method of automatic sketch synthesis, that can be used for creating test databases and sketch recognition tasks research and retrieval of corresponding photo. These methods were applied to two popular benchmark face databases. It was shown that for recognition of sketches very simple systems can be used. Slowa kluczowe: portrety pamieciowe (szkic), generowanie szkicow, porownanie szkicow z portretami fotograficznymi."
"Herman Tolle, K. Arai",2872406d1224c193a74d837e624c33fd799fb2d3,Manga content extraction method for automatic mobile comic content creation,2013 International Conference on Advanced Computer Science and Information Systems (ICACSIS),2013.0,8,"Creating a digital Manga comic for mobile devices is chalenging because of the limitation of device's screen size and time consuming of the process. In this paper, we proposed an efficient method for automatically creating mobile content of digital Manga comic from scanned of printed digital comic by extracting comic frame, comic balloon and Japanese character within a Manga comic then recompose it a new mobile content using ComicXML to store comic frame content information. Experimental results on Manga content extraction have 81.6% accuracy of non-flat comic page frame extraction, 100% accuracy of comic balloon detection, and about 93.75% accuracy of Japanese character text extraction."
"H. Yu, J. Zhang",126e7281a76d28e4419d4a08ad59e95e794f37d5,Mean value coordinates–based caricature and expression synthesis,Signal Image Video Process.,2013.0,7,"We present a novel method for caricature synthesis based on mean value coordinates (MVC). Our method can be applied to any single frontal face image to learn a specified caricature face pair for frontal and 3D caricature synthesis. This technique only requires one or a small number of exemplar pairs and a natural frontal face image training set, while the system can transfer the style of the exemplar pair across individuals. Further exaggeration can be fulfilled in a controllable way. Our method is further applied to facial expression transfer, interpolation, and exaggeration, which are applications of expression editing. Additionally, we have extended our approach to 3D caricature synthesis based on the 3D version of MVC. With experiments we demonstrate that the transferred expressions are credible and the resulting caricatures can be characterized and recognized."
"Hossein Nejati, L. Zhang, T. Sim",37fbb84ab6ac165660c870d34eeb53f9c6f1b89c,Eyewitness Face Sketch Recognition Based on Two-Step Bias Modeling,CAIP,2013.0,7,"Over 30 years of psychological studies on eyewitness testimonies procedures show severe flaws including ignoring human face perception biases that render these procedures unreliable. In addition, recent studies show that current automatic face sketch recognition methods are only tested on over simplified databases, and therefore cannot address the real cases. We here present a face sketch recognition method based on non-artistic sketches in which we firstly estimate and remove personal face perception biases from face sketches, and then recognize them based on a psychologically inspired matching technique. In addition, we use a general-specific modeling that only needs a few training samples for each individual for an accurate and robust performance. In our experiments, we tested accuracy and robustness against previous works, and the effect of number of training samples on the accuracy of our method."
"W. Chu, Chia-Hsiang Yu",32c6e79e33b9870a457e11aa9909fba525b57596,Optimized speech balloon placement for automatic comics generation,IMMPD '13,2013.0,5,"Comic presentation for videos has attracted more and more attention in recent years. This work deeply discusses one important component, i.e., speech balloon placement, that was depreciated and was done by heuristic approaches before. According to number of words and emotion embedded in subtitles, and audio energy corresponding to the targeted frame, speech balloons of various sizes and appropriate shapes are generated. How to locate speech balloons in panels at the same comic page is then formulated as an optimization problem. The objective function integrates an intra-panel cost with an inter-panel cost, where the former is designed to avoid occluding important regions of frames and to direct viewer's gaze, and the latter is designed to build the reading tempo. The experimental results show that the proposed method facilitates higher readability, higher content coverage, and better speech balloon placement."
"Yuto Nara, W. Fujimura, Yukua Koide, Genki Kunitomi, Akihiko Shirai",77d4eb86c705f722d9785d7bf6364ef1e6c2f142,KinEmotion: context controllable emotional motion analysis method for interactive cartoon generator,SIGGRAPH '13,2013.0,5,"Recently, cartoon contents are applying to various media like interactive systems. In a near future, the desire of user may become to immerse their live experience into a cartoon content deeply. In automatic cartoon generation environment using NUI (Natural User Interface) like Kinect, we can comprehend the importance of linking emotion expression with user's posture. Its story and impression are uncontrollable, if the system could not choose a suitable effect for each user motion. The system should have story driven method to protect the interpretation of the world, even if there is its original piece of manga."
"V. Simões, J. Coër, H. Laurent, M. Oliveira, J. Alves, P. Manach, L. Menezes",5d282b0e8214ed7163eb30defb153a3859efe215,Sensitivity Analysis of Process Parameters in the Drawing and Ironing Processes,,2013.0,4,"Deep drawing is one of the most important operations used in sheet metal forming. Within this, forming of cylindrical cup is one of the most widely studied deep drawing processes since it allows analysing the effect of different process parameters in phenomena such as earing, springback and ironing. In fact, during the deep drawing of a cylindrical cup the blank thickness gradually increases as the blank outer diameter is reduced to the die inner diameter, resulting in a thickness increase from a point near the bottom radius until the maximum value at the top of the cup. Therefore, if the gap between the punch and the die is not sufficiently large to allow the blank material to flow, ironing of the cup wall will occur. The ironing process typically imposes high contact forces, normal to the surface of the punch and the die, which can lead to the occurrence of galling, particularly for aluminium alloys. In this work an experimental device, adopted in previous studies, was used to analyse the influence of the lubricant conditions in the deep drawing of a cylindrical cup. The study considers an AA5754-O aluminium alloy blank with a diameter of 60 mm, which is fully deep drawn with a 33 mm diameter punch. Due to the forming conditions, the cup is deep drawn and ironing of the cup wall also occurs. The experimental tests were performed considering different amounts of lubricant in the blank surfaces in the contact with the die and with the blank-holder in order to better understand the influence of these tools on the process. The experimental study was complemented with numerical simulations, exploring the conditions induced by the ironing operation, quite challenging for the numerical simulation of the process using the finite element method. Besides the influence of the contact with friction conditions in the forming process (i.e. punch force evolution, thickness distribution along the cup wall and contact pressure), the influence of the die shoulder and inner radius were also analysed."
"J. He, Shanghe Wang, Yi Zhang, Jiawan Zhang",1daa38969e87447fd1ad0c9ae6073446c214497e,A computational fresco sketch generation framework,2013 IEEE International Conference on Multimedia and Expo (ICME),2013.0,3,"As a famous cultural wealth, the sketch of fresco is one of the most important art expression forms in the World Heritage. To avoid the damage of natural and human factors, painters can only use photos and videos to depict sketch in most world culture heritage sites, otherwise real frescos. Therefore, a computational method for extracting sketch is helpful and meaningful in sketch copying and researching area. However, existing approaches with the incomplete fresco are not enough to deal with the challenge of sketch extraction. In this paper, we proposes a framework to generate sketch of fresco with frescos as input. To reduce noise and refine detail lines, we adopt hierarchical segmentation technology to extract sketches of different regions respectively, and splice those sketches into an integrated sketch. For replacing the missing content and getting a complete sketch, we provide recommendations from a database of many existing fresco sketches elements for users to select. At last, users can adjust sketch based on vectorization to achieve optimization. Our framework can be used for artists or learners to study painting sketch images and research fresco art. The experimental results demonstrate the effectiveness of our framework."
"Cuixia Ma, Yongjin Liu, Qiufang Fu, Ye Liu, X. Fu, Guozhong Dai, Hongan Wang",13a70a8548f8fbf13bb63141ca2913c118e2c3b1,"Video sketch summarization, interaction and cognition analysis",,2013.0,3,"Video, as one typical digital media, is important for message communication. For efficient video content visualization and natural interaction such as video browsing and searching, we propose a sketch-based video summarization with fluent sketch interaction in this paper. Firstly, we present the sketch representation for video semantics, which takes the advantages of abstractness and generality of sketches. The concept of semantic sketch is proposed, which supports annotating video contents with sketches. Furthermore, an optimized layout algorithm for sketch summarization is presented. Secondly, we present the interaction techniques for sketch summarization and natural sketch gesture operations. From the viewpoint of cognitive psychology, we analyze the sketch representation, as well as the effects and relations of cognitive units in sketch interaction. Finally, user studies show that the proposed sketch summarization and sketch interaction improve user efficiency in terms of acquiring the main video content and reduce users’ cognitive load."
"Sourav Pramanik, D. Bhattacharjee",6fa565c94d391314961d6e7b25a75692061cdf93,An Approach: Modality Reduction and Face-Sketch Recognition,ArXiv,2013.0,2,"To recognize face sketch through face photo databas e is a challenging task for today’s researchers. Be cause face photo images in training set and face sketch images in testing s et have different modality. Difference between two face photos of differen pe rson is smaller than the difference between same pe rson in a face photo and face sketched. In this pap er, for reduction of th modality between face photo and face sketch we firs t bring face photo and face sketch images in a new dimension using 2D Discrete Haar wavelet transform with scale 3 followed by a n egative approach. After that, extract features from transformed images using Principal Component Analysis (PCA). Thereafter, we use SVM classifier and K classification. Our propos ed method is experimentally verified by its robustn ess against faces that are captured in a good lighting condition and in a frontal pose. The exper iment has been conducted with 100 male and female face images as training set and 100 male and female face s ketch images as testing set collected from CUHK tra ining and testing cropped photos and CUHK training and testing cropped sketches."
T. Biedl,b0e00e012d22c528e0908c4783d8b6f5e0ff9030,Transforming planar graph drawings while maintaining height,ArXiv,2013.0,1,"There are numerous styles of planar graph drawings, notably straight-line drawings, poly-line drawings, orthogonal graph drawings and visibility representations. In this note, we show that many of these drawings can be transformed from one style to another without changing the height of the drawing. We then give some applications of these transformations."
"Amit R.Sharma, Prakash.R.Devale Prakash.R.Devale",7a8c2743db1749c2d9f16f62ee633574c1176e34,Face Photo-Sketch Synthesis and Recognition,,2012.0,513,"Today in Modern Society Face Recognition has gained much attention in the field of network multimedia access. After the 9/11 tragedy in India, the need for technologies for identification, detection and recognition of suspects has increased. One of the most common biometric recognition techniques is face recognition since face is the convenient way used by the people to identify each other. In this paper we are going to study a method for representing face which is based on the features which uses geometric relationship among the facial features like mouth, nose and eyes .Feature based face representation is done by independently matching templates of three facial regions i.e eyes, mouth and nose .Principal Component Analysis method which is also called Eigen faces is appearance based technique used widely for the dimensionality reduction and recorded a greater performance in face recognition. Here we are going to study about PCA followed by Feed Forward Neural Network called PCA-NN."
"Shenlong Wang, Lei Zhang, Yan Liang, Q. Pan",0259e87451932948e98486903aac6f2d0aa5b5c3,Semi-coupled dictionary learning with applications to image super-resolution and photo-sketch synthesis,2012 IEEE Conference on Computer Vision and Pattern Recognition,2012.0,502,"In various computer vision applications, often we need to convert an image in one style into another style for better visualization, interpretation and recognition; for examples, up-convert a low resolution image to a high resolution one, and convert a face sketch into a photo for matching, etc. A semi-coupled dictionary learning (SCDL) model is proposed in this paper to solve such cross-style image synthesis problems. Under SCDL, a pair of dictionaries and a mapping function will be simultaneously learned. The dictionary pair can well characterize the structural domains of the two styles of images, while the mapping function can reveal the intrinsic relationship between the two styles' domains. In SCDL, the two dictionaries will not be fully coupled, and hence much flexibility can be given to the mapping function for an accurate conversion across styles. Moreover, clustering and image nonlocal redundancy are introduced to enhance the robustness of SCDL. The proposed SCDL model is applied to image super-resolution and photo-sketch synthesis, and the experimental results validated its generality and effectiveness in cross-style image synthesis."
"M. Eitz, Ronald Richter, T. Boubekeur, Kristian Hildebrand, M. Alexa",f3dda9be7880aa0ee66f73daaca9bda30bb0974b,Sketch-based shape retrieval,ACM Trans. Graph.,2012.0,278,"We develop a system for 3D object retrieval based on sketched feature lines as input. For objective evaluation, we collect a large number of query sketches from human users that are related to an existing data base of objects. The sketches turn out to be generally quite abstract with large local and global deviations from the original shape. Based on this observation, we decide to use a bag-of-features approach over computer generated line drawings of the objects. We develop a targeted feature transform based on Gabor filters for this system. We can show objectively that this transform is better suited than other approaches from the literature developed for similar tasks. Moreover, we demonstrate how to optimize the parameters of our, as well as other approaches, based on the gathered sketches. In the resulting comparison, our approach is significantly better than any other system described so far."
"Jun Yu, M. Wang, D. Tao",dabed28a5cb5aed6e6fd17bbf9bd071a99ef8b1b,Semisupervised Multiview Distance Metric Learning for Cartoon Synthesis,IEEE Transactions on Image Processing,2012.0,215,"In image processing, cartoon character classification, retrieval, and synthesis are critical, so that cartoonists can effectively and efficiently make cartoons by reusing existing cartoon data. To successfully achieve these tasks, it is essential to extract visual features that comprehensively represent cartoon characters and to construct an accurate distance metric to precisely measure the dissimilarities between cartoon characters. In this paper, we introduce three visual features, color histogram, shape context, and skeleton, to characterize the color, shape, and action, respectively, of a cartoon character. These three features are complementary to each other, and each feature set is regarded as a single view. However, it is improper to concatenate these three features into a long vector, because they have different physical properties, and simply concatenating them into a high-dimensional feature vector will suffer from the so-called curse of dimensionality. Hence, we propose a semisupervised multiview distance metric learning (SSM-DML). SSM-DML learns the multiview distance metrics from multiple feature sets and from the labels of unlabeled cartoon characters simultaneously, under the umbrella of graph-based semisupervised learning. SSM-DML discovers complementary characteristics of different feature sets through an alternating optimization-based iterative algorithm. Therefore, SSM-DML can simultaneously accomplish cartoon character classification and dissimilarity measurement. On the basis of SSM-DML, we develop a novel system that composes the modules of multiview cartoon character classification, multiview graph-based cartoon synthesis, and multiview retrieval-based cartoon synthesis. Experimental evaluations based on the three modules suggest the effectiveness of SSM-DML in cartoon applications."
"Xinbo Gao, N. Wang, D. Tao, Xuelong Li",bc955487a0b8d2fae3f2f44320389a12ae28f0f5,Face Sketch–Photo Synthesis and Retrieval Using Sparse Representation,IEEE Transactions on Circuits and Systems for Video Technology,2012.0,141,"Sketch-photo synthesis plays an important role in sketch-based face photo retrieval and photo-based face sketch retrieval systems. In this paper, we propose an automatic sketch-photo synthesis and retrieval algorithm based on sparse representation. The proposed sketch-photo synthesis method works at patch level and is composed of two steps: sparse neighbor selection (SNS) for an initial estimate of the pseudoimage (pseudosketch or pseudophoto) and sparse-representation-based enhancement (SRE) for further improving the quality of the synthesized image. SNS can find closely related neighbors adaptively and then generate an initial estimate for the pseudoimage. In SRE, a coupled sparse representation model is first constructed to learn the mapping between sketch patches and photo patches, and a patch-derivative-based sparse representation method is subsequently applied to enhance the quality of the synthesized photos and sketches. Finally, four retrieval modes, namely, sketch-based, photo-based, pseudosketch-based, and pseudophoto-based retrieval are proposed, and a retrieval algorithm is developed by using sparse representation. Extensive experimental results illustrate the effectiveness of the proposed face sketch-photo synthesis and retrieval algorithms."
"Hao Zhou, Zhanghui Kuang, K. K. Wong",3813a0f53371355f559b3843ab59af96264d2840,Markov Weight Fields for face sketch synthesis,2012 IEEE Conference on Computer Vision and Pattern Recognition,2012.0,124,"Great progress has been made in face sketch synthesis in recent years. State-of-the-art methods commonly apply a Markov Random Fields (MRF) model to select local sketch patches from a set of training data. Such methods, however, have two major drawbacks. Firstly, the MRF model used cannot synthesize new sketch patches. Secondly, the optimization problem in solving the MRF is NP-hard. In this paper, we propose a novel Markov Weight Fields (MWF) model that is capable of synthesizing new sketch patches. We formulate our model into a convex quadratic programming (QP) problem to which the optimal solution is guaranteed. Based on the Markov property of our model, we further propose a cascade decomposition method (CDM) for solving such a large scale QP problem efficiently. Experimental results on the CUHK face sketch database and celebrity photos show that our model outperforms the common MRF model used in other state-of-the-art methods."
"Jun Yu, D. Liu, D. Tao, S. H. Soon",bfdf04b9dcf303fae895d874d8a5f2da5e085f7a,On Combining Multiple Features for Cartoon Character Retrieval and Clip Synthesis,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",2012.0,105,"How do we retrieve cartoon characters accurately? Or how to synthesize new cartoon clips smoothly and efficiently from the cartoon library? Both questions are important for animators and cartoon enthusiasts to design and create new cartoons by utilizing existing cartoon materials. The first key issue to answer those questions is to find a proper representation that describes the cartoon character effectively. In this paper, we consider multiple features from different views, i.e., color histogram, Hausdorff edge feature, and skeleton feature, to represent cartoon characters with different colors, shapes, and gestures. Each visual feature reflects a unique characteristic of a cartoon character, and they are complementary to each other for retrieval and synthesis. However, how to combine the three visual features is the second key issue of our application. By simply concatenating them into a long vector, it will end up with the so-called “curse of dimensionality,” let alone their heterogeneity embedded in different visual feature spaces. Here, we introduce a semisupervised multiview subspace learning (semi-MSL) algorithm, to encode different features in a unified space. Specifically, under the patch alignment framework, semi-MSL uses the discriminative information from labeled cartoon characters in the construction of local patches where the manifold structure revealed by unlabeled cartoon characters is utilized to capture the geometric distribution. The experimental evaluations based on both cartoon character retrieval and clip synthesis demonstrate the effectiveness of the proposed method for cartoon application. Moreover, additional results of content-based image retrieval on benchmark data suggest the generality of semi-MSL for other applications."
"H. Purchase, Christopher Pilcher, B. Plimmer",fa91327491fbd5b87cf3c52470c75242587845bd,"Graph Drawing Aesthetics—Created by Users, Not Algorithms",IEEE Transactions on Visualization and Computer Graphics,2012.0,63,"Prior empirical work on layout aesthetics for graph drawing algorithms has concentrated on the interpretation of existing graph drawings. We report on experiments which focus on the creation and layout of graph drawings: participants were asked to draw graphs based on adjacency lists, and to lay them out ""nicely.” Two interaction methods were used for creating the drawings: a sketch interface which allows for easy, natural hand movements, and a formal point-and-click interface similar to a typical graph editing system. We find, in common with many other studies, that removing edge crossings is the most significant aesthetic, but also discover that aligning nodes and edges to an underlying grid is important. We observe that the aesthetics favored by participants during creation of a graph drawing are often not evident in the final product and that the participants did not make a clear distinction between the processes of creation and layout. Our results suggest that graph drawing systems should integrate automatic layout with the user's manual editing process, and provide facilities to support grid-based graph creation."
"A. Vishtal, E. Retulainen",30007422f3008f4f80ac1fa2f83251e1a66e9e12,DEEP-DRAWING OF PAPER AND PAPERBOARD: THE ROLE OF MATERIAL PROPERTIES,,2012.0,61,"Fibre-based packaging materials are widely utilized all over the world. They have several important advantages in comparison with fossil-based packaging: biodegradability, recyclability, and renewability. However, fibre-based packaging cannot fully compete with plastic in its barrier properties. Also there are limitations regarding its shapes due to poorer formability. The deep-drawing forming process can be used for the production of advanced three-dimensional shapes from paper-based materials. Formability and related characteristics are essential for deep-drawing of paper-based materials. This paper aims to give an overview of the deep-drawing of paper-based materials with the emphasis on the experienced deformations, on the role of mechanical properties of materials in deep-drawing, and on the typical defects found in the shapes after the forming. Additionally, strategies are proposed to help mitigate common problems in deep-drawing."
"Rong Zhou, Liuli Chen, Liqing Zhang",cd9d6f8d26cdf214827023ef30483c7b04c2a72c,Sketch-based image retrieval on a large scale database,ACM Multimedia,2012.0,54,"The paper presents a simple and effective sketch-based algorithm for large scale image retrieval. One of the main challenges in image retrieval is to localize a region in an image which would be matched with the query image in contour. To tackle this problem, we use the human perception mechanism to identify two types of regions in one image: the first type of region (the main region) is defined by a weighted center of image features, suggesting that we could retrieve objects in images regardless of their sizes and positions. The second type of region, called region of interests (ROI), is to find the most salient part of an image, and is helpful to retrieve images with objects similar to the query in a complicated scene. So using the two types of regions as candidate regions for feature extraction, our algorithm could increase the retrieval rate dramatically. Besides, to accelerate the retrieval speed, we first extract orientation features and then organize them in a hierarchal way to generate global-to-local features. Based on this characteristic, a hierarchical database index structure could be built which makes it possible to retrieve images on a very large scale image database online. Finally a real-time image retrieval system on 4.5 million database is developed to verify the proposed algorithm. The experiment results show excellent retrieval performance of the proposed algorithm and comparisons with other algorithms are also given."
"Gioacchino Noris, D. Sýkora, A. Shamir, Stelian Coros, B. Whited, M. Simmons, Alexander Sorkine-Hornung, M. Gross, R. Sumner",1b5e9cf9a1a2ecb7eb78f3c4011cbfa14edc1e92,Smart Scribbles for Sketch Segmentation,Comput. Graph. Forum,2012.0,54,"We present ‘Smart Scribbles’—a new scribble‐based interface for user‐guided segmentation of digital sketchy drawings. In contrast to previous approaches based on simple selection strategies, Smart Scribbles exploits richer geometric and temporal information, resulting in a more intuitive segmentation interface. We introduce a novel energy minimization formulation in which both geometric and temporal information from digital input devices is used to define stroke‐to‐stroke and scribble‐to‐stroke relationships. Although the minimization of this energy is, in general, an NP‐hard problem, we use a simple heuristic that leads to a good approximation and permits an interactive system able to produce accurate labellings even for cluttered sketchy drawings. We demonstrate the power of our technique in several practical scenarios such as sketch editing, as‐rigid‐as‐possible deformation and registration, and on‐the‐fly labelling based on pre‐classified guidelines."
"B. Li, T. Schreck, A. Godil, M. Alexa, T. Boubekeur, B. Bustos, J. Chen, M. Eitz, T. Furuya, Kristian Hildebrand, S. Huang, H. Johan, Arjan Kuijper, Ryutarou Ohbuchi, Ronald Richter, J. M. Saavedra, Maximilian Scherer, Tomohiro Yanagimachi, Gangjoon Yoon, S. Yoon",685a4a70f9c751bf30d721550cf2820688b01758,SHREC'12 Track: Sketch-Based 3D Shape Retrieval,3DOR@Eurographics,2012.0,52,"Sketch-based 3D shape retrieval has become an important research topic in content-based 3D object retrieval. The aim of this track is to measure and compare the performance of sketch-based 3D shape retrieval methods implemented by different participants over the world. The track is based on a new sketch-based 3D shape benchmark, which contains two types of sketch queries and two versions of target 3D models. In this track, 7 runs have been submitted by 5 groups and their retrieval accuracies were evaluated using 7 commonly used retrieval performance metrics. We hope that the benchmark, its corresponding evaluation code, and the comparative evaluation results of the state-of-the-art sketch-based 3D model retrieval algorithms will contribute to the progress of this research direction for the 3D model retrieval community."
"Hamed Kiani Galoogahi, T. Sim",12662b2cc9dab4cb1827915125abbe76decc1a8f,Inter-modality Face Sketch Recognition,2012 IEEE International Conference on Multimedia and Expo,2012.0,52,"Automatic face sketch recognition plays an important role in law enforcement. Recently, various methods have been proposed to address the problem of face sketch recognition by matching face photos and sketches, which are of different modalities. However, their performance is strongly affected by the modality difference between sketches and photos. In this paper, we propose a new face descriptor based on gradient orientations to reduce the modality difference in feature extraction stage, called Histogram of Averaged Oriented Gradients (HAOG). Experiments on CUFS database show that the new descriptor outperforms the state-of-the-art approaches."
"Anh Khoi Ngo Ho, J. Burie, J. Ogier",7b85a11f565696a035da0b56e4df2101b8c49991,Panel and Speech Balloon Extraction from Comic Books,2012 10th IAPR International Workshop on Document Analysis Systems,2012.0,50,"Comic books represent an important cultural heritage in many countries. However, few researches have been done in order to analyse the content of comics such as panels, speech balloons or characters. At first glance, the structure of a comic page may appear easy to determine. In practice, the configuration of the page, the size and the shape of the panels can be different from one page to the next. Moreover, authors often draw extended contents (speech balloon or comic art) that overlap two panels or more. In some situations, the panel extraction can become a real challenge. Speech balloons are other important elements of comics. Full text indexing is only possible if the text can be extracted. However the text is usually embedded among graphic elements. Moreover, unlike newspapers, the text layout in speech balloons can be irregular. Classic text extraction method can fail. We propose, in this paper, a method based on region growing and mathematical morphology to extract automatically the panels of a comic page and a method to detect speech balloons. Our approach is compared with other methods find in the literature. Results are presented and discussed."
"Zhenbang Sun, C. Wang, Liqing Zhang, Lei Zhang",6ecf4741af00fe3aa5458b436a0806a33e910785,Free Hand-Drawn Sketch Segmentation,ECCV,2012.0,48,"In this paper, we study the problem of how to segment a freehand sketch at the object level. By carefully considering the basic principles of human perceptual organization, a real-time solution is presented to automatically segment a user's sketch during his/her drawing. First, a graph-based sketch segmentation algorithm is proposed to segment a cluttered sketch into multiple parts based on the factor of proximity. Then, to improve the ability of detecting semantically meaningful objects, a semantic-based approach is introduced to simulate the past experience in the perceptual system by leveraging a web-scale clipart database. Finally, other important factors learnt from past experience, such as similarity, symmetry, direction, and closure, are also taken into account to make the approach more robust and practical. The proposed sketch segmentation framework has ability to handle complex sketches with overlapped objects. Extensive experimental results show the effectiveness of the proposed framework and algorithms."
"B. Li, H. Johan",343e9e93d749dbc571e2e881c2fd507f0ad78653,Sketch-based 3D model retrieval by incorporating 2D-3D alignment,Multimedia Tools and Applications,2012.0,44,"Sketch-based 3D model retrieval is very important for applications such as 3D modeling and recognition. In this paper, a sketch-based retrieval algorithm is proposed based on a 3D model feature named View Context and 2D relative shape context matching. To enhance the accuracy of 2D sketch-3D model correspondence as well as the retrieval performance, we propose to align a 3D model with a query 2D sketch before measuring their distance. First, we efficiently select some candidate views from a set of densely sampled views of the 3D model to align the sketch and the model based on their View Context similarities. Then, we compute the more accurate relative shape context distance between the sketch and every candidate view, and regard the minimum one as the sketch-model distance. To speed up retrieval, we precompute the View Context and relative shape context features of the sample views of all the 3D models in the database. Comparative and evaluative experiments based on hand-drawn and standard line drawing sketches demonstrate the effectiveness and robustness of our approach and it significantly outperforms several latest sketch-based retrieval algorithms."
"Konstantinos Bozas, E. Izquierdo",3b8a5be5508f809a2d68a78d21cbf1690db57d5c,Large Scale Sketch Based Image Retrieval Using Patch Hashing,ISVC,2012.0,43,"This paper introduces a hashing based framework that facilitates sketch based image retrieval in large image databases. Instead of exporting a single visual descriptor for every image, an overlapping spatial grid is utilised to generate a pool of patches. We rank similarities between a hand drawn sketch and the natural images in a database through a voting process where near duplicate in terms of shape and structure patches arbitrate for the result. Patch similarity is efficiently estimated with a hashing algorithm. A reverse index structure built on the hashing keys ensures the scalability of our scheme and at the same time allows for real time reranking on query updates. Experiments in a publicly available benchmark dataset demonstrate the superiority of our approach."
"Ying Cao, Antoni B. Chan, Rynson W. H. Lau",1a789ddb30abe008a3a62995f78c1b56b3e29109,Automatic stylistic manga layout,ACM Trans. Graph.,2012.0,43,"Manga layout is a core component in manga production, characterized by its unique styles. However, stylistic manga layouts are difficult for novices to produce as it requires hands-on experience and domain knowledge. In this paper, we propose an approach to automatically generate a stylistic manga layout from a set of input artworks with user-specified semantics, thus allowing less-experienced users to create high-quality manga layouts with minimal efforts. We first introduce three parametric style models that encode the unique stylistic aspects of manga layouts, including layout structure, panel importance, and panel shape. Next, we propose a two-stage approach to generate a manga layout: 1) an initial layout is created that best fits the input artworks and layout structure model, according to a generative probabilistic framework; 2) the layout and artwork geometries are jointly refined using an efficient optimization procedure, resulting in a professional-looking manga layout. Through a user study, we demonstrate that our approach enables novice users to easily and quickly produce higher-quality layouts that exhibit realistic manga styles, when compared to a commercially-available manual layout tool."
"B. Klare, S. Bucak, Anil K. Jain, Tayfun Akgül",4dd8db821bca35a3cb86db74e86550aa3b940d71,Towards automated caricature recognition,2012 5th IAPR International Conference on Biometrics (ICB),2012.0,40,"This paper addresses the problem of identifying a subject from a caricature. A caricature is a facial sketch of a subject's face that exaggerates identifiable facial features beyond realism, while still conveying his identity. To enable this task, we propose a set of qualitative facial features that encodes the appearance of both caricatures and photographs. We utilized crowdsourcing, through Amazon's Mechanical Turk service, to assist in the labeling of the qualitative features. Using these features, we combine logistic regression, multiple kernel learning, and support vector machines to generate a similarity score between a caricature and a facial photograph. Experiments are conducted on a dataset of 196 pairs of caricatures and photographs, which we have made publicly available. Through the development of novel feature representations and matching algorithms, this research seeks to help leverage the ability of humans to recognize caricatures to improve automatic face recognition methods."
"Hamed Kiani Galoogahi, T. Sim",798d042a70b2c824998b3fc39a6e21799b588832,Face sketch recognition by Local Radon Binary Pattern: LRBP,2012 19th IEEE International Conference on Image Processing,2012.0,38,"In this paper, we propose a new face descriptor to directly match face photos and sketches of different modalities, called Local Radon Binary Pattern (LRBP). LRBP is inspired by the fact that the shape of a face photo and its corresponding sketch is similar, even when the sketch is exaggerated by an artist. Therefore, the shape of face can be exploited to compute features which are robust against modality differences between face photo and sketch. In LRBP framework, the characteristics of face shape are captured by transforming face image into Radon space. Then, micro-information of face shape in new space is encoded by Local Binary Pattern (LBP). Finally, LRBP is computed by concatenating histograms of local LBPs. In order to capture both local and global characteristics of face shape, LRBP is extracted in a spatial pyramid fashion. Experiments on CUFS and CUFSF datasets indicate the efficiency of LRBP for face sketch recognition."
"Kai-Yu Tseng, Yen-Liang Lin, Yu-Hsiu Chen, Winston H. Hsu",0ff52722e6bedf2f5c1407fc3c153afa1fcc11b6,Sketch-based image retrieval on mobile devices using compact hash bits,ACM Multimedia,2012.0,36,"The advent of touch panels in mobile devices has provided a good platform for mobile sketch search. However, most of the previous sketch image retrieval systems usually adopt an inverted index structure on large-scale image database, which is formidable to be operated in the limited memory of mobile devices. In this paper, we propose a novel approach to address these challenges. First, we effectively utilize distance transform (DT) features to bridge the gap between query sketches and natural images. Then these high-dimensional DT features are further projected to more compact binary hash bits. The experimental results show that our method achieves very competitive retrieval performance with MindFinder approach [3] but only requires much less memory storage (e.g., our method only requires 3% of total memory storage of MindFinder in 2.1 million images). Due to its low consumption of memory, the whole system can independently operate on the mobile devices."
"Zhenbang Sun, C. Wang, Liqing Zhang, Lei Zhang",34b7dde92f7f3f26be9d4fb9ea009cdbf87091c3,Query-adaptive shape topic mining for hand-drawn sketch recognition,ACM Multimedia,2012.0,34,"In this work, we study the problem of hand-drawn sketch recognition. Due to large intra-class variations presented in hand-drawn sketches, most of existing work was limited to a particular domain or limited pre-defined classes. Different from existing work, we target at developing a general sketch recognition system, to recognize any semantically meaningful object that a child can recognize. To increase the recognition coverage, a web-scale clipart image collection is leveraged as the knowledge base of the recognition system. To alleviate the problems of intra-class shape variation and inter-class shape ambiguity in this unconstrained situation, a query-adaptive shape topic model is proposed to mine object topics and shape topics related to the sketch, in which, multiple layers of information such as sketch, object, shape, image, and semantic labels are modeled in a generative process. Besides sketch recognition, the proposed topic model can also be used for related applications such as sketch tagging, image tagging, and sketch-based image search. Extensive experiments on different applications show the effectiveness of the proposed topic model and the recognition system."
"J. Kopf, Dani Lischinski",6016e1305fa19861d8c635c329b875da8a5d8475,Digital reconstruction of halftoned color comics,ACM Trans. Graph.,2012.0,30,"We introduce a method for automated conversion of scanned color comic books and graphical novels into a new high-fidelity rescalable digital representation. Since crisp black line artwork and lettering are the most important structural and stylistic elements in this important genre of color illustrations, our digitization process is geared towards faithful reconstruction of these elements. This is a challenging task, because commercial presses perform halftoning (screening) to approximate continuous tones and colors with overlapping grids of dots. Although a large number of inverse haftoning (descreening) methods exist, they typically blur the intricate black artwork. Our approach is specifically designed to descreen color comics, which typically reproduce color using screened CMY inks, but print the black artwork using non-screened solid black ink. After separating the scanned image into three screening grids, one for each of the CMY process inks, we use non-linear optimization to fit a parametric model describing each grid, and simultaneously recover the non-screened black ink layer, which is then vectorized. The result of this process is a high quality, compact, and rescalable digital representation of the original artwork."
"J. M. Saavedra, B. Bustos, T. Schreck, S. Yoon, Maximilian Scherer",0dba5f321a154fac2f18eff514800e600d82e078,Sketch-based 3D Model Retrieval using Keyshapes for Global and Local Representation,3DOR@Eurographics,2012.0,30,"Since 3D models are becoming more popular, the need for effective methods capable of retrieving 3D models is becoming crucial. Current methods require an example 3D model as query. However, in many cases, such a query is not easy to get. An alternative is using a hand-drawn sketch as query. In this work, we present a new keyshape based approach named HKO-KASD for retrieving 3D models using rough sketches as queries. Our approach comprises two general steps. First, a global descriptor is used to determine the appropriate viewpoint for each model. Second, we apply a local matching process to determine the final ranking for an input sketch. To this end, we present a local descriptor capable of working with sketch representations. The global descriptors as well as the local descriptors rely on a set of keyshapes precomputed from 2D representations of 3D models and from the query sketch as well. We evaluate our method using the first-tier precision and compare it with current approaches (HELO, STELA). Our results show a significant increase in precision for many classes of 3D models."
"Sourav Pramanik, D. Bhattacharjee",90fbfd57bc996a221065575c1fad1a1183470766,Geometric feature based face-sketch recognition,"International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME-2012)",2012.0,29,"This paper presents a novel facial sketch image or face-sketch recognition approach based on facial feature extraction. To recognize a face-sketch, we have concentrated on a set of geometric face features like eyes, nose, eyebrows, lips, etc and their length and width ratio because it is difficult to match photos and sketches because they belong to two different modalities. In this system, first the facial features/components from training images are extracted, then ratios of length, width, and area etc. are calculated and those are stored as feature vectors for individual images. After that the mean feature vectors are computed and subtracted from each feature vector for centering of the feature vectors. In the next phase, feature vector for the incoming probe face-sketch is also computed in similar fashion. Here, K-NN classifier is used to recognize probe face-sketch. It is experimentally verified that the proposed method is robust against faces are in a frontal pose, with normal lighting and neutral expression and have no occlusions. The experiment has been conducted with 80 male and female face images from different face databases. It has useful applications for both law enforcement and digital entertainment."
"C. Tirkaz, Berrin A. Yanikoglu, T. M. Sezgin",e0fbc1969422c0d38677b1c12e56e45a9e44fd8e,Sketched symbol recognition with auto-completion,Pattern Recognit.,2012.0,28,"Sketching is a natural mode of communication that can be used to support communication among humans. Recently there has been a growing interest in sketch recognition technologies for facilitating human-computer interaction in a variety of settings, including design, art, and teaching. Automatic sketch recognition is a challenging problem due to the variability in hand drawings, the variation in the order of strokes, and the similarity of symbol classes. In this paper, we focus on a more difficult task, namely the task of classifying sketched symbols before they are fully completed. There are two main challenges in recognizing partially drawn symbols. The first is deciding when a partial drawing contains sufficient information for recognizing it unambiguously among other visually similar classes in the domain. The second challenge is classifying the partial drawings correctly with this partial information. We describe a sketch auto-completion framework that addresses these challenges by learning visual appearances of partial drawings through semi-supervised clustering, followed by a supervised classification step that determines object classes. Our evaluation results show that, despite the inherent ambiguity in classifying partially drawn symbols, we achieve promising auto-completion accuracies for partial drawings. Furthermore, our results for full symbols match/surpass existing methods on full object recognition accuracies reported in the literature. Finally, our design allows real-time symbol classification, making our system applicable in real world applications."
"Mingli Song, Chun Chen, Jiajun Bu, Teng Sha",43dee9804f28ef8a485b3ec96173a6294e96a030,Image-based facial sketch-to-photo synthesis via online coupled dictionary learning,Inf. Sci.,2012.0,25,"Image-based sketch-to-photo synthesis has received intense attention in recent years because of its potential applications in digital entertainment and law enforcement. In order to achieve successful hallucinating synthesis of a realistic face photo, a coupled dictionary is first learned from a set of training photo-sketch pairs for modeling the relationship between patches from sketches and photos. Then, a series of overlapped photo patches can be synthesized on the basis of the learned coupled dictionary. Afterwards, these overlapped photo patches are further selected by the proposed global energy minimization framework based on a Markov network. Finally, a multi-band blending process is carried out to synthesize a realistic face photo. The experimental results convincingly validate the effectiveness of the proposed approach in comparison with the existing techniques."
"Shadma Parveen, S. Yadav, N. Chauhan",fd79fd4bc91754b185c42a0c9abdfcef900cbcba,Sketch4Match – Content-based Image Retrieval System Using Sketches,,2012.0,25,"The content based image retrieval(CBIR) is one of the most popular, rising research areas of the digital image processing. Content-based image retrieval information systems use information extracted from the content of query. In these tools, images are manually annotated with keywords and then retrieved using textbased search methods. The goal of CBIR is to extract visual content of an image automatically, like color, texture, or shape. This paper aims to introduce the problems and challenges concerned with the design and the creation of CBIR systems, which is based on a free hand sketch (Sketch based image retrieval – SBIR). With the help of the existing methods, revealed that the proposed algorithm is better than the existing algorithms, which can handle the informational gap between a sketch and a colored image. Overall, the results show that the sketch based system allows users an intuitive access to searchtools. Experimental results show that the system retrieves the intended image with a high similarity score even from a partial or shifted query."
"Danielle Cummings, Francisco Vides, T. Hammond",2b5201eedb2c05493b329019d3cce9b859938c54,I don't believe my eyes!: geometric sketch recognition for a computer art tutorial,SBIM '12,2012.0,25,"Drawing is a common form of communication and a means of artistic expression. Many of us believe that the ability to draw accurate representations of objects is a skill that either comes naturally or is the result of hours of study or practice or both. As a result many people become intimidated when confronted with the task of drawing. Many books and websites have been developed to teach people step-by-step skills to draw various objects, but they lack the live feedback of a human examiner. We designed EyeSeeYou, a sketch recognition system that teaches users to draw eyes using a simple drawing technique. The system automatically evaluates the freehand drawn sketch of an eye at various stages during creation. We conducted frequent evaluations of the system in order to take an iterative development approach based on user feedback. Our system balances the flexibility of free-hand drawing with step-by-step instructions and realtime assessment. It also provides rigorous feedback to create a constructive learning environment to aid the user in improving her drawing. This paper describes the implementation details of the sketch recognition system. A similar implementation method could be used to provide sketching tutorials for a wide number of images."
"Luyuan Li, Yongtao Wang, Zhi Tang, L. Gao",0b035604ad0021f9a0ee1746127cce6b507d9415,Automatic comic page segmentation based on polygon detection,Multimedia Tools and Applications,2012.0,23,"Comic page segmentation aims to automatically decompose scanned comic images into storyboards (frames), which is the key technique to produce digital comic documents that are suitable for reading on mobile devices. In this paper, we propose a novel method for comic page segmentation by finding the quadrilateral enclosing box of each storyboard. We first acquire the edge image of the input comic image, and then extract line segments with a heuristic line segment detection algorithm. We perform line clustering to further merge the overlapped line segments and remove the redundancy line segments. Finally, we perform another round of line clustering and post-processing to compose the obtained line segments into complete quadrilateral enclosing boxes of the storyboards. The proposed method is tested on 2,237 comic images from 12 different printed comic series, and the experimental results demonstrate that our method is effective for comic image segmentation and outperforms the existing methods."
"M. Stommel, L. I. Merhej, Marion G. Müller",53d9e66c4f3d7f65a1b24c6ffc313d03c55f729f,Segmentation-Free Detection of Comic Panels,ICCVG,2012.0,21,"The detection of comic panels is a crucial funcionality in assistance systems for iconotextual media analysis. Most systems use recursive cuts based on image projections or background segmentation to find comic panels. Usually this limits the applicability to comics with white background and free space between the panels. In this paper, we introduce a set of new features that allow for a detection of panels by their outline instead of the separating space. Our method is therefore more tolerant against structured backgrounds."
"Hamed Kiani Galoogahi, T. Sim",c27c3f207c608dcd5c22b8e0b2348a89de9de8e5,Face photo retrieval by sketch example,ACM Multimedia,2012.0,20,"Face photo-sketch matching has received great attention in recent years due to its vital role in law enforcement. The major challenge of matching face photo and sketch is difference of visual characteristics between face photo and sketch which is referred as modality gap. Earlier approaches have reduced the modality gap by synthesizing face photos and sketches in a same modality (photo or sketch). However, the effectiveness of these approaches is highly affected by synthesis results. That means a poor synthesis might degrade the performance of matching. Therefore, recent works have focused to directly match face photo and sketch of different modalities. However, the features used by these approaches are not robust against modality gap. In this paper, a modality-invariant face descriptor called Gabor Shape is proposed to retrieve face photos based on a probe sketch. Experiments on CUFS and CUFSF datasets show that the new descriptor outperforms the state-of-the-art approaches."
"Kohei Takayama, H. Johan, T. Nishita",080ecd6c10fb637490e5dd7d1b592a18418f33c7,FACE DETECTION AND FACE RECOGNITION OF CARTOON CHARACTERS USING FEATURE EXTRACTION,,2012.0,20,"In this paper, we propose methods for face detection and face recognition of cartoon characters which appear in cartoons, comics, games, etc. These methods can be applied to various applications, such as character search, automatic character classification, and character image editing. Previous researches on face detection and face recognition of real people have been abundant, on the other hand, there are little researches on face detection and face recognition of cartoon characters. Using previous methods for real people, cartoon character faces can hardly be detected and recognized because the face features of cartoon characters differ greatly from those of real people in terms of size and shape. Our methods solve these problems by considering the face features of cartoon characters. Using our methods, face detection and face recognition for cartoon characters search can be performed with good accuracy."
"Yotam I. Gingold, E. Vouga, E. Grinspun, H. Hirsh",bf9282ae1bfa1a8edcbfa1a17222408c37e7a822,"Diamonds From the Rough: Improving Drawing, Painting, and Singing via Crowdsourcing",HCOMP@AAAI,2012.0,17,"It is well established that in certain domains, noisy inputs can be reliably combined to obtain a better answer than any individual. It is now possible to consider the crowdsourcing of physical actions, commonly used for creative expressions such as drawing, shading, and singing. We provide algorithms for converting low-quality input obtained from the physical actions of a crowd into high-quality output. The inputs take the form of line drawings, shaded images, and songs. We investigate single-individual crowds (multiple inputs from a single human) and multiple-individual crowds."
"Jonghyun Choi, Abhishek Sharma, D. Jacobs, L. Davis",4e332c2f05872b56f716b72edc25b73145db4b79,Data insufficiency in sketch versus photo face recognition,2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,2012.0,15,"Computerized sketch-face recognition is a crucial element for law enforcement and has received considerable attention in the recent literature. Sketches of the suspect are hand-drawn or computer-rendered based on a verbal description of the suspect. However, the most popular and the only publicly available dataset, i.e. the CUFS face-sketch dataset, is far from realistic because the sketches are hand-drawn with the artist looking at the photographs to be matched later. After years of effort, researchers are producing nearly perfect results. However, we show that this is not because the problem is solved, but because of flaws in the dataset. In this paper, we empirically show that an off-the-shelf face recognition system for photo-sketch and sketch-photo matching with simple shape and edge features outperforms more sophisticated state-of-the-art approaches even without using training data. We additionally show that just using the hair region gives a 85.22% recognition rate. Based on the empirical evidences we argue that the current dataset available for face-sketch matching purposes is not appropriate and needs to be replaced by a more realistic one for advancement of this field."
"S. Marvaniya, S. Bhattacharjee, Venkatesh Manickavasagam, Anurag Mittal",06f97e40c7bdcf3cda0fc5b0a4f2281666c320ae,Drawing an Automatic Sketch of Deformable Objects Using Only a Few Images,ECCV Workshops,2012.0,15,"We propose a method to automatically extract a sketch of a common object structure present in a small set of real world weakly-labeled images. Applying a part-based deformable contour matching technique gives the location of repeatable contours. An initial deformable search strategy selects a set of salient, repeatable contours robust to a large range of non-rigid deformations. A contour completion technique based on a locally greedy bi-directional search strategy is adopted to merge the repeatable contour fragments for obtaining a complete shape. The output of our algorithm is used as an input to a sketch-based object-recognizer with results that are either better, or on par with those obtained with the ground truth sketches provided with the dataset."
"Xuewei Li, Xiaochun Cao",4cbe4ce523f159cc90e8fc31f823957e71a41163,A Simple Framework for Face Photo-Sketch Synthesis,,2012.0,13,"This paper proposes a simple framework for face photo-sketch synthesis. We first describe the shadow details on faces and extract the prominent facial feature by two-scale decomposition using bilateral filtering. Then, we enhance the hair and some unapparent facial feature regions by combining the edge map and hair color similarity map. Finally, we obtain the face photo sketch by adding the results of the two processes. Compared with current methods, the proposed framework demands non feature localization, training or iteration process, creating vivid hair in sketch synthesis, and process arbitrary lighting conditions of input images, especially for complex self-shadows. And more importantly, it can be easily expanded to natural scene. The effectiveness of the presented framework is evaluated on a variety of databases."
"M. Sundaresan, S. Ranjini",cbe106e75f7797145046fcbc2af6dbf941322798,Text extraction from digital English comic image using two blobs extraction method,"International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME-2012)",2012.0,12,"Text extraction from image is one of the complicated areas in digital image processing. It is a complex process to detect and recognize the text from comic image due to their various size, gray scale values, complex backgrounds and different styles of font. Text extraction process from comic image helps to preserve the text and formatting during conversion process and provide high quality of text from the printed document. This paper talks about English text extraction from blob in comic image using various methods."
"Rui Hu, Stuart James, J. Collomosse",2d8cd8b12b1cb20bf23c138ae8adc1c31c771ef4,Annotated Free-Hand Sketches for Video Retrieval Using Object Semantics and Motion,MMM,2012.0,11,"We present a novel video retrieval system that accepts annotated free-hand sketches as queries. Existing sketch based video retrieval (SBVR) systems enable the appearance and movements of objects to be searched naturally through pictorial representations. Whilst visually expressive, such systems present an imprecise vehicle for conveying the semantics (e.g. object types) within a scene. Our contribution is to fuse the semantic richness of text with the expressivity of sketch, to create a hybrid ‘semantic sketch' based video retrieval system. Trajectory extraction and clustering are applied to pre-process each clip into a video object representation that we augment with object classification and colour information. The result is a system capable of searching videos based on the desired colour, motion path, and semantic labels of the objects present. We evaluate the performance of our system over the TSF dataset of broadcast sports footage."
"Chien-Chung Tseng, J. Lien",e0f5ee8f6fc5186e1a5b8f3886a7df9838209220,Colored exaggerative caricature creation using inter- and intra-correlations of feature shapes and positions,Image Vis. Comput.,2012.0,9,"This paper develops a system comprising a statistics-based exaggerative (SBE) module and a non-photorealistic rendering (NPR) module for the automatic creation of colored facial caricatures with exaggerated facial features and individual facial details such as beards and moles. Unlike previous research that focused on the inter-correlation (the difference between the facial features of input image and those of the mean face in the training database), the SBE module exaggerates the input image utilizing an iterative approach based on both inter- and intra-correlations of the facial features. The intra-correlation considered in this study makes the comparison with other features within the same input image, and has the effect of exaggerating the major facial features while simultaneously subduing the visual impact of non-major facial features. The NPR module consists of a black-and-white sketch creation process and a colored facial cartoon creation process. The results of the two processes are combined to generate a colored cartoon-like sketch, which is then warped into a colored exaggerative facial caricature based on the corresponding exaggerative shape and position created by the SBE module. The experimental results demonstrate that the proposed method can emphasize the major characteristics of a face better than previous methods that only considered feature inter-correlation."
"Sun-Young Lee, Jong-Chul Yoon, Ji-yong Kwon, In-Kwon Lee",273f9df5a209c4a3ee746ac0bdc4afebed5f1915,CartoonModes: Cartoon stylization of video objects through modal analysis,Graph. Model.,2012.0,6,We transform the motion and shape of a video object into cartoon style using a set of representative cartooning deformations which we relate to a modal analysis of the object. Results can be obtained at interactive rate and a user survey confirmed their plausibility.
"Mehrez Boulares, M. Jemni",25228b341fc7bbc2eee7d8f42e0bd38f947c3046,Toward an example-based machine translation from written text to ASL using virtual agent animation,ArXiv,2012.0,6,"Modern computational linguistic software cannot produce important aspects of sign language translation. Using some researches we deduce that the majority of automatic sign language translation systems ignore many aspects when they generate animation; therefore the interpretation lost the truth information meaning. Our goals are: to translate written text from any language to ASL animation; to model maximum raw information using machine learning and computational techniques; and to produce a more adapted and expressive form to natural looking and understandable ASL animations. Our methods include linguistic annotation of initial text and semantic orientation to generate the facial expression. We use the genetic algorithms coupled to learning/recognized systems to produce the most natural form. To detect emotion we are based on fuzzy logic to produce the degree of interpolation between facial expressions. Roughly, we present a new expressive language Text Adapted Sign Modeling Language TASML that describes all maximum aspects related to a natural sign language interpretation. This paper is organized as follow: the next section is devoted to present the comprehension effect of using Space/Time/SVO form in ASL animation based on experimentation. In section 3, we describe our technical considerations. We present the general approach we adopted to develop our tool in section 4. Finally, we give some perspectives and future works."
"Yang Liang, Mingli Song, L. Xie, Jiajun Bu, Chun Chen",410408f8c0c395ba4fc98e92c0809f7ef697bd6a,Face sketch-to-photo synthesis from simple line drawing,Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference,2012.0,5,"Face sketch-to-photo synthesis has attracted increasing attention in recent years for its useful applications on both digital entertainment and law enforcement. Although great progress has been made, previous methods only work on face sketches with rich textures which are not easily to obtain. In this paper, we propose a robust algorithm for synthesizing a face photo from a simple line drawing that contains only a few lines without any texture. In order to obtain a robust result, firstly, the input sketch is divided into several patches and edge descriptors are extracted from these local input patches. Afterwards, an MRF framework is built based on the divided local patches. Then a series of candidate photo patches are synthesized for each local sketch patch based on a coupled dictionary learned from a set of training data. Finally, the MRF is optimized to get the final estimated photo patches for each input sketch patch and a realistic face photo is synthesized. Experimental results on CUHK database have validated the effectiveness of the proposed method."
"Dang Li, Kong Fan-rang",2853f9024d8d6f52b28efb5f0394797030d88b23,Face sketch synthesis and recognition based on independent subspace,,2012.0,5,"Face sketch recognition plays an important role in determining the identity of the suspect through suspect sketch which is described by witnesses.In order to better realize face sketch recognition,a new face sketch synthesis and recognition algorithm was proposed based on face independent subspace and shape features.According to the face reconstruction based on independent component analysis(ICA) subspace,the face sketch synthesis based on ICA was studied,and the conversion between photo and sketch was realized.Considering the important role of the face structure information in face recognition and in analyzing the limitation of the structural information extracted by active shape model(ASM) algorithm,the polar shape model(PSM) was proposed.Finally,the synthesised sketch was recognized with the one to be recognized by combining ICA/linear discriminant analysis(LDA) and PSM.Experiment results indicate that the synthesis sketch performs very well by new algorithm,the recognition rate of one rank is 94.7%,and the recognition rate of ten rank is 99.1%.Recognition with subspace and PSM,one rank rate can be increased by 5.3%,and the first three rank rate can be increased by 4.2% evenly.The algorithm has higher recognition rate and basically meets the requirements of automatic face sketch recognition system."
"Shandong Wang, Ziyang Ma, X. Liu, Yanyun Chen, E. Wu",3fbee912526dcf631799ca13d81949f439630fc1,Coherence-enhancing line drawing for color images,Science China Information Sciences,2012.0,4,"Line drawing plays an important role in many image-based non-photorealistic applications. However, most existing approaches use a grayscale edge detector for line extraction, so that only luminance differences between nearby image pixels is taken into account, but the chrominance differences is ignored. This leads to the undesirable consequence that visually significant edges in adjacent regions with different colors of similar luminance cannot be detected. To address this limitation, we present a novel enhanced line drawing method based on a flow-based difference-of-Gaussians (FDoG) filter. Because of an inherent property of the thresholded DoG edge model, captured lines may appear dislodged from the true edges in the image. To this end, we provide a gradient-guided warping technique so that smooth and coherent lines can be extracted in the correct location. The GPU implementation of the proposed algorithms allows real-time performance, and experimental examples with various color images demonstrate the method’s superior qualitative performance over previous approaches."
"Chen-Yu Hong, Shuangjiu Xiao, Zehong Tan, Jianchao Lv",bdb5cdcb167cb85a0cee044ce4c4bd43523e5071,Real-time motion recognition based on skeleton animation,2012 5th International Congress on Image and Signal Processing,2012.0,4,"We propose a novel real-time motion recognition method based on hierarchical skeleton model. Its key modules include a self-adaptive training algorithm to boost a strong classifier among the features of rotation quaternions and a dynamic time warping algorithm based scoring method to pyramid match with standard motion class's classifier. For a sequence of recognized candidate motion class, a HMM-based most likely tagging algorithm is proposed in the end of recognition pipeline to work as a smoothing filter. Our method has a remarkable performance as it has high sensitivity, specialty and precision."
"I. Steiner, S. Ouni",f305864a5498a3dad078113bf3ef8cfcc1bbe9f7,Progress in animation of an EMA-controlled tongue model for acoustic-visual speech synthesis,ArXiv,2012.0,4,"We present a technique for the animation of a 3D kinematic tongue 
model, one component of the talking head of an acoustic-visual (AV) speech synthesizer. 
The skeletal animation approach is adapted to make use of a deformable 
rig controlled by tongue motion capture data obtained with electromagnetic articulography 
(EMA), while the tongue surface is extracted from volumetric magnetic 
resonance imaging (MRI) data. Initial results are shown and future work outlined."
"I. Steiner, S. Ouni",1fb3353cb2bf7c0b86a497495935505c4ca6ffad,Artimate: an articulatory animation framework for audiovisual speech synthesis,ArXiv,2012.0,3,"We present a modular framework for articulatory animation synthesis using speech motion capture data obtained with electromagnetic articulography (EMA). Adapting a skeletal animation approach, the articulatory motion data is applied to a three-dimensional (3D) model of the vocal tract, creating a portable resource that can be integrated in an audiovisual (AV) speech synthesis platform to provide realistic animation of the tongue and teeth for a virtual character. The framework also provides an interface to articulatory animation synthesis, as well as an example application to illustrate its use with a 3D game engine. We rely on cross-platform, open-source software and open standards to provide a lightweight, accessible, and portable workflow."
"Tobias Gritschacher, W. Slany",92fa7b813327a2bf01f022d2e701372375a3f013,Standing on the shoulders of their peers: success factors for massive cooperation among children creating open source animations and games on their smartphones,IDC '12,2012.0,3,"We developed a website for kids where they can share new as well as remixed animations and games, e.g., interactive music videos, which they created on their smartphones or tablets using a visual ""LEGO-style"" programming environment called Catroid. Online communities for children like our website have unique requirements, and keeping the commitment of kids on a high level is a continuous challenge. For instance, one key motivator for kids is the ability to entertain their friends. Another success factor is the ability to learn from and cooperate with other children. In this short position paper we attempt at identifying the requirements for the success of such an online community, both from the point of view of the kids as well as of their parents, and at finding ways to make it attractive for both."
"Shunichiro Nonaka, T. Sawano, Norihisa Haneda",4e0784f71a9903b6719688bb57c5a74994498f2f,"Development of “GT-Scan”, the Technology for Automatic Detection of Frames in Scanned Comic",,2012.0,3,"We have developed a new image processing technology, “GT-Scan”, to detect frames in comic pages automatically. GT-Scan enables to detect frames in about 95% of boyʼs comic pages and about 78% of girlʼs comic pages, contributing to reduce the costs and efforts for the digital comic authoring. In this paper, we introduce the structure of the technology and procedure of development. 本誌投稿論文(受理2011年12月15日) * 富士フイルム(株)ネット応用ビジネス推進部 〒106-8620 東京都港区西麻布2-26-30 * Internet Business Development Division FUJIFILM Corporation Nishiazabu, Minato-ku, Tokyo 106-8620, Japan"
"M. Nosrati, Ronak Karimi, Hojat Allah Hasanvand",2c2b64a7448391c1b24bc96194c78b85e5ca38db,Extracting the Initial Sketch of Paintings Using Different Hough Transforms - TI Journals,,2012.0,2,"Abstract: A method for extraction of sketch of paintings is presented in this paper. Due to this, the Hough transforms are introduced and got into. It includes linear, circular and other analytical curves. Using HT, extraction of basic curves is possible. 
In a separate section, the application of different Hough Transforms is investigated. Experimental results show the efficiency of proposed method. Results show that different values of parameters are important in accuracy of ending sketch."
"V. Vashisht, T. Choudhury, T. V. Prasad",e1254ebc53ecc03bdd6157d5b3fc8e6afb399b08,Sketch Recognition using Domain Classification,ArXiv,2012.0,2,"Conceptualizing away the sketch processing details in a user interface will enable general users and domain experts to create more complex sketches. There are many domains for which sketch recognition systems are being developed. But they entail image-processing skill if they are to handle the details of each domain, and also they are lengthy to build. The implemented system goal is to enable user interface designers and domain experts who may not have proficiency in sketch recognition to be able to construct these sketch systems. This sketch recognition system takes in rough sketches from user drawn with the help of mouse as its input. It then recognizes the sketch using segmentation and domain classification, the properties of the user drawn sketch and segments are searched heuristically in the domains and each figures of each domain, and finally it shows its domain, the figure name and properties. It also draws the sketch smoothly. The work is resulted through extensive research and study of many existing image processing and pattern matching algorithms."
Masayuki Arai,37c40253e2601665d8e20ff58426bb963152e99a,Feature extraction methods for cartoon character recognition,2012 5th International Congress on Image and Signal Processing,2012.0,1,"This paper describes feature extraction methods for an eye and hair to recognize cartoon characters. Image data sharing sites, such as YouTube, have numerous pictures that infringe on copyrights. To solve this problem, we study a method that recognizes authors or characters in cartoons and classifies the pictures infringing copyright. This paper proposes feature extraction methods for an eye and hair for cartoon character recognition. Experimental results show that black pixel density and peripheral direction contributively features of an eye and stroke density features of hair are effective for cartoon character recognition."
"I. Steiner, Korin Richmond, S. Ouni",568fa62d64c86816e3e704f7ebd2d24b6c4efa95,Using multimodal speech production data to evaluate articulatory animation for audiovisual speech synthesis,FAA '12,2012.0,1,"The importance of modeling speech articulation for high-quality audiovisual (AV) speech synthesis is widely acknowledged. Nevertheless, while state-of-the-art, data-driven approaches to facial animation can make use of sophisticated motion capture techniques, the animation of the intraoral articulators (viz. the tongue, jaw, and velum) typically makes use of simple rules or viseme morphing, in stark contrast to the otherwise high quality of facial modeling. Using appropriate speech production data could significantly improve the quality of articulatory animation for AV synthesis."
"M. Eitz, Kristian Hildebrand, T. Boubekeur, M. Alexa",5f7354634e13c9fad64163d53beb0a8eb5df30e1,Sketch-Based Image Retrieval: Benchmark and Bag-of-Features Descriptors,IEEE Transactions on Visualization and Computer Graphics,2011.0,381,"We introduce a benchmark for evaluating the performance of large-scale sketch-based image retrieval systems. The necessary data are acquired in a controlled user study where subjects rate how well given sketch/image pairs match. We suggest how to use the data for evaluating the performance of sketch-based image retrieval systems. The benchmark data as well as the large image database are made publicly available for further studies of this type. Furthermore, we develop new descriptors based on the bag-of-features approach and use the benchmark to demonstrate that they significantly outperform other descriptors in the literature."
"Abhishek Sharma, D. Jacobs",a3d7613971e52165f1693a972c11c54bb0bc085b,"Bypassing synthesis: PLS for face recognition with pose, low-resolution and sketch",CVPR 2011,2011.0,332,"This paper presents a novel way to perform multi-modal face recognition. We use Partial Least Squares (PLS) to linearly map images in different modalities to a common linear subspace in which they are highly correlated. PLS has been previously used effectively for feature selection in face recognition. We show both theoretically and experimentally that PLS can be used effectively across modalities. We also formulate a generic intermediate subspace comparison framework for multi-modal recognition. Surprisingly, we achieve high performance using only pixel intensities as features. We experimentally demonstrate the highest published recognition rates on the pose variations in the PIE data set, and also show that PLS can be used to compare sketches to photos, and to compare images taken at different resolutions."
"Michalis Raptis, D. Kirovski, Hugues Hoppe",bc404e002441e7aaa445f6ef62ab8d9420ff9ffc,Real-time classification of dance gestures from skeleton animation,SCA '11,2011.0,319,"We present a real-time gesture classification system for skeletal wireframe motion. Its key components include an angular representation of the skeleton designed for recognition robustness under noisy input, a cascaded correlation-based classifier for multivariate time-series data, and a distance metric based on dynamic time-warping to evaluate the difference in motion between an acquired gesture and an oracle for the matching gesture. While the first and last tools are generic in nature and could be applied to any gesture-matching scenario, the classifier is conceived based on the assumption that the input motion adheres to a known, canonical time-base: a musical beat. On a benchmark comprising 28 gesture classes, hundreds of gesture instances recorded using the XBOX Kinect platform and performed by dozens of subjects for each gesture class, our classifier has an average accuracy of 96:9%, for approximately 4-second skeletal motion recordings. This accuracy is remarkable given the input noise from the real-time depth sensor."
"Wayne Zhang, Xiaogang Wang, X. Tang",013896c2ae9533be88f285a031ce839c672078b5,Coupled information-theoretic encoding for face photo-sketch recognition,CVPR 2011,2011.0,194,"Automatic face photo-sketch recognition has important applications for law enforcement. Recent research has focused on transforming photos and sketches into the same modality for matching or developing advanced classification algorithms to reduce the modality gap between features extracted from photos and sketches. In this paper, we propose a new inter-modality face recognition approach by reducing the modality gap at the feature extraction stage. A new face descriptor based on coupled information-theoretic encoding is used to capture discriminative local face structures and to effectively match photos and sketches. Guided by maximizing the mutual information between photos and sketches in the quantized feature spaces, the coupled encoding is achieved by the proposed coupled information-theoretic projection tree, which is extended to the randomized forest to further boost the performance. We create the largest face sketch database including sketches of 1, 194 people from the FERET database. Experiments on this large scale dataset show that our approach significantly outperforms the state-of-the-art methods."
"Kenneth D. Forbus, Jeffrey M. Usher, A. Lovett, Kate Lockwood, Jon Wetzel",8fbf4e69d1eb81ea8f3e26b80381daee8882949b,CogSketch: Sketch Understanding for Cognitive Science Research and for Education,Top. Cogn. Sci.,2011.0,149,"Sketching is a powerful means of working out and communicating ideas. Sketch understanding involves a combination of visual, spatial, and conceptual knowledge and reasoning, which makes it both challenging to model and potentially illuminating for cognitive science. This paper describes CogSketch, an ongoing effort of the NSF-funded Spatial Intelligence and Learning Center, which is being developed both as a research instrument for cognitive science and as a platform for sketch-based educational software. We describe the idea of open-domain sketch understanding, the scientific hypotheses underlying CogSketch, and provide an overview of the models it employs, illustrated by simulation studies and ongoing experiments in creating sketch-based educational software."
"Jennifer Fernquist, Tovi Grossman, G. Fitzmaurice",41d7d0983ce72e276f15368a2218c69be978ad54,Sketch-sketch revolution: an engaging tutorial system for guided sketching and application learning,UIST,2011.0,86,"We describe Sketch-Sketch Revolution, a new tutorial system that allows any user to experience the success of drawing content previously created by an expert artist. Sketch-Sketch Revolution not only guides users through the application user interface, it also provides assistance with the actual sketching. In addition, the system offers an authoring tool that enables artists to create content and then automatically generates a tutorial from their recorded workflow history. Sketch-Sketch Revolution is a unique hybrid tutorial system that combines in-product, content-centric and reactive tutorial methods to provide an engaging learning experience. A qualitative user study showed that our system successfully taught users how to interact with a drawing application user interface, gave users confidence they could recreate expert content, and was uniformly considered useful and easy to use."
"Masoumeh Farokhi, M. Hashemi",1fb3aa1cb17529052b8e1fbbf58a5c63ea5bfc92,"The Analysis of Children's Drawings: Social, Emotional, Physical, and Psychological aspects",,2011.0,76,"Abstract The drawings of young children have attracted and interested many professionals in the field of education. Researchers, psychologists, teachers, and parents have done various researches to clarify the meaning and interpretation of children's drawings. Through the process of observing and analyzing the drawings of young children, insights can be gained as to the social/emotional, physical, and intellectual development of each child. Children usually explore the world around them through intellectual, physical and emotional methods for young children; pencil, brush and paper are the best means of conveying their fondest hopes and most profound fears. The progression of drawings that children make over a period of time can show significant growth and development, as well as determine academic capabilities and skills characteristic of their developmental level (Brittain & Lowenfeld, 1987). According to Lowenfeld, children begin their drawing process as early as they can physically hold a drawing utensil. From their first attempts at a drawing, consisting of random marks and lines, to their first representational drawing, children are making efforts to communicate to the world around them and establish meaning through the images they create (Brittain & Lowenfeld, 1987). It is through their drawings that children express the views and interpretations of theirexperiences."
"王晓刚, 汤晓鸥",ba11a1b757b7ea98d27ecb38cc119cb902fb500f,Coupled Information-Theoretic Encoding for Face Photo-Sketch Recognition,,2011.0,75,
"Tom Y. Ouyang, Randall Davis",e60f0277be4fdd819e1cb1c91aaa91c0017e82a3,ChemInk: a natural real-time recognition system for chemical drawings,IUI '11,2011.0,71,"We describe a new sketch recognition framework for chemical structure drawings that combines multiple levels of visual features using a jointly trained conditional random field. This joint model of appearance at different levels of detail makes our framework less sensitive to noise and drawing variations, improving accuracy and robustness. In addition, we present a novel learning-based approach to corner detection that achieves nearly perfect accuracy in our domain. The result is a recognizer that is better able to handle the wide range of drawing styles found in messy freehand sketches. Our system handles both graphics and text, producing a complete molecular structure as output. It works in real time, providing visual feedback about the recognition progress. On a dataset of chemical drawings our system achieved an accuracy rate of 97.4%, an improvement over the best reported results in literature. A preliminary user study also showed that participants were on average over twice as fast using our sketch-based system compared to ChemDraw, a popular CAD-based tool for authoring chemical diagrams. This was the case even though most of the users had years of experience using ChemDraw and little or no experience using Tablet PCs."
"M. Eitz, Ronald Richter, Kristian Hildebrand, T. Boubekeur, M. Alexa",f610031872e1a191e302268f120b0dc13b363cfd,Photosketcher: Interactive Sketch-Based Image Synthesis,IEEE Computer Graphics and Applications,2011.0,68,"Photosketcher is an interactive system for progressively synthesizing novel images using only sparse user sketches as input. Photosketcher works on the image content exclusively; it doesn't require keywords or other metadata associated with the images. Users sketch the rough shape of a desired image part, and Photosketcher searches a large collection of images for it. The search is based on a bag-of-features approach that uses local descriptors for translation-invariant retrieval of image parts. Composition is based on user scribbles: from the scribbles, Photosketcher predicts the desired part using Gaussian mixture models and computes an optimal seam using graph cuts. To further reduce visible seams, users can blend the composite image in the gradient domain."
"T. Shao, Weiwei Xu, KangKang Yin, Jingdong Wang, Kun Zhou, B. Guo",a07ae4aa759af95bed1387c166a7bc3708388f9a,Discriminative Sketch‐based 3D Model Retrieval via Robust Shape Matching,Comput. Graph. Forum,2011.0,68,"We propose a sketch‐based 3D shape retrieval system that is substantially more discriminative and robust than existing systems, especially for complex models. The power of our system comes from a combination of a contour‐based 2D shape representation and a robust sampling‐based shape matching scheme. They are defined over discriminative local features and applicable for partial sketches; robust to noise and distortions in hand drawings; and consistent when strokes are added progressively. Our robust shape matching, however, requires dense sampling and registration and incurs a high computational cost. We thus devise critical acceleration methods to achieve interactive performance: precomputing kNN graphs that record transformations between neighboring contour images and enable fast online shape alignment; pruning sampling and shape registration strategically and hierarchically; and parallelizing shape matching on multi‐core platforms or GPUs. We demonstrate the effectiveness of our system through various experiments, comparisons, and user studies."
"Rui Hu, T. Wang, J. Collomosse",23b84f5288401f22bbe8a6f54643217926d74e10,A bag-of-regions approach to sketch-based image retrieval,2011 18th IEEE International Conference on Image Processing,2011.0,61,"This paper presents a system for retrieving photographs using free-hand sketched queries. Regions are extracted from each image by gathering nodes of a hierarchical image segmentation into a bag-of-regions (BoR) representation. The BoR represents object shape at multiple scales, encoding shape even in the presence of adjacent clutter. We extract a shape representation from each region, using the Gradient Field HoG (GF-HOG) descriptor which enables direct comparison with the sketched query. The retrieval pipeline yields significant performance improvements over the previous GF-HOG results reliant on single-scale Canny edge maps, and over leading descriptors (SIFT, SSIM) for visual search. In addition, our system enables localization of the sketched object within matching images."
"K. Arai, Herman Tolle",25d1d80cbbfc82d8dcd4e98f03dae24027cc3e0f,Method for Real Time Text Extraction of Digital Manga Comic,,2011.0,54,"Manga is one of popular item in Japan and also in the rest of the world. Hundreds of manga printed everyday in Japan and some of printed manga book was digitized into web manga. People then make translation of Japanese language on manga into other language -in conventional wayto share the pleasure of reading manga through the internet. In this paper, we propose an automatic method for detect and extract Japanese character within a manga comic page for online language translation process. Japanese character text extraction method is based on our comic frame content extraction method using blob extraction function. Experimental results from 15 comic pages show that our proposed method has 100% accuracy of flat comic frame extraction and comic balloon detection, and 93.75% accuracy of Japanese character text extraction."
"G. Orbay, L. Kara",bace251b82ea71f8ece46d523c0b370ec8b805b2,Beautification of Design Sketches Using Trainable Stroke Clustering and Curve Fitting,IEEE Transactions on Visualization and Computer Graphics,2011.0,52,"We propose a new sketch parsing and beautification method that converts digitally created design sketches into beautified line drawings. Our system uses a trainable, sequential bottom-up and top-down stroke clustering method that learns how to parse input pen strokes into groups of strokes each representing a single curve, followed by point-cloud ordering that facilitates curve fitting and smoothing. This approach enables greater conceptual freedom during visual ideation activities by allowing designers to develop their sketches using multiple, casually drawn strokes without requiring them to indicate the separation between different stroke groups. With the proposed method, raw sketches are seamlessly converted into vectorized geometric models, thus, facilitating downstream assessment and editing activities."
"C. Price, Holly Cunningham, Nicole Coronado, A. Freedland, S. Cosentino, D. Penney, Alfio Penisi, D. Bowers, M. Okun, D. Libon",319e010c548cba5e23de32d9224df9789d9fe125,Clock Drawing in the Montreal Cognitive Assessment: Recommendations for Dementia Assessment,Dementia and Geriatric Cognitive Disorders,2011.0,50,"Background: Clock drawing is part of the Montreal Cognitive Assessment (MoCA) test but may have administration and scoring limitations. We assessed (1) the reliability of the MoCA clock criteria relative to a published error scoring approach, (2) whether command-only administration could distinguish dementia from cognitively intact individuals and (3) the value of adding a clock copy condition to the MoCA. Methods: Three novice raters and clocks from dementia and control participants were used to assess the 3 aims. Results: MoCA interrater and intrarater reliability were low (i.e. intraclass correlation coefficient = 0.12–0.31) and required repeat training. Clocks drawn to command classified dementia at chance. Inclusion of a copy condition demonstrated expected dementia subgroup patterns. Conclusion: Reliable clock scoring with MoCA criteria requires practice. Supplementing a clock copy to the standard MoCA test (takes <1 min) will improve dementia assessment."
Micheal. M. van Wyk,0af80381d400a6159a5990b5d5399c726dff57ff,The Use of Cartoons as a Teaching Tool to Enhance Student Learning in Economics Education,,2011.0,45,"Abstract Excellent and effective teaching demands a host of devices, techniques and strategies not only to achieve cross critical outcomes, but because variety, itself, is a desideratum. One teaching instrument which perhaps is too seldom used, is the economics cartoon. To encourage this development, learning activities become important. This paper investigates why Economics subject didactics students prescribed to cartoons as a teaching tool to enhance their learning. A survey was conducted to determine the use of cartoons as an effective teaching tool in Economics education. The results of the confirmatory factor analyses indicated that the six-factor-model shows a reasonable fit, since the two out of three conditions were consistently satisfied for the six-factor-model of this study. Further, interviews revealed that cartoons positively enhanced constructive learning, cooperative learning and collaborative learning amongst peers. Suggestions were made how to use cartoons as technique to creating interest and developing critical thinking and reflective teaching skills in Economics education."
"Christophe Rigaud, Norbert Tsopzé, J. Burie, J. Ogier",29953da60f470fc21dc484863e601bd5b4c6cb15,Robust Frame and Text Extraction from Comic Books,GREC,2011.0,41,"Comic books constitute an important heritage in many countries. Nowadays, digitization allows to search directly from content instead of metadata only (e.g. album title or author name). Few studies have been done in this direction. Only frame and speech balloon extraction have been experimented in the case of simple page structure. In fact, the page structure depends on the author which is why many different structures and drawings exist. Despite the differences, drawings have a common characteristic because of design process: they are all surrounded by a black line. In this paper, we propose to rely on this particularity of comic books to automatically extract frame and text using a connected-component labeling analysis. The approach is compared with some existing methods found in the literature and results are presented."
"N. Wang, Xinbo Gao, D. Tao, Xuelong Li",b719c22eb31867fbfab8fd632dd80f72205c2c86,Face Sketch-Photo Synthesis under Multi-dictionary Sparse Representation Framework,2011 Sixth International Conference on Image and Graphics,2011.0,40,"Sketch-photo synthesis is one of the important research issues of heterogeneous image transformation. Some available popular synthesis methods, like locally linear embedding (LLE), usually generate sketches or photos with lower definition and blurred details, which reduces the visual quality and the recognition rate across the heterogeneous images. In order to improve the quality of the synthesized images, a multi-dictionary sparse representation based face sketch-photo synthesis model is constructed. In the proposed model, LLE is used to estimate an initial sketch or photo, while the multi-dictionary sparse representation model is applied to generate the high frequency and detail information. Finally, by linear superimposing, the enhanced face sketch or photo can be obtained. Experimental results show that sketches and photos synthesized by the proposed method have higher definition and much richer detail information resulting in a higher face recognition rate between sketches and photos."
"R. Arandjelović, T. M. Sezgin",10d841796addb95e204afc21ff03c9ac7f0766fe,Sketch recognition by fusion of temporal and image-based features,Pattern Recognit.,2011.0,34,"The increasing availability of pen-based hardware has recently resulted in a parallel growth in sketch-based user interfaces. Sketch-based user interfaces aim to combine the expressive power of free-hand sketching with the processing power of computers. Most sketch-based systems require intelligent ink processing capabilities, which makes the development of robust sketch recognition algorithms a primary concern in the field. So far, the research in sketch recognition has produced various independent approaches to recognition, each of which uses a particular kind of information (e.g., geometric and spatial constraints, image-based features, temporal stroke-ordering patterns). These methods were designed in isolation as stand-alone algorithms, and there has been little work treating various recognition methods as alternative sources of information that can be combined to increase sketch recognition accuracy. In this paper, we focus on two such methods and fuse an image-based method with a time-based method in an attempt to combine the knowledge of how objects look (image data) with the knowledge of how they are drawn (temporal data). In the course of combining spatial and temporal information, we also introduce a mathematically well founded fusion method for combining recognizers. Our combination method can be used for isolated sketch recognition as well as full diagram recognition. Our evaluation with two databases shows that fusing image-based and temporal features yields higher recognition rates. These results are the first to confirm the complementary nature of image-based and temporal recognition methods for full sketch recognition, which has long been suggested, but never supported by data."
"J. M. Saavedra, B. Bustos, Maximilian Scherer, T. Schreck",36024cdcc9bc4fb85a3ef5223d085c3961e85fae,STELA: sketch-based 3D model retrieval using a structure-based local approach,ICMR '11,2011.0,28,"Since 3D models are becoming more popular, the need for effective methods capable of retrieving 3D models are becoming crucial. Current methods require an example 3D model as query. However, in many cases, such a query is not easy to get. An alternative is using a hand-draw sketch as query. We present a structure-based local approach (STELA) for retrieving 3D models using a rough sketch as query. It consists of four steps: get an abstract image, detect keyshapes, compute a local descriptor, and match local descriptors. We represent a 3D model by means of suggestive contours. Our proposal includes an additional step aiming at reducing the number of models that will be compared by our local approach. The proposed method is invariant to position, scale, and rotation changes as well. We evaluate our method using the first-tier precision and compare it with a current global approach (HELO). Our results show an increasing in precision for many classes of 3D models."
"L. Clarke, M. Chen, B. Mora",e36245856341016df6571b9322efec7334d939d7,Automatic Generation of 3D Caricatures Based on Artistic Deformation Styles,IEEE Transactions on Visualization and Computer Graphics,2011.0,26,"Caricatures are a form of humorous visual art, usually created by skilled artists for the intention of amusement and entertainment. In this paper, we present a novel approach for automatic generation of digital caricatures from facial photographs, which capture artistic deformation styles from hand-drawn caricatures. We introduced a pseudo stress-strain model to encode the parameters of an artistic deformation style using “virtual” physical and material properties. We have also developed a software system for performing the caricaturistic deformation in 3D which eliminates the undesirable artifacts in 2D caricaturization. We employed a Multilevel Free-Form Deformation (MFFD) technique to optimize a 3D head model reconstructed from an input facial photograph, and for controlling the caricaturistic deformation. Our results demonstrated the effectiveness and usability of the proposed approach, which allows ordinary users to apply the captured and stored deformation styles to a variety of facial photographs."
"Hongliang Li, G. Liu, K. Ngan",5750fff2798f8e50fff6ca535a78dadb9e0f19d9,Guided Face Cartoon Synthesis,IEEE Transactions on Multimedia,2011.0,20,"In this paper, we propose a new method, called guided synthesis, to synthesize a face cartoon from a face photo. The guided synthesis is defined as a local linear model, which generates a cartoon image by incorporating the content of guidance images taken from the training set. Our synthesis operation is achieved based on four weight functions. The first is a photo-photo weight that aims to measure the similarity between an input photo patch and a training photo patch. The second is defined as a photo-cartoon weight, which is used to compute the likelihood by computing the similarity between a cartoon patch and an input photo patch. The third weight is defined in the synthesized photos, which is to set a smoothness constraint between neighboring synthesized patches. The final weight is designed to evaluate the similarity of a synthesized patch to an input patch based on the spatial distance. Experimental evaluation on a number of face photos demonstrates the good performance of the proposed method on the face cartoon synthesis."
"Jiewei Zhang, N. Wang, Xinbo Gao, D. Tao, Xuelong Li",274a6cbed3f462497d45ddfd55c2c3d3d79e902f,Face sketch-photo synthesis based on support vector regression,2011 18th IEEE International Conference on Image Processing,2011.0,17,"The existing face sketch-photo synthesis methods trend to lose some vital details more or less. In this paper, we propose a novel sketch-photo synthesis approach based on support vector regression (SVR) to handle this difficulty. First, we utilize an existing method to acquire the initial estimate of the synthesized image. Then, the final synthesized image is obtained by combining the initial estimate and the SVR based high frequency information together to further enhance the quality of synthesized image. Experimental results on the benchmark database and our new constructed database demonstrate that the proposed method can achieve significant improvement on perceptual quality. Moreover, the synthesized face images can obtain higher recognition rate when used in retrieval system."
"W. Sun, K. Kise",f27ccd19c7fc446d6a7139238c90809e551226c8,Similar Manga Retrieval Using Visual Vocabulary Based on Regions of Interest,2011 International Conference on Document Analysis and Recognition,2011.0,17,"Manga, a kind of graphic novels expressed by sequential line drawings, is an important document image publication which is invoking more and more attentions for their copyright protection. Because of simple constructions and abstract expression styles, similar copies are always applied in plagiarisms of mangas. In addition, the enormous volume of copyrighted manga publications issues a challenge to the task of detecting suspicious images. Considering only some regions of interests (ROIs) require copyright protection, we propose a bag-of-features method using visual words based on ROIs for similar manga retrieval. In the experiments, we applied real manga publications as data and proved the effectiveness of the proposed method."
"S. Durocher, Debajyoti Mondal, Rahnuma Islam Nishat, S. Whitesides",e660d3ca1fc333898ce7f64fd2591ff24a2a0465,A Note on Minimum-Segment Drawings of Planar Graphs,CCCG,2011.0,16,"A straight-line drawing of a planar graph G is a planar drawing of G, where each vertex is mapped to a point on the Euclidean plane and each edge is drawn as a straight line segment. A segment in a straight-line drawing is a maximal set of edges that form a straight line segment. A minimum-segment drawing of G is a straightline drawing of G, where the number of segments is the minimum among all possible straight-line drawings of G. In this paper we prove that it is NP-complete to determine whether a plane graph G has a straight-line drawing with at most k segments, where k 3. We also prove that the problem of deciding whether a given partial drawing of G can be extended to a straight-line drawing with at most k segments is NP-complete, even when G is an outerplanar graph. Finally, we investigate a worst-case lower bound on the number of segments required by straight-line drawings of arbitrary spanning trees of a given planar graph."
"N. Ji, Xiujuan Chai, S. Shan, Xilin Chen",7bbd1ee4a89259939a13e6ee2b16b9a2f968d0fd,Local Regression Model for Automatic Face Sketch Generation,2011 Sixth International Conference on Image and Graphics,2011.0,15,"As one of the important artistic styles of portrait, sketch portrait has wide applications for both digital entertainment and law enforcement. In this paper, an automatic face sketch generation approach is presented by learning from photo-sketch pair examples. Specifically, the relationship between a face photo and its corresponding face sketch is learned on image patch level. By applying this relationship to the input face photo patch, we can infer the output face sketch patch by exploiting some regression techniques such as kNN, the Lasso and so on. Via our local regression model, we can synthesize an appealing sketch portrait from a given face photo in a few minutes. Experiments conducted on CUHK database have shown that our results are more compelling than previous methods especially in two respects: (1) our synthesized sketches preserve more identity information of the original face photo, (2) our synthesized sketches presents more pencil sketch texture."
"Hyungsin Kim, Young Suk Cho, E. Do",b373cec1ddd5cafdee608845223a0a60fc387ea9,Computational clock drawing analysis for cognitive impairment screening,Tangible and Embedded Interaction,2011.0,15,"This paper presents computational support for the Clock Drawing Test (CDT), a simple cognitive dysfunction diagnosis tool. Despite its popularity of current use, the CDT has been administered the same way for the past three decades as a pencil-and-paper test. By making a computerized drawing test, we can understand the process of clock drawing construction rather than simply analyzing the final drawing. In this paper, we will first introduce our computerized Clock Drawing Test, the ClockReader. Then, we will describe two automated data-capturing methods with specific data examples. The automated data analysis can provide neuropsychologists with useful qualitative information, such as the process of drawing, as well as patients' planning strategies."
"L. Chang, Mingquan Zhou, Xiaoming Deng, Zhongke Wu, Yanjun Han",cc12653d21ab9d25f3a48b3586db96d4afb484b7,Face Sketch Synthesis via Multivariate Output Regression,HCI,2011.0,13,"This paper presents a multivariate output regression based method to synthesize face sketches from photos. The training photos and sketches are divided into small image patches. For each pairs of photo patch and its corresponding sketch patch in training data, a local regression model is built by multivariate output regression methods such as kernel ridge regression and relevance vector machine (RVM). Compared with commonly used single-output regression, multivariate output regression can enforce the synthesized sketch patches with structure constraints. Experiments are given to show the validity and effectiveness of the approach."
"Yuxin Wang, M. Yu, Qi Jia, He Guo",3099e25764d879995bd19c5f9bf4fc39df3c3d9d,Query by sketch: An asymmetric sketch-vs-image retrieval system,2011 4th International Congress on Image and Signal Processing,2011.0,11,"This paper presents a novel query method in sketch-based image searching system. Semantically similar images can be retrieved via user-drawn sketches in large image collections. Firstly the system analyses the spatial distribution of user's sketch and computes the weight map. And then the system extracts features from the query sketch. The edge map descriptor and haar wavelet transform feature are used, which can match user-drawn sketch with the target image efficiently. To substantiate our approach, we build a retrieval system and allow the user to express a query as a simple sketch portraying ‘what’ she/he is looking for. We also show how our method can be used for the asymmetric sketch-vs-image retrieval efficiently."
"K. Hoashi, C. Ono, Daisuke Ishii, Hiroshi Watanabe",803b714debd40640674a90226a326f2c5a041850,Automatic preview generation of comic episodes for digitized comic search,ACM Multimedia,2011.0,8,"This research proposes a novel method to present ""thumbnails"" of episodes of digitized comics, in order to improve the efficiency of comic search. Comic episode thumbnails are generated based on image analysis technologies developed especially for comic images. Namely, the following procedures are developed for our system: automatic comic frame segmentation, text balloon extraction, and a linear regression based model to calculate the importance score of each extracted frame. The system then selects frames from each episode with high importance score, and aligns the selected frames to create the episode thumbnail, which is presented to the system user as a compact preview of the episode. User experiments conducted with actual Japanese comic images prove that the proposed method significantly decreases the time necessary to search for specific episodes from a large scaled comic data collection."
"N. Pantuwong, Masanori Sugimoto",86e061ad83cab187a422b1e7119f915ed530533e,A fully automatic rigging algorithm for 3D character animation,SA '11,2011.0,5,"This paper proposes an automatic algorithm to generate an inverse kinematic (IK) skeleton for 3D characters. First, a curve skeleton is extracted from the volume inside the character mesh. The extracted curve skeleton is then analyzed and classified by comparing it with the characteristics of templates for real animals. The outcome of this classification step is an associated class for the given 3D character model, together with the meaning of each skeleton segment. Next, each bone of the template skeleton is located in the appropriate skeleton segment of the input skeleton graph. Unlike previous methods, this algorithm does not require an original 3D character model that is created with a restricted pose, topology and orientation. Furthermore, all stages of the process are completed without user intervention."
"WangNannan, GaoXinbo, TaoDacheng, LiXuelong",60bbd3971cfe9652e834911945aaf88e6e8cda1b,Face sketch-photo synthesis under multi-dictionary sparse representation framework,,2011.0,4,"National natural science foundation of china; chinese academy of science; microsoft research asia; xian institute of optics and precision mechanics of cas; anhui crearo technology co., ltd"
"G. Nataneli, P. Faloutsos",5a5b797e03154b5ad308b79d24c08d0a4f6674b7,Bringing Sketch Recognition into Your Hands,IEEE Computer Graphics and Applications,2011.0,3,"The paper mentions that a flexible method of sketch recognition works consistently across a variety of software and hardware platforms, including mobile devices such as the Nintendo DS and iPhone. An example application employs this method to drive facial expressions."
"Xi Luo, Wen-Jin Guo, Yongjin Liu, Cuixia Ma, D. Song",ad3481aaab1390aab2510023519d777cea4afb40,A words-of-interest model of sketch representation for image retrieval,,2011.0,3,"In this paper we propose a method for sketch-based image retrieval. Sketch is a magical medium which is capable of conveying semantic messages for user. It’s in accordance with user’s cognitive psychology to retrieve images with sketch. In order to narrow down the semantic gap between the user and the images in database, we preprocess all the images into sketches by the coherent line drawing algorithm. During the process of sketches extraction, saliency maps are used to filter out the redundant background information, while preserve the important semantic information. We use a variant of Words-of-Interest model to retrieve relevant images for the user according to the query. Words-of-Interest (WoI) model is based on Bag-ofvisual Words (BoW) model, which has been proven successfully for information retrieval. Bag-of-Words ignores the spatial relationships among visual words, which are important for sketch representation. Our method takes advantage of the spatial information of the query to select words of interest. Experimental results demonstrate that our sketch-based retrieval method achieves a good tradeoff between retrieval accuracy and semantic representation of users’ query."
"W. Sun, K. Kise",da8faa132e8cd7329dc8e0bddda2b5f08c0ab2f8,Similar Partial Copy Recognition for Line Drawings Using Concentric Multi-Region Histograms of Oriented Gradients,MVA,2011.0,3,"Since line drawings just employ simple lines to represent objects, similar drawings which represent the same objects can be created easily. Therefore, for protecting the copyright of line drawings, similar partial copy is a problem we have to consider. In this paper, we focus on similar partial copy recognition for line drawings and propose Concentric Multi-Region Histograms of Oriented Gradients (CMR-HOG) to increase the recognition rate. By the experiments of similar comic face recognition, the effectiveness of the proposed method has been proved."
"Upasna Dal, S. Abraham, Divyata Dal",6711bc07e7d34ae46ab3bf85fcf31bf353632223,A Facial Caricature Generation system using Adaptive Thresholding,2011 World Congress on Information and Communication Technologies,2011.0,2,"Automatic Facial Caricature Generation involves extracting the feature points and emphasizing the distinctive features of a particular face. The input face is compared to an “Average Face” based on their respective facial distance parameters. The deviations are then scaled by an “Exaggeration Rate”, thereby elevating the peculiarity of the input face. A novel approach of Adaptive Thresholding has been used for the extraction of feature points from the input face to manage the non-uniform illuminations of the input face."
"Chun-Cheng Lin, H. Yen, S. Poon, J. Fan",de9e5dfbe006af477901c74237c01db20b3ecbb5,Complexity analysis of balloon drawing for rooted trees,Theor. Comput. Sci.,2011.0,2,"In a balloon drawing of a tree, all the children under the same parent are placed on the circumference of the circle centered at their parent, and the radius of the circle centered at each node along any path from the root reflects the number of descendants associated with the node. Among various styles of tree drawings reported in the literature, the balloon drawing enjoys a desirable feature of displaying tree structures in a rather balanced fashion. For each internal node in a balloon drawing, the ray from the node to each of its children divides the wedge accommodating the subtree rooted at the child into two sub-wedges. Depending on whether the two sub-wedge angles are required to be identical or not, a balloon drawing can further be divided into two types: even sub-wedge and uneven sub-wedge types. In the most general case, for any internal node in the tree there are two dimensions of freedom that affect the quality of a balloon drawing: (1) altering the order in which the children of the node appear in the drawing, and (2) for the subtree rooted at each child of the node, flipping the two sub-wedges of the subtree. In this paper, we give a comprehensive complexity analysis for optimizing balloon drawings of rooted trees with respect to angular resolution, aspect ratio and standard deviation of angles under various drawing cases depending on whether the tree is of even or uneven sub-wedge type and whether (1) and (2) above are allowed. It turns out that some are NP-complete while others can be solved in polynomial time. We also derive approximation algorithms for those that are intractable in general."
T. Iwaniec,86be2e211531f2f23314597d24d81758c99f009c,Let the Beauty of Harmonic Analysis be Revealed Through Nonlinear PDEs; A Work of Art in Three Sketches,,2011.0,0,"Paraphrasing Luciano Pavarotti on music, let me say: ""Learning mathematics by only reading about it is like making love by e-mail."""
"Rui Hu, M. Barnard, J. Collomosse",f0d4c0c1d2c28a644cad086d54871918cf69907e,Gradient field descriptor for sketch based retrieval and localization,2010 IEEE International Conference on Image Processing,2010.0,146,"We present an image retrieval system driven by free-hand sketched queries depicting shape. We introduce Gradient Field HoG (GF-HOG) as a depiction invariant image descriptor, encapsulating local spatial structure in the sketch and facilitating efficient codebook based retrieval. We show improved retrieval accuracy over 3 leading descriptors (Self Similarity, SIFT, HoG) across two datasets (Flickr160, ETHZ extended objects), and explain how GF-HOG can be combined with RANSAC to localize sketched objects within relevant images. We also demonstrate a prototype sketch driven photo montage application based on our system."
"M. Eitz, Kristian Hildebrand, T. Boubekeur, M. Alexa",582c87ef9e98c24694c83eb03853eb96a4d84809,An evaluation of descriptors for large-scale image retrieval from sketched feature lines,Comput. Graph.,2010.0,130,"We address the problem of fast, large scale sketch-based image retrieval, searching in a database of over one million images. We show that current retrieval methods do not scale well towards large databases in the context of interactively supervised search and propose two different approaches for which we objectively evaluate that they significantly outperform existing approaches. The proposed descriptors are constructed such that both the full color image and the sketch undergo exactly the same preprocessing steps. We first search for an image with similar structure, analyzing gradient orientations. Then, best matching images are clustered based on dominant color distributions, to offset the lack of color-based decision during the initial search. Overall, the query results demonstrate that the system offers intuitive access to large image databases using a user-friendly sketch-and-browse interface."
"Wayne Zhang, Xiaogang Wang, X. Tang",0c472b5666f13918c451d5ae64a9c37389bd03a1,Lighting and Pose Robust Face Sketch Synthesis,ECCV,2010.0,99,"Automatic face sketch synthesis has important applications in law enforcement and digital entertainment. Although great progress has been made in recent years, previous methods only work under well controlled conditions and often fail when there are variations of lighting and pose. In this paper, we propose a robust algorithm for synthesizing a face sketch from a face photo taken under a different lighting condition and in a different pose than the training set. It synthesizes local sketch patches using a multiscale Markov Random Field (MRF) model. The robustness to lighting and pose variations is achieved in three steps. Firstly, shape priors specific to facial components are introduced to reduce artifacts and distortions caused by variations of lighting and pose. Secondly, new patch descriptors and metrics which are more robust to lighting variations are used to find candidates of sketch patches given a photo patch. Lastly, a smoothing term measuring both intensity compatibility and gradient compatibility is used to match neighboring sketch patches on the MRF network more effectively. The proposed approach significantly improves the performance of the state-of-the-art method. Its effectiveness is shown through experiments on the CUHK face sketch database and celebrity photos collected from the web."
"Daniel Dixon, M. Prasad, T. Hammond",51a53ae98b7c626a51062198827b7005b6514b20,iCanDraw: using sketch recognition and corrective feedback to assist a user in drawing human faces,CHI,2010.0,96,"When asked to draw, many people are hesitant because they consider themselves unable to draw well. This paper describes the first system for a computer to provide direction and feedback for assisting a user to draw a human face as accurately as possible from an image. Face recognition is first used to model the features of a human face in an image, which the user wishes to replicate. Novel sketch recognition algorithms were developed to use the information provided by the face recognition to evaluate the hand-drawn face. Two design iterations and user studies led to nine design principles for providing such instruction, presenting reference media, giving corrective feedback, and receiving actions from the user. The result is a proof-of-concept application that can guide a person through step-by-step instruction and generated feedback toward producing his/her own sketch of a human face in a reference image."
"S. Yoon, Maximilian Scherer, T. Schreck, Arjan Kuijper",5c39eab68d716872f08bf3648e6b5655b48d6851,Sketch-based 3D model retrieval using diffusion tensor fields of suggestive contours,ACM Multimedia,2010.0,95,"The number of available 3D models in various areas increase steadily. Effective methods to search for those 3D models by content, rather than textual annotations, are crucial. For this purpose, we propose a new approach for content based 3D model retrieval by hand-drawn sketch images. This approach to retrieve visually similar mesh models from a large database consists of three major steps: (1) suggestive contour renderings from different viewpoints to compare against the user drawn sketches; (2) descriptor computation by analyzing diffusion tensor fields of suggestive contour images or the query sketch respectively; (3) similarity measurement to retrieve the models and the most probable view-point from which a model was sketched. Our proposed sketch based 3D model retrieval system is very robust against variations of shape, pose or partial occlusion of the user draw sketches. Experimental results are presented and indicate the effectiveness of our approach for sketch-based 3D mode retrieval."
"Huamin Wang, Florian Hecht, R. Ramamoorthi, James F. O'Brien",40cce30e13e9f9325c9d6cdcad70423bdd2dfcfe,Example-based wrinkle synthesis for clothing animation,,2010.0,85,"This paper describes a method for animating the appearance of clothing, such as pants or a shirt, that fits closely to a figure's body. Compared to flowing cloth, such as loose dresses or capes, these types of garments involve nearly continuous collision contact and small wrinkles, that can be troublesome for traditional cloth simulation methods. Based on the observation that the wrinkles in close-fitting clothing behave in a predominantly kinematic fashion, we have developed an example-based wrinkle synthesis technique. Our method drives wrinkle generation from the pose of the figure's kinematic skeleton. This approach allows high quality clothing wrinkles to be combined with a coarse cloth simulation that computes the global and dynamic aspects of the clothing motion. While the combined results do not exactly match a high-resolution reference simulation, they do capture many of the characteristic fine-scale features and wrinkles. Further, the combined system runs at interactive rates, making it suitable for applications where high-resolution offline simulations would not be a viable option. The wrinkle synthesis method uses a precomputed database built by simulating the high-resolution clothing as the articulated figure is moved over a range of poses. In principle, the space of poses is exponential in the total number of degrees of freedom; however clothing wrinkles are primarily affected by the nearest joints, allowing each joint to be processed independently. During synthesis, mesh interpolation is used to consider the influence of multiple joints, and combined with a coarse simulation to produce the final results at interactive rates."
"J. M. Saavedra, B. Bustos",8424e3fd52ad5495659098c56df1c0deb8fb996f,An Improved Histogram of Edge Local Orientations for Sketch-Based Image Retrieval,DAGM-Symposium,2010.0,66,"Content-based image retrieval requires a natural image (e.g, a photo) as query, but the absence of such a query image is usually the reason for a search. An easy way to express the user query is using a line-based hand-drawing, a sketch, leading to the sketch-based image retrieval. Few authors have addressed image retrieval based on a sketch as query, and the current approaches still keep low performance under scale, translation, and rotation transformations. In this paper, we describe a method based on computing efficiently a histogram of edge local orientations that we call HELO. Our method is based on a strategy applied in the context of fingerprint processing. This descriptor is invariant to scale and translation transformations. To tackle the rotation problem, we apply two normalization processes, one using principal component analysis and the other using polar coordinates. Finally, we linearly combine two distance measures. Our results show that HELO significantly increases the retrieval effectiveness in comparison with the state of the art."
"Y. Zhang, C. McCullough, J. Sullins, C.R. Ross",f38409e401e3aae3852419a2fe7c4c7fb4ecc1b6,Hand-Drawn Face Sketch Recognition by Humans and a PCA-Based Algorithm for Forensic Applications,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",2010.0,64,"Because face sketches represent the original faces in a very concise yet recognizable form, they play an important role in criminal investigations, human visual perception, and face biometrics. In this paper, we compared the performances of humans and a principle component analysis (PCA)-based algorithm in recognizing face sketches. A total of 250 sketches of 50 subjects were involved. All of the sketches were drawn manually by five artists (each artist drew 50 sketches, one for each subject). The experiments were carried out by matching sketches in a probe set to photographs in a gallery set. This study resulted in the following findings: 1) A large interartist variation in terms of sketch recognition rate was observed; 2) fusion of the sketches drawn by different artists significantly improved the recognition accuracy of both humans and the algorithm; 3) human performance seems mildly correlated to that of PCA algorithm; 4) humans performed better in recognizing the caricature-like sketches that show various degrees of geometrical distortion or deviation, given the particular data set used; 5) score level fusion with the sum rule worked well in combining sketches, at least for a small number of artists; and 6) the algorithm was superior with the sketches of less distinctive features, while humans seemed more efficient in handling tonality (or pigmentation) cues of the sketches that were not processed with advanced transformation functions."
"L. Chang, Mingquan Zhou, Yanjun Han, Xiaoming Deng",4d52fae5b1856b35338217b6ff7dd3d8f9be9b29,Face Sketch Synthesis via Sparse Representation,2010 20th International Conference on Pattern Recognition,2010.0,62,"Face sketch synthesis with a photo is challenging due to that the psychological mechanism of sketch generation is difficult to be expressed precisely by rules. Current learning-based sketch synthesis methods concentrate on learning the rules by optimizing cost functions with low-level image features. In this paper, a new face sketch synthesis method is presented, which is inspired by recent advances in sparse signal representation and neuroscience that human brain probably perceives images using high-level features which are sparse. Sparse representations are desired in sketch synthesis due to that sparseness can adaptively selects the most relevant samples which give best representations of the input photo. We assume that the face photo patch and its corresponding sketch patch follow the same sparse representation. In the feature extraction, we select succinct high-level features by using the sparse coding technique, and in the sketch synthesis process each sketch patch is synthesized with respect to high-level features by solving an $l_1$-norm optimization. Experiments have been given on CUHK database to show that our method can resemble the true sketch fairly well."
"P. Sousa, Manuel J. Fonseca",fc431e64757acc1829769569e1124363f3c19ac8,Sketch-based retrieval of drawings using spatial proximity,J. Vis. Lang. Comput.,2010.0,52,"Currently, there are large collections of drawings from which users can select the desired ones to insert in their documents. However, to locate a particular drawing among thousands is not easy. In our prior work we proposed an approach to index and retrieve vector drawings by content, using topological and geometric information automatically extracted from figures. In this paper, we present a new approach to enrich the topological information by integrating spatial proximity in the topology graph, through the use of weights in adjacency links. Additionally, we developed a web search engine for clip art drawings, where we included the new technique. Experimental evaluation reveals that the use of topological proximity results in better retrieval results than topology alone. However, the increase in precision was not as high as we expected. To understand why, we analyzed sketched queries performed by users in previous experimental sessions and we present here the achieved conclusions."
"Bing Xiao, Xinbo Gao, D. Tao, Yuan Yuan, J. Li",2546f055c217055cdd140a55d812036b46b63e38,Photo-sketch synthesis and recognition based on subspace learning,Neurocomputing,2010.0,51,"This paper aims to reducing difference between sketches and photos by synthesizing sketches from photos, and vice versa, and then performing sketch-sketch/photo-photo recognition with subspace learning based methods. Pseudo-sketch/pseudo-photo patches are synthesized with embedded hidden Markov model. Because these patches are assembled by averaging their overlapping area in most of the local strategy based methods, which leads to blurring effect to the resulted pseudo-sketch/pseudo-photo, we integrate the patches with image quilting. Experiments are carried out to demonstrate that the proposed method is effective to produce pseudo-sketch/pseudo-photo with high quality and achieve promising recognition results."
"S. Bagon, Or Brostovski, M. Galun, M. Irani",329641b3194aa238ce3ace04f1c01e1562536aad,Detecting and sketching the common,2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2010.0,47,"Given very few images containing a common object of interest under severe variations in appearance, we detect the common object and provide a compact visual representation of that object, depicted by a binary sketch. Our algorithm is composed of two stages: (i) Detect a mutually common (yet non-trivial) ensemble of ‘self-similarity descriptors’ shared by all the input images. (ii) Having found such a mutually common ensemble, ‘invert’ it to generate a compact sketch which best represents this ensemble. This provides a simple and compact visual representation of the common object, while eliminating the background clutter of the query images. It can be obtained from very few query images. Such clean sketches may be useful for detection, retrieval, recognition, co-segmentation, and for artistic graphical purposes."
"T. Herman, K. Arai",684524e2a8c89810655f02e626f6d16e10a5f37b,Automatic E-Comic Content Adaptation,,2010.0,41,"Reading digital comic on mobile phone is demanding now. Instead of create a new mobile comic contents, adaptation of the existing digital comic web portal is valuable. In this paper, we proposed an automatic e-comic mobile content adaptation method for automatically create mobile comic content from existing digital comic website portal. Automatic e-comic content adaptation is based on our comic frame extraction method combine with additional process to extract comic balloon and text from digital comic page. The proposed method work as a content adaptation intermediary proxy server application, while generating a Comic XML file as an input source for mobile phone to render a specific mobile comic contents. Our proposed method is an effective and efficient method for real time implementation of reading e-comic comparing to other methods. Experimental results show that our proposed method has 100% accuracy of flat comic frame extraction, 91.48% accuracy of non-flat comic frame extraction, and about 90% processing time faster than previous method."
"M. Eitz, Kristian Hildebrand, T. Boubekeur, M. Alexa",395f4ab6038b4f5fd42d590eab3572f7c126f5bc,Sketch-based 3D shape retrieval,SIGGRAPH '10,2010.0,34,"As large collections of 3D models are starting to become as common as public image collections, the need arises to quickly locate models in such collections. Models are often insufficiently annotated such that a keyword based search is not promising. Our approach for content based searching of 3D models relies entirely on visual analysis and is based on the observation that a large part of our perception of shapes stems from their salient features, usually captured by dominant lines in their display. Recent research on such feature lines has shown that 1) people mostly draw the same lines when asked to depict a certain model and 2) the shape of an object is well represented by the set of feature lines generated by recent NPR line drawing algorithms [Cole et al. 2009]. Consequently, we suggest an image based approach for 3D shape retrieval, exploiting the similarity of human sketches and the results of current line drawing algorithms. Our search engine takes a sketch of the desired model drawn by a user as the input and compares this sketch to a set of line drawings automatically generated for each of the models in the collection."
"S. Thuillier, P. Manach, L. Menezes",2f08d537c4c136bb1eb140ecf0e00a8a871daac9,Occurence of strain path changes in a two-stage deep drawing process,,2010.0,34,"This work is dedicated to the influence of the strain path change on the prediction of the deep-drawing of cylindrical cups. The aim of this work is to highlight the influence of the hardening model on the numerical prediction of the applied punch load, in the case of the 1999 Numisheet benchmark of the reverse re-drawing of cylindrical cups. The forming process consists in drawing a circular blank into a cylindrical cup in two stages, firstly in one direction and then in the opposite one. Three-dimensional numerical simulations of the process were performed using the Hill’s 1948 yield criterion associated with three different hardening laws: a purely isotropic hardening, a mixed hardening with both isotropic and non-linear kinematic contributions and a dislocation-based hardening model, which takes into account transient behaviors recorded during strain path changes. The experimental setup is presented as well as results obtained with a mild steel. Numerical simulation results obtained with the three hardening models are compared with experimental ones. It is shown that there is a significant influence of the hardening model in the second stage, when important strain path changes occur during the process."
"K. Arai, Herman Tolle",d10db1694aedd2f5c144f3171f61dd844b02f3cc,Method for Automatic E-Comic Scene Frame Extraction for Reading Comic on Mobile Devices,2010 Seventh International Conference on Information Technology: New Generations,2010.0,27,"A method for automatic e-comic scene frame extraction is proposed for displaying large scale of comic scenes onto relatively small size of display screen such as mobile devices. In line with the rapid development of mobile devices, reading comic in small screen mobile devices is also demanded and required. The challenge in providing e-comics for small screen is how to separate comic scene frames and display it in the right order to read. We propose Automatic E-Comic Frame Extraction (ACFE) for extraction of scene frames from a digital comic page automatically. ACFE is based on the blob extraction method using connected component labeling algorithm, together with a filter combination pre-processing and efficient method for detection of line between frames. Experimental results show that 91.483 percent of 634 pages in 5 digital comics are successfully extracted into scene frames by the proposed method."
"S. Sadimon, M. Sunar, D. Mohamad, H. Haron",db701407fef901a1bfed6b692760f913a67c3b9b,Computer Generated Caricature: A Survey,2010 International Conference on Cyberworlds,2010.0,27,"Caricature is a pictorial representation of a person or subject in summarizing way by exaggerating the most distinctive features and simplifies the common features in order to make that subject different from others and at the same time, preserve the likeness of the subject. Computer Generated Caricature is developed in order to assist the user in producing caricature automatically or semi-automatically. It is derived from the rapid advance in computer graphics and computer vision and introduced as a part of computer graphics’ non-photo realistic rendering technologies as well. Recently, Computer Generated Caricature becomes particularly interesting research topic due to the advantageous features of privacy, security, simplification, amusement and their explosive emergent real-world application such as in magazine, digital entertainment, Internet and mobile application. On the basis of the previous facts, this paper surveys the uses of caricature in variety of applications, theories and rules in the art of drawing caricature, how these theories are simulated in the development of caricature generation system and the current research trend in this field. Computer generated caricature can be divided into two main categories based on their input data type: human centered approach and image processing approach. Next, process of generating caricature from input photo is explained briefly. It also reported the state of the art techniques in generating caricature by classifying it into four approaches: interactive, regularity-based, learning-based and predefined database of caricature illustration. Lastly, this paper will discuss relevant issues, problems and several promising direction of future research."
"C. Tu, J. Lien",0197dd8c5ec045ec186193f6ab232da184ae076f,Automatic Location of Facial Feature Points and Synthesis of Facial Sketches Using Direct Combined Model,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",2010.0,26,"Automatically locating multiple feature points (i.e., the shape) in a facial image and then synthesizing the corresponding facial sketch are highly challenging since facial images typically exhibit a wide range of poses, expressions, and scales, and have differing degrees of illumination and/or occlusion. When the facial sketches are to be synthesized in the unique sketching style of a particular artist, the problem becomes even more complex. To resolve these problems, this paper develops an automatic facial sketch synthesis system based on a novel direct combined model (DCM) algorithm. The proposed system executes three cascaded procedures, namely, (1) synthesis of the facial shape from the input texture information (i.e., the facial image); (2) synthesis of the exaggerated facial shape from the synthesized facial shape; and (3) synthesis of a sketch from the original input image and the synthesized exaggerated shape. Previous proposals for reconstructing facial shapes and synthesizing the corresponding facial sketches are heavily reliant on the quality of the texture reconstruction results, which, in turn, are highly sensitive to occlusion and lighting effects in the input image. However, the DCM approach proposed in this paper accurately reconstructs the facial shape and then produces lifelike synthesized facial sketches without the need to recover occluded feature points or to restore the texture information lost as a result of unfavorable lighting conditions. Moreover, the DCM approach is capable of synthesizing facial sketches from input images with a wide variety of facial poses, gaze directions, and facial expressions even when such images are not included within the original training data set."
"M. Eitz, Kristian Hildebrand, T. Boubekeur, M. Alexa",f708a10770033bbc1fd132ac75c508e77d7e5d5a,Sketch-based 3 D shape retrieval,,2010.0,23,"As large collections of 3D models are starting to become as common as public image collections, the need arises to quickly locate models in such collections. Models are often insufficiently annotated such that a keyword based search is not promising. Our approach for content based searching of 3D models relies entirely on visual analysis and is based on the observation that a large part of our perception of shapes stems from their salient features, usually captured by dominant lines in their display. Recent research on such feature lines has shown that 1) people mostly draw the same lines when asked to depict a certain model and 2) the shape of an object is well represented by the set of feature lines generated by recent NPR line drawing algorithms [Cole et al. 2009]. Consequently, we suggest an image based approach for 3D shape retrieval, exploiting the similarity of human sketches and the results of current line drawing algorithms. Our search engine takes a sketch of the desired model drawn by a user as the input and compares this sketch to a set of line drawings automatically generated for each of the models in the collection."
"P. Taele, T. Hammond",a3ee2a73b04ab8b40af8b3e52d29854e236e1e11,LAMPS: A sketch recognition-based teaching tool for Mandarin Phonetic Symbols I,J. Vis. Lang. Comput.,2010.0,23,"The non-Romanized Mandarin Phonetic Symbols I (MPS1) system is a highly advantageous phonetic system for native English users studying Chinese Mandarin to learn, yet its steep initial learning curve discourages language programs to instead adopt Romanized phonetic systems. Computer-assisted language instruction (CALI) can greatly reduce this learning curve, in order to enable students to sooner benefit from the long-term advantages presented in MPS1 usage during the course of Chinese Mandarin study. Unfortunately, the technologies surrounding existing online handwriting recognition algorithms and CALI applications are insufficient in providing a ''dynamic'' counterpart to traditional paper-based workbooks employed in the classroom setting. In this paper, we describe our sketch recognition-based LAMPS system for teaching MPS1 by emulating the naturalness and realism of paper-based workbooks, while extending their functionality with human instructor-level critique and assessment at an automated level."
"Rui Hu, J. Collomosse",f0fcaff569fce1405b4b2a11beeab46706b1bc26,Motion-sketch Based Video Retrieval Using a Trellis Levenshtein Distance,2010 20th International Conference on Pattern Recognition,2010.0,19,"We present a fast technique for retrieving video clips using free-hand sketched queries. Visual keypoints within each video are detected and tracked to form short trajectories, which are clustered to form a set of space-time tokens summarising video content. A Viterbi process matches a space-time graph of tokens to a description of colour and motion extracted from the query sketch. Inaccuracies in the sketched query are ameliorated by computing path cost using a Levenshtein (edit) distance. We evaluate over datasets of sports footage."
"W. Sun, K. Kise",913b47c1ed8072b1248ed61a96dc3157d7c229a6,Similar Partial Copy Detection of Line Drawings Using a Cascade Classifier and Feature Matching,ICWF,2010.0,19,"Copyright protection of image publications is an important task of forensics. In this paper, we focus on line drawings, which are represented by lines in monochrome. Since partial copies and similar copies are always applied in plagiarisms of line drawings, we propose combining the technique of object detection and image retrieval to detect similar partial copies from suspicious images: first, detecting regions of interest (ROIs) by a cascade classifier; then, locate the corresponding source parts from copyrighted images using a feature matching method. The experimental results have proved the effectiveness of proposed method for detecting similar partial copies from complex backgrounds."
"Daisuke Ishii, Hiroshi Watanabe",2388660f2e3b2b3e9f87aaa38a4b45e085afea84,A STUDY ON FRAME POSITION DETECTION OF DIGITIZED COMICS IMAGES,,2010.0,13,"Recently, comic is read not only through paper media, but also digital devices i.e. personal computer, cell phone, epaper reader and etc. Thus, the display environment is quite different at each device. Comic consists of many frames that have text, character and illustrations. Moreover, the reading order of comic is defined by frames. Therefore, in order to provide user centric presentation functions for various types of digital devices, and facilitate the developments of other high level contents application i.e. auto text extraction, copyright protection system and so on, accurate frame shape extraction is needed. There are many types of document analysis methods which utilized for general documents. For example utilizing histograms, connected components, density of pixels and so on are proposed [1-3]. However, comics have characteristics, which are different from other general document. For instance, unlike regular document structure, comics have free arrangement where some content protrusion from the frame borders is allowable. Some comic frame separation methods have been proposed. Tanaka et al. have proposed a comic segmentation method by iterative separation [4]. We have extended this iterative separation method utilizing consistency of density gradient, and proposed frame corner detection method [5-6]. However, most of results by frame separation method have redundant blanks. Moreover, results of frame corner detection cannot be used alone for determining frame shapes. In this paper, we propose a frame position detection method that utilizes the result of frame separation and frame corner detection for comic images."
"Mohamed R. Amer, R. Raich, S. Todorovic",14bd8f107aba046d309f2738d95a391c36a6cdc3,Monocular Extraction of 2.1D Sketch,ICIP,2010.0,13,"The 2.1D sketch is a layered representation of occluding and occluded surfaces of the scene. Extracting the 2.1D sketch from a single image is a difficult and important problem arising in many applications. We present a fast and robust algorithm that uses boundaries of image regions and T-junctions, as important visual cues about the scene structure, to estimate the scene layers. The estimation is a quadratic optimization with hinge-loss based constraints, so the 2.1D sketch is smooth in all image areas except on image contours, and image regions forming “stems” of the T-junctions correspond to occluded surfaces in the scene. Quantitative and qualitative results on challenging, real-world images—namely, Stanford depthmap and Berkeley segmentation dataset—demonstrate high accuracy, efficiency, and robustness of our approach."
H. Tobita,a7f236582be3aee2d83c6b0eb34b81d9fffd3e23,Comic Engine: interactive system for creating and browsing comic books with attention cuing,AVI,2010.0,11,"Comic Engine is an interactive comic creation system that uses a unique Attention Cuing technique. Our system focuses on both comic creation and comic browsing. To enhance both functions, we use a unique Attention Cuing technique, which is a kind of comic grammar, and is used to control the reader's viewpoint by professional comic creators. This technique is common for comic creators; therefore, we integrated it with comic creation to create more practical comic books. Both functions based on Attention Cuing are simple. However, users can depict a wide variety of comic content using simple interactions of the graphical user interface. We describe a prototype of the Comic Engine system, focusing on the design features and efficiencies."
"J. Johnston, T. Hammond",b701564456062d46e9c061e2ff1b54a0651ef583,Computing Confidence Values for Geometric Constraints for use in Sketch Recognition,SBIM,2010.0,10,"Geometric constraints are used by many sketch recognition systems to perform high-level assembly of components of a sketch into semantic structures. However, with a few notable exceptions, most of the current recognition systems do not have constraints that use real-valued notions of confidence. We discuss methods for assigning confidence values to different kinds of constraints. We show how these confidence values equate to user perception, how they can be used to balance speed and accuracy in recognition algorithms, and how they can be used to assign confidence values to the high-level shapes they are used to construct. We use these constraints to extend the LADDER shape definition language in a system that recognizes 5,900 hand-drawn examples of 485 different military course-of-action diagrams at an accuracy of 89.9%."
"Qingzheng Zheng, Frederick W. B. Li, Rynson W. H. Lau",347dade2e1e72c7daedef337c59d58705be5b6e1,Sketching-Based Skeleton Generation,2010 3rd IEEE International Conference on Ubi-Media Computing,2010.0,9,"Articulated character animation can be performed by manually creating and rigging a skeleton into an unfolded 3D object. Such tasks are not trivial, as it requires a substantial amount of training and practices. Although methods have been proposed to help automatic extraction of skeleton structure, they may not guarantee that the resulting skeleton can help produce desired animations according to user intention. In this paper, we present a sketching-based skeleton generation method suitable for use in the mobile environment. This method takes user sketching as an input, and based on the mesh segmentation result of a 3D object, it estimates a skeleton for articulated character animation. Results show that our method can produce better skeletons in terms of joint positions and topological structure."
"Lulin Chen, Guofeng Qin",020f815b2c5d01151065104736cd5b03262589be,Optimization of the collision detection technology in 3D skeleton animation,2010 International Conference on Computer Application and System Modeling (ICCASM 2010),2010.0,8,"Collision detection is one of the key research areas in computer simulation and virtual reality, and bounding box-based collision detection algorithm is a relatively convenient and effective way. In this paper, in order to overcome the shortcomings of the traditional bounding box algorithm, a series of optimization methods are listed. Experimental results show that the optimized bounding box collision detection algorithm has effectively improved the accuracy and the speed of collision detection, and it has also enhanced the interaction and real-time of the system."
"Takamasa Tanaka, F. Toyama, J. Miyamichi, K. Shoji",c09ba5cda8f7e7d8fa3c480f8e93130939278a85,Detection and Classification of Speech Balloons in Comic Images,,2010.0,8,"Today, the demand is increasing for comic contents on cellular phones and speech software for the visually impaired. When speech software reads aloud a comic character's speech, it is useful for both the visually impaired and unimpaired to have the character's voice injected with his/her feeling, which is inferred from types of speech balloons. As a result, comic contents come to life. In this research, a method has been developed to detect speech balloons on comic pages and then classify them into four types. In this method, speech balloon candidates are extracted based on speech text information detected by AdaBoost, and then speech balloons are selected and classified using SVM. Experimental results show that the proposed method successfully detected and classified 86 percent of 2844 speech balloons."
"Dominik Rausch, I. Assenmacher, T. Kuhlen",46924791d25cfaf27b3da4bd1f917f184d8892c7,3D Sketch Recognition for Interaction in Virtual Environments,VRIPHYS,2010.0,7,"We present a comprehensive 3D sketch recognition framework for interaction within Virtual Environments that allows to trigger commands by drawing symbols, which are recognized by a multi-level analysis. It proceeds in three steps: The segmentation partitions each input line into meaningful segments, which are then recognized as a primitive shape, and finally analyzed as a whole sketch by a symbol matching step. The whole framework is configurable over well-defined interfaces, utilizing a fuzzy logic algorithm for primitive shape learning and a textual description language to define compound symbols. It allows an individualized interaction approach that can be used without much training and provides a good balance between abstraction and intuition. We show the real-time applicability of our approach by performance measurements."
"Xingyu Gao, Jingye Zhou, Zhenyu Chen, Yiqiang Chen",6317a749fe29467cdb36b0b3cef492940ee6beb9,Automatic Generation of Pencil Sketch for 2D Images,ICASSP,2010.0,7,"Non-Photo-Realistic Rendering (NPR) is becoming increasingly important research topic in computer graphics and image processing. This paper puts forward a novel method for automatically generating a pencil sketch from a real 2D color image in non-photo-realistic rendering. First of all, the edge of the color image is detected by Sobel operator. Secondly, the color image is sharpened by Unsharp Mask (USM), then color scaling is used to get an image with radial and edge details. Furthermore, the original image is divided into many meaningful regions using an efficient method of image segmentation, then the texture direction is determined by Fourier transform and shape feature. To render better effects of illumination and local texture of pencil sketch, the Line Integral Convolution (LIC) algorithm is applied and combined color scaling and white noise image. At last, the pencil sketch is created and the generation results from the superposition of the edge, the USM image and the texture. The experimental results prove that our approach could efficiently generate more obvious edge, more natural tone and more real texture than existed methods."
"Xinyu Wang, Huosheng Xu, Heng Wang",33ae88b51360909e1b4bbe403859217d73efd5a9,On-line sketch recognition for course of action diagrams,2010 IEEE International Conference on Mechatronics and Automation,2010.0,6,"In this paper, we present a robust method of sketch recognition for course of action (COA) diagrams. User input is through free-hand sketching. COA symbols are recognized incrementally and the informal sketching input is replaced with formal vector graphs or images of the symbols. Multi-stroke COA symbols are divided into temporally continuous uni-stroke shapes. Firstly, it removes over-crossed end part of the uni-stroke shapes. Then, it extracts invariant geometric features of convex hull, largest-area inscribed and smallest-area enclosing polygons, perimeter and area ratios, and distinctive features of the concave and the open ended. Thirdly, the uni-stroke shapes are recognized by support vector machines (SVM). Fourthly, an intermediate feature recognizer is used to recognize shapes of intermediate complexity such as a dashed line, which improves sketch recognition performance in the COA domain. Finally, the system uses the LADDER shape definition language to represent the geometric properties of shapes, and is capable of recognizing common COA symbols of multi-stroke sketches and gesture commands with a recognition accuracy of more than 98%."
"S. F. Wang, S. Lai",2de9e64be2ac5f5f923478ac7bd14f847db6a765,Manifold‐Based 3D Face Caricature Generation with Individualized Facial Feature Extraction,Comput. Graph. Forum,2010.0,5,"Caricature is an interesting art to express exaggerated views of different persons and things through drawing. The face caricature is popular and widely used for different applications. To do this, we have to properly extract unique/specialized features of a person's face. A person's facial feature not only depends on his/her natural appearance, but also the associated expression style. Therefore, we would like to extract the neutural facial features and personal expression style for different applicaions. In this paper, we represent the 3D neutral face models in BU–3DFE database by sparse signal decomposition in the training phase. With this decomposition, the sparse training data can be used for robust linear subspace modeling of public faces. For an input 3D face model, we fit the model and decompose the 3D model geometry into a neutral face and the expression deformation separately. The neutral geomertry can be further decomposed into public face and individualized facial feature. We exaggerate the facial features and the expressions by estimating the probability on the corresponding manifold. The public face, the exaggerated facial features and the exaggerated expression are combined to synthesize a 3D caricature for a 3D face model. The proposed algorithm is automatic and can effectively extract the individualized facial features from an input 3D face model to create 3D face caricature."
"Ney Renau-Ferrer, Céline Rémi",5855cb4ab5fa870df6132cccf7f90ad0994dc3f3,A Method For Visuo-Spatial Classification Of Freehand Shapes Freely Sketched,IPCV,2010.0,5,"We present the principle and the main steps of a new method for the visuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial analysis is a necessary step for multi-level analysis. Multi-level analysis simultaneously allows classification, comparison or clustering of the constituent parts of a pattern according to their visuo-spatial properties, their procedural strategies, their structural or temporal parameters, or any combination of two or more of those parameters. The first results provided by this method concern the comparison of sketches to some perfect patterns of simple geometrical figures and the measure of dissimilarity between real sketches. The mean rates of good decision higher than 95% obtained are promising in both cases."
Nicolaos Matsakis,cd160f1a344bd03e7a37a7791ec8e620b477008a,Transforming a random graph drawing into a Lombardi drawing,ArXiv,2010.0,5,"The visualization of any graph plays important role in various aspects, such as graph drawing software. Complex systems (like large databases or networks) that have a graph structure should be properly visualized in order to avoid obfuscation. One way to provide an aesthetic improvement to a graph visualization is to apply a force-directed drawing algorithm to it. This method, that emerged in the 60's views graphs as spring systems that exert forces (repulsive or attractive) to the nodes. 
A Lombardi drawing of a graph is a drawing where the edges are drawn as circular arcs (straight edges are considered circular arcs of infinite radius) with perfect angular resolution. This means, that consecutive edges around a vertex are equally spaced around it. In other words, each angle between the tangents of two consecutive edges is equal to $2\pi/d$ where d is the degree of that specific vertex. The requirement of using circular edges in graphs when we want to provide perfect angular resolution is necessary, since even cycle graphs cannot be drawn with straight edges when perfect angular resolution is needed. 
In this survey, we provide an algorithm that takes as input a random drawing of a graph and provides its Lombardi drawing, giving a proper visualization of the graph."
"Sudip Biswas, Debajyoti Mondal, Rahnuma Islam Nishat, Md. Saidur Rahman",6e6c86cc740496283680e926ab5abb9f1e20f720,Minimum-Segment Convex Drawings of 3-Connected Cubic Plane Graphs,COCOON,2010.0,4,"A convex drawing of a plane graph G is a plane drawing of G, where each vertex is drawn as a point, each edge is drawn as a straight line segment and each face is drawn as a convex polygon. A maximal segment is a drawing of a maximal set of edges that form a straight line segment. A minimum-segment convex drawing of G is a convex drawing of G where the number of maximal segments is the minimum among all possible convex drawings of G.I n this paper, we present al inear- time algorithm to obtain a minimum-segment convex drawing Γ of a 3-connected cubic plane graph G of n vertices, where the drawing is not a grid drawing. We also give a linear-time algorithm to obtain a convex grid drawing of G on an ( n +1 )× ( n 2 + 1) grid with at mostsn +1 maximal segments, where sn = n 2 + 3 is the lower bound on the number"
Daniel Dixon,0a8df0092d4bf438d2ffea59216ee966ee7b4821,A Methodology for Using Assistive Sketch Recognition For Improving a Person’s Ability to Draw,,2010.0,4,"A Methodology Using Assistive Sketch Recognition for Improving a Person’s Ability to Draw. (December 2009) Daniel Meyer Dixon, B.S., Texas A&M University Chair of Advisory Committee: Dr. Tracy Hammond When asked to draw, most people are hesitant because they believe themselves unable to draw well. A human instructor can teach students how to draw by encouraging them to practice established drawing techniques and by providing personal and directed feedback to foster their artistic intuition and perception. This thesis describes the first methodology for a computer application to mimic a human instructor by providing direction and feedback to assist a student in drawing a human face from a photograph. Nine design principles were discovered and developed for providing such instruction, presenting reference media, giving corrective feedback, and receiving actions from the student. Face recognition is used to model the human face in a photograph so that sketch recognition can map a drawing to the model and evaluate it. New sketch recognition techniques and algorithms were created in order to perform sketch understanding on such subjective content. After two iterations of development and user studies for this methodology, the result is a computer application that can guide a person toward producing his/her own sketch of a human model in a reference photograph with step-bystep instruction and computer generated feedback."
"T. Yang, S. Lai",b471cc86b2260ad515d49b0fca6a366354c1983f,A learning-based system for generating exaggerative caricature from face images with expression,"2010 IEEE International Conference on Acoustics, Speech and Signal Processing",2010.0,3,"In this paper, we propose a learning-based system for generating exaggerative caricatures with expression. Most of the previous works can only deal with frontal face images with neutral expression without glasses or hats, and are unable to apply more than one drawing prototype which was learned from the caricatures drawn by one single cartoonist at a time. The proposed caricature generation system exaggerates face images with expressions and learns the drawing prototypes from training data as well. Experimental results show that our system can capture the features selected by the artist and exaggerate them in similar ways."
"M. Eitz, Kristian Hildebrand, T. Boubekeur, M. Alexa",0531a8440455a1a999f10e2750c69de42d76d3fd,A descriptor for large scale image retrieval based on sketched feature lines,SBIM '09,2009.0,112,"We address the problem of large scale sketch based image retrieval, searching in a database of over a million images. The search is based on a descriptor that elegantly addresses the asymmetry between the binary user sketch on the one hand and the full color image on the other hand. The proposed descriptor is constructed such that both the full color image and the sketch undergo exactly the same preprocessing steps. We also design an adapted version of the descriptor proposed for MPEG-7 and compare their performance on a database of 1.5 million images. Best matching images are clustered based on color histograms, to offset the lacking color in the query. Overall, the query results demonstrate that the system allows users an intuitive access to large image databases."
"Jianyuan Min, Y. Chen, Jinxiang Chai",99fa16e4a4031e69f9459d52e4675b528c8cc822,Interactive generation of human animation with deformable motion models,TOGS,2009.0,104,"This article presents a new motion model deformable motion models for human motion modeling and synthesis. Our key idea is to apply statistical analysis techniques to a set of precaptured human motion data and construct a low-dimensional deformable motion model of the form x = M(α, γ), where the deformable parameters α and γ control the motion's geometric and timing variations, respectively. To generate a desired animation, we continuously adjust the deformable parameters' values to match various forms of user-specified constraints. Mathematically, we formulate the constraint-based motion synthesis problem in a Maximum A Posteriori (MAP) framework by estimating the most likely deformable parameters from the user's input. We demonstrate the power and flexibility of our approach by exploring two interactive and easy-to-use interfaces for human motion generation: direct manipulation interfaces and sketching interfaces."
Armando Solar-Lezama,2d38fad1c1d1b9cdd0ca8e0f3061b32fce12e987,The Sketching Approach to Program Synthesis,APLAS,2009.0,95,"Sketching is a new form of localized software synthesis that aims to bridge the gap between a programmer's high-level insights about a problem and the computer's ability to manage low-level details. In sketching, the programmer uses partial programs to describe the desired implementation strategy , and leaves the low-level details of the implementation to an automated synthesis procedure. This paper describes the sketching approach to program synthesis, including the details of the Sketch language and synthesizer. The paper will then describe some of the techniques that make synthesis from sketches possible, and will close with a brief discussion of open problems in programmer guided synthesis."
"D. Sýkora, J. Dingliana, S. Collins",8fc784e217e103352616638860c8e6cbb1ffc2f3,LazyBrush: Flexible Painting Tool for Hand‐drawn Cartoons,Comput. Graph. Forum,2009.0,81,"In this paper we present LazyBrush, a novel interactive tool for painting hand‐made cartoon drawings and animations. Its key advantage is simplicity and flexibility. As opposed to previous custom tailored approaches [ SBv05 , QWH06 ] LazyBrush does not rely on style specific features such as homogenous regions or pattern continuity yet still offers comparable or even less manual effort for a broad class of drawing styles. In addition to this, it is not sensitive to imprecise placement of color strokes which makes painting less tedious and brings significant time savings in the context cartoon animation. LazyBrush originally stems from requirements analysis carried out with professional ink‐and‐paint illustrators who established a list of useful features for an ideal painting tool. We incorporate this list into an optimization framework leading to a variant of Potts energy with several interesting theoretical properties. We show how to minimize it efficiently and demonstrate its usefulness in various practical scenarios including the ink‐and‐paint production pipeline."
"Tom Y. Ouyang, Randall Davis",7877446f51cc24a4fe482bb176833fd55e6fb85e,A Visual Approach to Sketched Symbol Recognition,IJCAI,2009.0,78,"There is increasing interest in building systems that can automatically interpret hand-drawn sketches. However, many challenges remain in terms of recognition accuracy, robustness to different drawing styles, and ability to generalize across multiple domains. To address these challenges, we propose a new approach to sketched symbol recognition that focuses on the visual appearance of the symbols. This allows us to better handle the range of visual and stroke-level variations found in freehand drawings. We also present a new symbol classifier that is computationally efficient and invariant to rotation and local deformations. We show that our method exceeds state-of-the-art performance on all three domains we evaluated, including handwritten digits, PowerPoint shapes, and electrical circuit symbols."
"Bing Xiao, Xinbo Gao, D. Tao, Xuelong Li",9af9430bb5fffb0440bcbc52d9f74a073ad80427,A new approach for face recognition by sketches in photos,Signal Process.,2009.0,73,"Face recognition by sketches in photos remains a challenging task. Unlike the existing sketch-photo recognition methods, which convert a photo into sketch and then perform the sketch-photo recognition through sketch-sketch recognition, this paper devotes to synthesizing a photo from the sketch and transforming the sketch-photo recognition to photo-photo recognition to achieve better performance in mixture pattern recognition. The contribution of this paper mainly focuses on two aspects: (1) in view of that there are no many research findings of sketch-photo recognition based on the pseudo-photo synthesis and the existing methods require a large set of training samples, which is nearly impossible to achieve for the high cost of sketch acquisition, we make use of embedded hidden Markov model (EHMM), which can learn the nonlinearity of sketch-photo pair with less training samples, to produce pseudo-photos in terms of sketches; and (2) photos and sketches are divided into patches and pseudo-photo is generated by combining pseudo-photo patches, which makes pseudo-photo more recognizable. Experimental results demonstrate that the newly proposed method is effective to identify face sketches in photo set."
J. Tchalenko,1090634b3ae1e39fbed4e0b9abd4348c1624a23a,Segmentation and accuracy in copying and drawing: Experts and beginners,Vision Research,2009.0,55,"As part of an ongoing investigation into real-world copying and drawing, I recorded the eye-hand drawing strategies of 16 subjects with drawing experiences ranging from expert to novice while they copied a line drawing of a standing nude. The experts produced accurate copies whereas all the beginners produced marked inaccuracies of overall scaling, proportion and shape. Analysis of eye and hand movements showed that the experts alone segmented the original drawing into simple line sections that were copied one at a time using a direct eye-hand strategy not requiring intermediary encoding to visual memory. The results suggest that segmentation into simple lines defines the task-specific process of accurate copying, and that this process is restricted to experts, i.e. acquired through training and practice. Additional preliminary tests also suggest that a similar process may apply to drawing a model from life."
"J. Collomosse, Graham McNeill, Yu Qian",aa57815f071551828e30ad67609c84d0ff2686f1,Storyboard sketches for Content Based Video Retrieval,2009 IEEE 12th International Conference on Computer Vision,2009.0,49,"We present a novel Content Based Video Retrieval (CBVR) system, driven by free-hand sketch queries depicting both objects and their movement (via dynamic cues; streak-lines and arrows). Our main contribution is a probabilistic model of video clips (based on Linear Dynamical Systems), leading to an algorithm for matching descriptions of sketched objects to video. We demonstrate our model fitting to clips under static and moving camera conditions, exhibiting linear and oscillatory motion. We evaluate retrieval on two real video data sets, and on a video data set exhibiting controlled variation in shape, color, motion and clutter."
"P. Sousa, Manuel J. Fonseca",5c422f34c4e9f54d33aaaf5960626eeaa3973742,Geometric matching for clip-art drawing retrieval,J. Vis. Commun. Image Represent.,2009.0,32,"Currently, there are large collections of clip-art vector drawings from which users can select the desired figures to insert in their documents. However, to locate a particular drawing among thousands is not easy. Although there are some solutions for drawing retrieval, almost all of them are designed to retrieve simple and not complex drawings as for instance clip-arts. In our prior work we proposed an approach to index and retrieve complex vector drawings by content, using topological and geometric information automatically extracted from figures. In this paper, we present a new algorithm to improve the geometric matching of two drawings, which takes into account the drawing as a whole and each of the shapes in it. We developed a web search engine for clip-art drawings, where we included this new technique. Experimental evaluation reveals that this new geometric matching algorithm conducts to better retrieval results than the prior matching solution."
"Mohamad Faizal Ab Jabal, M. Rahim, Nur Zuraifah Syazrah Othman, Zahabidin Jupri",dfbed18db601d49248c468725f7af0f2398e5830,A Comparative Study on Extraction and Recognition Method of CAD Data from CAD Drawings,2009 International Conference on Information Management and Engineering,2009.0,32,"In recent years, various researchers have put in great effort to produce an efficient method of drawing extraction. This paper will focus on CAD data extraction from CAD drawing and study the method that has been proposed by previous researchers. CAD data extraction became a popular research since the early 80’s. Nowadays, most applications in engineering field are already computerized. This includes the CAD application system, the systems used by engineers to design their products. As the use of computerized application became important tool in engineering field, the production field is also affected. This raises the issue of integrating CAD with manufacture systems. For that reason, most researchers try to create a system that can extract meaningful information from the CAD drawing and create a connection between CAD and manufacture system.  For example in manufacturing field, manufacture system is a machine system where it is also known as CAM systems. However, there is no direct connection from CAD system to CAM system. Therefore, many approaches have been proposed by the previous researchers to solve the issues. Focus on this paper is to study the approaches and make comparison among it. Finding from this paper is suitable approach can be used for next stage in this research."
"Eakta Jain, Yaser Sheikh, J. Hodgins",7fe6826b094cf82b972c8420eb2b09fbc1dd016e,Leveraging the talent of hand animators to create three-dimensional animation,SCA '09,2009.0,31,"The skills required to create compelling three-dimensional animation using computer software are quite different from those required to create compelling hand animation with pencil and paper. The three-dimensional medium has several advantages over the traditional medium---it is easy to relight the scene, render it from different view-points, and add physical simulations. In this work, we propose a method to leverage the talent of traditionally trained hand animators to create three-dimensional animation of human motion, while allowing them to work in the medium that is familiar to them. The input to our algorithm is a set of hand-animated frames. Our key insight is to use motion capture data as a source of domain knowledge and 'lift' the two-dimensional animation to three dimensions, while maintaining the unique style of the input animation. A motion capture clip is projected to two dimensions. First, time alignment is done to match the timing of the hand-drawn frames and then, the limbs are aligned to better match the pose in the hand-drawn frames. Finally the motion is reconstructed in three dimensions. We demonstrate our algorithm on a variety of hand animated motion sequences on different characters, including ballet, a stylized sneaky walk, and a sequence of jumping jacks."
"P. Taele, T. Hammond",82b3658128e9e81961d5bc160682ea83406409db,Hashigo: A Next-Generation Sketch Interactive System for Japanese Kanji,IAAI,2009.0,31,"Language students can increase their effectiveness in learning written Japanese by mastering the visual structure and written technique of Japanese kanji.  Yet, existing kanji handwriting recognition systems do not assess the written technique sufficiently enough to discourage students from developing bad learning habits.  In this paper, we describe our work on Hashigo, a kanji sketch interactive system which achieves human instructor-level critique and feedback on both the visual structure and written technique of students’ sketched kanji.  This type of automated critique and feedback allows students to target and correct specific deficiencies in their sketches that, if left untreated, are detrimental to effective long-term kanji learning."
"J. Pu, D. Gur",d3edfea0df28ecfe3a6eb81fbe5258cf616829cf,Automated freehand sketch segmentation using radial basis functions,Comput. Aided Des.,2009.0,27,"Freehand sketching is widely regarded as an efficient and natural way for interaction between computers and humans. We present a robust computerized scheme to automatically segment freehand sketches into a series of components with specific geometric meaning regardless of whether these are generated online or offline. This task is a necessary first step toward sketch understanding. By exploiting the interpolation / extrapolation characteristic of Radial Basis Functions (RBFs), a greedy algorithm consisting of forward and backward operations is proposed for finding the minimum set of segmentation points that can be used to reconstruct with high fitting accuracy freehand sketches in the form of implicit functions. To obtain segmentation points, a simple angle based rule is used to remove ""bridging"" points that provide a smooth transition between consecutive sketch components. Feasibility of the proposed algorithm is demonstrated by a preliminary performance assessment study using ten computer generated drawings. These experiments show that in this dataset sensitivity of the segmentation was higher than 97.5% with a false positive (FP) rate of approximately 25%. The majority of false positive identifications are located on arc regions where a larger number of segmentation points are needed for reconstruction purposes. The primary contribution of this algorithm is that it transforms an ambiguous problem namely, freehand sketch segmentation, into an implicit function fitting operation. Therefore, this proposed approach has several advantages including independence of the actual sketching activity, and the ability for a satisfactory detection of the transition point between a line and an arc or between two arcs."
"Xiaohan Ma, B. Le, Z. Deng",d18f46cb7468b9b8a592e5ada00f4c27b2474879,Style learning and transferring for facial animation editing,SCA '09,2009.0,26,"Most of current facial animation editing techniques are frame-based approaches (i.e., manually edit one keyframe every several frames), which is ineffective, time-consuming, and prone to editing inconsistency. In this paper, we present a novel facial editing style learning framework that is able to learn a constraint-based Gaussian Process model from a small number of facial-editing pairs, and then it can be effectively applied to automate the editing of the remaining facial animation frames or transfer editing styles between different animation sequences. Comparing with the state of the art, multiresolution-based mesh sequence editing technique, our approach is more flexible, powerful, and adaptive. Our approach can dramatically reduce the manual efforts required by most of current facial animation editing approaches."
"Junfa Liu, Yiqiang Chen, C. Miao, Jinjing Xie, C. Ling, Xingyu Gao, Wen Gao",83ab51c5da5bbef3687c2e9381a563a3cd65acb6,Semi‐Supervised Learning in Reconstructed Manifold Space for 3D Caricature Generation,Comput. Graph. Forum,2009.0,25,"Recently, automatic 3D caricature generation has attracted much attention from both the research community and the game industry. Machine learning has been proven effective in the automatic generation of caricatures. However, the lack of 3D caricature samples makes it challenging to train a good model. This paper addresses this problem by two steps. First, the training set is enlarged by reconstructing 3D caricatures. We reconstruct 3D caricatures based on some 2D caricature samples with a Principal Component Analysis (PCA)‐based method. Secondly, between the 2D real faces and the enlarged 3D caricatures, a regressive model is learnt by the semi‐supervised manifold regularization (MR) method. We then predict 3D caricatures for 2D real faces with the learnt model. The experiments show that our novel approach synthesizes the 3D caricature more effectively than traditional methods. Moreover, our system has been applied successfully in a massive multi‐user educational game to provide human‐like avatars."
"Chyi-Yeu Lin, Li-Wen Chuang, Thi Thoa Mac",bb8eac73fdd5e94eb62c84a0355382f1c75e9b6d,Human portrait generation system for robot arm drawing,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,2009.0,19,"This research aims to develop a human portrait generation system that enables the two-armed humanoid robot, Pica, to autonomously draw the face portrait of the person sitting in front of Pica. This portrait generation system converts a face image captured by the CCD camera installed on the head of Pica, to line segments that constitute a portrait of a good artist quality and are suitable for the robot arm to draw within a short period of time. A selected reduced number of pixel points on the line segments of the portrait are used to control the motion of the robot arm. The control points on the portrait plane are then automatically transformed into the robot's coordinates. A PD controller drives the motors of the robot arm to complete the real-time portrait drawing and signature."
"Junfa Liu, Yiqiang Chen, Jinjing Xie, Xingyu Gao, W. Gao",ad3299bdfcd52e6aae59d801242c456548bbb756,Semi-supervised Learning of Caricature Pattern from Manifold Regularization,MMM,2009.0,17,"Automatic caricature synthesis is to transform the input face to an exaggerated one. It is becoming an interesting research topic, but it remains an open issue to specify the caricature's pattern for the input face. This paper proposed a novel pattern prediction method based on MR (manifold regularization), which comprises three steps. Firstly, we learn the caricature pattern by manifold dimension reduction, and select some low dimensional caricature pattern as the labels for corresponsive true faces. Secondly, manifold regularization is performed to build a semi-supervised regression between true faces and the pattern labels. In the third step of offline phase, the input face is mapped to a pattern label by the learnt regressive model, and the pattern label is further transformed to caricature parameters by a locally linear reconstruction algorithm. This approach takes advantage of manifold structure lying in both true faces and caricatures. Experiments show that, low dimensional manifold represents the caricature pattern well and the semi-supervised regressive model from manifold regularization can predict the target caricature pattern successfully."
"Jinjing Xie, Yiqiang Chen, Junfa Liu, C. Miao, Xingyu Gao",86a56313023e35460e7a18f95a108ee7884f2179,Interactive 3D caricature generation based on double sampling,ACM Multimedia,2009.0,12,"Recently, 3D caricature generation and applications have attracted wide attention from both the research community and the entertainment industry. This paper proposes a novel interactive approach for various and interesting 3D caricature generation based on double sampling. Firstly, according to user's operation, we obtain a coarse 3D caricature with local features transformation by sampling in well-built principle component analysis (PCA) subspace. Secondly, to utilize information of the 2D caricature dataset, we sample in the local linear embedding (LLE) manifold subspace. Finally, we use the learned 2D caricature information to further refine the coarse caricature by applying Kriging interpolation. The experiments show that the 3D caricature generated by our method can preserve highly artistic styles and also reflect the user's intention."
"W. Sun, K. Kise",e109b4bb86f7d934b44f454c7b076ccbd2402739,Detecting Printed and Handwritten Partial Copies of Line Drawings Embedded in Complex Backgrounds,2009 10th International Conference on Document Analysis and Recognition,2009.0,10,"The partial copy is a kind of copy produced by cropping parts of original materials. Illegal users often use this technique for plagiarizing copyrighted materials. In addition, original parts are not necessarily copied intact but may be modified by various techniques, and embedded into other materials, which make the detection quite difficult. In this paper, we propose a method of copyright protection applicable to partial copies aiming at the protection of line drawings such as comics. In order to cope with handwritten partial copies, we apply local feature matching with a database of copyrighted line drawings. Experimental results show that the proposed method not only performs good for detecting printed copies of line drawings, but also has effectiveness on the detection of handwritten ones, even if partial copies are embedded in complex backgrounds."
"M. Obaid, D. Lond, R. Mukundan, M. Billinghurst",4af2b29732cbfa6cce1dda104d7899cf8d6ba7fb,Facial caricature generation using a quadratic deformation model,Advances in Computer Entertainment Technology,2009.0,7,"In this paper we propose a novel approach for generating expressive caricatures from an input image. The novelty of this work comes from combining an Active Appearance Model facial feature extraction system with a quadratic deformation model representation of facial expressions. The extracted features are deformed using the quadratic deformation parameters, resulting in an expressive caricature. The facial feature extraction requires an offline training process which uses natural expression annotated images from 30 model subjects, selected randomly from the Cohn-Kanade Database. The results show that from an input facial image, expressive caricatures are generated for the main six face expressions (smile, sad, fear, surprise, disgust, and anger). The proposed approach yields to promising expressive caricatures, and could lead to future research directions in the field of non-photorealistic rendering. In addition, the proposed approach can be employed in entertaining standalone applications or caricature animations."
"Rui Mo, Yi Zhu, Z. Peng, Y. Zhang, Wei Gao, Lei Wei",51f344d7887a791c6eea09a4e52ea3ac63df0198,Template-based portrait caricature generation with facial components analysis,2009 IEEE International Conference on Intelligent Computing and Intelligent Systems,2009.0,7,"This paper presents a template-based facial caricature generation approach. Since the major difficulty in generating facial caricature automatically is the uniqueness of individuals and the polymorphism of features, a modified Active Shape Model (ASM) is first designed to locate key feature points accurately by using 2D local grey-level structures. Then, extracted facial components are classified into low-accuracy ones and high-accuracy ones according to their fitting accuracy and are processed respectively. Hierarchical clustering combined with the template-based method is employed for low-accuracy components to bridge the gap between the accuracy provided by feature localization and that required by caricature generation. Experimental results illustrate the effectiveness of the presented approach."
"Luoting Fu, L. Kara",3fd5a452bd36a9ba8aeb160a6648f68dd119afd5,Recognizing Network-Like Hand-Drawn Sketches: A Convolutional Neural Network Approach,DAC 2009,2009.0,7,"Hand-drawn sketches are powerful cognitive devices for the efficient exploration, visualization and communication of emerging ideas in engineering design. It is desirable that CAD/CAE tools be able to recognize the back-of-the-envelope sketches and extract the intended engineering models. Yet this is a nontrivial task for freehand sketches. Here we present a novel, neural network-based approach designed for the recognition of network-like sketches. Our approach leverages a trainable, detector/recognizer and an autonomous procedure for the generation of training samples. Prior to deployment, a Convolutional Neural Network is trained on a few labeled prototypical sketches and learns the definitions of the visual objects. When deployed, the trained network scans the input sketch at different resolutions with a fixed-size sliding window, detects instances of defined symbols and outputs an engineering model. We demonstrate the effectiveness of the proposed approach in different engineering domains with different types of sketching inputs.Copyright © 2009 by ASME"
"D. Wu, Qionghai Dai",89cde908b97cb2eff8c470ff869b93f48bc50e64,Sketch realizing: lifelike portrait synthesis from sketch,CGI,2009.0,6,"People usually visualize their imaginations or memories through sketching. However, it might be difficult to record color and texture details powered by a large database of photographs gathered from the Web. This paper deals with the imagination visualization problem for human faces. A framework for synthesizing lifelike portraits from user specifications and input sketches is proposed which is an inverse process of sketch generation. The proposed framework synthesizes the realistic appearance of a face by taking parts from an annotated face library of photographs and stitching them together followed by further deformation.
 The algorithm consists of three parts primarily: First, given user specifications and an input sketch, search good matches for each facial component in the library; Second, extract each facial component from matching source images and composite them together; Third, deform the synthesized lifelike portraits to further approximate the sketch. The key component lies in a measurement for finding the right contents to bridge the gap between shapes and lifelike images. A set of diverse lifelike portraits can be synthesized from a single sketch. The effectiveness of the proposed approach is demonstrated with a variety of experimental results."
"Ney Renau-Ferrer, Céline Rémi",3ae0f83dcef2ee6be292d4ffb3c05c25481e9ad9,Automatic analysis of online-sketch based on use of local descriptors,,2009.0,6,"In this paper we describe the various steps of a method using local descriptors in order to classify freehand sketches, which are drawn in an unconstrained manner and recorded online. Our final objective is to simultaneously allow classification, comparison or clustering of those elements according to their Visuo spatial properties, their realization strategies, their structural or temporal parameters, or any combination of two or more of those parameters. The context and the motivation of this work-in-progress are described. First, we'll explain the detection step: we decided to use a mixed segmentation process. Indeed recognition methods based on local descriptor are not fully adapted to our types of shapes and to the one-line context. Later, we will show how we plan to give a global perception of the shape to our local descriptor by using segmentation results. Then we will introduce the local descriptor and how it is computing. Next we'll explain how we calculate the dissimilarity between two descriptors. Finally, we'll describe the approach we have chosen to determine the dissimilarity between shapes represented by sets of local descriptors."
"Wenjuan Chen, H. Yu, Minyong Shi, Qingjie Sun",e22baa3623d44c14c2c9587e0c24ec394b84a76e,Regularity-Based Caricature Synthesis,2009 International Conference on Management and Service Science,2009.0,5,"In this paper we present a regularity-based caricature synthesis technique from a frontal face image, consisting of shape exaggeration, relationship exaggeration. Three rules are introduced which are important in caricature exaggeration. The first is the relativity concept: the relationship between features of different subjects and the relationship between facial features of the same subject, which make the exaggerative effect more contrastive. The second is the so called proportion, which characterises the face in a proportion form. It makes global feature synthesis a simple task and the normalizing of facial features unnecessary. The third is hierarchical- exaggeration model. We define all facial proportions three hierarchy to guide exaggeration. The effectiveness of our algorithm is demonstrated with experimental results."
"Rong Yang, B. Wunsche",14d27fd02ff6e9334ff033d23b66babeea9ce186,Automatic joint and skeleton computation for the animation of sketch-based 3D objects,2009 24th International Conference Image and Vision Computing New Zealand,2009.0,4,"Animated models are essential for simulations and virtual worlds. In many applications approximate models are sufficient and an efficient model creation and animation suitable for untrained users is required. Sketch-based modelling has been shown to be a suitable interface for creating such models because the underlying pen-and-paper metaphor is intuitive and effective. However, there is no similarly easy process for animating these models. In this paper we present an automatic skeletalisation and rigging algorithm for sketch-based models. Our algorithm analyses sketched contours and creates fully automatically a hierarchical skeleton with joints. The surface mesh is bound to the curved skeleton bones using skinning techniques and the resulting model can be animated using skeletal animation techniques. Our analysis and user evaluation suggests that the joints placements are perceived as natural. The models can be animated using traditional skeletal animation techniques such as key-framing and motion capturing, or can be used as input to physically-based animation techniques and evolutionary algorithms."
"B. Paulson, T. Hammond",b208dc205bd02e4f1e6f48ac4854c9af2beeeb21,Towards a Framework for Truly Natural Low-level Sketch Recognition,,2009.0,4,"Although stroke-based systems may be considered the stateof-the-art in low-level sketch recognition, they still contain constraints and intricacies that may be invisible to most novice users. In this paper, we identify some common assumptions and problems of stroke-based systems and propose a plan for the development of a new low-level framework to deal with these issues. The broader impact of this framework will be the development of sketch recognition systems which place fewer (and hopefully no) drawing constraints on users and will allow for more natural sketching, starting at the lowest and most fundamental level. Author Keywords sketch recognition, primitive recognition, low-level framework"
"Jakarin Smitaveja, K. Sookhanaphibarn, C. Lursinsap",a3b2b70d63c708d274c65fcf2e7e33d8deef43e0,Facial Metrical and Caricature-Pattern-Based Learning in Neural Network System for Face Recognition,2009 Eighth IEEE/ACIS International Conference on Computer and Information Science,2009.0,2,"Face recognition technology has been an increasingly important module in security systems. A challenging problem is how to extract features tolerant to the appearance variables such as changes in shape, illumination, and occlusion. Extracted metrical features of facial caricatures that are combined with their facial photographs in the training set are examined. The facial caricature is a personal representative amplifying perceptually significant information of individuals. Unlike Eigenfaces, Fisherfaces, and Laplacianfaces, the twenty-nine metrical features that used in this study do not depend upon illumination and occlusion variables. Our results show that facial caricature-trained neural networks outperform significantly of those only facial photograph-trained neural networks."
"Ricardo Lopes, Tiago Cardoso, Nelson F. Silva, Manuel J. Fonseca",16456cbf8d3913f28edfc4e6bf76c071655b3c7d,Calligraphic Shortcuts for Comics Creation,Smart Graphics,2009.0,2,"The interactive creation of comics on the World Wide Web has become increasingly relevant over the last few years as a way for amateur creators to produce, share and distribute their comics. However, web applications that allow this kind of creation still restrict users interaction by not considering the repetition of previous elements across a comics story. Moreover, they use very simple methods for creating new content, therefore not allowing visually complex and rich comics. 
 
In this paper, we present a solution that seeks to converge the creation of web comics with the basic principles of traditional paper comics. To that end, we propose a new approach that combines rich interaction methods and geometric transformations for free hand drawings with a retrieval mechanism based on calligraphic shortcuts, to retrieve previous elements of comics. 
 
Experimental evaluation with users demonstrated that our approach is better suited for these problems than existent applications. Our solution allows creating comics online with higher flexibility and efficiency, while achieving visually more complex and rich content."
"R. Bodík, Armando Solar-Lezama",ae74531e6e73afaffb264b4e536b8fde95d03202,Program synthesis by sketching,,2008.0,331,"The goal of software synthesis is to generate programs automatically from high-level specifications. However, efficient implementations for challenging programs require a combination of high-level algorithmic insights and low-level implementation details. Deriving the low-level details is a natural job for a computer, but the synthesizer can not replace the human insight. Therefore, one of the central challenges for software synthesis is to establish a synergy between the programmer and the synthesizer, exploiting the programmer's expertise to reduce the burden on the synthesizer. 
This thesis introduces sketching, a new style of synthesis that offers a fresh approach to the synergy problem. Previous approaches have relied on meta-programming, or variations of interactive theorem proving to help the synthesizer deduce an efficient implementation. The resulting systems are very powerful, but they require the programmer to master new formalisms far removed from traditional programming models. To make synthesis accessible, programmers must be able to provide their insight effortlessly, using formalisms they already understand. 
In Sketching, insight is communicated through a partial program, a sketch that expresses the high-level structure of an implementation but leaves holes in place of the low-level details. This form of synthesis is made possible by a new SAT-based inductive synthesis procedure that can efficiently synthesize an implementation from a small number of test cases. This algorithm forms the core of a new counterexample guided inductive synthesis procedure (CEGIS) which combines the inductive synthesizer with a validation procedure to automatically generate test inputs and ensure that the generated program satisfies its specification. With a few extensions, CEGIS can even use its sequential inductive synthesizer to generate concurrent programs; all the concurrency related reasoning is delegated to an off-the-shelf validation procedure. 
The resulting synthesis system scales to real programming problems from a variety of domains ranging from bit-level ciphers to manipulations of linked datastructures. The system was even used to produce a complete optimized implementation of the AES cipher. The concurrency aware synthesizer was also used to synthesize, in a matter of minutes, the details of a fine-locking scheme for a concurrent set, a sense reversing barrier, and even a solution to the dining philosophers problem. 
The system was also extended with domain specific knowledge to better handle the problem of implementing stencil computations, an important domain in scientific computing. For this domain, we were able to encode domain specific insight as a problem reduction that converted stencil sketches into simplified sketch problems which CEGIS resolved in a matter of minutes. This specialized synthesizer was used to quickly implement a MultiGrid solver for partial differential equations containing many difficult implementation strategies from the literature. 
In short, this thesis shows that sketching is a viable approach to making synthesis practical in a general programming context."
"Michael Neff, M. Kipp, I. Albrecht, H. Seidel",86aae06409f84028697f6aede2e28394d03c8723,Gesture modeling and animation based on a probabilistic re-creation of speaker style,TOGS,2008.0,218,"Animated characters that move and gesticulate appropriately with spoken text are useful in a wide range of applications. Unfortunately, this class of movement is very difficult to generate, even more so when a unique, individual movement style is required. We present a system that, with a focus on arm gestures, is capable of producing full-body gesture animation for given input text in the style of a particular performer. Our process starts with video of a person whose gesturing style we wish to animate. A tool-assisted annotation process is performed on the video, from which a statistical model of the person's particular gesturing style is built. Using this model and input text tagged with theme, rheme and focus, our generation algorithm creates a gesture script. As opposed to isolated singleton gestures, our gesture script specifies a stream of continuous gestures coordinated with speech. This script is passed to an animation system, which enhances the gesture description with additional detail. It then generates either kinematic or physically simulated motion based on this description. The system is capable of generating gesture animations for novel text that are consistent with a given performer's style, as was successfully validated in an empirical user study."
"B. Paulson, T. Hammond",545d3d4bc14f99ce37e21ed83e23804c2cc78532,PaleoSketch: accurate primitive sketch recognition and beautification,IUI '08,2008.0,201,"Sketching is a natural form of human communication and has become an increasingly popular tool for interacting with user interfaces. In order to facilitate the integration of sketching into traditional user interfaces, we must first develop accurate ways of recognizing users' intentions while providing feedback to catch recognition problems early in the sketching process. One approach to sketch recognition has been to recognize low-level primitives and then hierarchically construct higher-level shapes based on geometric constraints defined by the user, however, current low-level recognizers only handle a few number of primitive shapes. We propose a new low-level recognition and beautification system that can recognize eight primitive shapes, as well as combinations of these primitives, with recognition rates at 98.56%. Our system also automatically generates beautified versions of these shapes to provide feedback early in the sketching process. In addition to looking at geometric perception, much of our recognition success can be attributed to two new features, along with a new ranking algorithm, which have proven to be significant in distinguishing polylines from curved segments."
"Xinbo Gao, J. Zhong, J. Li, Chunna Tian",c97542d949a1394a740a774d9e94dbd85aa37d12,Face Sketch Synthesis Algorithm Based on E-HMM and Selective Ensemble,IEEE Transactions on Circuits and Systems for Video Technology,2008.0,127,"Sketch synthesis plays an important role in face sketch-photo recognition system. In this manuscript, an automatic sketch synthesis algorithm is proposed based on embedded hidden Markov model (E-HMM) and selective ensemble strategy. First, the E-HMM is adopted to model the nonlinear relationship between a sketch and its corresponding photo. Then based on several learned models, a series of pseudo-sketches are generated for a given photo. Finally, these pseudo-sketches are fused together with selective ensemble strategy to synthesize a finer face pseudo-sketch. Experimental results illustrate that the proposed algorithm achieves satisfactory effect of sketch synthesis with a small set of face training samples."
"B. Bickel, M. Lang, M. Botsch, M. Otaduy, M. Gross",d5ca7a3a03ed3926d6f6076b8878496acb974e52,Pose-space animation and transfer of facial details,SCA '08,2008.0,98,"This paper presents a novel method for real-time animation of highly-detailed facial expressions based on a multi-scale decomposition of facial geometry into large-scale motion and fine-scale details, such as expression wrinkles. Our hybrid animation is tailored to the specific characteristics of large- and fine-scale facial deformations: Large-scale deformations are computed with a fast linear shell model, which is intuitively and accurately controlled through a sparse set of motion-capture markers or user-defined handle points. Fine-scale facial details are incorporated using a novel pose-space deformation technique, which learns the correspondence of sparse measurements of skin strain to wrinkle formation from a small set of example poses. Our hybrid method features real-time animation of highly-detailed faces with realistic wrinkle formation, and allows both large-scale deformations and fine-scale wrinkles to be edited intuitively. Furthermore, our pose-space representation enables the transfer of facial details to novel expressions or other facial models."
"M. E. Sargin, Y. Yemez, E. Erzin, A. Tekalp",2ec4b47bc648b214f5c58fd664bbf37e2d692c34,Analysis of Head Gesture and Prosody Patterns for Prosody-Driven Head-Gesture Animation,IEEE Transactions on Pattern Analysis and Machine Intelligence,2008.0,67,"We propose a new two-stage framework for joint analysis of head gesture and speech prosody patterns of a speaker towards automatic realistic synthesis of head gestures from speech prosody. In the first stage analysis, we perform hidden Markov model (HMM) based unsupervised temporal segmentation of head gesture and speech prosody features separately to determine elementary head gesture and speech prosody patterns, respectively, for a particular speaker. In the second stage, joint analysis of correlations between these elementary head gesture and prosody patterns is performed using Multi-Stream HMMs to determine an audio-visual mapping model. The resulting audio-visual mapping model is then employed to synthesize natural head gestures from arbitrary input test speech given a head model for the speaker. In the synthesis stage, the audio-visual mapping model is used to predict a sequence of gesture patterns from the prosody pattern sequence computed for the input test speech. The Euler angles associated with each gesture pattern are then applied to animate the speaker head model. Objective and subjective evaluations indicate that the proposed synthesis by analysis scheme provides natural looking head gestures for the speaker with any input test speech, as well as in ``prosody transplant"" and ``gesture transplant"" scenarios."
"Shuang Liang, Zhengxing Sun",21a3c87d9bdbdf9f325620fe18fb39f4198d0770,Sketch retrieval and relevance feedback with biased SVM classification,Pattern Recognit. Lett.,2008.0,62,"This paper proposes an effective approach for content-based sketch retrieval. It addresses three characteristics as follows. Firstly, both structural relations and global shape descriptors are combined to represent sketch content. Secondly, feature weighting and combination are performed to obtain a reasonable mechanism for similarity calculation. Finally, relevance feedback based on biased SVM (BSVM) algorithm is employed to capture user's query interests online and thus improve retrieval performance. Experiments prove the effectiveness of our proposed method in sketch retrieval."
"Xinbo Gao, J. Zhong, D. Tao, Xuelong Li",46704b6f9337fe5ddd5f09e1bfbcda5f1239a010,Local face sketch synthesis learning,Neurocomputing,2008.0,57,"Facial sketch synthesis (FSS) is crucial in sketch-based face recognition. This paper proposes an automatic FSS algorithm with local strategy based on embedded hidden Markov model (E-HMM) and selective ensemble (SE). By using E-HMM to model the nonlinear relationship between a photo-sketch patch pair, a series of pseudo-sketch patches, generated based on several learned models for a given photo patch, are integrated with SE strategy to synthesize a finer face pseudo-sketch patch. Finally, the intact pseudo-sketch can be generated by combining all synthesized patches. Experimental results illustrate that the proposed FSS algorithm works well."
"T. M. Sezgin, Randall Davis",402071770149fedb7870eab6633750d6629eb9fd,Sketch recognition in interspersed drawings using time-based graphical models,Comput. Graph.,2008.0,52,"Sketching is a natural mode of interaction used in a variety of settings. With the increasing availability of pen-based computers, sketch recognition has gained attention as an enabling technology for natural pen-based interfaces. Previous work in sketch recognition has shown that in certain domains the stroke orderings used when drawing objects contain temporal patterns that can aid recognition. So far, systems that use temporal information for recognition have assumed that objects are drawn one at a time. This paper shows how this assumption can be relaxed to permit temporal interspersing of strokes from different objects. We describe a statistical framework based on dynamic Bayesian networks that explicitly models the fact that objects can be drawn interspersed. We present recognition results for hand-drawn electronic circuit diagrams, showing that handling interspersed drawing provides a significant increase in accuracy."
Nicole Martin,64a8fb2c5197b30df20ed33529632c64e4ced8d1,Assessing Portrait Drawings Created by Children and Adolescents With Autism Spectrum Disorder,,2008.0,32,"The ability to attend to the human face is a striking and possibly characteristic deficit for individuals with autism spectrum disorder (ASD). This study collected and reviewed data on how people with ASD approach the drawing task and represent faces in particular. Drawings that were created by 25 children and adolescents with autism spectrum disorder and 15 neurotypical children were collected for a pilot study of the Portrait Drawing Assessment. Participants with ASD were rated as more engaged and conversational during the art therapy assessment than their neurotypical counterparts, contradicting widespread characterization of people with ASD as asocial. Portrait drawing was found to be successful as a structured, concrete means for engaging in relationships and holds potential as a therapeutic task for developing face processing and face recognition skills."
"T. Hammond, Brian Eoff, B. Paulson, Aaron Wolin, K. Dahmen, J. Johnston, P. Rajan",d3e313f2219caf22be11003063147bff2979758b,Free-sketch recognition: putting the chi in sketching,CHI Extended Abstracts,2008.0,29,"Sketch recognition techniques have generally fallen into two camps. Gesture-based techniques, such as those used by the Palm Pilot's Graffiti, can provide high-accuracy, but require the user to learn a particular drawing style in order for shapes to be recognized. Free-sketch recognition allows users to draw shapes as they would naturally, but most current techniques have low accuracies or require significant domain-level tweaking to make them usable. Our goal is to recognize free-hand sketches with high accuracy by developing generalized techniques that work for a variety of domains, including design and education. This is a work-in-progress, but we have made significant advancements toward our over-arching goal."
"J. Collomosse, Graham McNeill, L. Watts",fba969fabf1ad17633c848a15dcb77631b9aa5b9,Free-hand sketch grouping for video retrieval,2008 19th International Conference on Pattern Recognition,2008.0,28,"We present an algorithm for extracting object descriptions from free-hand sketches of remembered scenes, drawn as video retrieval queries. Our sketches depict scene content, as well as indicators of motion. We report an exploratory study investigating how people sketch to depict recalled events. We incorporate several observations from this study into the design of a novel sketch parsing algorithm. We draw upon a temporal HMM classifier to recognise common pictograms, and graph-cut to identify more general objects."
"Sangwon Lee, David Feng, B. Gooch",adb715883aaa3afbc5806ecb702414d8bf9047f8,Automatic construction of 3D models from architectural line drawings,I3D '08,2008.0,20,"We present a semi-automatic framework for construction of curved and polygonal 3D models from a 2D line drawing, such as architectural or mechanical drawings. Despite advances in image-based modeling, 3D modeling from a drawn image remains largely manual. In contrast, our method only requires the user to annotate the source image with a drawn cube for camera calibration. 3D models are then generated automatically. The modeling process has four steps: camera calibration, a novel line detection algorithm for noisy input, line labeling to calculate polygon adjacencies, a new incremental construction method that uses plane hinging-angle optimization to improve scalability over previous approaches. We also present algorithms for handling curved surfaces when they are part of a polygonal model that provides boundary conditions."
"P. Rajan, T. Hammond",a1140a8f8a882c5a0ffa1327e3e87177623e0ca1,From paper to machine: extracting strokes from images for use in sketch recognition,SBM'08,2008.0,17,"Sketching is a way of conveying ideas to people of diverse backgrounds and culture without any linguistic medium. With the advent of inexpensive tablet PCs, online sketches have become more common, allowing for stroke-based sketch recognition techniques, more powerful editing techniques, and automatic simulation of recognized diagrams. Online sketches provide significantly more information than paper sketches, but they still do not provide the flexibility, naturalness, and simplicity of a simple piece of paper. Recognition methods exist for paper sketches, but they tend to be domain specific and don't benefit from the advances of stroke-based sketch recognition. Our goal is to combine the power of stroke-based sketch recognition with the flexibility and ease of use of a piece of paper. In this paper we will present a stroke-tracing algorithm that can be used to extract stroke data from the pixilated image of the sketch drawn on paper. The presented method handles overlapping strokes and also attempts to capture sequencing information, which is helpful in many sketch recognition techniques. We present preliminary results of our algorithm on several paper-drawn, hand-sketched, scanned-in pixilated images."
"M. Fairhurst, T. Linnell, S. Glenat, R. Guest, L. Heutte, T. Paquet",201110a5879cb6f12465eb623b724e1b391dde6f,Developing a generic approach to online automated analysis of writing and drawing tests in clinical patient profiling,Behavior research methods,2008.0,16,"Writing and drawing tests are widely used in the clinical environment for the diagnosis of a variety of neuro-psychological conditions. Conventional assessment of these tests involves the inspection by trained assessors of the completed patient response. This article describes the development of a computer-based framework for data capture, automated feature analysis, and result reporting for a range of drawing- and writing-based test batteries. In developing this framework, we have exploited the commonality between tasks while allowing for both flexibility in configuration across condition-specific testing requirements and extensibility for future test development. Using the two example clinical conditions of visuospatial neglect and dyspraxia, we illustrate the advantages of utilizing a computer-based analysis system, describe a structured approach to system implementation, and demonstrate the generality of this implementation for different conditions of interest, which extends to feature selection and design."
"Tiago Santos, Alfredo Ferreira, Filipe Dias, Manuel J. Fonseca",6b0037317c15e1f3ab0ba8b71ab128d4360b1533,Using sketches and retrieval to create LEGO models,SBM'08,2008.0,13,"In this paper we describe a system to create LEGO models using sketches. Although there are a few applications to create LEGO models, they are difficult to use, mainly due to the searching and manipulation mechanisms that they (do not) offer. Here, we propose a sketch based approach, where users can easily insert parts, by specifying their dimensions through sketches and the system suggests a list of possible parts. To help with the modeling and the manipulation we also developed a constraint based mechanism, which keeps parts connected, performs snapto- grid and detects collisions. Experimental tests with users revealed that our approach is easier and faster to use than a conventional application, such as LeoCAD."
"Zhenyu Chen, Jingye Zhou, Xingyu Gao, Longsheng Li, Junfa Liu",9bd48efdada5c142d7e17f2a4cea4db958f1e0ca,A Novel Method for Pencil Drawing Generation in Non-Photo-Realistic Rendering,PCM,2008.0,11,"This paper puts forward a novel method for automatically generating a pencil drawing from a real 2D color image in non-photo-realistic rendering. First, the edge of the color image is detected by Sobel operator. Next, the color image is sharpened by Unsharp Mask (USM), and then color scaling is used to get an image with radial and edge details. Furthermore, the original image is divided into many meaningful regions using an efficient method of image segmentation, then the texture direction is determined by Fourier transform and shape feature. To render better effects of illumination and local texture of pencil drawing, the line integral convolution (LIC) algorithm is applied and combined with color scaling and white noise image. Finally, the pencil drawing is created and the generation results from the superposition of the edge, the USM image, and the texture. Experimental results prove that our method could enhance the generated efficiency greatly by creating a more obvious edge, more natural tone, and more real texture than those offered by existed methods."
"P. Li, Yiqiang Chen, Junfa Liu, Guanhua Fu",6d956d65a5fd5607abda6f9c99c6ce8a32cc2fac,3D caricature generation by manifold learning,2008 IEEE International Conference on Multimedia and Expo,2008.0,11,"3D caricature generation is becoming an interesting and important research program, but it is impossible for the computer to draw an elegant caricature without any background. In this paper, we build a training set which contains 110 true face photographs and corresponsive 3D caricature models. Based on that training set, the LLE manifold learning is performed to discover the low dimensional embeddings. Between the 2D true face embeddings and 3D caricature embeddings, a regressive model is learnt by the Extreme Learning Machine. Experiments show that, the regressive manifold model is effective to generate the final 3D caricature for a 2D facial photograph."
"Md. Abul Hassan Samee, Muhammad Jawaherul Alam, Muhammad Abdullah Adnan, Md. Saidur Rahman",ad62387f7f8b98b982235586bf443017507c11e8,Minimum Segment Drawings of Series-Parallel Graphs with the Maximum Degree Three,Graph Drawing,2008.0,11,"A minimum segment drawing Γ of a planar graph G is a straight line drawing of G that has the minimum number of segments among all straight line drawings of G . In this paper, we give a linear-time algorithm for computing a minimum segment drawing of a series-parallel graph with the maximum degree three. To the best of our knowledge, this is the first algorithm for computing minimum segment drawings of an important subclass of planar graphs."
"P. Taele, T. Hammond",c193e125e0ed6ac9cf6a0870947504899e26f316,A Geometric-based Sketch Recognition Approach for Handwritten Mandarin Phonetic Symbols I,DMS,2008.0,11,"Abstract Inputting written Chinese, unlike written English, is a non-trivial operation using a standard keyboard. To accommodate this operation, numerous existing phonetic systems using the Roman alphabet were adopted as a means of input while still making use of a Western keyboard. With the growing prevalence of computing devices capable of pen-based input, naturally sketching written Chinese using a phonetic system becomes possible, and is also generally faster and simpler than sketching entire Chinese characters. One method for sketching Chinese characters for computing devices capable of pen-based input involves using an existing non-alphabetic phonetic system called the Mandarin Phonetic Symbols I (MPS1). The benefits of inputting Chinese characters by its corresponding MPS1 symbols – unlike letters from its alphabetic-based counterpart – is that it retains the phonemic components of the corresponding Chinese characters. The work in the paper describes our geometric-based MPS1 recognition system, a system designed particularly for novice users of MPS1 symbols that gives reasonable vision-based recognition rates and provides useful feedback for symbols drawn with incorrect sketching technique such as stroke order."
"P. Sousa, Manuel J. Fonseca",1a6f78df5582498c3402c857eb1d57ab5a654f29,Sketch-based Retrieval of Drawings Using Topological Proximity,DMS,2008.0,8,"Currently, there are large collections of drawings from which users can select the desired ones to insert in their documents. However, to locate a particular drawing among thousands is not easy. In our prior work we proposed an approach to index and retrieve vector drawings by content, using topological and geometric information automatically extracted from figures. In this paper, we present a new approach to enrich the topological information by integrating spatial proximity in the topology graph, through the use of weights in adjacency links. Additionally, we developed a web search engine for clip art drawings, where we included the new technique. Experimental evaluation reveal that the use of topological proximity results in better retrieval results than topology alone."
"Ilya Baran, Jovan Popovic",0517d616e182cc71ebce2cd679c4074d2c9ce2c2,Automatic rigging and animation of 3D characters,ACM Trans. Graph.,2007.0,297,"Animating an articulated 3D character currently requires manual rigging to specify its internal skeletal structure and to define how the input motion deforms its surface. We present a method for animating characters automatically. Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character. Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children. Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC."
"J. LaViola, R. Zeleznik",21b66194f9057e84abd587fb2d314a324c310f9c,MathPad2: a system for the creation and exploration of mathematical sketches,SIGGRAPH '07,2007.0,166,"We present mathematical sketching, a novel, pen-based, modeless gestural interaction paradigm for mathematics problem solving. Mathematical sketching derives from the familiar pencil-and-paper process of drawing supporting diagrams to facilitate the formulation of mathematical expressions; however, with a mathematical sketch, users can also leverage their physical intuition by watching their hand-drawn diagrams animate in response to continuous or discrete parameter changes in their written formulas. Diagram animation is driven by implicit associations that are inferred, either automatically or with gestural guidance, from mathematical expressions, diagram labels, and drawing elements. The modeless nature of mathematical sketching enables users to switch freely between modifying diagrams or expressions and viewing animations. Mathematical sketching can also support computational tools for graphing, manipulating and solving equations; initial feedback from a small user group of our mathematical sketching prototype application, MathPad2, suggests that it has the potential to be a powerful tool for mathematical problem solving and visualization."
"Maria C. Yang, J. Cham",da1ae63b11d6eff18de46fe9910da643e58cf4fe,An Analysis of Sketching Skill and Its Role in Early Stage Engineering Design,,2007.0,103,"Previous studies have demonstrated the importance of sketching in design cognition, particularly in the early stages of engineering design. The goal of this preliminary study is to consider the role of a designer's sketching ability and to examine the potential link between sketching skill and measures of engineering design performance. Sketching ability was evaluated on three distinct aspects relevant to engineering design: visual recall, rendering, and novel visualization. These evaluations were correlated with each other and with measures for sketch fluency, reviewer ranking, and design project outcome. The results of this study suggest that sketching skill is not comprehensive nor is it solely task based. Rather, a designer's sketching ability lies between these two poles. Positive correlations were found between the quantity of sketches produced and two of the sketching skills that emphasize drawing facility, but a negative correlation was found between sketch quantity and a skill related to mechanism visualization. No conclusive correlations were found between the sketching skills and design outcome and reviewer ranking. This study's findings suggest an important interplay between a designer's ability to sketch and their ability to visualize in their heads or through prototypes. Results also suggest that designers who are given sketch instruction tended to draw more overall."
"T. M. Sezgin, T. Stahovich, Randall Davis",0afd88db86946b4b13304c14375ec0c48e262c03,Sketch based interfaces: early processing for sketch understanding,SIGGRAPH '07,2007.0,94,"Freehand sketching is a natural and crucial part of everyday human interaction, yet is almost totally unsupported by current user interfaces. We are working to combine the flexibility and ease of use of paper and pencil with the processing power of a computer, to produce a user interface for design that feels as natural as paper, yet is considerably smarter. One of the most basic steps in accomplishing this is converting the original digitized pen strokes in a sketch into the intended geometric objects. In this paper we describe an implemented system that combines multiple sources of knowledge to provide robust early processing for freehand sketching."
"V. Dujmovic, D. Eppstein, M. Suderman, D. Wood",7cdf2a36afa5f6ef024fca620c3567113b991938,Drawings of planar graphs with few slopes and segments,Comput. Geom.,2007.0,87,"We study straight-line drawings of planar graphs with few segments and few slopes. Optimal results are obtained for all trees. Tight bounds are obtained for outerplanar graphs, 2-trees, and planar 3-trees. We prove that every 3-connected plane graph on n vertices has a plane drawing with at most 5 n segments and at most 2n slopes. We prove that every cubic 3-connected plane graph has a plane drawing with three slopes (and three bends on the outerface). In a companion paper, drawings of non-planar graphs with few slopes are also considered."
"Takamasa Tanaka, K. Shoji, F. Toyama, J. Miyamichi",7c18ce23c8128f4a5940eab67cb7bb5b5be6be0e,Layout Analysis of Tree-Structured Scene Frames in Comic Images,IJCAI,2007.0,77,"Today, the demand of services for comic contents increases because paper magazines and books are bulky while digital contents can be read anytime and anywhere with cellular phones and PDAs. To convert existing print comic materials into digital format such that they can be read using the cellular phones and the PDAs with small screens, it is necessary to divide each page into scene frames and to determine reading order of the scene frames. The division of comic images into the scene frames can be considered as a type of document layout analysis. We analyzed layout of comic images using density gradient. The method can be applied to comics in which comic balloons or pictures are drawn over scene frames. In this research, a method for detecting the scene frame division in comic images using the density gradient after filling the quadrangle regions in each image with black is proposed. Experimental results show that 80 percent of 672 pages in four print comic booklets are successfully divided into scene frames by the proposed method."
Randall Davis,6705d00eef4ca398f6e239379abde175108cf0c2,Magic Paper: Sketch-Understanding Research,Computer,2007.0,74,"Sketches are hand-drawn informal figures often created as a way of thinking about or working through a problem. Sketch-understanding systems let users interact with computers by drawing naturally, offering a freedom not available with traditional CAD systems."
"J. Zhong, Xinbo Gao, Chunna Tian",a6661693204c31de9f668e8ed12d2bcc3375e142,Face Sketch Synthesis using E-HMM and Selective Ensemble,"2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07",2007.0,67,"In this manuscript, we propose an automatic sketch synthesis algorithm based on embedded hidden Markov model (E-HMM) and selective ensemble strategy. The E-HMM is used to model the nonlinear relationship between a photo-sketch pair firstly, and then a series of pseudo-sketches, which are generated based on several learned models for a given photo, are integrated together with selective ensemble strategy to synthesize a finer face pseudo-sketch. The experimental results illustrate that the proposed algorithm achieves satisfactory effect of sketch synthesis."
"C. Alvarado, Randall Davis",6fe7118279142c8392892e041bfd793affaf8cc3,Resolving ambiguities to create a natural computer-based sketching environment,SIGGRAPH '07,2007.0,67,"Current computer-based design tools for mechanical engineers are not tailored to the early stages of design. Most designs start as pencil and paper sketches, and are entered into CAD systems only when nearly complete. Our goal is to create a kind of ""magic paper"" capable of bridging the gap between these two stages. We want to create a computer-based sketching environment that feels as natural as sketching on paper, but unlike paper, understands a mechanical engineer's sketch as it is drawn. One important step toward realizing this goal is resolving ambiguities in the sketch--- determining, for example, whether a circle is intended to indicate a wheel or a pin joint---and doing this as the user draws, so that it doesn't interfere with the design process. We present a method and an implemented program that does this for freehand sketches of simple 2-D mechanical devices."
"C. Frowd, V. Bruce, David Ross, A. McIntyre, P. Hancock",bf0105605c97508189fc4e0cd51f4cefd4a1ec47,An application of caricature: How to improve the recognition of facial composites,,2007.0,62,"Facial caricatures exaggerate the distinctive features of a face and may elevate the recognition of a familiar face. We investigate whether the recognition of facial composites, or pictures of criminal faces, could be similarly enhanced. In this study, participants first estimated the degree of caricature necessary to make composites most identifiable. Contrary to expectation, an anticaricature was found to be best, presumably as this tended to reduce the appearance of errors. In support of this explanation, more positive caricature estimates were assigned to morphed composites: representations that tend to contain less overall error. In addition, anticaricaturing reduced identification for morphed composites but enhanced identification for individual composites. Although such improvements were too small to be of value to law enforcement, a sizeable naming benefit was observed when presenting a range of caricature states, which appeared to capitalize on individual differences in the internal representation of familiar faces."
"Tai-Pang Wu, C. Tang, M. S. Brown, H. Shum",440c42a52aa2dc1848e0f6c374389c46f5ff3916,ShapePalettes: interactive normal transfer via sketching,ACM Trans. Graph.,2007.0,50,"We present a simple interactive approach to specify 3D shape in a single view using ""shape palettes"". The interaction is as follows: draw a simple 2D primitive in the 2D view and then specify its 3D orientation by drawing a corresponding primitive on a shape palette. The shape palette is presented as an image of some familiar shape whose local 3D orientation is readily understood and can be easily marked over. The 3D orientation from the shape palette is transferred to the 2D primitive based on the markup. As we will demonstrate, only sparse markup is needed to generate expressive and detailed 3D surfaces. This markup approach can be used to model freehand 3D surfaces drawn in a single view, or combined with image-snapping tools to quickly extract surfaces from images and photographs."
"Robert T. Schweller, Zhichun Li, Y. Chen, Y. Gao, A. Gupta, Yin Zhang, P. Dinda, M. Kao, G. Memik",758e8c8ea4d2ac58724e2565430ab753f4bf9bb4,Reversible Sketches: Enabling Monitoring and Analysis Over High-Speed Data Streams,IEEE/ACM Transactions on Networking,2007.0,49,"A key function for network traffic monitoring and analysis is the ability to perform aggregate queries over multiple data streams. Change detection is an important primitive which can be extended to construct many aggregate queries. The recently proposed sketches are among the very few that can detect heavy changes online for high speed links, and thus support various aggregate queries in both temporal and spatial domains. However, it does not preserve the keys (e. g., source IP address) of flows, making it difficult to reconstruct the desired set of anomalous keys. To address this challenge, we propose the reversible sketch data structure along with reverse hashing algorithms to infer the keys of culprit flows. There are two phases. The first operates online, recording the packet stream in a compact representation with negligible extra memory and few extra memory accesses. Our prototype single FPGA board implementation can achieve a throughput of over 16 Gb/s for 40-byte packet streams (the worst case). The second phase identifies heavy changes and their keys from the representation in nearly real time. We evaluate our scheme using traces from large edge routers with OC-12 or higher links. Both the analytical and experimental results show that we are able to achieve online traffic monitoring and accurate change/intrusion detection over massive data streams on high speed links, all in a manner that scales to large key space size. To the best of our knowledge, our system is the first to achieve these properties simultaneously."
"Chung Chan, Howard Leung, T. Komura",bdad7980d45a646108cafd26a70ec1a58b961cf9,Automatic Panel Extraction of Color Comic Images,PCM,2007.0,46,"In this paper, an automatic approach for detecting and extracting panels in a color comic image is proposed. Panel extraction is challenging because the background color, the background pixel locations, the panel shapes and the panel layout are not known in advance. In our approach, uniform color stripes are first identified and used as separators to segment the color comic page image into sub-regions in a recursive manner. Panels are recognized as the sub-regions that cannot be further segmented. The structure of the panels is thus obtained in the extraction process and it contains the layout of the panels as well as the reading order. Panel extraction is useful because: 1) the extracted panels can be better fitted into a handheld device for viewing; and 2) the panels can then be further analyzed to extract features used for content based indexing and retrieval."
Michael Oltmans,d789666af53685d10460c0d85b6f15923058208a,Envisioning sketch recognition: a local feature based approach to recognizing informal sketches,,2007.0,39,"Hand drawn sketches are an important part of the early design process and are an important aspect of creative design. They are used in many fields including electrical engineering, software engineering and web design. Recognizing shapes in these sketches is a challenging task due to the imprecision with which they are drawn. We tackle this challenge with a visual approach to recognition. The approach is based on a representation of a sketched shape in terms of the visual parts it is made of. By taking this part-based visual approach we are able to recognize shapes that are extremely difficult to recognize with current sketch recognition systems that focus on the individual strokes. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
"H. Kim, Seokkwan Hong",8cf71f69ef38c174217d8dd153e477c133e849f3,FEM-based optimum design of multi-stage deep drawing process of molybdenum sheet,,2007.0,37,"Abstract Molybdenum, one of the refractory metals, has high heat and electrical conductivity while remaining strong, mechanically, at high, as well as low, temperatures. Therefore, it is a technologically very useful material, especially for high temperature applications. However, due to its very low drawability, a multi-stage process is necessary to make a deep drawn part from the molybdenum sheet. In this study, a multi-stage circular cup deep drawing process for a molybdenum sheet was designed by including ironing, which was effective in increasing drawability. A parametric study by finite element analysis of deep drawing was conducted to evaluate the effect of die design variables. From parametric study results, the design variables of the multi-stage deep drawing process were selected. Then, nonlinear process optimization, based on finite element simulation, was conducted to obtain the optimum multi-stage deep drawing process, using a global, as well as a local, optimum search algorithm."
"M. Gavas, M. Izciler",70ebfc68e1e7988ee836f1771d3e54e7de5e6aed,Effect of blank holder gap on deep drawing of square cups,,2007.0,32,"The blank holder gap is an effective way to control material flow. The effect of this gap on deep drawing of square cups with ETIAL-8 sheets was studied by the experimental approach. Different blank holder gaps ranging from 1 mm to 1.8 mm for 1 mm aluminum sheets were used in the experiments. The experimental implementation shows that a reasonable (optimized, controlled) value of blank holder gap has a great effect on the forming quality of the final part. Finally, a suitable blank holder gap for deep drawing of square cup for given tooling and material is proposed and the reasons of the failure modes are explained."
C. Alvarado,10273fc54326ad29c81a0aabdb33498c878c3a51,Multi-domain sketch understanding,SIGGRAPH '07,2007.0,31,"People use sketches to express and record their ideas in many domains, including mechanical engineering, software design, and information architecture. In recent years there has been an increasing interest in sketch-based user interfaces, but the problem of robust free-sketch recognition remains largely unsolved. Current computer sketch recognition systems are difficult to construct, and either are fragile or accomplish robustness by severely limiting the designer's drawing freedom. 
This work explores the challenges of multi-domain sketch recognition. We present a general framework and implemented system, called SketchREAD , for diagrammatic sketch recognition. Our system can be applied to a variety of domains by providing structural descriptions of the shapes in the domain. Robustness to the ambiguity and uncertainty inherent in complex, freely-drawn sketches is achieved through the use of context. Our approach uses context to guide the search for possible interpretations and uses a novel form of dynamically constructed Bayesian networks to evaluate these interpretations. This process allows the system to recover from low-level recognition errors (e.g., a line misclassified as an arc) that would otherwise result in domain level recognition errors. We evaluated SketchREAD on real sketches in two domains—family trees and circuit diagrams—and found that in both domains the use of context to reclassify low-level shapes significantly reduced recognition error over a baseline system that did not reinterpret low-level classifications. We discuss remaining challenges for multi-domain sketch recognition revealed by our evaluation. Finally, we explore the system's potential role in sketch-based user interfaces from a human computer interaction perspective. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
T. Hammond,60bb5572f0e225b3cf15fac1570190cc06c29a0c,Perceptually-based language to simplify sketch recognition user interface development,,2007.0,29,"Diagrammatic sketching is a natural modality of human-computer interaction that can be used for a variety of tasks, for example, conceptual design. Sketch recognition systems are currently being developed for many domains. However, they require signal-processing expertise if they are to handle the intricacies of each domain, and they are time-consuming to build. 
Our goal is to enable user interface designers and domain experts who may not have expertise in sketch recognition to be able to build these sketch systems. We created and implemented a new framework (FLUID - facilitating user interface development) in which developers can specify a domain description indicating how domain shapes are to be recognized, displayed, and edited. This description is then automatically transformed into a sketch recognition user interface for that domain. LADDER, a language using a perceptual vocabulary based on Gestalt principles, was developed to describe how to recognize, display, and edit domain shapes. A translator and a customizable recognition system (GUILD - a generator of user interfaces using ladder descriptions) are combined with a domain description to automatically create a domain specific recognition system. With this new technology, by writing a domain description, developers are able to create a new sketch interface for a domain, greatly reducing the time and expertise for the task. 
Continuing in pursuit of our goal to facilitate UI development, we noted that (1) human generated descriptions contained syntactic and conceptual errors, and that (2) it is more natural for a user to specify a shape by drawing it than by editing text. However, computer generated descriptions from a single drawn example are also flawed, as one cannot express all allowable variations in a single example. 
In response, we created a modification of the traditional model of active learning in which the system selectively generates its own near-miss examples and uses the human teacher as a source of labels. System generated near-misses offer a number of advantages. Human generated examples are tedious to create and may not expose problems in the current concept. It seems most effective for the near-miss examples to be generated by whichever learning participant (teacher or student) knows better where the deficiencies lie; this will allow the concepts to be more quickly and effectively refined. When working in a closed domain such as this one, the computer learner knows exactly which conceptual uncertainties remain, and which hypotheses need to be tested and confirmed. The system uses these labeled examples to automatically build a LADDER shape description, using a modification of the version spaces algorithm that handles interrelated constraints, and which also has the ability to learn negative and disjunctive constraints."
"F. Levet, Xavier Granier",2b6bea28c699a1f27952bbeb4997763a43593733,Improved skeleton extraction and surface generation for sketch-based modeling,GI '07,2007.0,24,"For the generation of freeform models, sketching interfaces have raised an increasing interest due to their intuitive approach. It is now possible to infer a 3D model directly from a sketched curved. Unfortunately, a limit of current systems is the poor quality of the skeleton automatically extracted from this silhouette, leading to low quality meshes for the resulting objects.
 In this paper, we present new solutions that improve the surface generation for sketch-based modeling systems. First, we propose a new algorithm that extracts a smoother skeleton compared to previous approaches. Then, we present a new sampling scheme for the creation of good-quality 3D mesh. Finally, we propose to use a profile curve composed of disconnected components in order to create models which genus is greater than 0."
"L. Kara, T. Stahovich",9332a95ca76912f7f205c92a6bfe25dd342aca67,Hierarchical parsing and recognition of hand-sketched diagrams,SIGGRAPH '07,2007.0,22,"A long standing challenge in pen-based computer interaction is the ability to make sense of informal sketches. A main difficulty lies in reliably extracting and recognizing the intended set of visual objects from a continuous stream of pen strokes. Existing pen-based systems either avoid these issues altogether, thus resulting in the equivalent of a drawing program, or rely on algorithms that place unnatural constraints on the way the user draws. As one step toward alleviating these difficulties, we present an integrated sketch parsing and recognition approach designed to enable natural, fluid, sketch-based computer interaction. The techniques presented in this paper are oriented toward the domain of network diagrams. In the first step of our approach, the stream of pen strokes is examined to identify the arrows in the sketch. The identified arrows then anchor a spatial analysis which groups the uninterpreted strokes into distinct clusters, each representing a single object. Finally, a trainable shape recognizer, which is informed by the spatial analysis, is used to find the best interpretations of the clusters. Based on these concepts, we have built SimuSketch, a sketch-based interface for Matlab's Simulink software package. An evaluation of SimuSketch has indicated that even novice users can effectively utilize our system to solve real engineering problems without having to know much about the underlying recognition techniques."
"Chien-Chung Tseng, J. Lien",96aab145793caea4783c77868514f3dd6241770e,Synthesis of Exaggerative Caricature with Inter and Intra Correlations,ACCV,2007.0,17,"We developed a novel system consisting of two modules, statistics-based synthesis and non-photorealistic rendering (NPR), to synthesize caricatures of exaggerated facial features and other particular characteristics, such as beards or nevus. The statistics-based synthesis module can exaggerate shapes and positions of facial features based on non-linear exaggerative rates determined automatically. Instead of comparing only the inter relationship between features of different subjects at the existing methods, our synthesis module applies both inter and intra (i.e. comparisons between facial features of the same subject) relationships to make the synthesized exaggerative shape more contrastive. Subsequently, the NPR module generates a line-drawing sketch of original face, and then the sketch is warped to an exaggerative style with synthesized shape points. The experimental results demonstrate that this system can automatically, and effectively, exaggerate facial features, thereby generating corresponding facial caricatures."
"E. Han, Kirak Kim, HwangKyu Yang, K. Jung",772b9a6b5e964dec02698187fcca24b3f53bb0a0,Frame Segmentation Used MLP-Based X-Y Recursive for Mobile Cartoon Content,HCI,2007.0,16,"With rapid growth of the mobile industry, the limitation of small screen mobile is attracting a lot of researchers attention for transforming on/off-line contents into mobile contents. Frame segmentation for limited mobile browsers is the key point of off-line contents tranformation. The X-Y recursive cut algorithm has been widely used for frame segmentation in document analysis. However, this algorithm has drawbacks for cartoon images which have various image types and image with noises, especially the online cartoon contents obtain during scanning. In this paper, we propose a method to segment on/off-line cartoon contents into fitted frames for the mobile screen. This makes the x-y recursive cut algorithm difficult to find the exact cutting point. Therefore we use a method by combining two concepts: an X-Y recursive cut algorithm to extract candidate segmenting positions which shows a good performance on noises free contents, and Multi-Layer Perceptrons (MLP) concept use on candidate for verification. These methods can increase the accuracy of the frame segmentation and feasible to apply on various off-line cartoon images with frames."
V. Pinto,ad1114c98d5a8bddd073b2b17ef3841819e2367c,"Reusable facial rigging and animation: create once, use many",,2007.0,14,"Facial animation is a serious bottleneck in any computer generated (CG) production, It is the key element to convey emotion to 3D characters. Speeding up the rigging process remains an unresolved problem, specially for film and videogames, that require high quality results. The character rigging is analogous to setting up the strings that control a puppet. Today, skilled artists manually create the facial rig to ensure the best quality in the animations; but, this is a slow, labor-intensive and costly process. This thesis presents a portable character rigging system that integrates into current animation production pipelines. It automatically transfers the facial rig and animations created for one character to different characters, independent of their shape and appearance. It enables artists to create more lifelike facial models in less time; about 90-99 percent faster than traditional manual rigging. Characters can display complex expressions and behavior, easier and with decreased artistic effort. As a result, we dramatically reduce the time needed to create high-quality facial animations for the entertainment industry.
We studied techniques from the fields of computer graphics and computer vision, to come up with a solution to the rigging problem. Based on a generic facial rig definition and a new deformation method, our system converts 3D face models into digital puppets that experienced artists can control. The system adapts the skeleton, weights and influence objects (NURBS surfaces, lattice, etc.) from a source rig to individual face models to obtain unique expressions, and enables easy re-use of existing animation scripts. Our work differs from previous morphing and retargeting techniques, because that work was oriented towards transferring animations, while ours aims to transfer the complete facial rig, in addition to animations.
The system was validated with a series of experiments. We used models and rigs from major film and videogame companies (Electr"
Kevin Stolt,befc819a7d7673eb5f6e8aecea981a513b8ee795,Sketch Recognition for Course of Action Diagrams,,2007.0,5,"This thesis describes a software program that recognizes hand-drawn Course of Action diagrams. User input is through sketching, or a combination of sketching and speech. Course of Action symbols are recognized incrementally, and the informal sketching input is replaced with formal images of the symbols. The system uses the LADDER shape definition language to represent the geometric properties of shapes, and is capable of recognizing 327 distinct Course of Action symbols. The Intermediate Feature Recognizer is used to recognize shapes of intermediate complexity and is capable of recognizing some shapes that cannot be described using LADDER defintions. By detecting features of intermediate complexity, the system is capable of automatic error correction of some stroke segmentation errors and dealing with filled-in and multi-segment lines. The system is also able to recognize a combination of speech and sketching input of some information that can’t easily be communicated through sketching alone. The system has a shape grammar to allow the sketch recognizer to conform to rules for creating Course of Action symbols. The system is also capable of “interpreting” the sketch understanding the higher-level details of military units and actions that were sketched in the Course of Action diagram. Thesis Supervisor: Randall Davis Title: Professor of Electrical Engineering and Computer Science"
"X. Li, F. Bian, M. Crovella, C. Diot, R. Govindan, G. Iannaccone, A. Lakhina",6b27451fcd6d4103c75d19e12216a5ace0c65f34,Detection and identification of network anomalies using sketch subspaces,IMC '06,2006.0,217,"Network anomaly detection using dimensionality reduction techniques has received much recent attention in the literature. For example, previous work has aggregated netflow records into origin-destination (OD) flows, yielding a much smaller set of dimensions which can then be mined to uncover anomalies. However, this approach can only identify which OD flow is anomalous, not the particular IP flow(s) responsible for the anomaly. In this paper we show how one can use random aggregations of IP flows (i.e., sketches) to enable more precise identification of the underlying causes of anomalies. We show how to combine traffic sketches with a subspace method to (1) detect anomalies with high accuracy and (2) identify the IP flows(s) that are responsible for the anomaly. Our method has detection rates comparable to previous methods and detects many more anomalies than prior work, taking us a step closer towards a robust on-line system for anomaly detection and identification."
"T. Hammond, Randall Davis",6cfb862a3c4af3817a44d70fad87a9fa7e74b9dc,Tahuti: a geometrical sketch recognition system for UML class diagrams,SIGGRAPH Courses,2006.0,195,"We have created and tested Tahuti, a dual-view sketch recognition environment for class diagrams in UML. The system is based on a multi-layer recognition framework which recognizes multi-stroke objects by their geometrical properties allowing users the freedom to draw naturally as they would on paper rather than requiring the user to draw the objects in a pre-defined manner. Users can draw and edit while viewing either their original strokes or the interpreted version of their strokes engendering user-autonomy in sketching. The experiments showed that users preferred Tahuti to a paint program and to Rational Rose™ because it combined the ease of drawing found in a paint program with the ease of editing available in a UML editor."
"Y. Qu, T. Wong, P. Heng",f2e4b98295a6e11a329bc800fd24123ae1760c2c,Manga colorization,SIGGRAPH 2006,2006.0,126,"This paper proposes a novel colorization technique that propagates color over regions exhibiting pattern-continuity as well as intensity-continuity. The proposed method works effectively on colorizing black-and-white manga which contains intensive amount of strokes, hatching, halftoning and screening. Such fine details and discontinuities in intensity introduce many difficulties to intensity-based colorization methods. Once the user scribbles on the drawing, a local, statistical based pattern feature obtained with Gabor wavelet filters is applied to measure the pattern-continuity. The boundary is then propagated by the level set method that monitors the pattern-continuity. Regions with open boundaries or multiple disjointed regions with similar patterns can be sensibly segmented by a single scribble. With the segmented regions, various colorization techniques can be applied to replace colors, colorize with stroke preservation, or even convert pattern to shading. Several results are shown to demonstrate the effectiveness and convenience of the proposed method."
"J. Pu, K. Ramani",302e631bf51560494d09085fa5a7ea56458c036a,On visual similarity based 2D drawing retrieval,Comput. Aided Des.,2006.0,86,"A large amount of 2D drawings have been produced in engineering fields. To reuse and share the available drawings efficiently, we propose two methods in this paper, namely 2.5D spherical harmonics transformation and 2D shape histogram, to retrieve 2D drawings by measuring their shape similarity. The first approach represents a drawing as a spherical function by transforming it from a 2D space into a 3D space. Then a fast spherical harmonics transformation is employed to get a rotation invariant descriptor. The second statistics-based approach represents the shape of a 2D drawing using a distance distribution between two randomly sampled points. To allow users to interactively emphasize certain local shapes that they are interested in, we have adopted a flexible sampling strategy by specifying a bias sampling density upon these local shapes. The two proposed methods have many valuable properties, including transform invariance, efficiency, and robustness. In addition, their insensitivity to noise allows for the user's causal input, thus supporting a freehand sketch-based retrieval user interface. Experiments show that a better performance can be achieved by combining them together using weights."
"S. Reddy, M. Dass",3e4d01a4845893a4286f35e58a9880bc78b1203f,Modeling On-Line Art Auction Dynamics Using Functional Data Analysis,,2006.0,58,"In this paper, we examine the price dynamics of online art auctions of Modern Indian Art using Functional Data Analysis. The purpose here is not just to understand what determines the final prices of art objects but also the price movement during the entire auction. We identify several factors such as artist characteristics (established or emerging artist; prior sales history), art characteristics (size; painting medium - canvas or paper), competition characteristics (current no. of bidders; current no. of bids) and auction design characteristics (opening bid; position of the lot in the auction) that explain the dynamics of price movement in an online art auction. We find that the effects on price vary over the duration of the auction, with some of these effects being stronger at the beginning of the auction (such as the opening bid and historical prices realized). In some cases, the rate of change in prices (velocity) increases at the end of the auction (for canvas paintings and paintings by established artists). Our analysis suggests that the opening bid is positively related to online auction price levels of art at the beginning of the auction but its effect declines towards the end of the auction. The order in which the lots appear in an art auction is negatively related to the current price level with this relationship decreasing towards the end of the auction. This implies that lots that appear earlier have higher current prices during the early part of the auction but that effect diminishes by the end of the auction. Established artists show a positive relationship with the price level at the beginning of the auction. Reputation or popularity of the artists and their investment potential as assessed by previous history of sales are positively related to the price levels at the beginning of the auction. The medium (canvas or paper) of the painting did not show any relationship with art auction price levels, but the size of the painting was negatively related to the current price during the early part of the auction. Important implications for auction design are drawn from the analysis."
"Daehyun Kim, Myoung-Jun Kim",da2da6329dd6b1a65960d12bff2cdcb2547d3976,A curvature estimation for pen input segmentation in sketch-based modeling,Comput. Aided Des.,2006.0,54,"A proper segmentation of pen marking enhances shape recognition and enables a natural interface for sketch-based modeling from simple line drawing tools to 3D solid modeling applications; user input is otherwise restricted to draw only one segment per one stroke. In general, the pen marking segmentation is achieved by detecting the points of high curvature-called, segmenting points-and splitting the pen marking at those points. This paper presents a curvature estimation method, which considers only local shape information. The proposed method can therefore estimate curvature on-the-fly while user is drawing on a pen-input display, such as tablet PCs."
"Yung-hui Li, M. Savvides, B. V. Kumar",b9abb124e2ae1065db1d3f4450f871ad4bc2be7a,Illumination Tolerant Face Recognition Using a Novel Face From Sketch Synthesis Approach and Advanced Correlation Filters,2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings,2006.0,48,"Current state-of-the-art approach for performing face sketch recognition transforms all the test face images into sketches, and then performs recognition on sketch domain using the sketch composite. In our approach we propose the opposite; which has advantages in a real-time system; we propose to generate a realistic face image from the composite sketch using a hybrid subspace method and then build an illumination tolerant correlation filter which can recognize the person under different illumination variations from a surveillance video footage. We show how effective proposed algorithm works on the CMU PIE (pose illumination and expression) database"
"Christina N. de Juan, B. Bodenheimer",435064cc12e0cd10609f33fe436f6df0b163ddb6,Re-using traditional animation: methods for semi-automatic segmentation and inbetweening,SCA '06,2006.0,43,"A large body of traditional animation exists that contains characters with poses, expressions, and appeal not easily achievable with modern 3D techniques. To create new uses for this body of animation, this paper presents components of a system that can help incorporate the animation into re-usable libraries. In particular, we discuss two semi-automatic techniques that allow the re-use of traditional animation. First, support vector machines are used to segment cartoon images from their backgrounds for incorporation into an image library, for such applications as re-sequencing. Second, a radial basis function implicit surface modeling technique and a fast non-rigid elastic registration algorithm provide inbetween contours and textures given two key images of traditional animation. Our system is fast, model-free, and requires minimal animator intervention."
"I. Kokkinos, P. Maragos, A. Yuille",3f3cbe95dc58f3d5b9343e8654dc4f9bec731ded,Bottom-Up &amp; Top-down Object Detection using Primal Sketch Features and Graphical Models,2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06),2006.0,43,"A combination of techniques that is becoming increasingly popular is the construction of part-based object representations using the outputs of interest-point detectors. Our contributions in this paper are twofold: first, we propose a primal-sketch-based set of image tokens that are used for object representation and detection. Second, top-down information is introduced based on an efficient method for the evaluation of the likelihood of hypothesized part locations. This allows us to use graphical model techniques to complement bottom-up detection, by proposing and finding the parts of the object that were missed by the front-end feature detection stage. Detection results for four object categories validate the merits of this joint top-down and bottom-up approach."
"Junfa Liu, Yiqiang Chen, W. Gao",8d26bb3029bc8d03ed96cdfa2990662f1c56a703,Mapping learning in eigenspace for harmonious caricature generation,MM '06,2006.0,41,"This paper proposes a mapping learning approach for caricature auto-generation. Simulating the artist's creativity based on the object's facial feature, our approach targets discovering what are the principal components of the facial features, and what's the difference between facial photograph and caricature measured by those components. In training phase, PCA approach is adopted to obtain the principal components. Then, machine learning of SVR (Support Vector Regression) is carried out to learn the mapping model in principal component space. With the mapping model, in application phase, users just need to input a frontal facial photograph for the caricature generation. The caricature is exaggerated based on the original face while reserving essential similar features. Experiments proved comparatively that our approach could generate more harmonious caricatures."
"D. Sharon, M. V. D. Panne",4554c0f4d846e84edb8afb85b47c6a583844b6d3,Constellation models for sketch recognition,SBM'06,2006.0,30,"Sketch-based modeling shares many of the difficulties of the branch of computer vision that deals with single image interpretation. Most obviously, they must both identify the parts observed in a given 2D drawing or image.We draw on constellation models first proposed in the computer vision literature to develop probabilistic models for object sketches, based on multiple example drawings. These models are then applied to estimate the most-likely labels for a new sketch. A multi-pass branch-and-bound algorithm allows well-formed sketches to be quickly labelled, while still supporting the recognition of more ambiguous sketches. Results are presented for five classes of objects."
"C. Alvarado, Randall Davis",1cf9eccfe8d7fc1f80fbd9f1342c4df0866e5caf,Dynamically constructed Bayes nets for multi-domain sketch understanding,SIGGRAPH Courses,2006.0,29,"This paper presents a novel form of dynamically constructed Bayes net, developed for multi-domain sketch recognition. Our sketch recognition engine integrates shape information and domain knowledge to improve recognition accuracy across a variety of domains using an extendible, hierarchical approach. Our Bayes net framework integrates the influence of stroke data and domain-specific context in recognition, enabling our recognition engine to handle noisy input. We illustrate this behavior with qualitative and quantitative results in two domains: hand-drawn family trees and circuits."
"Suyu Hou, K. Ramani",f531ab313c5070e2762ca02178aa310c5bd14e3b,Sketch-based 3D engineering part class browsing and retrieval,SBM'06,2006.0,26,"We present a two-tier sketch-based engineering part retrieval system enhanced with classifier combination. Given a free-hand user sketch, we propose to use an ensemble of classifiers to estimate the likelihood of the sketch belonging to each category by exploring the strengths of individual classifiers. This supports high quality part retrieval by motivating user feedback with a ranked list of top choices. Three shape descriptors have been used to generate the probability-based classifiers independently. Experiments are conducted using the Engineering Shape Benchmark database in order to evaluate the selected combination rules before we integrate the best rule for sketch classification. User studies with the system show that users can easily identify the desired groups and then the parts. In addition, the precision attained using the synthesis is better than results from independent classifiers when applied to both user sketches and 3D models."
"L. Itti, Nitin Dhavale, Frédéric H. Pighin",9fabefeeee57ceeee75cf28f3640400b71e9deab,Photorealistic Attention-Based Gaze Animation,2006 IEEE International Conference on Multimedia and Expo,2006.0,25,"We apply a neurobiological model of visual attention and gaze control to the automatic animation of a photorealistic virtual human head. The attention model simulates biological visual processing along the occipito-parietal pathway of the primate brain. The gaze control model is derived from motion capture of human subjects, using high-speed video-based eye and head tracking apparatus. Given an arbitrary video clip, the model predicts visual locations most likely to attract an observer's attention, and simulates the dynamics of eye and head movements towards these locations. Tested on 85 video clips including synthetic stimuli, video games, TV news, sports, and outdoor scenes, the model demonstrates a strong ability at saccading towards and tracking salient targets. The resulting autonomous virtual human animation is of photorealistic quality"
"Won-Il Hwang, Pyung-Jun Lee, Bong-Kyung Chun, Dong-Sung Ryu, Hwan-Gue Cho",82be97d83bf1e19346df83db991e21c73c80a4e5,Cinema comics: Cartoon generation from video stream,GRAPP,2006.0,23,"This paper presents CORVIS(COmics Rendering system on VIdeo Stream) which helps to create comic strips from video streams in semi-automated manner. For this, first we manually select a set of important featuring scenes in a cinema and transform them into simplified illustrations by Mean-Shift segmentation. Then we insert the stylized comic effects to each illustration by considering the before/after video images. We newly proposed some techniques for this cartoon rendering effects. These stylized effects include the speed line, rotational trajectory and the background effect. Finally CORVIS automatically places the word balloons to represent the dialogues of actors. And echoic words e.g., “BANG”, will be inserted in the comic cut to imitate the sound effects of the original film. We tested CORVIS with the well-known cinemas, “Spider Man II” and “I ROBOT”. The final results show that our technique is quite effective and efficient to create a comic booklet from video streams."
"A. Lovett, Morteza Dehghani, Kenneth D. Forbus",416e08f85844ec604316cd70a1de421cf70b65e0,Efficient Learning of Qualitative Descriptions for Sketch Recognition,,2006.0,17,"We are trying to solve the problem of learning to recognize objects in an open-domain sketching environment. Our system builds generalizations of objects based upon previous sketches of those objects and uses those generalizations to classify new sketches. We represent sketches qualitatively because we believe qualitative information provides a level of description that abstracts away details that distract from classification, such as exact dimensions. Bayesian reasoning is used in the process of building up representations to deal with the inherent uncertainty in the perception problem. Qualitative representations are compared using SME, a computational model of analogy and similarity that is supported by psychological evidence from studies of perceptual similarity. We produce generalizations based on the common structure found by SME in different sketches of the same object. We report on the results of testing the system on a corpus of sketches of everyday objects, drawn by ten"
"Yu-Lun Chen, W. Liao, P. Chiang",14f7cbb0f5d164d107bc93d6323236de6d8483f1,Generation of 3D Caricature by Fusing Caricature Images,"2006 IEEE International Conference on Systems, Man and Cybernetics",2006.0,9,"Caricatures are exaggerated, cartoon-like portraits that try to capture the essence of the subject with a bit of humor or sarcasm. In this paper, we extend the automatic caricature generation algorithm developed previously in two important aspects: 1) we improve the facial feature detection procedure by incorporating active appearance models, and 2) we extend the original 2D model to stereo by fusing caricature images obtained from different views. The result is a simple yet effective procedure for creating stylized 3D models with a high degree of flexibility in selecting artistic flavors."
D. Eppstein,7cc2ba228852dc92f04ba6ede7459b989fcad30f,Upright-Quad Drawing of st-Planar Learning Spaces,Graph Drawing,2006.0,9,"We consider graph drawing algorithms for learning spaces, a type of st-oriented partial cube derived from antimatroids and used to model states of knowledge of students. We show how to draw any st-planar learning space so all internal faces are convex quadrilaterals with the bottom side horizontal and the left side vertical, with one minimal and one maximal vertex. Conversely, every such drawing represents an st-planar learning space. We also describe connections between these graphs and arrangements of translates of a quadrant."
"Hongmei He, O. Sýkora",cd5d7daa33160d4dd5a8f908005e66646254918a,A Hopfield Neural Network Model for the Outerplanar Drawing Problem,IMECS,2006.0,6,"In the outerplanar (other alternate concepts are circular or one-page) drawing, one places vertices of a n−vertex m−edge connected graph G along a circle, and the edges are drawn as straight lines. The minimal number of crossings over all outerplanar drawings of the graph G is called the outerplanar (circular, convex, or one-page) crossing number of the graph G. To find a drawing achieving the minimum crossing number is an NP-hard problem. In this work we investigate the outerplanar crossing number problem with a Hopfield neural network model, and improve the convergence of the network by using the Hill Climbing algorithm with local movement. We use two kinds of energy functions, and compare their convergence. We also test a special kind of graphs, complete p-partite graphs. The experimental results show the neural network model can achieve crossing numbers close to the optimal values of the graphs tested."
"Jianming Liu, Dongming Lu, X. Shi",872cd022ce646cfad9b9c2ba591f8446a22cae89,Interactive Sketch Generation for Dunhuang Frescoes,Edutainment,2006.0,5,"Taking Dunhuang MoGao Frescoes as research background, a new method to generate the sketch for Dunhuang frescoes is proposed. Learning from the traditional manual imitation procedure, we first get the contour line of a Dunhuang fresco which is composed of many connected curves, and then render the strokes by learning styles from examples. For several example strokes, the style of example strokes are captured and expressed as style function. Given a target curve, a new stroke can be generated with the style of one example and moreover, the style of the target stroke can be further customized into different styles similar to the examples by interpolation of styles. This research has the potential to provide a computer aided tool for art historians to do imitation work, and improve the efficiency of imitation."
"K. Lai, P. Chung, E. Edirisinghe",231fc0b45e5d9d5c7eb02dacb4ba305eada64655,NOVEL APPROACH TO NEURAL NETWORK BASED CARICATURE GENERATION,,2006.0,5,"A caricature is defined as a funny drawing of someone that makes some of his/her distinct features appear exaggerated or more amusing. However the caricatures of the same person created by different artists can be very different, since the artists drawing styles play an important role (Hughes, 1999). Therefore learning the drawing style of an artist provides the key to the computer based automatic generation of professional caricature. Unfortunately, no caricature generation system in the past has attempted to address this issue with the aid of artificial intelligence technologies. In this paper, the authors propose an example-based caricature generation system with experimental results and detailed analysis to prove that neural networks can be used for capturing the drawing style of an artist. This work is the first system to use neural networks in generating caricature."
"K. Lai, E. Edirisinghe, P. Chung",ae03f532c84a2d64993ce77d2bc7153ef4494b97,A facial component based hybrid approach to caricature generation using neural networks,Computational Intelligence,2006.0,5,Coatings particularly useful as marking inks in which an epichlorhydrin-modified polyethylenimine and an ethylene oxide-modified polyethylenimine cooperate in aqueous solution to form a composition capable of application to form deposits adherent to most materials and resistant to most organic solvents but readily removable by water.
V. V. Migunov,c184b10dc2c1381ebf155372aed1f04da0a1f18c,Environment of development of the programs of parametric creating of the drawings in CAD-system of renovation of the enterprises,ArXiv,2006.0,0,"The main ideas, data structures, structure and realization of operations with them in environment of development of the programs of parametric creating of the drawings are considered for the needs of the automated design engineering system of renovation of the enterprises. The example of such program and example of application of this environment for creating the drawing of the base for equipment in CAD-system TechnoCAD GlassX are presented"
"Michael Elad, J. Starck, P. Querre, D. Donoho",c77338d031d41c3c5ae027e64a64242555b3ec2d,Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA),,2005.0,880,"This paper describes a novel inpainting algorithm that is capable of filling in holes in overlapping texture and cartoon image layers. This algorithm is a direct extension of a recently developed sparse-representation-based image decomposition method called MCA (morphological component analysis), designed for the separation of linearly combined texture and cartoon layers in a given image (see [J.-L. Starck, M. Elad, D.L. Donoho, Image decomposition via the combination of sparse representations and a variational approach, IEEE Trans. Image Process. (2004), in press] and [J.-L. Starck, M. Elad, D.L. Donoho, Redundant multiscale transforms and their application for morphological component analysis, Adv. Imag. Electron Phys. (2004) 132]). In this extension, missing pixels fit naturally into the separation framework, producing separate layers as a by-product of the inpainting process. As opposed to the inpainting system proposed by Bertalmio et al., where image decomposition and filling-in stages were separated as two blocks in an overall system, the new approach considers separation, hole-filling, and denoising as one unified task. We demonstrate the performance of the new approach via several examples."
"Qingshan Liu, X. Tang, Hongliang Jin, Hanqing Lu, Songde Ma",0495cb430916e2657d4d42c9b695029f020a33d3,A nonlinear approach for face sketch synthesis and recognition,2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05),2005.0,310,"Most face recognition systems focus on photo-based face recognition. In this paper, we present a face recognition system based on face sketches. The proposed system contains two elements: pseudo-sketch synthesis and sketch recognition. The pseudo-sketch generation method is based on local linear preserving of geometry between photo and sketch images, which is inspired by the idea of locally linear embedding. The nonlinear discriminate analysis is used to recognize the probe sketch from the synthesized pseudo-sketches. Experimental results on over 600 photo-sketch pairs show that the performance of the proposed method is encouraging."
"T. M. Sezgin, Randall Davis",92a75bc96529228605358981a8014b4a8d9dbb22,HMM-based efficient sketch recognition,IUI '05,2005.0,166,"Current sketch recognition systems treat sketches as images or a collection of strokes, rather than viewing sketching as an interactive and incremental process. We show how viewing sketching as an interactive process allows us to recognize sketches using Hidden Markov Models. We report results of a user study indicating that in certain domains people draw objects using consistent stroke orderings. We show how this consistency, when present, can be used to perform sketch recognition efficiently. This novel approach enables us to have polynomial time algorithms for sketch recognition and segmentation, unlike conventional methods with exponential complexity."
"Tong Lu, C. Tai, Feng Su, Shijie Cai",045c4e110157b5abf1c13ffca4bbf248a4816d58,A new recognition model for electronic architectural drawings,Comput. Aided Des.,2005.0,85,"Current methods for recognition and interpretation of architectural drawings are limited to either low-level analysis of paper drawings or interpretation of electronic drawings that depicts only high-level design entities. In this paper, we propose a Self-Incremental Axis-Net-based Hierarchical Recognition (SINEHIR) model for automatic recognition and interpretation of real-life complex electronic construction structural drawings. We design and implement a series of integrated algorithms for recognizing dimensions, coordinate systems and structural components. We tested our approach on more than 200 real-life drawings. The results show that the average recognition rate of structural components is about 90%, and the computation time is significantly shorter than manual estimation time."
"Pascal Barla, J. Thollot, F. Sillion",a7e1f466cf615e9e2fac51223b39b36e65ef1f80,Geometric clustering for line drawing simplification,SIGGRAPH '05,2005.0,72,"We present a new approach to the simplification of line drawings, in which a smaller set of lines is created to represent the geometry of the original lines. An important feature of our method is that it maintains the morphological structure of the original drawing while allowing user-de ned decisions about the appearance of lines. The technique works by analyzing the structure of the drawing at a certain scale and identifying clusters of lines that can be merged given an extendable error threshold. These clusters are then processed to create new lines, in a separate stage where different scenarios can be favored based on the application. Successful results are presented for a variety of drawings including scanned and vectorized artwork, original vector drawings, drawings created from 3d models, and hatching marks. The clustering technique is shown to be effective in all these situations."
"J. Pu, Kuiyang Lou, K. Ramani",7dbdb80f12924124de1892bb32f7d39ba74f6cd5,A 2D Sketch-Based User Interface for 3D CAD Model Retrieval,,2005.0,69,"AbstractThis paper describes a sketch user interface enhanced by feedback for 3D CAD model retrieval. Users can express their intent by sketching 2D shape in the way as engineers draw three views of 3D models. It not only supports users’ free form sketches, but also accepts users’ further editing operations and feedbacks. The interaction paradigm proposed in this paper is supported by a 3D shape matching method, in which three problems are solved: determination of projecting planes and directions, 2D view generation, and similarity measuring between views. In addition, experiments are conducted to evaluate the performance of this sketch user interface by 3D model retrieval."
"Yao-Jen Chang, T. Ezzat",9e01d25596e542a621475075d4a5200365a9fa0d,Transferable videorealistic speech animation,SCA '05,2005.0,55,"Image-based videorealistic speech animation achieves significant visual realism at the cost of the collection of a large 5- to 10-minute video corpus from the specific person to be animated. This requirement hinders its use in broad applications, since a large video corpus for a specific person under a controlled recording setup may not be easily obtained In this paper, we propose a model transfer and adaptation algorithm which allows for a novel person to be animated using only a small video corpus. The algorithm starts with a multidimensional morphable model (MMM) previously trained from a different speaker with a large corpus, and transfers it to the novel speaker with a much smaller corpus. The algorithm consists of 1) a novel matching-by-synthesis algorithm which semi-automatically selects new MMM prototype images from the new video corpus and 2) a novel gradient descent linear regression algorithm which adapts the MMM phoneme models to the data in the novel video corpus. Encouraging experimental results are presented in which a morphable model trained from a performer with a 10-minute corpus is transferred to a novel person using a 15-second movie clip of him as the adaptation video corpus."
"J. Pu, K. Ramani",f30e1a4e1eb8a968f32203a68ae44af6236aa5ac,A 3D Model Retrieval Method Using 2D Freehand Sketches,International Conference on Computational Science,2005.0,45,"In this paper, a method is proposed to retrieve desired 3D models by measuring the similarity between a user's freehand sketches and 2D orthogonal views generated from 3D models. The proposed method contains three parts: (1) pose determination of a 3D model; (2) 2D orthogonal view generation along the orientations; and (3) similarity measurement between a user's sketches and the 2D views. Users can submit one, two or three views intuitively as a query, which are similar to the three main views in engineering drawing. It is worth pointing point out that our method only needs three views, while 13 views is the minimum set that has been reported by other researchers."
"Manuel J. Fonseca, Alfredo Ferreira, J. Jorge",26432c119d4b4e30163a56727aa7d435ea72b150,Content-based retrieval of technical drawings,Int. J. Comput. Appl. Technol.,2005.0,41,"This paper presents a new approach to classify, index and retrieve technical drawings by content. Our work uses spatial relationships, shape geometry and high-dimensional indexing mechanisms to retrieve complex drawings from CAD databases. This contrasts with conventional approaches which use mostly textual metadata. Creative designers and draftspeople often re-use data from previous projects, publications and libraries of ready-to-use components. Usually, retrieving these drawings is a slow, complex and error-prone endeavour. Unfortunately, the widespread use of CAD systems, while making it easier to create drawings, exacerbates this problem, insofar as the number of projects grows enormously, without providing adequate searching mechanisms to support retrieving these documents. We describe an approach that supports automatic indexation of technical drawing databases through drawing simplification, feature extraction and efficient algorithms to index large amounts of data. We describe in detail our classification process and present results from usability tests on our prototype."
"L. Duchêne, A. Habraken",0ad78aa0db2c997ad2980ca18993366e1fbc926e,Analysis of the sensitivity of FEM predictions to numerical parameters in deep drawing simulations,,2005.0,34,"In this study, deep drawing finite element (FE) simulations are compared with experimental results. The steel grade, the geometry and the parameters of the experimental deep drawing processes are detailed in this paper. Particular attention is paid to numerical models. The main part of the article is dedicated to a broad sensitivity study. The influence of several numerical parameters on the predicted punch force and earing profile is analysed. A quadratic [Hill, R., 1948. A theory of the yielding and plastic flow of anisotropic metals. Proc. Roy. Soc. London Ser. A 193, 281-297] constitutive law is compared with more sophisticated micro-macro constitutive laws. The sensitivity of these laws to the initial data characterizing material behaviour is presented. A significant influence of the FE type and the number of FE layers is noticed. Finally, it also appears that friction parameters (penalty coefficient and Coulomb friction coefficient) have a significant influence on numerical results. The low anisotropy of the steel sheet increases the influence of several numerical parameters. That influence would not be observed with a highly anisotropic steel."
"R. N. Shet, K. Lai, E. Edirisinghe, P. Chung",4eec281384531ba93abe1cc2a82957d22480be0a,Use of Neural Networks in Automatic Caricature Generation: An Approach Based on Drawing Style Capture,IbPRIA,2005.0,25,"Caricature is emphasizing the distinctive features of a particular face. Exaggerating the Difference from the Mean (EDFM) is widely accepted among caricaturists to be the driving factor behind caricature generation. However the caricatures created by different artists have different drawing style. No attempt has been taken in the past to identify these distinct drawing styles. Yet the proper identification of the drawing style of an artist will allow the accurate modelling of a personalised exaggeration process, leading to fully automatic caricature generation with increased accuracy. In this paper we provide experimental results and detailed analysis to prove that a Cascade Correlation Neural Network (CCNN) can be used for capturing the drawing style of an artist and thereby used in realistic automatic caricature generation. This work is the first attempt to use neural networks in this application area and have the potential to revolutionize existing automatic caricature generation technologies."
"H. Kang, W. He, C. Chui, U. Chakraborty",76508fba312ad35645b16ea4fd52caf15a7f9897,Interactive sketch generation,The Visual Computer,2005.0,24,"In this paper, we propose an interactive system for generating artistic sketches from images, based on the stylized multiresolution B-spline curve model and the livewire contour tracing paradigm. Our multiresolution B-spline stroke model allows interactive and continuous control of style and shape of the stroke at any level of details. Especially, we introduce a novel mathematical paradigm called the wavelet frame to provide essential properties for multiresolution stroke editing, such as feature point preservation, locality, time-efficiency, good approximation, etc. The livewire stroke map construction leads the user-guided stroke to automatically lock on to the target contour, allowing fast and accurate sketch drawing. We classify the target contours as outlines and interior flow, and develop two respective livewire techniques based on extended graph formulation and vector flow field. Experimental results show that the proposed system facilitates quick and easy generation of artistic sketches of various styles."
"Hyun-Chul Lee, In-Kwon Lee",5afded540f0d5ba60a7855192492c2042f12c961,Automatic Synchronization of Background Music and Motion in Computer Animation,Comput. Graph. Forum,2005.0,24,"We synchronize background music with an animation by changing the timing of both, an approach which minimizes the damage to either. Starting from a MIDI le and motion data, feature points are extracted from both sources, paired, and then synchronized using dynamic programming to time-scale the music and to timewarp the motion. We also introduce the music graph, a directed graph which encapsulates connections between many short music sequences. By traversing a music graph we can generate large amounts of new background music, in which we expect to nd a sequence which matches the motion better than the original music."
"Shuang Liang, Z. Sun, B. Li, Gui-Huan Feng",b002f8914e9be261c498c33cb854b8e89a5a2616,Effective sketch retrieval based on its contents,2005 International Conference on Machine Learning and Cybernetics,2005.0,15,"Content of sketch is different to that of image, since sketch is made up of strokes, not pixels, contains more structural and semantic information. In this paper, an effective approach for content-based sketch retrieval is proposed. With structural and ambiguous properties, the contents what sketch retrieval stressed would be the topology among constitutes of sketch, which accommodate geometry invariance. Sketches retrieval is achieved by means of similarity calculation of topological features representing the sketch content. The relevance feedback is also introduced to refine the retrieval results. Experiments prove the effectiveness and efficiency of the method in content-based sketch retrieval and user independent."
"R. Glasberg, A. Samour, K. Elazouzi, T. Sikora",5211acb7d70c605e869a1edd6920149d6fa4de02,Cartoon-recognition using video & audio descriptors,2005 13th European Signal Processing Conference,2005.0,13,"We present a new approach for classifying mpeg-2 video sequences as `cartoon' or `non-cartoon' by analyzing specific video and audio features of consecutive frames in real-time. This is part of the well-known video-genre-classification problem, where popular TV-broadcast genres like cartoon, commercial, music, news and sports are studied. Such applications have also been discussed in the context of MPEG-7 [12]. In our method the extracted features from the visual descriptors are non-linearly combined using a multilayered perceptron and then considered together with the output of the audio-descriptor to produce a reliable recognition. The results demonstrate a high identification rate based on a large collection of 100 representative video sequences (20 cartoons and 4*20 non-cartoons) gathered from free digital TV-broadcasting."
"Junfa Liu, Yiqiang Chen, W. Gao, Rong Fu, Renqin Zhou",9234917e15e118dd8645d8d1a900edc1419d351a,Creative Cartoon Face Synthesis System for Mobile Entertainment,PCM,2005.0,5,"This paper presents a prototype system, which synthesizes entertainment-oriented cartoon face and translates text message to multimedia animation in mobile phone. While a digital real facial photograph and some text are imputed, a piece of exaggerated facial animation with entertainment will be shown in the phone. Three steps are used to get this entertainment effect: first is the illustration generation of the real face image, General-Scale-Edge (GSE) is adopted to take various scale of the edge into account, which can extract the feature edge on human's face efficiently. The second is the expression warping to produce a caricature. The improved feature based warping method is employed. Finally, we generate the exaggerated facial animation based on the caricature using TTVS method. In addition, we improved modified Active Shape Model to remove the background and control more feature points on the face. Experiments show the system work well with high performance on the PDA."
"X. Tang, Xiaogang Wang",79a176d432659450524290555460947ef7cdd895,Face sketch recognition,IEEE Transactions on Circuits and Systems for Video Technology,2004.0,328,"Automatic retrieval of face images from police mug-shot databases is critically important for law enforcement agencies. It can effectively help investigators to locate or narrow down potential suspects. However, in many cases, a photo image of a suspect is not available and the best substitute is often a sketch drawing based on the recollection of an eyewitness. We present a novel photo retrieval system using face sketches. By transforming a photo image into a sketch, we reduce the difference between photo and sketch significantly, thus allowing effective matching between the two. Experiments over a data set containing 188 people clearly demonstrate the efficacy of the algorithm."
"J. LaViola, R. Zeleznik",ab606d64fb476b8826a7a5c3c455318f045cae26,MathPad 2 : a system for the creation and exploration of mathematical sketches,SIGGRAPH 2004,2004.0,202,"We present mathematical sketching, a novel, pen-based, modeless gestural interaction paradigm for mathematics problem solving. Mathematical sketching derives from the familiar pencil-and-paper process of drawing supporting diagrams to facilitate the formulation of mathematical expressions; however, with a mathematical sketch, users can also leverage their physical intuition by watching their hand-drawn diagrams animate in response to continuous or discrete parameter changes in their written formulas. Diagram animation is driven by implicit associations that are inferred, either automatically or with gestural guidance, from mathematical expressions, diagram labels, and drawing elements. The modeless nature of mathematical sketching enables users to switch freely between modifying diagrams or expressions and viewing animations. Mathematical sketching can also support computational tools for graphing, manipulating and solving equations; initial feedback from a small user group of our mathematical sketching prototype application, MathPad2, suggests that it has the potential to be a powerful tool for mathematical problem solving and visualization."
"C. Alvarado, Randall Davis",4a57056566e741e4daa34059374f078f46d8717d,SketchREAD: a multi-domain sketch recognition engine,UIST '04,2004.0,161,"We present SketchREAD, a multi-domain sketch recognition engine capable of recognizing freely hand-drawn diagrammatic sketches. Current computer sketch recognition systems are difficult to construct, and either are fragile or accomplish robustness by severely limiting the designer's drawing freedom. Our system can be applied to a variety of domains by providing structural descriptions of the shapes in that domain; no training data or programming is necessary. Robustness to the ambiguity and uncertainty inherent in complex, freely-drawn sketches is achieved through the use of context. The system uses context to guide the search for possible interpretations and uses a novel form of dynamically constructed Bayesian networks to evaluate these interpretations. This process allows the system to recover from low-level recognition errors (e.g., a line misclassified as an arc) that would otherwise result in domain level recognition errors. We evaluated Sketch-READ on real sketches in two domains--family trees and circuit diagrams--and found that in both domains the use of context to reclassify low-level shapes significantly reduced recognition error over a baseline system that did not reinterpret low-level classifications. We also discuss the system's potential role in sketch based user interfaces."
"Robert T. Schweller, A. Gupta, E. Parsons, Y. Chen",ec16f48079432902f62ed8f98604f7ab0e0bba58,Reversible sketches for efficient and accurate change detection over network data streams,IMC '04,2004.0,147,"Traffic anomalies such as failures and attacks are increasing in frequency and severity, and thus identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows and looks for heavy changes in traffic patterns (<i>e.g.</i>, volume, number of connections). However, as link speeds and the number of flows increase, keeping per-flow state is not scalable. The recently proposed sketch-based schemes [14] are among the very few that can detect heavy changes and anomalies over massive data streams at network traffic speeds. However, sketches do not preserve the key (<i>e.g.</i>, source IP address) of the flows. Hence, even if anomalies are detected, it is difficult to infer the culprit flows, making it a big practical hurdle for online deployment. Meanwhile, the number of keys is too large to record.
 To address this challenge, we propose efficient <i>reversible hashing</i> algorithms to infer the keys of culprit flows from sketches without storing any explicit key information. No extra memory or memory accesses are needed for recording the streaming data. Meanwhile, the heavy change detection daemon runs in the background with space complexity and computational time sublinear to the key space size. This short paper describes the conceptual framework of the reversible sketches, as well as some initial approaches for implementation. See [23] for the optimized algorithms in details. comment We further apply various emph IP-mangling algorithms and emph bucket classification methods to reduce the false positives and false negatives. Evaluated with netflow traffic traces of a large edge router, we demonstrate that the reverse hashing can quickly infer the keys of culprit flows even for many changes with high accuracy."
"D. Sýkora, J. Buriánek, J. Zára",28077cc8f499bba7036b2a31ebc88a0fd9c9542a,Unsupervised colorization of black-and-white cartoons,NPAR '04,2004.0,99,"We present a novel color-by-example technique which combines image segmentation, patch-based sampling and probabilistic reasoning. This method is able to automate colorization when new color information is applied on the already designed black-and-white cartoon. Our technique is especially suitable for cartoons digitized from classical celluloid films, which were originally produced by a paper or cel based method. In this case, the background is usually a static image and only the dynamic foreground needs to be colored frame-by-frame. We also assume that objects in the foreground layer consist of several well visible outlines which will emphasize the shape of homogeneous regions."
"P. Chiang, W. Liao, T. Li",575949a974e1b86f2cacd8553126f48429f6aef4,Automatic Caricature Generation by Analyzing Facial Features,,2004.0,77,"We developed a system for automatic generation of caricatures by analyzing unique facial features of the subject. The proposed face model contains 119 parameters derived from the MPEG-4 standard. These nodes are categorized into 8 groups with a pre-defined hierarchy to guide the placement of face components after shape exaggeration. Given an input image, the system determines which and how the face component should be altered. Using an artist’s finished work as the source image, the system is capable of producing caricatures of a similar style effectively and efficiently."
"H. Hse, A. Newton",822273b5a17ef2ad5058e8172177279ef86f280a,Sketched symbol recognition using Zernike moments,"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.",2004.0,63,"We present an on-line recognition method for hand-sketched symbols. The method is independent of stroke-order, -number, and -direction, as well as invariant to scaling, translation, rotation and reflection of symbols. Zernike moment descriptors are used to represent symbols and three different classification techniques are compared: support vector machines (SVM), minimum mean distance (MMD), and nearest neighbor (NN). We have obtained a 97% recognition accuracy rate on a dataset consisting of 7,410 sketched symbols using Zernike moment features and a SVM classifier."
"Derek T. Anderson, Craig Bailey, M. Skubic",f3ad387153b733fc037d16bcf57a726a0b77f014,Hidden Markov Model Symbol Recognition for Sketch-Based Interfaces,AAAI Technical Report,2004.0,60,"A central challenge for sketch-based interfaces is robust symbol recognition. Artifacts such as sketching style, pixelized symbol representation and affine transformations are just a few of the problems. Temporal pattern recognition through Hidden Markov Models (HMM) can be used to recognize and distinguish symbols as pixel-driven gestures. The key challenges of such a system are the type and amount of necessary pre-processing, feature extraction, HMM parameter selection and optional post processing. In this paper, we describe a recognition strategy based on HMMs and include recognition results on twelve sketched symbols. In addition, we have successfully applied this methodology to a PDA sketch-based interface to control a team of robots. The symbol recognition component is used to identify sketched formations and issue commands that drive the behavior of the robot team."
"Zhenyao Mo, J. P. Lewis, U. Neumann",a5393833b07463528b36a41614f8c2f672103da9,Improved automatic caricature by feature normalization and exaggeration,SIGGRAPH '04,2004.0,51,"This sketch presents an improved formalization of automatic caricature that extends a standard approach to account for the population variance of facial features. Caricature is generally considered a rendering that emphasizes the distinctive features of a particular face. A formalization of this idea, which we term “Exaggerating the Difference from the Mean” (EDFM), is widely accepted among caricaturists [Redman 1984] and was first implemented in a groundbreaking computer program by [Brennan 1985]. Brennan’s “Caricature generator” program produced caricatures by manually defining a polyline drawing with topology corresponding to a frontal, mean, face-shape drawing, and then displacing the vertices by a constant factor away from the mean shape. Many psychological studies have applied the “Caricature Generator” or EDFM idea to investigate caricaturerelated issues in face perception [Rhodes 1997]."
"T. Hammond, Randall Davis",9bac471a202c6c7fa1ebcda031e2457034bd2358,Automatically Transforming Symbolic Shape Descriptions for Use in Sketch Recognition,AAAI,2004.0,46,"Sketch recognition systems are currently being developed for many domains, but can be time consuming to build if they are to handle the intricacies of each domain. This paper presents the first translator that takes symbolic shape descriptions (written in the LADDER sketch language) and automatically transforms them into shape recognizers, editing recognizers, and shape exhibitors for use in conjunction with a domain independent sketch recognition system. This transformation allows us to build a single domain independent recognition system that can be customized for multiple domains. We have tested our framework by writing several domain descriptions and automatically created a domain specific sketch recognition system for each domain."
"Kenneth D. Forbus, Kate Lockwood, M. Klenk, E. Tomai, Jeffrey M. Usher",153c62fb39dcded5b1e994270d49a7fa3d9a4648,Open-Domain Sketch Understanding: The nuSketch Approach,AAAI Technical Report,2004.0,42,"Sketching is often used when working out ideas. This combination of drawing and conceptual labeling is a very natural and effective form of communication and problemsolving. Creating software that can participate in sketching provides many challenges. We outline the nuSketch approach to sketch understanding, which focuses on visual and conceptual understanding instead of recognition. We summarize three experiments in progress with the sketching Knowledge Entry Associate (sKEA), the first open-domain sketch understanding system. sKEA exploits a variety of visual and qualitative spatial reasoning capabilities and human-like analogical matching to tackle a variety of tasks. We present experimental results, and outline future plans. The nuSketch approach Sketching is a form of multimodal interaction where participants use a combination of interactive drawing and language to provide high-bandwidth communication. This communication relies on shared understanding, both visual and conceptual. Multimodal interface research has mainly focused on providing more natural interfaces to legacy software, using recognition technologies to provide the desired interaction (Alvarado and Davis 2001, Cohen et al. 1997). While such systems have been shown to be quite useful in practice, we take a radically different approach. The nuSketch approach is based on a key observation about human-to-human sketching: Recognition is not essential. People are not artists in real time; they rely on language for conceptual labeling much of the time. While some specialized domains have visual symbol languages that practitioners use fluently, sketching is used far more broadly than that. In other words, for people, recognition is an accelerant, not a necessity. This suggests a very different approach to sketch understanding that complements recognition-oriented research. In the nuSketch approach, we sidestep recognition issues by providing other interface mechanisms for people to conceptually label their ink. This provides two crucial advantages. First, it enables us to focus on deeper visual and conceptual understanding of sketches. Second, it enables us to build sketching systems that can operate outside the tight domain constraints that bind today’s recognition-based systems. In particular, the sketching Knowledge Entry Associate (sKEA) (Forbus and Usher 2002) is, we believe, the first open-domain sketch understanding system. sKEA’s only coverage limitation comes from the underlying knowledge base it uses – currently a subset of Cyc, consisting of over 35,000 concepts, constrained by 1.2M facts. This does not mean that we can effectively reason with all of these concepts in sketches yet – that is the nature of the challenge we have undertaken! The nuSketch Architecture and sKEA In the nuSketch architecture, the basic unit in a sketch is a glyph. Every glyph has ink and content. The ink consists of one or more poly-lines, representing what the user drew. The content is a conceptual entity, the kind of thing that the glyph is representing. There are two key problems that any sketching system must solve: 1. Segmentation. What pieces of ink should be considered together as glyphs? 2. Conceptual Labeling. What conceptual entity does a glyph denote? We solve the segmentation problem by having the user click a button when they begin drawing a glyph and click it again when they are finished. Other segmentation techniques, such as time-outs and connectivity, are in our experience very frustrating for users and error-prone. We solve the conceptual labeling problem by enabling the content of a glyph to be declared, via a simple dialog, as one or more types drawn from the underlying knowledge base. This requires users to be familiar with the subset of the knowledge base that they need in their task, which is a strong limitation with the current version of the system. (We return to this issue at the end.) The nuSketch architecture uses a variety of geometric computations to visually construct qualitative representations, including RCC8 relations (Cohen 1996), Voronoi diagrams (Edwards and Moulin 1998) for approximating proximity, and polygon operations to capture domain constraints. A central feature of nuSketch is our use of analogical processing, based on Gentner’s structure-mapping theory (Gentner 1983). Analogy provides a powerful means of entering and testing knowledge. Currently sKEA enables users to compare two layers of a sketch, which enables the detection of similarities and differences. We use the Structure-Mapping Engine (SME) (Falkenhainer, Forbus and Gentner 1989) to perform the comparisons. SME is a general-purpose analogical matcher. sKEA’s analogies are based on both the visual and the conceptual material in a sketch. Some of our experiments also take advantage of the MAC/FAC system (Forbus, Gentner and Law 1994) which does a coarse matching using content vectors and then uses SME to narrow the results. SME produces candidate inferences, conjectures about one description based on its alignment with another. Candidate inferences are useful in knowledge capture because they suggest ways to flesh out a description based on similarities with prior knowledge. Since there is independent psychological evidence that structural alignment occurs in visual processing, and that SME captures many aspects of this processing accurately, it means that when our sense of similarity and our software’s sense of similarity about a sketch diverge, it is a sign that our representations have failed to capture something crucial about the sketch. This provides a powerful constraint that drives the visual and conceptual representations we compute. Even if one does not care about modeling human performance, a sketching system will be a better partner if you and it agree on when things look alike. Spatial Processing in nuSketch and sKEA While we do not use recognition techniques on our sketches, we do compute some simple spatial properties of the ink (Forbus and Usher 2002). We focus on the spatial relationships between the glyphs rather than doing detailed analysis of the structure of the glyphs themselves; we call this approach blob semantics. When a glyph is added, moved, or resized, sKEA computes a set of spatial attributes and relationships. This process is described in detail in (Forbus, Tomai, and Usher 2003). The spatial attributes and relationships that make up the visual structure of the sketch are: groupings, positional relationships, size, and orientation. sKEA automatically computes two kinds of groupings: contained glyph groups and connected glyph groups. A contained group consists of a single container glyph and the set of glyphs that are fully contained within it, possibly tangentially so. The contained group does not include glyphs that are contained within other glyphs in the group. A connected glyph group consists of a set of glyphs that overlap ink strokes with one another. Articulation points can be computed over connected glyph groups and tangentially connected pairs of glyphs can be noted as such. Positional relationships are computed pair-wise and expressed in a viewer-oriented coordinate system of left/right and above/below. They are not computed between all pairs of glyphs, but rather in local neighborhoods based on adjacency, as determined via a Voronoi diagram. Positional relationships are computed only between glyphs on the same layer of a sketch. Glyph size in sKEA is assigned as either tiny, small, medium, large or huge. Sizes are based on the area of a glyph’s axis-aligned bounding box, a coarse but empirically useful approximation. Glyph areas are normalized with respect to either the area of the bounding box around all glyphs on all layers or the users view port, whichever is larger. The normalized areas are then clustered into qualitative size values based on a logarithmic scale of the square root of the area. Additional Spatial Reasoning As part of our ongoing research we are developing more spatial reasoning capabilities to accomplish different research goals. Currently we are working on adding the ability to articulate the “important” points and segments on different objects as well as to more specifically define the relationship between adjacent glyphs. Another area where we need to expand our available spatial reasoning abilities is curvature. We are working on different techniques to qualitative summarize degree of curvature."
"E. Kaiser, D. Demirdjian, Alexander Gruenstein, Xiaoguang Li, J. Niekrasz, Matt Wesson, Sanjeev Kumar",e2ca45c612003d15074aa3c596dffaca319f2fa3,"A multimodal learning interface for sketch, speak and point creation of a schedule chart",ICMI '04,2004.0,39,"We present a video demonstration of an agent-based test bed application for ongoing research into multi-user, multimodal, computer-assisted meetings. The system tracks a two person scheduling meeting: one person standing at a touch sensitive whiteboard creating a Gantt chart, while another person looks on in view of a calibrated stereo camera. The stereo camera performs real-time, untethered, vision-based tracking of the onlooker's head, torso and limb movements, which in turn are routed to a 3D-gesture recognition agent. Using speech, 3D deictic gesture and 2D object de-referencing the system is able to track the onlooker's suggestion to move a specific milestone. The system also has a speech recognition agent capable of recognizing out-of-vocabulary (OOV) words as phonetic sequences. Thus when a user at the whiteboard speaks an OOV label name for a chart constituent while also writing it, the OOV speech is combined with letter sequences hypothesized by the handwriting recognizer to yield an orthography, pronunciation and semantics for the new label. These are then learned dynamically by the system and become immediately available for future recognition."
"Olya Veselova, Randall Davis",0f1e88e05ec2a6e92f7f6baafc20505aa8848b1f,Perceptually based learning of shape descriptions for sketch recognition,AAAI,2004.0,36,"We are interested in enabling a generic sketch recognition system that would allow more natural interaction with design tools in various domains, such as mechanical engineering, military planning, logic design, etc. We would like to teach the system the symbols for a particular domain by simply drawing an example of each one -- as easy as it is to teach a person. Studies in cognitive science suggest that, when shown a symbol, people attend preferentially to certain geometric features. Relying on such biases, we built a system capable of learning descriptions of hand-drawn symbols from a single example. The generalization power is derived from a qualitative vocabulary reflecting human perceptual categories and a focus on perceptually relevant global properties of the symbol. Our user study shows that the system agrees with the subjects' majority classification about as often as any individual subject did."
"G. Costagliola, V. Deufemia, G. Polese, M. Risi",d9ccd44f1842b785deb5120b6105c00af6713847,A Parsing Technique for Sketch Recognition Systems,2004 IEEE Symposium on Visual Languages - Human Centric Computing,2004.0,32,"Several disciplines require the support of computer-based tools for creating sketches during early design phases. Unfortunately, most computer programs cannot parse and semantically interpret handwritten sketches. In this paper, we present a framework for modeling sketch languages and for generating parsers to recognize them. The underlying parsing technique addresses the issues of stroke clustering and ambiguity resolution in sketches. We also present a workbench supporting the presented framework"
"Manuel J. Fonseca, Alfredo Ferreira, J. Jorge",3a42a29b782b9429511f8c66d88161c7ef17c59c,Towards 3D modeling using sketches and retrieval,SBM'04,2004.0,23,"Retrieving 2D and 3D drawings by content is not an easy task. Automatic feature extraction, indexing and matching are some of the problems raised by these approaches. We have developed a generic method to classify, index and retrieve drawings using sketches, based on spatial relationships, shape geometry and high-dimensional indexing mechanisms. This approach has been applied with success to retrieving clip-art and complex technical drawings from large databases. In this paper we give a brief overview of our approach for content-based retrieval and describe two prototypes for retrieving 2D drawings. We also present a preliminary study that combines retrieval of 3D objects and expectation lists to define a new interaction paradigm based on suggestions. 3D objects are described using their face and edge graphs, which are then mapped into multidimensional descriptors through graph spectra. Preliminary results show that the combination of these two descriptors (faces and edges) provide a good novel method to describe and retrieve similar 3D objects. Finally, rather than developing a system to specify and display 3D queries and results, we integrated the retrieval system into a 3D modeling tool, through the use of expectation lists. This way, results from the query are presented as suggestions to the user, in what constitutes a new interaction paradigm, which is more flexible then present approaches."
C. Alvarado,7413a813fa5cbcd5c014fda13bd1806ab888ad46,Sketch Recognition User Interfaces: Guidelines for Design and Development,AAAI Technical Report,2004.0,22,"We present a free-sketch recognition-based tool for creating Microsoft Power Point diagrams. Unlike many previous pen-based interfaces, this tool performs aggressive and robust recognition, allowing the user to sketch freely while the system recognizes the sketched diagram and seamlessly imports it into Power Point. Although pen-based user interfaces have been developed and studied, little has been said about the user interface issues involved in developing sketch recognition user interfaces. We present initial user interface guidelines for creating sketch recognition user interfaces (SkRUIs) based on informal, iterative user studies of our Power Point tool. Finally, based on our experience, we claim that a number of iterative design techniques developed for traditional user interfaces cannot be readily applied to SkRUIs. We discuss which techniques are best suited to the design and development of SkRUIs."
"Zhigeng Pan, Zhao Dong, Mingmin Zhang",f207199186e90b1182d5b1c85d04e85fb815a4d1,A New Algorithm for Adding Color to Video or Animation Clips,WSCG,2004.0,21,"Colorizing grayscale video is a useful technique in scientific computing visualization and entertainment. In this paper, we introduce a method to transfer color from a reference image to the whole video. Although the general problem of adding chromatic values to a grayscale image has no exact, objective solution, the current approach attempts to free user from laborious work, except that the user may contribute their skill to reference image. Rather than choosing RGB colors from a palette to color individual components, we resort to anther color space, called lαβ, which minimizes correlation between channels for many natural scenes. Taking advantage of the correlation between two conjoint frames of video, we track the object and assign the color of it in the preceding frame to that of the posterior one. Experimental results show the algorithm works quite well."
"Robert T. Schweller, Y. Chen, E. Parsons, A. Gupta, G. Memik, Yin Zhang",4224aef6d38eb51f53a19df9fa7c72c58f906d43,Reverse Hashing for Sketch-based Change Detection on High-speed Networks,,2004.0,15,"With the ever-increasing link speeds and traffic volumes of the Internet, monitoring and analyzing network traffic usage becomes a challenging but essential service for network administrators of large ISPs or institutions. There are two popular primitives for efficient analysis over massive data streams: heavy hitter detection and heavy change detection. Although numerous approaches have been proposed for efficient heavy hitter detection [1], [2], [3], [4], [5], the sketch-based scheme [6] is one of the very few that can detect heavy changes and anomalies over massive data streams at network traffic speeds. However, sketches do not preserve keys (e.g., source IP address) of the flows. Thus even if anomalies are detected, it is difficult to infer the culprit flows. To address this challenge, we propose efficient reversible hashing schemes to infer the keys of culprit flows from sketches with negligible extra memory and few extra memory accesses for recording streaming data implementing on a single FPGA board, we can achieve a throughput of over 16Gbps for all 40-byte-packet streams (the worst case traffic). Meanwhile, the heavy change detection daemon runs in the background with space complexity and computational time sublinear to the key space size. Evaluation with traces from a large edge router show that we can infer the keys for even 1,000 heavy changes while achieving over a 99% real positive percentage and less than a 0.5% false positive percentage in 22 seconds."
"G. Xu, M. Kaneko, A. Kurematsu",36113205c0493b33e7ba1585b9c0ceb371db1693,Synthesis of facial caricature using eigenspaces,,2004.0,13,"A facial caricature expresses features of an individual face summarily and has many uses for newspapers, magazines, home pages, agents, and the like. This paper presents a method of synthesizing a caricature having higher flexibility in controlling individual shape features of various parts of a face, as well as features of arrangements and inclines of these parts. In addition, it obtains eigenspaces for contours of facial parts such as the eyebrows, eyes, and mouth. It also obtains eigenspaces for arrangements of various facial parts. Next, it obtains differences of the shapes and arrangements of the facial parts with the average face and performs orthogonal expansion to the eigenspace bases (eigenvectors) on these differences. It determines magnifying power according to the coefficients obtained by orthogonal expansion and performs an emphasizing procedure on eigenvectors. The differences with the slopes of the facial parts of the average face are emphasized for the slopes of the facial parts using a second-order function. It obtains the shape of a caricature by adding the mean shape, mean arrangement, and mean slope to these results. The efficacy of the caricature synthesis method is verified by subjective evaluation tests on synthesized faces. © 2004 Wiley Periodicals, Inc. Electron Comm Jpn Pt 3, 87(8): 43–54, 2004; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/ecjc.20088"
"S. Chindaro, R. Guest, M. Fairhurst, J. Potter",137549e79dfbceb37fbdef719f3f8935c7fc4448,Assessing Visuo-Spatial Neglect Through Feature Selection From Shape Drawing Performance And Sequence Analysis,Int. J. Pattern Recognit. Artif. Intell.,2004.0,13,"The reported work aims to objectively and accurately assess the post-stroke clinical condition of visuo-spatial neglect using a series of standardized geometric shape drawing tasks. We present a method implementing existing pencil-and-paper diagnostic methods and define a set of static and dynamic features that can be extracted from drawing responses captured online using a graphics tablet. We also present a method for automatically assessing the constructional sequence of the drawing using Hidden Markov Models. The method enables the automated extraction, position identification and drawing order of individual sides of a shape within a drawing. Discrimination between two populations (a neglect population and stroke subjects without neglect as determined by existing standard assessment methods) using a combination of performance features and constructional sequence is examined across three separate drawing tasks. Results from experimentation show how a combination of sequence and performance features is able to generalize across a wide variety of input samples and obtain a diagnostic classification which can be used alongside other forms of conventional assessment. Furthermore, the application of a multi-classifier combination strategy leads to a significant increase in recognition ability."
"A. Namboodiri, Anil K. Jain",f51648f66e96c68c7de859d11669005f4c75b3f1,Retrieval of on-line hand-drawn sketches,"Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.",2004.0,10,"Sketch matching algorithms are commonly used for indexing and retrieval of documents based on printed or hand-drawn sketches. One could use a hand-held computer to do sketch-based queries to a database containing hand-drawn and printed sketches. We present an on-line hand-drawn sketch matching algorithm based on a line-based representation of sketches. A distance measure is defined for comparing two sketches based on this representation. The algorithm is computationally efficient and achieves a recall rate of 88.44% at the same precision, when tested on a database of 150 sketches collected from 5 users."
"T. Hammond, Randall Davis",fbea9bb870b2e5539fed992cb0f10542569b6a2b,SHADY: A Shape Description Debugger for Use in Sketch Recognition,AAAI Technical Report,2004.0,10,"Sketch recognition systems are currently being developed for many domains, but can be time consuming to build if they are to handle the intricacies of each domain. LADDER is a language for describing how domain shapes are drawn, displayed, and edited in a sketch recognition system for that domain. LADDER shape descriptions can be automatically translated into JAVA code to be compiled with a multi-domain sketch recognition system to create a domain specific sketch interface. In this paper we present S HADY, a graphical tool to aid in the creation and debugging of LADDER shape descriptions. S HADY allows sketch interface developers to enter new shape descriptions or debug previously created descriptions, finding both syntactic and conceptual bugs. SHADY checks to see whether a shape descriptions is over-constrained by allowing the developer to draw sample shapes and then indicating which constraints are not met. This paper also describes work in progress on debugging under-constrained descriptions by automatically generating near-miss shapes."
T. Hammond,6944c0829f2f07adf51a64b0a0bf7a6c9773463b,Automatically Generating Sketch Interfaces from Shape Descriptions,,2004.0,4,"As pen-based input devices have become more common, sketch recognition systems are being developed for many hand-drawn diagrammatic domains such as mechanical engineering, GUI design, course of action diagrams, and many others. These sketch interfaces 1) allow for more natural interaction than a traditional mouse and palette tool by allowing users to hand-sketch the diagram, 2) can automatically connect to a CAD system preventing the designer from having to enter the same information twice, 3) can offer realtime design advice from CAD systems, 4) allow more powerful editing since the shape is recognized as a whole, 5) provide diagram beautification to remove mess and clutter, 6) use display as a trigger to inform the user that the shapes have been correctly recognized. However, sketch recognition systems can be quite time consuming to build if they are to handle the intricacies of each domain. Also we would prefer that the builder of a sketch recognition system be an expert in the domain rather than an expert in sketch recognition at a signal level. Rather than build each recognition system separately, our group has been working on a multi-domain recognition system that can be customized for each domain."
"T. Hammond, Randall Davis",f4a699900d54c5a59ddf3b50be47c35f2bbeaedc,LADDER: A Sketch Recognition Language,,2004.0,4,"We have created LADDER [5], a language to describe how sketched diagrams in a domain aredrawn, displayed, and edited. The difﬁculty in creating such a language is choosing a set of predeﬁnedentities that is broad enough to support a wide range of domains, while remaining narrow enough tobe comprehensible. The language consists of predeﬁned shapes, constraints, editing behaviors, and dis-play methods, as well as a syntax for specifying a domain description sketch grammar, ensuring thatshapes and shape groups from many domains can be described. The language allows shapes to be builthierarchically (e.g., an arrow is built out of three lines), and includes the concept of “abstract shapes”,analogous to abstract classes in an object oriented language. Shape groups describe how multiple do-main shapes interact and can provide the sketch recognition system with information to be used intop-down recognition. Shape groups can also be used to describe “chain-reaction” editing commandsthat effect multiple shapes at once. To test that recognition is feasible using this language, we havebuilt a simple domain-independent sketch recognition system that parses the domain descriptions andgenerates the code necessary to recognize the shapes."
"H. Shum, Y. Xu, Michael F. Cohen, Hua Zhong",ec0808168fd876d3f7c6870d2b602b039e73757d,Sample Based Face Caricature Generation,,2004.0,2,"In this paper we present a system to automatically create a caricature drawing from a frontal face photograph. The system learns how to exaggerate features based on training examples from a particular caricaturist. The input to the system is a frontal face image along with its vector based line-drawing. The system creates a face shape model of the given face with a minimum of user interaction. The face shape is then converted to a set of semantic face features. A Kernel Regression (KR) algorithm determines how much each feature should be exaggerated based on the knowledge learned from a particular artist. The exaggerated features are then projected into an exaggerated face shape using a maximum likelihood estimation (MLE) algorithm. This MLE algorithm also maintains face constraints to generate reasonable caricatures. Finally, the exaggerated face shape together with the unexaggerated face shape are used to morph the input line-drawing to create a caricature. A user interface is provided to indicate the extent of overall exaggeration. We have trained the system with two separate artists and show results of passing several photographs and line drawings through the system."
"V. Vuckovic, D. Vidanovic",4bb8c0e9705bd78ab9ec6cdc24dae68d15824c4a,A New Approach to Draw Detection by Move Repetition in Computer Chess Programming,ArXiv,2004.0,0,"We will try to tackle both the theoretical and practical aspects of a very important problem in chess programming as stated in the title of this article - the issue of draw detection by move repetition. The standard approach that has so far been employed in most chess programs is based on utilising positional matrices in original and compressed format as well as on the implementation of the so-called bitboard format. 
The new approach that we will be trying to introduce is based on using variant strings generated by the search algorithm (searcher) during the tree expansion in decision making. We hope to prove that this approach is more efficient than the standard treatment of the issue, especially in positions with few pieces (endgames). To illustrate what we have in mind a machine language routine that implements our theoretical assumptions is attached. The routine is part of the Axon chess program, developed by the authors. Axon, in its current incarnation, plays chess at master strength (ca. 2400-2450 Elo, based on both Axon vs computer programs and Axon vs human masters in over 3000 games altogether)."
"B. Krishnamurthy, S. Sen, Yin Zhang, Y. Chen",35a25052bf9fc89e0b28499236322c5786fc58a9,"Sketch-based change detection: methods, evaluation, and applications",IMC '03,2003.0,566,"Traffic anomalies such as failures and attacks are commonplace in today's network, and identifying them rapidly and accurately is critical for large network operators. The detection typically treats the traffic as a collection of flows that need to be examined for significant changes in traffic pattern (eg, volume, number of connections). However, as link speeds and the number of flows increase, keeping per-flow state is either too expensive or too slow. We propose building compact summaries of the traffic data using the notion of sketches. We have designed a variant of the sketch data structure, k-ary sketch, which uses a constant, small amount of memory, and has constant per-record update and reconstruction cost. Its linearity property enables us to summarize traffic at various levels. We then implement a variety of time series forecast models (ARIMA, Holt-Winters, etc.) on top of such summaries and detect significant changes by looking for flows with large forecast errors. We also present heuristics for automatically configuring the model parameters.Using a large amount of real Internet traffic data from an operational tier-1 ISP, we demonstrate that our sketch-based change detection method is highly accurate, and can be implemented at low computation and memory costs. Our preliminary results are promising and hint at the possibility of using our method as a building block for network anomaly detection and traffic measurement."
"L. Itti, Nitin Dhavale, Frédéric H. Pighin",6c35413b3458762d2d62035fd64a0c979cc41fe3,Realistic avatar eye and head animation using a neurobiological model of visual attention,SPIE Optics + Photonics,2003.0,315,"We describe a neurobiological model of visual attention and eye/head movements in primates, and its application to the automatic animation of a realistic virtual human head watching an unconstrained variety of visual inputs. The bottom-up (image-based) attention model is based on the known neurophysiology of visual processing along the occipito-parietal pathway of the primate brain, while the eye/head movement model is derived from recordings in freely behaving Rhesus monkeys. The system is successful at autonomously saccading towards and tracking salient targets in a variety of video clips, including synthetic stimuli, real outdoors scenes and gaming console outputs. The resulting virtual human eye/head animation yields realistic rendering of the simulation results, both suggesting applicability of this approach to avatar animation and reinforcing the plausibility of the neural model."
"X. Tang, Xiaogang Wang",38faebc01eadaab68d2220f93536c29f00a12408,Face sketch synthesis and recognition,Proceedings Ninth IEEE International Conference on Computer Vision,2003.0,254,"We propose a novel face photo retrieval system using sketch drawings. By transforming a photo image into a sketch, we reduce the difference between photo and sketch significantly, thus allow effective matching between the two. To improve the synthesis performance, we separate shape and texture information in a face photo, and conduct transformation on them respectively. Finally a Bayesian classifier is used to recognize the probing sketch from the synthesized pseudo-sketches. Experiments on a data set containing 606 people clearly demonstrate the efficacy of the algorithm."
M. Kipp,32d19b46dfef6ec36040986df955866f13699039,Gesture generation by imitation: from human behavior to computer character animation,,2003.0,251,"In an e ort to extend traditional human-computer interfaces research has introduced embodied agents to utilize the modalities of everyday human-human communication, like facial expression, gestures and body postures. However, giving computer agents a human-like body introduces new challenges. Since human users are very sensitive and critical concerning bodily behavior the agents must act naturally and individually in order to be believable. This dissertation focuses on conversational gestures. It shows how to generate conversational gestures for an animated embodied agent based on annotated text input. The central idea is to imitate the gestural behavior of a human individual. Using TV show recordings as empirical data, gestural key parameters are extracted for the generation of natural and individual gestures. The gesture generation task is solved in three stages: observation, modeling and generation. For each stage, a software module was developed. For observation, the video annotation research tool ANVIL was created. It allows the eAEcient transcription of gesture, speech and other modalities on multiple layers. ANVIL is application-independent by allowing users to de ne their own annotation schemes, it provides various import/export facilities and it is extensible via its plugin interface. Therefore, the tool is suitable for a wide variety of research elds. For this work, selected clips of the TV talk show \Das Literarische Quartett"" were transcribed and analyzed, arriving at a total of 1,056 gestures. For the modeling stage, the NOVALIS module was created to compute individual gesture pro les from these transcriptions with statistical methods. A gesture pro le models the aspects handedness, timing and function of gestures for a single human individual using estimated conditional probabilities. The pro les are based on a shared lexicon of 68 gestures, assembled from the data. Finally, for generation, the NOVA generator was devised to create gestures based on gesture pro les in an overgenerate-andlter approach. Annotated text input is processed in a graph-based representation in multiple stages where semantic data is added, the location of potential gestures is determined by heuristic rules, and gestures are added and ltered based on a gesture pro le. NOVA outputs a linear, player-independent action script in XML."
"M. Colgan, J. Monaghan",9af705b07c002265c4082e079117146ae271c0a5,Deep drawing process: analysis and experiment,,2003.0,126,"Abstract This paper reports on the initial stages of a combined experimental and finite element analysis (FEA) of a deep drawing process. The objective of this research is to determine the most important factors influencing a drawing process, utilizing the help of a design of experiments and statistical analysis. The parameters varied include the punch and die radii, the punch velocity, clamping force, friction and draw depth. A deep drawing rig was designed and built for this purpose. Punches and dies of various geometries were manufactured. From previous FEA work and the experimental work performed to date, it seems that the punch/die radii have the greatest effect on the thickness of the deformed mild steel cups compared to blank-holder force or friction. The smaller is the punch/die radii, the greater is the punch force and shorter is the final draw. It has also been observed from the work to date that the speed of drawing plays an interesting role, in so far as, the higher is the speed the further is the draw, which is not entirely as expected. The cause of this will be further investigated. If the blank-holder force is not kept within the upper and lower limit of reasonable range it does have a significant effect on depth of draw, with the punch tearing through the bottom of the cup if the force is too high and if too low wrinkling of the flange area occurs. After observing the anisotropic effects of the rolling process on the sheet material through drawing it and seeing the extent of earing in the flange, some blanks were annealed for stress relief, then the draw depth was compared to that of the original mild steel blanks."
"T. Hammond, Randall Davis",b037d87a6052314b286beeacb7f2387863bbca5f,"LADDER: a language to describe drawing, display, and editing in sketch recognition",IJCAI,2003.0,125,"We have created LADDER, the first language to describe how sketched diagrams in a domain are drawn, displayed, and edited. The difficulty in creating such a language is choosing a set of predefined entities that is broad enough to support a wide range of domains, while remaining narrow enough to be comprehensible. The language consists of predefined shapes, constraints, editing behaviors, and display methods, as well as a syntax for specifying a domain description sketch grammar and extending the language, ensuring that shapes and shape groups from many domains can be described. The language allows shapes to be built hierarchically (e.g., an arrow is built out of three lines), and includes the concept of ""abstract shapes"", analogous to abstract classes in an object oriented language. Shape groups describe how multiple domain shapes interact and can provide the sketch recognition system with information to be used in top-down recognition. Shape groups can also be used to describe ""chain-reaction"" editing commands that effect multiple shapes at once. To test that recognition is feasible using this language, we have built a simple domain-independent sketch recognition system that parses the domain descriptions and generates the code necessary to recognize the shapes."
"Pushkar Joshi, Wen C. Tien, Mathieu Desbrun, Frédéric H. Pighin",8e831f8175a898155ebce7950e1ee23a156477ea,Learning controls for blend shape based realistic facial animation,SCA '03,2003.0,123,"Blend shape animation is the method of choice for keyframe facial animation: a set of blend shapes (key facial expressions) are used to define a linear space of facial expressions. However, in order to capture a significant range of complexity of human expressions, blend shapes need to be segmented into smaller regions where key idiosyncracies of the face being animated are present. Performing this segmentation by hand requires skill and a lot of time. In this paper, we propose an automatic, physically-motivated segmentation that learns the controls and parameters directly from the set of blend shapes. We show the usefulness and efficiency of this technique for both, motion-capture animation and keyframing. We also provide a rendering algorithm to enhance the visual realism of a blend shape model."
"Yongsheng Gao, M. Leung, S. C. Hui, M. W. Tananda",9fcd0236fe63ac709d8fbd95e1d8f56da53ce254,Facial expression recognition from line-based caricatures,IEEE Trans. Syst. Man Cybern. Part A,2003.0,122,"The automatic recognition of facial expression presents a significant challenge to the pattern analysis and man-machine interaction research community. Recognition from a single static image is particularly a difficult task. In this paper, we present a methodology for facial expression recognition from a single static image using line-based caricatures. The recognition process is completely automatic. It also addresses the computational expensive problem and is thus suitable for real-time applications. The proposed approach uses structural and geometrical features of a user sketched expression model to match the line edge map (LEM) descriptor of an input face image. A disparity measure that is robust to expression variations is defined. The effectiveness of the proposed technique has been evaluated and promising results are obtained. This work has proven the proposed idea that facial expressions can be characterized and recognized by caricatures."
"W. Freeman, J. Tenenbaum, E. Pasztor",d48b02a9eefce1a6a89abe175f9c9e4733e8f72a,Learning style translation for the lines of a drawing,TOGS,2003.0,73,"We present an example-based method for translating line drawings into different styles. We fit each line as a linear combination of similar lines in a training set, and interpolate between the corresponding training examples in the output style. The synthesized lines preserve the desired stylistic features of the output style."
"Pin-Chou Liu, Fu-Che Wu, Wan-Chun Ma, Rung-Huei Liang, Ming Ouhyoung",be6f2c3fc127e0abaf3930404efdbd7eff267718,Automatic Animation Skeleton Construction Using Repulsive Force Field,,2003.0,62,"A method is proposed in this paper to automatically generate the animation skeleton of a model such that the model can be manipulated according to the skeleton. With our method, users can construct the skeleton in a short time, and bring a static model both dynamic and alive.The primary steps of our method are finding skeleton joints, connecting the joints to form an animation skeleton, and binding skin vertices to the skeleton. Initially, a repulsive force field is constructed inside a given model, and a set of points with local minimal force magnitude are found based on the force field. Then, a modified thinning algorithm is applied to generate an initial skeleton, which is further refined to become the final result. When the skeleton construction completes, skin vertices are anchored to the skeleton joints according to the distances between the vertices and joints. In order to build the repulsive force field, hundreds of rays are shot radially from positions inside the model, and it leads to that the force field computation takes most of the execution time. Therefore, an octree structure is used to accelerate this process. Currently, the skeleton generated from a typical 3D model with 1000 to 10000 polygons takes less than 2 minutes on a Intel Pentium 4 2.4 GHz PC."
"Boran Yu, Shijie Cai",fd925815cb6a27e965cca334f0ffced7ec6304e4,A domain-independent system for sketch recognition,GRAPHITE '03,2003.0,61,"Freehand sketching is a natural and powerful means of interpersonal communication. But to date, it still cannot be supported effectively by human-computer interface. In this paper, we describe a domain-independent system for sketch recognition. Our system allows users to draw sketches as naturally as how they do on paper, and it recognizes the drawing through imprecise stroke approximation which is implemented in a unified and incremental procedure. This method can handle smooth curves and hybrid shapes as gracefully as it does to polylines. With a feature-area verification mechanism and the intelligent adjustment in the post-process, the system can produce user-intended results. Moreover, the output is organized in a hierarchical structure which includes syntactic and semantic information as well as raw data. Our system mainly utilizes low-level geometric features and does not rely on any domain-specific knowledge. Therefore, it will serve as a general and solid foundation for future high-level applications."
"T. Ianeva, A. D. Vries, H. Röhrig",99ff623b96a2709ad1be53e34b3f3a29883e9bc6,Detecting cartoons: a case study in automatic video-genre classification,2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698),2003.0,59,"This paper presents a new approach for classifying individual video frames as being a 'cartoon' or a 'photographic image'. The task arose from experiments performed at the TREC-2002 video retrieval benchmark: 'cartoons' are returned unexpectedly at high ranks even if the query gave only 'photographic' image examples. Distinguishing between the two genres has proved difficult because of their large intra-class variation. In addition to image metrics used in prior cartoon-classification work, we introduce novel metrics like ones based on the pattern spectrum of parabolic size distributions derived from parabolic granulometries and the complexity of the image signal approximated by its compression ratio. We evaluate the effectiveness of the proposed feature set for classification (using support vector machines) on a large set of keyframes from the TREC-2002 video track collection and a set of Web images. The paper reports the identification error rates against the number of images used as training set. The system is compared with one that classifies Web images as photographs or graphics and its superior performance is evident."
Maria C. Yang,c70858244ca8b030135e87dd33f751bf2b58650c,Concept Generation and Sketching: Correlations With Design Outcome,,2003.0,59,"Design outcome is influenced by many hard-to-measure factors in the design process. This paper examines four of these factors to understand their possible correlation with design success. First, is the quantity of design concepts linked to design outcome? Second, is the timing of concept generation associated with design outcome? In both of these cases, the sketches created by designers were taken as evidence of concept generation. Third, is the type of sketch linked to design outcome? And finally, what is the role of a novice designer’s prior experience in design outcome? Statistically significant correlations were found between dimensioned drawings generated at the early stages of design and design outcome, and also between a novice designer’s prior fabrication and building experience and design outcome. Ultimately, the goal of this research is to develop paradigms for appropriate graphics- and text-based information tools for design."
P. Piwek,b25a78533a64e75735b5f13820f9c66c241b5830,A Flexible Pragmatics-Driven Language Generator for Animated Agents,EACL,2003.0,44,"This paper describes the NECA MNLG; a fully implemented Multimodal Natural Language Generation module. The MNLG is deployed as part of the NECA system which generates dialogues between animated agents. The generation module supports the seamless integration of full grammar rules, templates and canned text. The generator takes input which allows for the specification of syntactic, semantic and pragmatic constraints on the output."
"W. Leung, Tsuhan Chen",78336a3c48d7abf6838c4c65719b49755b199e7a,Hierarchical matching for retrieval of hand-drawn sketches,2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698),2003.0,34,"As pen-based devices become more popular, it has motivated several novel research issues in the area of pen computing. One interesting and practical problem is the storage and retrieval of hand-drawn sketches. A sketch can consist of handwritten notes, symbols, free-form hand-drawings, annotations on a document, and others. It is very useful to store the sketches in a database and then retrieve them later. In our prior work, we proposed a method for hand-drawn sketch retrieval by performing stroke-by-stroke matching and by considering the spatial relationship between them. In this paper, we propose a method to simplify a sketch and perform matching in a hierarchical manner. With this approach, a shaded region or a region of complex strokes can be detected automatically and represented as a single hyper-stroke. In the matching stage, the similarity is computed by combining the similarity scores across the feature spaces at each level and the similarity of the stroke hierarchies. A sketch may be better represented by exploiting the structural relationship between the strokes. In addition, as a general rule to the hierarchical approach, it has the advantage of reduced computation thus the retrieval process would speed up."
"Pin-Chou Liu, Fu-Che Wu, Wan-Chun Ma, Rung-Huei Liang, Ming Ouhyoung",7f1537f4710fe5feb558ed6d775785d0f4e8bd25,Automatic animation skeleton using repulsive force field,"11th Pacific Conference onComputer Graphics and Applications, 2003. Proceedings.",2003.0,26,"A method is proposed in this paper to automatically generate the animation skeleton of a model such that the model can be manipulated according to the skeleton. With our method, users can construct the skeleton in a short time, and bring a static model both dynamic and alive. The primary steps of our method are finding skeleton joints, connecting the joints to form an animation skeleton, and binding skin vertices to the skeleton. Initially, a repulsive force field is constructed inside a given model, and a set of points with local minimal force magnitude are found based on the force field. Then, a modified thinning algorithm is applied to generate an initial skeleton, which is further refined to become the final result. When the skeleton construction completes, skin vertices are anchored to the skeleton joints according to the distances between the vertices and joints. In order to build the repulsive force field, hundreds of rays are shot radially from positions inside the model, and it leads to that the force field computation takes most of the execution time. Therefore, an octree structure is used to accelerate this process. Currently, the skeleton generated from a typical 3D model with 1000 to 10000 polygons takes less than 2 minutes on a Intel Pentium 4 2.4 GHz PC."
"M. Fiorentino, G. Monno, Pietro Renzulli, A. Uva",c8a013be9215588797014c9345c07ced8b7e73f4,3D Sketch Stroke Segmentation and Fitting in Virtual Reality,,2003.0,22,"In this paper we present a method which tries to automatically represent the designer’s intention while sketching threedimensional curves in a Virtual Reality environment. We translate conceptual sketch strokes into a suitable B-spline representation with a three step method. Firstly a data filter is used to eliminate redundancy and noise in ‘pen’ position recorded by the 3D tracking system. Secondly an knowledge based algorithm tries to interpret user’s intention, according to direction, speed and curvature of the virtual pen segmenting the stroke into two types of curves joined respectively with C 0 and G 1 continuity. Lastly an algorithm translates the points of each segmented sketch stroke into a cubic B-spline with adaptive approximation. This method, which has been integrated in our Virtual Reality sketching system, is illustrated and tested with various types of sketches."
"D. Sýkora, J. Buriánek, J. Zára",6da887bca30be85d6500481bc5cfef7d50f5cf93,Segmentation of black and white cartoons,SCCG '03,2003.0,22,"We introduce novel semi-automatic, fast and accurate segmentation technique that allow us to simplify color transfer to the old black and white cartoons produced by classical paper or foil technology, where foreground parts are represented by homogeneous regions with constant grey-scale intensity surrounded by bold dark contours. We assume that original analogue material has been converted to the sequence of digital grey-scale images with PAL resolution suitable for TV broadcasting."
"Jaehwa Park, Young-Bin Kwon",5febe8d6522b357a82605cab475ee352d5ae84bf,Main Wall Recognition of Architectural Drawings Using Dimension Extension Line,GREC,2003.0,12,"This paper deals with plain figures on the architectural drawings of apartment. This kind of architectural drawings consist of main walls represented by two parallel bold lines, symbols(door, window, tile...), dimension line, extension line, and dimensions represent various numerical values and characters. This paper suggests a method for recognizing main wall which is a back-bone of apartment in an architectural drawing. In this thesis, the following modules are realized: an efficient image binarization, a removal of thin lines, a vectorization of detected lines, a region bounding for main walls, a calculation of extension lines, a finding main walls based on extension line, and a field expansion by searching other main walls which are linked with the detected main walls. Although the windows between main walls are not represented as main walls, a detection module for the windows is considered during the recognition period. So the windows are found as a part of main wall. An experimental result on 9 different architectural drawings shows 96.5% recognition of main walls and windows, which is about 5.8% higher than that of Karl Tombre."
"Saeko Takagi, Noriyuki Matsuda, M. Soga, H. Taki, Takashi Shima, F. Yoshimoto",7e32ae54c066f8498e972af65f74d90f947a67b3,A learning support system for beginners in pencil drawing,GRAPHITE '03,2003.0,10,"A picture is one of important research subjects to make our life spiritually rich. Most studies on pictures, however, only propose some substitute functions of actual drawing or painting materials. There is no system that evaluates pictures drawn by users and gives advice about them. We propose a learning support system of beginner's pencil drawing that is the basis of pictures. Our system receives a motif data set and a user's sketch image, and returns advice to the user. The processing is composed of the four functions: feature extraction of motifs, feature extraction of sketches, error identification, and generation and presentation of advice. We developed and experimented a prototype system limited to treat a basic motif and principal advice. As a result, the validity of the proposed system was confirmed."
C. Alvarado,4acc730380f1ee9021b775c96897265b399036bd,Dynamically Constructed Bayesian Networks for Sketch Understanding,,2003.0,9,"People sketch to express their early design ideas in many domains, but current computer tools offer few advantages to designers during this sketching phase. Our goal is to construct a general recognition architecture that can be applied to a number of domains that is capable of parsing the user’s strokes (in real time) and interpreting them as depicting objects in the domain of interest without limiting the designer’s drawing freedom. Such an interpretation engine will enable the creation of powerful and natural early-stage computer aided design tools."
A. Adler,cc62c399722212a8e0e1def55611ace90cecad63,Segmentation and Alignment of Speech and Sketching in a Design Environment,,2003.0,9,
"R. Mayer, R. Moreno",42ab50234d37200eb984279de18491875d6668ad,Animation as an Aid to Multimedia Learning,,2002.0,682,"How can animation be used to promote learner understanding of scientific and mathematical explanations? In this review, we examine the role of animation in multimedia learning (including multimedia instructional messages and microworld games), present a cognitive theory of multimedia learning, and summarize our program of research, which has yielded seven principles for the use of animation in multimedia instruction. These include the multimedia principle (present animation and narration rather than narration alone), spatial contiguity principle (present on-screen text near rather than far from corresponding animation), temporal contiguity principle (present corresponding animation and narration simultaneously rather than successively), coherence principle (exclude extraneous words, sounds, and video), modality principle (present animation and narration rather than animation and on-screen text), redundancy principle (present animation and narration rather than animation, narration, and on-screen text), and personalization principle (present words in conversational rather than formal style). Animation can promote learner understanding when used in ways that are consistent with the cognitive theory of multimedia learning."
"X. Tang, Xiaogang Wang",820da5dddcd35dba3d8f8d8b0c99143f2611d7aa,Face photo recognition using sketch,Proceedings. International Conference on Image Processing,2002.0,144,"Automatic retrieval of face images from police mug-shot databases is critically important for law enforcement agencies. It can help investigators to locate or narrow down potential suspects efficiently. However, in many cases, the photo image of a suspect is not available and the best substitute is often a sketch drawing based on the recollection of an eyewitness. We present a novel photo retrieval system using face sketches. By transforming a photo image into a sketch, we reduce the difference between photo and sketch significantly, thus allowing effective matching between the two. Experiments over a data set containing 188 people clearly demonstrate the efficacy of the algorithm."
"Lin Liang, H. Chen, Y. Xu, H. Shum",cddd5381d57014c02155b0eb38f831369263c355,Example-based caricature generation with exaggeration,"10th Pacific Conference on Computer Graphics and Applications, 2002. Proceedings.",2002.0,128,"In this paper, we present a system that automatically generates caricatures from input face images. From example caricatures drawn by an artist, our caricature system learns how an artist draws caricatures. In our approach, we decouple the process of caricature generation into two parts, i.e., shape exaggeration and texture style transferring. The exaggeration of a caricature is accomplished by a prototype-based method that captures the artist's understanding of what are distinctive features of a face and the exaggeration style. Such prototypes are learnt by analyzing the correlation between the image caricature pairs using partial least-squares (PLS). Experimental results demonstrate the effectiveness of our system."
"L. Wade, Richard E. Parent",1f3faddc82ea04d60de66f50137f63455a90c357,Automated generation of control skeletons for use in animation,The Visual Computer,2002.0,107,"The animation of an articulated figure is typically accomplished through the use of a corresponding control skeleton. Although the control skeleton is an effective tool, the manual construction of the skeleton can be a laborious process often requiring several hours of work and a fair degree of proficiency with the animation software used. 
The focus of the research described here is the automatic generation of such control skeletons. To this end, two solutions to the problem are presented, one general and one specific. In both cases, the input is required to be a set of polygonal data that defines the figure, and the output is a description of a control skeleton to be used in animating that figure. 
The general solution is widely applicable; it makes very few assumptions about the figure given as input or about the type of control skeleton that should be generated. A system is described that divides the problem into a series of steps, each of which is performed automatically. The basic process involves discretizing the figure, approximating its medial surface, and using that surface to construct a control skeleton. The system can produce a reasonably good control skeleton for any of a variety of figures in as little as one or two minutes on a low-end PC. 
The specific solution builds upon the general one but is geared toward producing more desirable skeletons for the very common case involving human-like and animal-like figures. Certain assumptions are made about the figure and about the type of control skeleton desired. In addition, heuristics based upon human and animal anatomy are invoked to adjust the control skeleton so that it is more anatomically appropriate. The motivation for this solution is the belief that a more anatomically appropriate control skeleton allows for more natural looking movement of a human or animal-like figure. 
Partly to support that claim, the system can produce geometry for individual bones that might function as the anatomical skeleton of the figure. This skeletal geometry can form the foundation for additional anatomical modeling that might add more realism to the animation of the figure."
"C. Alvarado, Michael Oltmans, Randall Davis",08d42fa9ea2101f5db97f42799f649862e9a5539,A Framework for Multi-Domain Sketch Recognition,,2002.0,82,"People use sketches to express and record their ideas in many domains, including mechanical engineering, software design, and information architecture. Unfortunately, most computer programs cannot interpret free-hand sketches; designers transfer their sketches into computer design tools through menu-based interfaces. The few existing sketch recognition systems either tightly constrain the user’s drawing style or are fragile and difficult to construct. In previous work we found that domain knowledge can aid recognition. Here we present an architecture to support the development of robust recognition systems across multiple domains. Our architecture maintains a separation between low-level shape information and high-level domain-specific context information, but uses the two sources of information together to improve recognition accuracy."
"James V. Mahoney, M. Fromherz",b9da965305862dee361166d0c3937966e86366bb,Three main concerns in sketch recognition and an approach to addressing them,,2002.0,61,"This paper discusses the problem of matching models of curvilinear configurations to hand-drawn sketches. It collects observations from our own recent research, which focused initially on the domain of sketched human stick figures in diverse postures, as well as related computer vision literature. Sketch recognition, i.e., labeling strokes in the input with the names of the model parts they depict, would be a key component of higher-level sketch understanding processes that reason about the recognized configurations. A sketch recognition technology must meet three main requirements. It must cope reliably with the pervasive variability of hand sketches, provide interactive performance, and be easily extensible to new configurations. We argue that useful sketch recognition may be within the grasp of current research, if these requirements are addressed systematically and in concert."
"Se-ho Kim, Seung-Ho Kim, H. Huh",f5e81ed0e83c61cef07406bc154b1efd30869878,Tool design in a multi-stage drawing and ironing process of a rectangular cup with a large aspect ratio using finite element analysis,,2002.0,44,Tool design is carried out for a multi-stage deep drawing and ironing process of a rectangular cup with the large aspect ratio using the result of the finite element analysis. The analysis incorporates three-dimensional continuum elements for an elasto-plastic finite element method with the explicit time integration scheme using LS-DYNA3D. The analysis simulates the five-stage deep drawing and ironing process with the thickness control of the cup wall. Simulation is performed in order to investigate the failure by tearing during the forming process at the initial state of tool design. The analysis reveals that the difference of the drawing ratio within the cross section induces non-uniform metal flow which causes severe local extension. The irregular contact condition between the blank and the die also induces non-uniform metal flow which causes local wrinkling. This paper identifies such unfavorable mechanism in the rectangular cup drawing with ironing and proposes a new tool design with the guideline for modification in the design of the process and the sequential tool shape. The finite element analysis result with the improved tool design confirms that the proposed design not only reduces the possibility of failure but also improves the quality of a deep-drawn product. The numerical result shows fair coincidence with the experimental result.
"W. Leung, Tsuhan Chen",4e1d946c72921d2e68ad5e5ff0bd494fb944d38c,User-independent retrieval of free-form hand-drawn sketches,"2002 IEEE International Conference on Acoustics, Speech, and Signal Processing",2002.0,38,"In this paper we propose a method to retrieve free-form hand-drawn sketches stored in the form of multiple strokes, by extracting the shape information for each stroke and by considering the geometric relationship between the strokes. To extract the shape information, a number of shape estimators are applied to each stroke to provide a soft decision about how similar it is to a particular shape type. Then, two strokes are matched according to a specific set of features for each shape type. The proximity of the corresponding strokes is used to account for the geometric relationship between multiple strokes during the matching stage. Our approach is robust to different drawing styles, thus making our retrieval system user-independent. Sketch retrieval is useful in applications where a user can easily search through a database of hand-draw sketches by inputting a sketch about what he/she is looking for, without the trouble of describing it using keywords."
A. Doring,f00d4cdc356afc99dd0cd8236f5685b115f094ab,The Use of Cartoons as a Teaching and Learning Strategy with Adult Learners.,,2002.0,32,
"J. Storey, J. Rowland, D. Basic, D. Conforti",ea08173e1e939db3e411db9e02e735dd87662a97,Accuracy of the Clock Drawing Test for Detecting Dementia in a Multicultural Sample of Elderly Australian Patients,International Psychogeriatrics,2002.0,30,"Objective: To assess the accuracy of clock drawing for detecting dementia in a multicultural, non-English-speaking-background population. Design: A prospective cohort study. Setting: A general geriatric medical outpatient clinic in southwest Sydney, Australia. Participants: Ninety-three consecutive new patients to the clinic who had a non-English-speaking-background country of birth (mean age 78.0 years). Measurements: The clock drawing test was conducted at the beginning of each clinic visit by a blinded investigator. Each patient was then assessed by a geriatrician who collected demographic data, administered the Modified Barthel Index, the Geriatric Depression Scale, and the Folstein Mini-Mental State Examination, and categorized each patient as normal or demented, according to DSM-IV criteria. Interpreters were used for participants who spoke a language other than English or who requested them. Each clock drawing was scored according to the 4-point CERAD scale and the previously published methods of Mendez, Shulman, Sunderland, Watson, and Wolf-Klein. Scoring was evaluated for reliability and predictive accuracy, using receiver operating characteristic (ROC) curve analysis. Logistic regression analysis was used to assess the potential interaction between level of education and each of the clock scoring methods. Results: Using ROC curve analysis, there was no significant difference between the clock scoring methods (area under the curve varied from 0.60 to 0.72). The most sensitive was the Mendez scoring method (98%), with a specificity of 16%. Specificity above 50% was found only for the Wolf-Klein method, with an intermediate sensitivity of 78%. Conclusions: There were no significant differences in the clock scoring methods used to detect dementia. Performance of the clock drawing test was modest at best with low levels of specificity across all methods. Scored according to these methods, clock drawing was not a useful predictor of dementia in our multicultural population."
"Céline Rémi, C. Frélicot, P. Courtellemont",6c9bd4ebae5cb919541ddb577b9cba9f1dc5692b,Automatic analysis of the structuring of children's drawings and writing,Pattern Recognit.,2002.0,27,"The aim of this work was to build an objective tool for the detection of graphomotor 
difficulties involving disorders in the writing of children. We outline some characteristics of 
layouts, describing the automation level of the graphic activity. We have defined exercises, 
like copying figures or writing sentences under different conditions that allowed us to 
measure simple aspects of graphomotor skill up to complex ones. A tool was conceived 
which was able to automatically extract low-level and high-level primitives. Based on such 
descriptors, we focus on the analysis of the temporal structuring of two particular drawings. 
In the final part, we present the method we used to select features that can describe the 
automation level of the graphic activity and we show that, in most cases, these features allow 
to discriminate children with academic difficulties."
Randall Davis,bef5ff39deed0ec83f25ce2f495e5a7e7d5a26fb,Position Statement and Overview: Sketch Recognition at MIT,,2002.0,26,"The problem with software is not that it needs a good user interface, it needs to have no user interface. Interacting with software should — ideally — feel as natural, informal, rich, and easy as working with a human assistant. One key to this lies in enabling means of interacting with software that are similarly natural, informal, rich and easy. We are making it possible for people involved in design and planning tasks to sketch, gesture, and talk about their ideas (rather than type, point, and click), and have the computer system understand their messy freehand sketches, their casual gestures, and the fragmentary utterances that are part and parcel of such interaction. A second key lies in appropriate use each of the means of interaction. Our work to date has made it clear, for example, that different means are well suited to communicating different things: Geometry is best sketched, behavior and rationale are best described in words and gestures. A third key lies in the claim that interaction will be effortless only if the listener is smart: effortless interaction and invisible interfaces must be knowledge-based. If it is to make sense of informal sketches, the listener has to understand something about the domain and something about how freehand sketches are drawn. This paper provides an overview of six current pieces of work at the MIT AI Lab on the sketch recognition part of this overall goal."
"R. Lu, Songmao Zhang",e135146be01214fcb384c3bb6848cc0618808f27,Automatic generation of computeranimation: using AI for movie animation,,2002.0,26,"Overview of Research on Computer Animation and Related Topics.- SWAN: Full Life Cycle Automation of Computer Animation.- Understanding the Limited Chinese Natural Language.- Story Understanding: The Theory.- Story Understanding: The Practice.- Plot Planning and Act Planning.- Director's Planning.- Camera Planning.- Light, Color, and Role Planning.- Knowledge Base and Libraries."
"Xiaoyang Mao, Yoshinori Nagasaka, A. Imamiya",4e936745d23ca87332e41e3d759cc06c34e2c5da,Automatic generation of pencil drawing using LIC,SIGGRAPH '02,2002.0,23,"Line Integral Convolution (LIC)[Cabral and Leedom 1993]] is a texture based vector field visualization technique. Why using LIC for pencil drawing generation? Let us look at the two images shown in Figure 1. Figure 1(a) is a digitized sample of a real pencil drawing. Look over it, we can perceive the traces of parallel pencil strokes and a gray scale tone built with the strokes. If we look at any local area of the image, however, we can find that the direction of strokes and the intensity of pixels vary randomly. The variance of intensity results from the interaction of lead material and drawing paper. The LIC image shown in Figure 1(b), however, presents the very similar features. Since an LIC image is obtained by low-pass filtering a white noise along the streamlines of a vector field, we can see traces along streamlines. On the other hand, the intensities of pixels within any local area vary randomly as the input image is a white noise. Such similarity suggests us that we can imitate the tone of pencil drawings with an LIC image."
"R. W. Ferguson, Kenneth D. Forbus",7338e01027f261738b674c11da4009c6e13fd957,A Cognitive Approach to Sketch Understanding,,2002.0,14,"Sketching is an interactive process of communication, using drawings and linguistic information to convey spatial and conceptual material. Our work on a computational model of sketching has the goal of both explaining human sketching and creating software that can be a human-like partner in sketching interactions. This focus has lead us to explore a very different set of tradeoffs from those typically chosen in multimodal interfaces. We highlight some results of our approach, including research performed using GeoRep, our diagrammatic reasoning architecture, and sKEA, a multimodal sketching tool used for knowledge acquisition in spatial domains. cc"
"T. Hammond, Randall Davis",c891f1346abcf8c6db0b5a17b2009cc6277ec049,A Domain Description Language for Sketch Recognition,,2002.0,8,"The Problem: Pervasive environments, complete with digital whiteboards and pocket PC’s, have increasingly included applications with sketchable interfaces. Sketch recognition applications built for the Oxygen platform include Ligature [4], Tahuti [6], and Assist [1] / Assistance [9]. To date, sketch recognition systems have been domain-specic, with the recognition details of the domain hard-coded into the system. A domain-independent recognition system is advantageous since it may be used for several domains, increasing the exibility and capabilities of a system. However, the system cannot identify the domain shapes if it doesn’t know that they are. In order to properly recognize a sketch of a particular domain, domain-specic information must be supplied to the domain-independent recognition system. Motivation: We propose a domain description language used to describe domain-specic information to a domain-independent sketch recognition system. The language is primarily based on shape to ensure correlation between the drawn shape and the recognized shapes. and to enable designers to draw the shapes as they would naturally. The language is different from other such languages because it can be also be to describe non-shape information, including display information, editing behavior, and drawing order. Previous Work: Shape description languages have been around for a long time [10]. These grammars have been studied widely within the eld or architecture, and many systems are still built using shape grammars [5]. However, they have been developed for design generation rather than recognition, and don’t provide for non-graphical information, such as stroke order, that may be helpful in recognition. Within the eld of sketch recognition, there have been other attempts to create shape languages for sketch recognition. [8] use a language to model and recognize stick gur es. The language currently is not hierarchical, making large objects cumbersome to describe. [3] use fuzzy relational grammars and [2] use BNF grammars to describe shape information. Both lack the ability to describe non-shape domain information such as stroke order or direction and editing behavior information. Approach: The difculties in determining the language’s components and syntax include ensuring that the language allows all common helpful domain information to be specied. The language must also encourage and facilitate the creation of correct programs. For instance, to encourage the reuse of geometric shape denitions, the language distinguishes between geometric shape denitions (shapes usable in many domains) and domain shapes (shapes specic to a domain). The language also provides abstract shape denitions that describe a class of similar shapes to prevent rewriting of identical attributes."
C. Magny,d7d0eb9ae7848cf425b9dd89136677a8f4548e81,Friction laws dedicated to the numerical simulation of deep drawing,,2002.0,3,"Efforts made since a few years in view of the integration of mechanical laws in numerical simulation now spread to friction behaviour. After presentation of the major laws available in the literature, a method permitting to obtain an empirical friction law is described. The validity of this approach is illustrated through the analysis of the tribological behaviours of three steel sheets: cold rolled, electro-galvanized and hot dip galvanized."
"T. Hammond, T. M. Sezgin, Olya Veselova, A. Adler, Michael Oltmans, C. Alvarado, R. Hitchcock",77229b72d77265d70384fca2fa17260bf5b3c6c3,Multi-Domain Sketch Recognition,,2002.0,3,"In this paper, we describe a new framework for multi-domain sketch recognition which is being developed by the Design Rationale Group at the MIT AI laboratory. The framework uses a blackboard architecture for recognition in which the knowledge sources are a combination of domain-independent and domain-specific recognizers. Domain-specific recognizers are automatically generated from the domain description which is written using the domain description language syntax. Domain descriptions can be automatically generated by a system that learns shape descriptions from a drawn example."
"K. V. D. Doel, P. Kry, D. Pai",1284a9db84cf8c1a086e11c5dd09ae7480b47272,FoleyAutomatic: physically-based sound effects for interactive simulation and animation,SIGGRAPH,2001.0,311,"We describe algorithms for real-time synthesis of realistic sound effects for interactive simulations (e.g., games) and animation. These sound effects are produced automatically, from 3D models using dynamic simulation and user interaction. We develop algorithms that are efficient, physically-based, and can be controlled by users in natural ways. We develop effective techniques for producing high quality continuous contact sounds from dynamic simulations running at video rates which are slow relative to audio synthesis. We accomplish this using modal models driven by contact forces modeled at audio rates, which are much higher than the graphics frame rate. The contact forces can be computed from simulations or can be custom designed. We demonstrate the effectiveness with complex realistic simulations."
"H. Chen, Y. Xu, H. Shum, Song-Chun Zhu, Nanning Zheng",f9ca0bcacda7a54ebb303ba3ac7cd12f995b1dce,Example-based facial sketch generation with non-parametric sampling,Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001,2001.0,130,"In this paper, we present an example-based facial sketch system. Our system automatically generates a sketch from an input image, by learning from example sketches drawn with a particular style by an artist. There are two key elements in our system: a non-parametric sampling method and a flexible sketch model. Given an input image pixel and its neighborhood, the conditional distribution of a sketch point is computed by querying the examples and finding all similar neighborhoods. An ""expected sketch image"" is then drawn from the distribution to reflect the drawing style. Finally, facial sketches are obtained by incorporating the sketch model. Experimental results demonstrate the effectiveness of our techniques."
"M. Parsa, K. Yamaguchi, N. Takakura",59db3e17da66b550659a5d911eb5102a44b649ee,Redrawing analysis of aluminum–stainless-steel laminated sheet using FEM simulations and experiments,,2001.0,53,"Abstract The behavior of two-layer aluminum–stainless-steel (AL-SUS) laminated sheets during deep drawing, direct and reverse redrawing processes (first and second drawing stages), have been examined by simulations and laboratory experiments. For the simulation a rigid-plastic finite element program has been used. The results of simulations are presented as the variation of drawing ratios with respect to various thickness ratios and setting conditions. They show that to achieve the highest drawing ratios in direct and reverse redrawing, the thickness ratio should be about 1 3 (one-layer aluminum and three-layer stainless-steel) and the setting conditions are opposite to each other. Considering the FEM results, laminated sheets with a thickness ratio of 71.3% aluminum and 28.7% stainless-steel were used to prepare deep drawing and redrawing experiments. The results of experiments are presented as the variation of thickness strain distribution in the drawn cup and punch load–stroke curves with respect to the setting condition. Results show that while in direct redrawing, contact of stainless-steel with the punch leads to the maximum drawing ratio, in reverse redrawing, aluminum should contact the punch in order to achieve the highest drawing ratio. An explanation for this finding is offered based on the thickness strain distribution, and punch load–stroke curves."
"F. D. Fiore, Philip Schaeken, Koen Elens, F. V. Reeth",5699886886c95db5828afd794e8f5bcb80310005,Automatic in-betweening in computer assisted animation by exploiting 2.5D modelling techniques,Proceedings Computer Animation 2001. Fourteenth Conference on Computer Animation (Cat. No.01TH8596),2001.0,51,"This paper introduces a new method for automatic in-betweening in computer assisted traditional animation. The solution is based on novel 2.5D modelling and animation techniques within the context of a multi-level approach, starting with basic 2D drawing primitives (curves) at level 0, over explicit 2.5D modelling structures at level 1 and inclusion of 3D information by means of skeletons at level 2, to high-level deformation tools (and possibly other tools for supporting specific purposes such as facial expression) at level 3. The underlying methodologies are explained and implementation results are elucidated."
"Matt J. Roach, J. Mason, M. Pawlewski",6b0c5720e96a2efa17e3df6d097f7780b29c7667,Motion-based classification of cartoons,"Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing. ISIMP 2001 (IEEE Cat. No.01EX489)",2001.0,45,This paper describes a simple high-level classification of multimedia broadcast material into cartoon non-cartoon. The input video sequences are from a broad range of material which is representative of entertainment viewing. Classification of this type of high-level video genre is difficult because of its large inter-class variation. The task is made more difficult when classification is over a small time (10's of seconds) introducing a great deal of intra-class variation. This paper presents a purely dynamic based approach for content-based classification of video sequences in the form of a new global motion measure of foreground objects. Experiments are reported on a diverse database consisting of: 8 cartoon and 20 non-cartoon sequences. Results are shown in identification error rates against time of sequence used for classification. The system produces a best identification error rate of 3% on 66 separate decisions based on 23 second sequences trained using a total of /spl sim/20 minutes of video.
"Seung Ho Kim, Se-ho Kim, H. Huh",e633890f7b32e07485f0b341be2813b8ba96cf01,Finite element inverse analysis for the design of intermediate dies in multi-stage deep-drawing processes with large aspect ratio,,2001.0,41,"Abstract An inverse finite element approach for multi-stage deep-drawing processes is introduced for robust capability to determine the optimum blank shape from the desired final shape and to obtain the thickness strain distribution in the final shape with a small amount of computing time and effort. A direct numerical analysis of multi-stage deep-drawing processes is extremely difficult to carry out because of its complexities and convergence problems as well as tremendous computing time. The analysis of elliptical or rectangular cup drawing with large aspect ratio is likewise very difficult with respect to the design process parameters including the intermediate die profiles. In order to overcome the difficulties, an inverse scheme is proposed in the present analysis and design. The multi-stage inverse analysis deals with the convergence among intermediate shapes and the corresponding sliding constraint surfaces. In this paper, finite element inverse analysis is applied to multi-stage deep-drawing processes in order to calculate the thickness strain distribution in each intermediate shape and to design the intermediate die shapes. The original design has been modified to enhance the discrepancy in the thickness strain distribution for each intermediate shape."
E. Do,307f8320b96d6dee8dc0bf19b4487c06f02b8ee5,VR Sketchpad. Create Instant 3D Worlds by Sketching on a Transparent Window,,2001.0,40,"This paper describes VR Sketchpad, a pen-based computing environment for inputting and locating 3D objects in a virtual world. Designer can use the transparency layers to quickly trace and extract any image underlay from other application software. The 3D scene generation has three levels of complexity: simple extrusion of any drawn lines of shapes (i.e., straight or curved wall and column extrusion), solid modelling from a given geometric object representation (spheres, cones and boxes), and complex configuration with objects from graphics library (furniture layout)."
T. M. Sezgin,5c3213da1a6d8af5acdbe223cd8413321cbfde8c,Feature point detection and curve approximation for early processing of free-hand sketches,,2001.0,36,"Freehand sketching is both a natural and crucial part of design, yet is unsupported by current design automation software. We are working to combine the flexibility and ease of use of paper and pencil with the processing power of a computer to produce a design environment that feels as natural as paper, yet is considerably smarter. One of the most basic steps in accomplishing this is converting the original digitized pen strokes in the sketch into the intended geometric objects using feature point detection and approximation. We demonstrate how multiple sources of information can be combined for feature detection in strokes and apply this technique using two approaches to signal processing, one using simple average based thresholding and a second using scale space. Thesis Supervisor: Randall Davis Title: Department of Electrical Engineering and Computer Science"
"Wenyin Liu, Wenjie Qian, R. Xiao, Xiangyu Jin",fe567787c53b55101e0a6f20fb0ad6d266d9e4e0,Smart Sketchpad-an on-line graphics recognition system,Proceedings of Sixth International Conference on Document Analysis and Recognition,2001.0,35,"An online graphics recognition system is presented, which provides users a natural, convenient, and efficient way to input rigid and regular shapes or graphic objects (e.g., triangles, rectangles, ellipses, straight line, arrowheads, etc.) by quickly drawing their sketchy shapes in single or multiple strokes. An input sketchy (hand-drawn) shape is immediately converted into the user-intended rigid shape based on the shape similarity and the time constraint of the sketchy line. Three different (rule-based, SVM-based, and ANN-based) approaches have been applied and compared in the system. Experiments and evaluation are also presented, which show good performance of the system."
"P. Hu, Y. Liu, J. Wang",115c135bafcd8c877ff6cfdaab55e34144d196f0,Numerical study of the flange earring of deep-drawing sheets with stronger anisotropy,,2001.0,27,"Abstract A Barlat–Lian anisotropy yield function is introduced into a quasi-flow corner theory of elastic–plastic finite deformation and the elastic–plastic large deformation finite element formulation based on the principle of virtual velocity and the discrete Kirchhoff triangle plate shell element model. The focus of the present researches is on the numerical simulation of the flange earring of deep-drawing process of circular sheets with stronger anisotropy, based on which, the schemes for controlling the flange earring are proposed."
"Jean-Philippe Valois, Myriam Côté, M. Cheriet",3ec2410c03ebaf62e9598c20e8afcb20ec5e7628,Online recognition of sketched electrical diagrams,Proceedings of Sixth International Conference on Document Analysis and Recognition,2001.0,26,"In this paper, a model-based scheme for recognizing and beautifying online hand-drawn sketches of electric diagrams is presented. The system uses a structural and topological relations matching mechanism that allows scale, translation, rotation invariant recognition. A simple prototype was developed and preliminary experimental results show how this technique, although simple, is efficient in recognizing such sketches."
"B. Huet, G. Guarascio, Nicholas J. Kern, B. Mérialdo",438a643d7769b1edaee3f40255c844d83d6b5871,Relational skeletons for retrieval in patent drawings,Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205),2001.0,26,"This paper presents the evaluation of a number of algorithm alternatives for content based retrieval from a database of technical drawings representing patents. The objective is to help patent evaluators in their quest for a possible patent bearing too much similarity with the one under investigation. To achieve this, we have devised a system where images (drawings) are represented using attributed graphs based on the extracted line-patterns or histograms of attributes computed from the graphs. Retrieval is either performed using histogram comparison (see Huet, B. and Hancock, E.R., PAMI, vol.21, no.12, p.1363-70, 1999) or thanks to a graph similarity measure (see Huet and Hancock, CVPR, p.138-43, 1998). Promising results are presented along with possible work extension."
"James V. Mahoney, M. Fromherz",46ce914715524236737c67a3255ab32f058e795a,Handling ambiguity in constraint-based recognition of stick figure sketches,IS&T/SPIE Electronic Imaging,2001.0,13,"Even seemingly simple drawings, diagrams, and sketches are hard for computer programs to interpret, because these inputs can be highly variable in several respects. This variability corrupts the expected mapping between a prior model of a configuration and an instance of it in the scene. We propose a scheme for representing ambiguity explicitly, within a subgraph matching framework, that limits its impact on the computational and program complexity of matching. First, ambiguous alternative structures in the input are explicitly represented by coupled subgraphs of the data graph, using a class of segmentation post-processing operations termed graph elaboration. Second, the matching process enforces mutual exclusion constraints among these coupled alternatives, and preferences or rankings associated with them enable better matches to be found early on by a constrained optimization process. We describe several elaboration processes, and extend a straightforward constraint-based subgraph matching scheme to elaborated data graphs. The discussion focuses on the domain of human stick figures in diverse poses."
"Khalid Goudeaux, Tsuhan Chen, Shyue-Wu Wang, Jen-Duo Liu",d0c6a20592cb7eb30fa0fa3aa5e9ab44e85dabd8,Principal component analysis for facial animation,"2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)",2001.0,11,"This paper presents a technique for animating a three-dimensional face model through the application of principal component analysis (PCA). Using PCA has several advantages over traditional approaches to facial animation because it reduces the number of parameters needed to describe a face and confines the facial motion to a valid space to prevent unnatural contortions. First, real data is optically captured in real time from a human subject using infrared cameras and reflective trackers. This data is analyzed to find a mean face and a set of eigenvectors and eigenvalues that are used to perturb the mean face within the range described by the captured data. The result is a set of vectors that can be linearly combined and interpolated to represent different facial expressions and animations. We also show that it is possible to map the eigenvectors of one face onto another face or to change the eigenvectors to describe new motion."
T. Hammond,d5b387a28938ad7ea7817242c7ee0a95f19c6dfe,Natural Sketch Recognition in UML Class Diagrams,,2001.0,3,"I created a natural sketch recognition environment for UML (Unified Modeling Language) (Alhir, 1998). My system differs from graffiti-based approaches to this task, in that it recognizes objects by how they look, not by how they are drawn. My goal is a system where the user can sketch UML diagrams on a tablet or whiteboard in the same way they would on paper, but the diagrams would then be recognized by the computer to provide clean interpreted diagrams, stub code, and enhanced editing ability."
"L. Menezes, C. Teodosiu",aebbf3a4f5d09b2b2a49a85476d370af545d94c0,Three-dimensional numerical simulation of the deep-drawing process using solid finite elements,,2000.0,234,Abstract The main goal of this work is to present a three-dimensional mechanical model for the numerical simulation of the deep-drawing process. The model takes into account the large elastoplastic strains and rotations that occur in the deep-drawing process. Hill’s orthotropic yield criteria with isotropic and kinematics hardening describes the anisotropic plastic properties of the sheet. Coulomb’s classical law models the frictional contact problem treated with an augmented Lagrangian approach. This method yields a mixed system where the final unknowns of the problem are static (frictional contact forces) and kinematic (displacements) variables. To solve this problem use is made of a fully implicit algorithm of Newton–Raphson type. Three-dimensional isoparametric finite elements with a selective reduced integration are used for the spatial discretization of the deformed body. The geometry of the forming tools is modelled by Bezier surfaces. The numerical results of the deep-drawing of a square cup are presented to focus their good agreement with the results of experiment.
"A. Quigley, P. Eades",a6840b0bb2743fafef46005d152de0edcb88a52f,"FADE: Graph Drawing, Clustering, and Visual Abstraction",Graph Drawing,2000.0,202,"A fast algorithm(FADE) for the 2D drawing, geometric clustering and multilevel viewing of large undirected graphs is presented. The algorithm is an extension of the Barnes-Hut hierarchical space decomposition method, which includes edges and multilevel visual abstraction. Compared to the original force directed algorithm, the time overhead is O(e + n log n) where n and e are the numbers of nodes and edges. The improvement is possible since the decomposition tree provides a systematic way to determine the degree of closeness between nodes without explicitly calculating the distance between each node. Different types of regular decomposition trees are introduced. The decomposition tree also represents a hierarchical clustering of the nodes, which improves in a graph theoretic sense as the graph drawing approaches a lower energy state. Finally, the decomposition tree provides a mechanism to view the hierarchical clustering on various levels of abstraction. Larger graphs can be represented more concisely, on a higher level of abstraction, with fewer graphics on screen."
"P. Dosch, K. Tombre, Christian Ah-Soon, G. Masini",7bdf55bb150bdebd4b425ae043376b77db710f12,A complete system for the analysis of architectural drawings,International Journal on Document Analysis and Recognition,2000.0,136,"Abstract. In this paper, we present a complete system for the analysis of architectural drawings, with the aim of reconstructing in 3D the represented buildings. We successively describe the graphics recognition algorithms used for image processing and feature extraction, the 2D modeling step, which includes symbol recognition and converts the drawing into a description in terms of basic architectural entities, and a proposed 3D modeling process which matches reconstructed floors. The system also includes a powerful and flexible user interface."
"J. Arvo, K. Novins",aafee5d151eaf9e604c2d0a0d61610a5c80f84e8,Fluid sketches: continuous recognition and morphing of simple hand-drawn shapes,UIST '00,2000.0,106,"We describe a new sketching interface in which shape recognition and morphing are tightly coupled. Raw input strokes are continuously morphed into ideal geometric shapes, even before the pen is lifted. By means of smooth and continual shape transformations the user is apprised of recognition progress and the appearance of the final shape, yet always retains a sense of control over the process. At each time t the system uses the trajectory traced out thus far by the pen coupled with the current appearance of the time-varying shape to classify the sketch as one of several pre-defined basic shapes. The recognition operation is performed using shape-specific fits based on least-squares or relaxation, which are continuously updated as the user draws. We describe the time-dependent transformation of the sketch, beginning with the raw pen trajectory, using a family of first-order ordinary differential 
equations that depend on time and the current shape 
of the sketch. Using this formalism, we describe several possible behaviors that result by varying the relative significance of new and old portions of a stroke, changing the “viscosity” of the morph, and enforcing different end conditions. A preliminary user study suggests that the new interface is particularly effective for rapidly constructing diagrams consisting of simple shapes."
"Hod Lipson, M. Shpitalni",599600e855d61e79206293a8146f844df8c498c3,Conceptual design and analysis by sketching,"Artificial Intelligence for Engineering Design, Analysis and Manufacturing",2000.0,86,"The ability of a CAD system to perceive a three-dimensional model depicted in a single freehand sketch presents the practical possibility of bringing numerous established analysis tools into the early stages of design to institute conceptual analysis. In this article we hypothesize that the key to enabling systems to reason and communicate about conceptual design is the language of sketching. We explore this approach, outline the basic algorithms required, and provide several examples of an implemented system."
"Sébastien Adam, J. Ogier, C. Cariou, R. Mullot, J. Labiche, J. Gardes",6beb050721077d16a60990cd57c073e58371a8f1,Symbol and character recognition: application to engineering drawings,International Journal on Document Analysis and Recognition,2000.0,85,"Abstract. In this paper, we consider the general problem of technical document interpretation, as applied to the documents of the French Telephonic Operator, France Télécom. More precisely, we focus the content of this paper on the computation of a new set of features allowing the classification of multioriented and multiscaled patterns. This set of invariants is based on the Fourier–Mellin Transform. The interests of this computation rely on the excellent classification rate obtained with this method and also on using this Fourier–Mellin transform within a “filtering mode”, with which we can solve the well known difficult problem of connected character recognition."
"S. H. Soon, Feng Tian",e34748c591c300277d5d8f8a87e14683835421e4,Computer-assisted coloring by matching line drawings,The Visual Computer,2000.0,24,"An approach to automatically color line drawings based on feature matching is proposed. The motivation is that coloring 2D animation is still a labor-intensive process in current cartoon film production. The objective of our work is to investigate how to automatically color an image in a cartoon sequence on the basis of the previous frame. Our method first establishes the matching relationship of two images, after which it automatically paints one of them with the color information of the other using a region-matching algorithm. The region-matching algorithm is based on feature correspondences. The results show that the proposed algorithm can straightforwardly and robustly realize our objective and has a promising future for our next step to further automate conventional animation."
"L. Wade, Richard E. Parent",f75f1dcf2f0ff4c252c4785a4529ea0cac39e03d,"Fast, fully-automated generation of control skeletons for use in animation",Proceedings Computer Animation 2000,2000.0,21,"This paper describes an algorithm for automatically generating a control skeleton for use in animating a polygonal data model. The algorithm has several steps. First, the figure is voxelized, and a Euclidean distance map is computed for voxels interior to the figure. A path creation algorithm then generates a tree-structured set of voxel paths spanning the object's interior. Simplification of these paths leads to a control skeleton for the object. The voxelization is used again to anchor the vertices of the polygonal model to the skeleton. Afterwards, new joint angles may be specified for the skeleton, and once the skeleton has been updated, vertices of the model can be repositioned accordingly. Unlike previous methods, the algorithm is fully automated, requiring very little user input. Also, it can be applied successfully to a wide variety of objects. Furthermore, the algorithm is fast-it can produce a useful control skeleton for most objects in under two minutes on a low-end PC."
"E. D. Sciascio, G. Mingolla, M. Mongiello",55faa95a898b87377b41f2acc707b877abb84389,Content-Based Image Retrieval over the Web Using Query by Sketch and Relevance Feedback,VISUAL,1999.0,70,"This paper investigates the combined use of query by sketch and relevance feedback as techniques to ease user interaction and improve retrieval effectiveness in content-based image retrieval over the World Wide Web. To substantiate our ideas we implemented DrawSearch, a prototype image retrieval by content system that uses color, shape and texture to index and retrieve images. The system avails of Java applets for query by sketch and uses relevance feedback to allow users dynamically refine queries."
"D. Dori, Wenyin Liu",0e60ed9c3466a21827651a00c5d4eaca8f82018f,"Automated CAD conversion with the Machine Drawing Understanding System: concepts, algorithms, and performance",IEEE Trans. Syst. Man Cybern. Part A,1999.0,58,"The Machine Drawing Understanding System (MDUS) is an experimental CAD conversion system aimed at realizing the entire process of understanding mechanical engineering drawings, from scanning to 3D reconstruction. This paper describes the structure, algorithms and current performance of MDUS. The modular structure of the system provides for further improvements and makes it an ideal workbench for researchers wishing to test their own algorithms and incorporate them into the system."
"W. Freeman, J. Tenenbaum, E. Pasztor",6c70fbb62ea308f6e609fccb599f74516cd10d1e,An example-based approach to style translation for line drawings,,1999.0,43,"We present an example-based system for translating line drawings into di erent styles. The system is given a training set of many di erent lines, each drawn by an artist in various styles, which is used to translate new lines made by a user into a particular desired style with a K-nearest neighbor algorithm. This algorithm ts each input line as a linear combination of the several training lines in the same style which are most similar to it. The t line can then be rendered in di erent styles because the training set contains versions of each training line in each style. By describing input lines as linear combinations of training set lines, this procedure is expressive enough to t a broad range of input drawings. By restricting these linear combinations to contain only the most similar training set lines, this procedure is constrained enough to preserve the distinctive stylistic features of translated lines. We represent input lines by splines with nonuniformly spaced control points, which emphasizes these stylistic features. Our example-based approach has a number of advantages over conventional parameteric approaches to translating style. It can handle styles which are di cult to describe parametrically, and its repertoire can be easily extended by the user at any time. Moreover, given appropriate representations, it can be generalized to modify the style of other kinds of graphics objects, such as the font of a letter or the movement style of an animated character."
Klaus Kaindl,da2244aa6113857f2a0b26676332b686310d13e7,"Thump, Whizz, Poom: A Framework for the Study of Comics under Translation",,1999.0,40,"Abstract: Notwithstanding their importance as a segment of high-volume translation, comics have largely been neglected in Translation Studies. This paper presents a theoretical framework for studying the translation of comics as a social practice. On the premise that the production and reception of texts is dependent on their position and relative value in a given society, comics are first analyzed as a social phenomenon with the help of Bourdieu 's theory of the cultural field. The translation-relevant elements of comics are then identified on the linguistic, typographic, and pictorial levels, and concepts of rhetoric are used to establish a classification of translation strategies which applies to both verbal and nonverbal textual material. Finally, a number of examples are discussed to highlight the diversity of translation strategies for the various elements of comics.Resume: En depit de leur frequence, les traductions des bandes dessinees (BD) sont souvent laissees pour compte par les traductologues. Le present travail propose un cadre theorique pour leur etude systematique. Partant de la premisse que la production et reception des textes dependent de leurs positions et valeurs au sein d'une societe donnee, et en reference a la theorie de Bourdieu du champ culturel, les BD sont d'abord analysees comme un phenomene social. Ensuite, leurs traits propres a interesser la traduction sont identifies sur les plans linguistique, typographique et pictural, tandis que des concepts rhetoriques aident a etablir un classement des strategies traductives s'appliquant a la matiere verbale et non verbale des BD. Enfin, des exemples permettent d'etayer les strategies traductives qui se rapportent aux differents aspects des BD."
"T. Fujiwara, Takeshi Nishihara, M. Tominaga, H. Koshimizu, Kunihito Kato, K. Murakami",8404bcba2fa15bdaf1397eff0b37eed3576abb42,On the detection of feature points of 3D facial image and its application to 3D facial caricature,Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062),1999.0,20,"The paper proposes an automated method for extracting 27 feature points from a 3D facial image. It also shows that 3D facial caricaturing can be realized by such a small number of feature points and that these 27 feature points can be extracted automatically. As a result, it was clarified by comparing a 3D caricature of a 3D PICASSO system with that of a famous caricaturist, Mr. Yoshida, that 3D features of the facial image could be utilized to generate a more impressive facial caricature than the 2D version."
J. Mcfadzean,3cd0263cff5a93634bd8e440db4ad7aaed64e0fb,Computational Support for Conceptual Sketching Analysis and Interpretation of the Graphical Notation of Visual Representations,,1999.0,8,The research investigates how designers sketch specifically analysing the physical details of mark-making. It contrasts the physical representations with the abstract cognitive processes of architectural design. A new form of protocol analysis has been developed using video and computer records of designers' sketching activity. The research compares the designer's post-hoc commentary and interpretations of the sketching activity with the computer's record of that activity. This process will lead to a greater understanding of the relationships between design events and graphical events.
"J. Mcfadzean, N. Cross, J. Johnson",eb7dfe2b48190061c70e6c88c1cf3238bbb898ea,An analysis of architectural visual reasoning in conceptual sketching via Computational Sketch Analysis (CSA),1999 IEEE International Conference on Information Visualization (Cat. No. PR00210),1999.0,4,"Visual reasoning in design is facilitated by sketching. This research investigates how designers sketch, specifically analysing the physical details of mark making. It relates the graphical representations to the abstract cognitive processes of architectural design. A new form of protocol analysis has been developed using video and computer records of designers' sketching activity. The analysis of the resulting data compares the designer's retrospective commentary and interpretations of the sketching activity with the computer's record of that activity. The analysis will lead to a greater understanding of the relationships between 'Design Events' and 'Graphical Events' and thus how the notational activity of sketching supports the cognitive activity of conceptual design."
"G. Byatt, G. Rhodes",4207b37ccb6984d353cb3842771a562606af3b00,Recognition of own-race and other-race caricatures: implications for models of face recognition,Vision Research,1998.0,98,"Valentine's (Valentine T. Q J Exp Psychol 1991;43A:161-204) face recognition framework supports both a norm-based coding (NBC) and an exemplar-only, absolute coding, model (ABC). According to NBC; (1) faces are represented in terms of deviations from a prototype or norm; (2) caricatures are effective because they exaggerate this norm deviation information; and (3) other-race faces are coded relative to the (only available) own-race norm. Therefore NBC predicts that, for European subjects, caricatures of Chinese faces made by distorting differences from the European norm would be more effective than caricatures made relative to the Chinese norm. According to ABC; (1) faces are encoded as absolute values on a set of shared dimensions with the norm playing no role in recognition; (2) caricatures are effective because they minimise exemplar density and (3) the dimensions of face-space are inappropriate for other-race faces leaving them relatively densely clustered. ABC predicts that all faces would be recognised more accurately when caricatured against their own-race norm. We tested European subjects' identification of European and Chinese faces, caricatured against both race norms. The ABC model's prediction was supported. European faces were also rated as more distinctive and recognised more easily than Chinese faces. However, the own-race recognition bias held even when the races were equated for distinctiveness which suggests that the ABC model may not provide a complete account of race effects in recognition."
Zhaoyang Lu,e4732d06f10440f980a0af8758db17819ad88ba6,Detection of Text Regions From Digital Engineering Drawings,IEEE Trans. Pattern Anal. Mach. Intell.,1998.0,65,"An algorithm for text/graphics separation is presented in this paper. The basic principle of the algorithm is to erase nontext regions from mixed text and graphics engineering drawings, rather than extract text regions directly. This algorithm can be used to extract both Chinese and Western characters, dimensions, and symbols and has few limitations on the kind of engineering drawings and noise level. It is robust to text-graphics touching, text fonts, and written orientations."
"M. Jain, J. Allin, M. J. Bull",479b96ca00df52664e41a07c8791bd75da2a1025,Deep drawing characteristics of automotive aluminum alloys,,1998.0,61,"Abstract Limiting draw ratios (LDRs) and other axisymmetric deep drawing characteristics of AA5754-O and AA6111-T4 automotive aluminum sheet materials are investigated as a function of die profile radii by experiments and numerical predictions. A procedure for rapid determination of LDR based on a characteristic limit load of the material at fracture is developed and verified. Other deep drawing characteristics such as punch load versus displacement traces, flange draw-in, strain distribution along the cup profile, flange wrinkling, wall ironing and fracture characteristics are experimentally assessed for the two sheet materials as a function of the die profile radius. The results are compared with a recent analytical model by Schedin (Ph.D. Thesis, Royal Institute of Technology, Stockholm, Sweden, 1991). as well as axisymmetric FE models of cup draw, to analyse the sensitivity of various material and test parameters towards the maximum punch load and stresses and strains in various regions of the cup. The deep drawability of AA5754-O, as measured by cup depth at fracture and LDR, is superior to that of AA6111-T4. The differences in the deep drawing behaviour of the two materials can be explained in terms of the competition in work hardening between the material in the flange at the die profile region versus the material at the punch profile region, bendability of the two materials, and fracture characteristics. A decrease in LDR and flange draw-in is observed as a function of the die profile radius. This decrease is attributed to the increased work hardening in the die profile region resulting from additional bending, unbending, and stretching of the material as it enters the die cavity, as well as increased tendency towards fracture for AA6111-T4."
"D. Dori, Yelena Velkovitch",da18c6aae82f5b8aee6558adcc6cbbc9764d2610,Segmentation and Recognition of Dimensioning Text from Engineering Drawings,Comput. Vis. Image Underst.,1998.0,24,"Recognition of dimensioning text in engineering drawings is an essential part of the drawing understanding process, as this text provides the exact dimensions and tolerances of the object described in the drawing. We consider engineering drawings produced according to either ISO or ANSI drafting standards. Text segmentation and recognition are preceded by orthogonal zig-zag vectorization, arc segmentation, and arrowhead pair recognition. Initial textbox extraction is done by a region growing process, performed on text-wire candidates. On the basis of textbox context (neighboring annotation wires) the drafting standard is detected. Raw textboxes are divided into logical textboxes, which are further decomposed into basic textboxes. A neural network based OCR algorithm is applied to each basic textbox. Finally, the OCR recognition results are verified by using contextual information and comparing the results with the measurements made directly on the drawing."
"S. J. Cho, S. Yoo",7063dd308a253b6bf397cf974815fcf48d823523,Image retrieval using topological structure of user sketch,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",1998.0,7,"Content-based image retrieval system retrieves an image from a database using visual information. Among approaches to expressing visual aspects in queries, ""query by sketch"" is most convenient and expressive. However, the query drawn by the user is typically quite different from the original image and makes it difficult to retrieve the intended image effectively. In this paper, a new method to retrieve the intended image from imperfect queries is presented. The user-drawn query image is converted to a prime edge graph that represents the topological structure of the objects in the image. The experimental results show that the system retrieves the intended image even from a partial or shifted query."
"M. Suwa, B. Tversky",bf7551a995c71a7960787f7293669c6ac2b04f70,What do architects and students perceive in their design sketches? A protocol analysis,,1997.0,623,"The present research aims at examining what information architects think of and read off from their own freehand sketches, and at revealing how they perceptually interact with and benefit from sketches. We explored this in a protocol analysis of retrospective reports; each participant worked on an architectural design task while drawing freehand sketches and later reported what she/he had been thinking of during the design task. This research lies within the scope of examinations of why freehand sketches as external representation are essential for crystallizing design ideas in early design processes."
"A. Bimbo, P. Pala",e6182e4e462fd25ac6e1744415b481d422c861b2,Visual Image Retrieval by Elastic Matching of User Sketches,IEEE Trans. Pattern Anal. Mach. Intell.,1997.0,475,"Effective image retrieval by content from database requires that visual image properties are used instead of textual labels to properly index and recover pictorial data. Retrieval by shape similarity, given a user-sketched template is particularly challenging, owing to the difficulty to derive a similarity measure that closely conforms to the common perception of similarity by humans. In this paper, we present a technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks. The degree of matching achieved and the elastic deformation energy spent by the sketch to achieve such a match are used to derive a measure of similarity between the sketch and the images in the database and to rank images to be displayed. The elastic matching is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries. Examples from a prototype system are expounded with considerations about the effectiveness of the approach and comparative performance analysis."
"M. Shpitalni, Hod Lipson",c363eb7f37d2c957b54d22aa20dbf3625544f94a,Classification of Sketch Strokes and Corner Detection Using Conic Sections and Adaptive Clustering,,1997.0,85,"This paper presents a method for classifying pen strokes in an on-line sketching system. The method, based on linear least squares fitting to a conic section equation, proposes using the conic equation's natural classification property to help classify sketch strokes and identify lines, elliptic arcs, and corners composed of two lines with an optional fillet. The hyperbola form of the conic equation is used for corner detection. The proposed method has proven to be fast, suitable for real-time classification, and capable of tolerating noisy input, including cusps and spikes. The classification is obtained in o(n) time in a single path, where n is the number of sampled points. In addition, an improved adaptive method for clustering disconnected endpoints is proposed. The notion of in-context analysis is discussed, and examples from a working implementation are given."
K. Tombre,b8e1207e4b7ec339cfab98a9f18c8f6fa293e8dd,Analysis of Engineering Drawings: State of the Art and Challenges,GREC,1997.0,76,"In this paper, we analyze the state of the art in interpretation of engineering drawings, both from a methodological point of view and from the perspective of the applications. We try to emphasize where techniques are mature, where they need further maturing, and where we still have open challenges. Special attention is given to the progress in the last two years, i.e. to the evolution in the field since GREC'95."
Jochen Seemann,9b878cbfecd6cb5d340f71a0c58b535e2340963c,Extending the Sugiyama Algorithm for Drawing UML Class Diagrams: Towards Automatic Layout of Object-Oriented Software Diagrams,Graph Drawing,1997.0,66,The automatic layout of software diagrams is a very attractive graph drawing application for use in software tools. Object-oriented software may be modelled using a visual language called the Unified Modeling Language (UML). In this paper we present an algorithm for the automatic layout of UML class diagrams using an extension of the Sugiyama algorithm together with orthogonal drawing. These diagrams visualize the static structure of object-oriented software systems and are characterised by the use of two main types of edges corresponding to different relationships between the classes. The graph drawing algorithm accounts for these concepts by treating the different edge types in different ways.
"M. Moshksar, A. Zamanian",1ceb4f7ab3ac9d54f0ceb91ada404cc3a4b48ff9,Optimization of the tool geometry in the deep drawing of aluminium,,1997.0,40,"The ability to predict a successful deep-drawing operation is important when designing a deep-drawing schedule. This paper presents the results of a series of cup-drawing tests carried out to study the deep drawing of commercial aluminium blanks. The critical die and punch shoulder radii, the limiting blank diameters and the limiting drawing ratios were recorded. Over the ranges of conditions investigated, the drawing process was found to be strongly sensitive to the die and punch-nose radii. Based on the experimental data obtained, the maximum punch force for aluminium cup drawing is proposed."
"Yuanzhong Li, H. Kobatake",10d1e7319dd03049d497b4dcb9b2479acda40ce5,Extraction of facial sketch image based on morphological processing,Proceedings of International Conference on Image Processing,1997.0,25,"This paper proposes a new method to extract a facial sketch image from a facial image robustly. The extraction process consists of two processing steps and morphology plays an important role in the whole processing. Firstly, a generalized symmetry operator, rectangle-filter and a geometric template are used to detect the eyes and mouth. Based on the detected facial parts, the locations of other facial parts are detected using their geometrical locations and characteristic shapes. Secondly, the feature points are determined from the edges of each facial part. Line-drawings connecting them give the facial sketch image. Experiments using 300 facial images were performed and the rate of extracting the facial sketch image correctly was 91%. This result shows the effectiveness of the proposed system."
"Chueh-Wei Chang, Suh-Yin Lee",f5593996a80e2a69b2795a803d73b453a4e4f69f,Automatic Cel Painting in Computer-assisted Cartoon Production using Similarity Recognition,Comput. Animat. Virtual Worlds,1997.0,19,"The task of painting each cel of an animated sequence has always been a tedious work using traditional methods. In order to simplify and speed up the process, the development of an automatic cel painting system is desired. This paper presents a method for assisting the production of cartoon animation using computers in order to reduce the production expense and to improve the overall quality. It signals a great improvement in the working environment where 2-D animation is produced. The basic idea of our automatic cel painting mechanism is to extract both statistical and topological features of regions from input animation drawings, and to search for similar corresponding regions in the previous drawing. If the similarity measures are within the accepted thresholds, the corresponding colour will be inherited. A new integrated labelling algorithm constructing statistical region and topological graph features is proposed. Furthermore, a similarity measure of regions is defined and an algorithm of partial matching of attribute graphs is presented. The experimental result shows the feasibility and practicability of the proposed approach.  1997 by John Wiley & Sons, Ltd."
"Chueh-Wei Chang, Suh-Yin Lee",394393c4270e665c8149c9e944984258e5f1cc21,Automatic cel painting in computer-assisted cartoon production using similarity recognition,,1997.0,13,"The task of painting each cel of an animated sequence has always been a tedious work using traditional methods. In order to simplify and speed up the process, the development of an automatic cel painting system is desired. This paper presents a method for assisting the production of cartoon animation using computers in order to reduce the production expense and to improve the overall quality. It signals a great improvement in the working environment where 2-D animation is produced. The basic idea of our automatic cel painting mechanism is to extract both statistical and topological features of regions from input animation drawings, and to search for similar corresponding regions in the previous drawing. If the similarity measures are within the accepted thresholds, the corresponding colour will be inherited. A new integrated labelling algorithm constructing statistical region and topological graph features is proposed. Furthermore, a similarity measure of regions is defined and an algorithm of partial matching of attribute graphs is presented. The experimental result shows the feasibility and practicability of the proposed approach. © 1997 John Wiley & Sons, Ltd."
"A. K. Das, N. Langrana",15fed491c655ee9fa737d9bf0678c3164ad0553e,Recognition and Integration of Dimension Sets in Vectorized Engineering Drawings,Comput. Vis. Image Underst.,1997.0,8,The benefits of the existing CAD systems are not available to a large number of engineering drawings which were created manually on paper using conventional drafting methods. An automated system which will scan and convert these drawings into CAD files recognizable by the existing CAD systems is very desirable. An important element in the conversion process is the automatic recognition and understanding of dimensional information which is used to denote the exact size and location of the various entities present in the geometry described in the drawing. This paper discusses a system which has been developed to recognize the dimension sets from the vectorized image of the drawing and obtain the logical relationship between the dimension sets and the geometry. The recognized dimension sets are also integrated with the geometry of the object using a variational geometry approach to rectify the errors which are introduced during preprocessing. The drawing obtained after processing consists of an accurate vectorized representation of the geometry in terms of the basic geometric entities and a vectorized representation of the dimension sets which can be used in an dimension-driven CAD system.
G. Rhodes,a5f3878fc0679d462184170d7d9bd575ec4c92d7,Superportraits: Caricatures and Recognition,,1996.0,105,Introduction. The Nature of Caricature. Caricatures by Computer. Peacock's Tails and other Natural Caricatures. The Power of Extremes. The Psychology of Caricatures. Caricatures and Face Recognition. The View from Here.
"D. Dori, Wenyin Liu",fd68254b4fccc40431dc494caf89fdfcda242027,Vector-Based Segmentation of Text Connected to Graphics in Engineering Drawings,SSPR,1996.0,36,"A method for segmentation of text that may be connected to graphics in engineering drawings is presented. It consists of three steps: growing individual characterbox regions, using a recursive merging scheme by stroke linking; merging the detected characterboxes into a textbox and determining its orientation; and re-segmenting the textbox back into the refined characterbox that can be input to an OCR subsystem. The method can segment dimensioning text as well as other classes of text. It handles both isolated and touching characters, aligned at any slant. The capability of segmenting characters that touch either themselves or graphics, which is an important feature in handling real life drawings, is obtained by focusing on intermediate vector information rather that on the raw pixel data. We present the details of the algorithm and show both successful and unsuccessful examples from an experimental set of 36 dimensioning textboxes, in which 94% segmentation rate was achieved with 3% false alarm rate."
"J. Savoie, Y. Zhou, J. Jonas, S. Macewen",7809cd2d20aecef937d6920d48dad0000289749b,Textures induced by tension and deep drawing in aluminum sheets,,1996.0,31,"Abstract The textures induced by tensile deformation and deep drawing were investigated. For this purpose, the textures of three types of aluminum sheet (1145, a batch and a continuously annealed experimental alloy) were measured and analyzed using the series expansion method. The results indicate that the initial textures evolve towards the 〈111〉 and 〈100〉 type fiber textures after 20–30% of tensile deformation. After plane strain flange deformation during the early stages of deep drawing, the orientation densities increase around the P {011}〈111〉 and Goss {011}〈100〉 components. During the later stages of drawing, when flange thickening occurs, sometimes followed by ironing, the P orientation becomes unstable, whereas those along the α D -fiber are strengthened. The distinct texture changes taking place in each alloy are interpreted in terms of differences in the strengths and distributions of the initial texture components. The earing behaviors of the three materials are also analyzed in terms of the initial strengths of the cube {001}〈100〉, Goss {011}〈100〉 and R {113}〈574〉 components."
Ming-Ming Cheng,5e5f91968f528b262d0879546c8fcd8c11382329,Curve Structure Extraction for Cartoon Images,,1996.0,22,"We propose a novel method for curve structure extraction of cartoon images. Our method handles two types of cartoon curves, decorative curves and boundary curves, in a uniform way. The method consists of two steps. First, we calculate curve points by applying non-maximal suppress on secondary derivative of cartoon images. Second, these curve points are linked together to form structure curves while unreliable curves are removed away. Compared to curve structure extraction algorithm proposed by Steger, the number of curves generated by our algorithm is only 19% of Steger’s on average, with better curve quality. Furthermore, more accurate curve position can be obtained by our method."
D. Dori,0b06db544708285de691dbb2cc7d0f1b193117cf,Vector-Based Arc Segmentation in the Machine Drawing Understanding System Environment,IEEE Trans. Pattern Anal. Mach. Intell.,1995.0,61,"Arcs are important primitives in engineering drawings. Extracting these primitives during the lexical analysis phase is a prerequisite to syntactic and semantic understanding of engineering drawings within the machine drawing understanding system. Bars are detected by the orthogonal zig-zag vectorization algorithm. Some of the detected bars are linear approximations of arcs. As such, they provide the basis for arc segmentation. An arc is detected by finding a chain of bars and a triplet of points along the chain. The arc center is first approximated as the center of mass of the triangle formed by the intersection of the perpendicular bisectors of the chords these points define. The location of the center is refined by recursively finding more such triplets and converging to within no more than a few pixels from the actual arc center after two or three iterations. The high performance of the algorithm, demonstrated on a set of real engineering drawings, is due to the fact that it avoids both raster-to-vector and massive pixel-level operations, as well as any space transformations. >"
"D. Min, B. Jeon, Hyung-Jong Kim, Naksoo Kim",ed413b80635bd0b147547ea5c32d15d52c84e23d,A study on process improvements of multi-stage deep-drawing by the finite-element method,,1995.0,33,"Abstract Multi-stage deep-drawing processes, including normal drawing, reverse drawing, and redrawing, to shape the front shell of a master VAC for an automobile have been analyzed sequentially by the use of the rigid-plastic finite-element method, computational results on the punch/die loads and thickness distributions being obtained. The thickness strains were compared with the results of experiments on current drawing processes, good agreement being found. Deep-drawing processes of the redesigned shell to improve the specific strength and stiffness were simulated with the numerical method developed. By varying several process parameters, such as the blank size, the corner radii of the tools, and the clearances, the simulation results showed improvements in reducing the forming loads. Also, forming defects were found during simulation and the appropriate blank size could be verified."
P. Cook,278a61140f82a7be3d94568f744b950e0f6b91c1,Integration of Physical Modeling for Synthesis and Animation,ICMC,1995.0,22,
D. Dori,806fcbd85839b5ccd809cb159ff7bf47f8c7e23f,Representing pattern recognition-embedded systems through object-process diagrams: the case of the machine drawing understanding system,Pattern Recognit. Lett.,1995.0,17,"Abstract Pattern recognition involves a host of problems, algorithms and techniques dealing with all aspects of detection and classification of objects in scenes and their conversion into meaningful interpretations. Frequently, such tasks are embedded within vision systems that are themselves embedded within more complex systems. Concentrating on minute, albeit important, details of some pattern recognition algorithm, may result in blurring of the “big picture” that puts the algorithm under consideration in the more general framework. Pattern recognition (PR)-embedded systems feature a combination of complexity on the one hand and a balance between structure and behavior on the other hand. Analysis and understanding of such systems call therefore for a methodology that represents equally well structure and behavior within a unified frame of reference and has adequate tools for complexity management. This work proposes the object-process analysis (OPA) as an approach to tackle this task. The Machine Drawing Understanding System (MDUS) is as an instance of a PR-embedded system used as a case in point. We provide a motivation for the development of the system in general and its specialized Orthogonal Zig-Zag (OZZ) vectorization algorithm in particular. To demonstrate the suitability of OPA for representing PR-embedded systems at any level of detail, we apply it to communicate a top-down introduction of MDUS and its OZZ algorithm. The result is a series of consistent, inter-related object-process diagrams that gradually expose the details of the system. Complexity is managed through visibility control, which is obtained by a host of options for scaling object process diagrams. The ease of application of object-process analysis to the case in point suggests that it can be successfully applied to analyze, understand and communicate PR-embedded systems."
Robin L. Kullberg,ae70c792600ab2ce4973df6f844ba0b3412856d5,Mark your calendar!: learning personalized annotation from integrated sketch and speech,CHI '95,1995.0,8,"An intelligent agent learns the user’s personal sketch annotations by gathering, integrating, and interpreting sketch and speech input. This agent-assisted, multi-modal interaction affords a natural and adaptable approach to graphical annotation of a personal datebook."
"W. Lu, W. Wu, M. Sakauchi",07776e278b246f876d4c8895aa6ca7044583d941,A drawing recognition system with rule acquisition ability,Proceedings of 3rd International Conference on Document Analysis and Recognition,1995.0,5,"We propose a new way of constructing a drawing recognition system. The system has the ability of rule acquisition and therefore can be easily adopted to drawings of different specifications. Rule acquisition is realized through an empirical learning module, which constructs decision trees from teacher examples and translates the decision trees into production rules for actual recognition. The teacher examples are stored along with the corresponding environmental parameters so that future modification/expansion becomes much more easier. Since most of the attribute values are continuous-valued so that the construction of decision tree is more time consuming, we propose can improved algorithm for more efficient selection of cut points. Experimental results show that the proposed algorithm for cut point selection in decision tree generation improves the efficiency by up to 6 times while ensuring the optimal result."
"M. Freedman, L. Leach, E. Kaplan, G. Winocur, K. Shulman, D. Delis",1763602abad89d1d76d0077ebffea15be25793f9,Clock Drawing: A Neuropsychological Analysis,,1994.0,292,Introduction 1. Normative study 2. Dementia and related disorders 3. Well elderly in senior's residence 4. Focal brain damage
"A. Bimbo, P. Pala, S. Santini",b52c024c11f27208ada0bccb41469002d295ef70,Visual image retrieval by elastic deformation of object sketches,Proceedings of 1994 IEEE Symposium on Visual Languages,1994.0,61,"We present a method for image retrieval based on sketches of object shapes. In our method, the shape is drawn by the user, and instantiated as an elastic template. The template is then deformed to match as well as possible the objects in the images. The degree of match achieved, and the elastic deformation energy spent to achieve such a match are used as a measure of the similarity between the template and the image object. Images can be ranked according to the matching of their objects with the sketch, and the top ranking ones can be presented to the user for browsing. The elastic matching is integrated with arrangements to provide for scale invariance, to take into account rotations and spatial relationships between objects for multiple-object queries.<<ETX>>"
"C. Lai, R. Kasturi",7ccf87542d57874f7370361e798dee22be8f386f,Detection of Dimension Sets in Engineering Drawings,IEEE Trans. Pattern Anal. Mach. Intell.,1994.0,43,"This correspondence presents a system for detecting dimension sets in engineering drawings that are drawn to ANSI drafting standards. A new rule-based text/graphics separation algorithm and a model-based procedure for detecting arrowheads in any orientation have been developed. Arrowhead tracking and search methods are used to extract leaders, tails, and witness lines from segmented images containing only graphics. Text blocks and feature control frames extracted from the segmented images are than associated with their corresponding leaders to obtain complete dimension sets. Experimental results are presented. >"
"Atish Bagchi, Charles Wells",bdf55f6b0981c2641fac3f2e761337046d827a9e,Graph-based Logic and Sketches I: The General Framework,,1994.0,11,"Traditional treatments of formal logic provide: 1. A syntax for formulas. 2. An inference relation between sets of formulas. 3. A rule for assigning meaning to formulas (semantics) that is sound with respect to the inference relation. 
First order logic, the logic and semantics of programming languages, and the languages that have been formulated for various kinds of categories are all commonly described in this way. The formulas in those logics are strings of symbols that are ultimately modeled on the sentences mathematicians speak and write when proving theorems. 
Mathematicians with a categorial orientation frequently state and prove theorems using graphs and diagrams. The theory of sketches provides a formal way to describe mathematical structures and impose requirements (such as equations) on them using graphs, diagrams and similar structures. The graphs, diagrams and other data of a sketch are formal objects that correspond to the graphs and diagrams used by such mathematicians in much the same way as the formulas of traditional logic correspond to the sentences mathematicians use in proofs. 
Sketch theory has a well-known and well-developed functorial semantics corresponding to item 3 in the description of logic above. The content of this paper is to propose a structure in sketch theory that corresponds to items 1 and 2 in that description."
A. Manning,405dea794fe583b910f8ff4b147d91350e4f33f3,Understanding Comics: The Invisible Art,,1993.0,1519,
"R. Mayer, Richard B. Anderson",c194a7435bfba610b365f9924642bb9f4c3b2c61,The instructive animation: helping students build connections between words and pictures in multimedia learning,,1992.0,929,"In 2 experiments, students studied an animation depicting the operation of a bicycle tire pump or an automobile braking system, along with concurrent oral narration of the steps in the process (concurrent group), successive presentation of animation and narration (by 4 different methods), animation alone, narration alone, or no instruction (control group). On retention tests, the control group performed more poorly than each of the other groups, which did not differ from one another. On problem-solving tests, the concurrent group performed better than each of the other groups, which did not differ from one another. These results are consistent with a dual-coding model in which retention requires the construction of representational and referential connections"
"Toshikazu Kato, T. Kurita, N. Otsu, Keiji Hirata",fdf2c1986afd802f1163b6c08895eb11ed1e1877,A sketch retrieval method for full color image database-query by visual example,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,1992.0,213,"Gives a basic idea and its fundamental algorithms of the visual interface for image database systems. The QVE (Query by Visual Example) accepts a sketch roughly drawn by a user to retrieve the original image and the similar images. The system evaluates the similarity between the rough sketch, i.e. a visual example, and each of the image data in the database automatically. The QVE interface is implemented and examined on an experimental electronic art gallery called ART MUSEUM. This paper also gives some experimental results and a current evaluation. The algorithms are quite effective for content based image retrieval.<<ETX>>"
"R. Mauro, M. Kubovy",3786ff7efb3ca3800c08cf414bc8f28d37a908a7,Caricature and face recognition,Memory & cognition,1992.0,99,"Although caricatures are often gross distortions of faces, they frequently appear to be super-portraits capable of eliciting recognition better than veridical depictions. This may occur because faces are encoded as distinctive feature deviations from a prototype. The exaggeration of these deviations in a caricature may enhance recognition because it emphasizes the features of the face that are encoded. In two experiments, we tested the superportrait hypothesis and the encoding-by-caricature hypothesis. In the first experiment, caricatures were recognized better than faces, and true caricatures of previously seen faces were recognized better than the faces from which the caricatures had been developed. In the second experiment, faces and their caricatures were tachistoscopically presented in a sequential same/different reaction time task. Subjects were slower to distinguish the stimuli when the face preceded its caricature, indicating that caricatures are more similar to the encoded representation of a face than are stimuli in which the distinctive features are deemphasized."
"S. Shimotsuji, O. Hori, M. Asano, Kaoru Suzuki, Fumihiko Hoshino, T. Ishii",eddf316606c64ba5eb59f7e093baeb6b4188d8ee,A robust recognition system for a drawing superimposed on a map,Computer,1992.0,38,"A robust and efficient drawing recognition system that is based on a representation technique using accurate shape and topological line information for an input drawing image is described. This representation supports primitive decomposition and object extraction that enable accurate automatic interpretation even for low-quality drawings. The system, which is adapted to an underground electric cable diagram, has been implemented on a workstation.<<ETX>>"
"L. Boatto, Vincenzo Consorti, M. Buono, V. Eramo, A. Esposito, F. Melcarne, Marco Meucci, Andrea Morelli, M. Mosciatti, Aido Spirito, M. Tucci",f296d0580d05f3753a39361ef426996e35011233,Detection and separation of symbols connected to graphics in line drawings,"Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems",1992.0,14,"Presents a technique for the detection and separation of symbols connected to graphics in line drawings. The approach is based on a special image representation, that the authors call graph representation. The graph representation is especially convenient for line-like images, since it decomposes the line structure into 'edges' and 'nodes', that formalise the intuitive notions of 'line' and 'crossing point between lines'. In this way, well-known algorithms from graph theory can be used. The graph is searched for characteristic sub-graphs, revealing the presence of symbols or noisy objects overlapping lines. Each symbol candidate is accurately processed, in order to make the area of its connection to lines as regular as possible. Actually, two different algorithms have been designed to perform this task: one for symbols crossing lines and the other for symbols only touching lines. Both of them are rotation invariant.<<ETX>>"
"A. Hrivnak, L. Sobotová",27520dc1e039a375fdfec6ddab83f816a6243c7e,The influence of the deformational ageing and the conditions of stress on the properties of the deep-drawing steel sheet,,1992.0,10,"Abstract In the contributions there are shown the results of the experimental research of the influences of deformational ageing on the mechanical and technological properties of the deep-drawn steel sheets. The influence of temperature on ageing and the deformation degree at the uniaxial and biaxial tensile stress before ageing was experimentally studied on the index of ageing δ A , ductility, hardness and on the deeping of the modified Erichsen cupping test."
"P. Benson, D. Perrett",329b76418ad7777e069fd73dc25199a61237dc19,Perception and recognition of photographic quality facial caricatures: Implications for the recognition of natural images,,1991.0,229,"Abstract The perception and recognition of photographic images of famous faces was compared with the same images transformed to produce caricatures of different degrees of exaggeration. Following Brennan (1982; 1985). caricatures were produced by first comparing the position of facial features in a frame-grabbed image with the average position for a series of faces; deviations from the average were then accentuated by a constant fraction (16, 32 or 48%). Photographic quality caricatures for seven famous faces were generated by distorting regions of the original images in accordance with the change in feature positions. Images reducing the distinctiveness of faces (anticaricatures) were produced by decreasing deviations from the norm. In Experiment 1, perceptual ratings of the degree to which images resembled the individuals depicted was found to vary with the degree of caricaturing (−32, −16, 0, +16, +32%). Interpolation from the data indicated that the best likeness occurred for images with a small degre..."
"P. Benson, D. Perrett",dd2778c653dfcaa8318fa039ac2a09aca32f9db6,Synthesising continuous-tone caricatures,Image Vis. Comput.,1991.0,132,"Abstract A series of tools has been developed to synthesize full colour photographic quality facial caricatures. Real faces, photographs or single-frame video films are frame-grabbed and the position of (186) key points around external and internal features are interactively defined. Following procedures of Brennan 7,8 the 2D Cartesian coordinates of each feature point are compared with those of an average for many faces; differences in positions are exaggerated (to produce caricature data sets) or reduced (giving ‘anticaricature’ data sets). Line-drawing representations of faces and their caricatures are formed by linking appropriate feature points. To produce continuous-tone caricatures, the original and caricature images are resolved into (340) adjacent triangular tessellations. Rendering of the final image is accomplished by mapping the pixel values (grey-scale or colour) from each source triangle in the original image to the corresponding triangle in the caricature image. The caricatures not only provide amusement, but can be used as stimuli in psychological investigations into the representation of faces in human memory."
"S. Yossifon, J. Tirosh",e096034f168d17520fe671b687bc44526b578518,On the dimensional accuracy of deep drawing products by hydroforming processes,,1991.0,17,"Abstract In the hydroforming process the punch deforms the blank to its final shape by moving against a controllable fluid-pressure in a pre-determined path. The present work exhibits the fact that the final geometry of the product (mainly the wall thickness variations) depends on the overall history by which the fluid pressure-path is operated during the drawing process. In addition, other phenomena akin to hydroforming processes have been observed, e.g. the shift in the location of the rupture site (if it occurs) from near the bottom of the product to near its lip and the (slight) variation in the final length of the product. In order to explain these occurrences a detailed numerical stress analysis is offered, featured by an ad-hoc “finite difference” scheme. It differs from previous solutions by admitting changes in the thickness of the blank and still accounting for the blank/tool interfacial friction and the out-of-plane curvature of the product. The material behavior of the blank includes exponential strain hardening, normal anisotropy and initial strain. The experiments shown here were carried out on aluminum sheets with a specially built hydroforming machine."
"M. Marques, R. Baptista",756639fa3434809431ea036f8840962f72017d3f,Theoretical and experimental analysis of axisymmetrical deep drawing,,1990.0,13,"Abstract The paper deals with the use of the code ABAQUS in the analysis of axisymmetric cup deep drawing. The selected cases take into account the different friction effects at the punch/sheet, die/sheet and holder/sheet interfaces. Coulomb friction's law is assumed. The true stress-true strain curve of the cup material was obtained from tensile tests on AISI 304 stainless steel. The tests were performed in an universal testing machine and the deformations were calculated from grids impressed on the specimens. To validate the computational results, experimental work was carried out. Hemispherical cup deep drawing tests were performed in a double effect hydraulic press. Punch and holder loads, as well as the punch displacement were recorded by a data acquisition system during the deep drawing operation. Radial and hoop strains were measured from grids impressed in the blank by an electrochemical process. Computational results, punch force-punch displacement curve and strain distributions are discussed and compared with the experimental ones."
"L. Cannizzaro, F. Micari, S. L. Diega",c903db56cb199643755431e3e21d17afbc155758,Finite element analysis of the reverse drawing process,,1990.0,10,Abstract A finite element analysis has been applied to model the reverse drawing process. The influence of two different strain hardening behaviours and of some operating parameters has been investigated by means of the updated Lagrangian approach which allows taking into account large deformations and strains.
"R. Tamassia, G. Battista, C. Batini",4a6e77716a298650dda87925689eac904119f63b,Automatic graph drawing and readability of diagrams,IEEE Trans. Syst. Man Cybern.,1988.0,475,"The state of the art in automatic graph drawing is reviewed, with special attention to the readability of information system diagrams. Existing results in the literature are compared, and a comprehensive algorithmic approach to the problem is proposed. The algorithm presented draws graphs on a grid and is suitable for both undirected graphs and mixed graphs that contain as subgraphs hierarchic structures. Several applications of GIOTTO, a graphic tool that embodies the aforementioned facility, are shown. >"
"T. Pavlidis, C. V. Wyk",646ad58b0d56f0934fcbaa24c920fe3e76b19086,An automatic beautifier for drawings and illustrations,SIGGRAPH '85,1985.0,135,"We describe a method for inferring constraints that are desirable for a given (rough) drawing and then modifying the drawing to satisfy the constraints wherever possible. The method has been implemented as part of an online graphics editor running under the UNIX&trade; operating system and it has undergone modifications in response to user input. Although the framework we discuss is general, the current implementation is polygon-oriented. The relations examined are: approximate equality of the slope or length of sides, collinearity of sides, and vertical and horizontal alignment of points."
"C. H. Toh, Shiro Kobayashi",48a5689316e681192aee2a6ac35943da386a81d1,Deformation analysis and blank design in square cup drawing,,1985.0,91,"Abstract A finite-element procedure is developed for modeling of the square cup drawing process based on finite strain formulation and membrane theory. The sheet material was assumed to obey Hill's anisotropic yield criterion and its associated flow rule. The workhardening characteristics of the material and Coulomb friction between the sheet metal and forming tools were incorporated into the simulations. Computed results with a square blank for the strain distributions were found to be consistent experimental data. Solutions were also obtained for various blank shapes with identical surface areas. Good correlations were found between the finite-element predictions and experiments for load-displacement curves and deformed-flange configurations. Based on the finite-element results of net material flow during the deformaion, an optimum blank shape was determined. Using this optimum blank shape, both the finite-element simulation and cup drawing experiment were performed and it was shown that a cup with the flange of uniform size around its periphery was obtained at a predetermined cup height."
"A. Sengupta, B. Fogg, S. Ghosh",b5056fc0e7ac486cbefd550c299efbde4c63dda1,On the mechanism behind the punch-blank surface conformation in stretch-forming and deep-drawing,,1981.0,11,"Abstract In industrial sheet-metal forming operations such as deep-drawing and stretching, friction and evolution of surface texture are very important factors, especially to secure optimum forming depth and acceptable surface finish, and to prevent defects in the final products. The punch profile region experiences a severe tribological condition as the blank elements are subjected to sub-surface plastic flow and moderate-to-high tool-contact-pressure at extremely low relative sliding speeds. In the present paper a brief literature survey is presented concerning the surface interaction and friction between a workpiece experiencing bulk plastic flow and a polished, rigid tool. A friction measuring apparatus is described which could be used to investigate various tribological relationships pertaining to the sliding friction characteristics of the tool—workpiece interface. Results of a series of sliding friction tests, surface profile traces and their digital analyses and micro-hardness surveys are discussed and, based on these, an attempt has been made to understand the mechanism leading to the high tool—blank conformation at the punch profile in stretch-forming and deep-drawing operations."
"M. Gotoh, F. Ishisé",fc9363af738dfb00d772f0d47c726370721e972f,A finite element analysis of rigid-plastic deformation of the flange in a deep-drawing process based on a fourth-degree yield function,,1978.0,64,"Abstract A general formulation for finite element analyses of very large rigid-plastic deformation is given by introducing a local system of convected co-ordinates into each element and taking the rotation of the principal axes of orthotropy of the material into consideration with respect to the two cases: (1) the case where the equivalent strain-rate is given by a function of strain-rate components ϵ ij and (2) the case where is defined by the formula = σ ij ϵ ij \ gs , where σ ij are stress components and \ gs is the equivalent stress. example, large deformation of the flange region in a deep-drawing process of a circular orthotropic metal sheet is analyzed on the basis of the conventional quadratic yield function and a fourth-degree one. The result shows that the effect of the axis rotation suppresses the ear-development to a certain extent, that any explicit expression of in terms of ϵ ij is not necessarily required for calculation and the definition = σ ij ϵ ij \ gs suffices for the purpose, that the fourth-degree yield function gives us the shape of the deformed flange in good agreement with the experiment in contrast with the quadratic one which gives a too excessive ear-development, and so forth."
"W. Pferd, K. Ramachandran",02b49c7e1d89ac5b8713618e8b2004f0e9a283dd,Computer aided automatic digitizing of engineering drawings,COMPSAC,1978.0,16,"This paper discusses Computer Aided Automatic Digitizing (CAAD) of engineering drawings and the software necessary for efficient encoding, editing and display of the data. Various methods are discussed for scanning documents and an overview of algorithms is presented for encoding of the resulting data. A new vector-coding algorithm that is amenable to line extraction in real time is reported. Compaction ratios for various stages of the data processing are given."
Christopher F. Herot,53acb1a8495e66a8d9d07a9b46b491f3b8671c33,Graphical input through machine recognition of sketches,SIGGRAPH '76,1976.0,63,"A family of programs has been developed to allow graphical input through continuous digitizing. Drawing data, sampled at a high and constant rate, is compressed and mapped into lines and splines, in two and three dimensions. This is achieved by inferring a particular user's intentions from measures of speed and pressure.Recent experiments have shown that even the most basic inference making cannot rely solely upon knowledge of the user's drawing style, but needs additional knowledge of the subject being drawn, the protocols of its domain, and the stage of development of the user's design. This requirement implies a higher level of machine intelligence than currently exists. An alternate approach is to increase the user's involvement in the recognition process.Contrary to previous efforts to move from sketch to mechanical drawing without human intervention, this paper reports on an interactive system for graphical input in which the user overtly partakes in training the machine and massaging the data at all levels of interpretation. The initial routines for data compression employ parallel functions for extracting such features as bentness, straightness, and endness. These are planned for implementation in microprocessors.Results offer a system for rapid (and enjoyable) graphical input with real-time interpretation, the beginnings of an intelligent tablet."
D. Perkins,a0360def5675bc09e572922ba05b4fe21a0e4029,A Definition of Caricature and Caricature and Recognition,,1975.0,64,
Christopher F. Herot,3cd9b131b86f4953f23a901004c18ad7b9536aed,Using context in sketch recognition.,,1974.0,3,"A central problem in graphical communication between a human and a computer is the ability of the computer to build an internal representation of the human designer's intentions, something which is not possible if the machine does not have some knowledge of the subject matter being sketched. This thesis describes a system for storing such knowledge in the computer, to be used by the machine in building a model of the user's intentions. This semantic knowledge is stored in a network and matched to the input sketch in a top-down manner, using the knowledge to direct the machine's search for entities in the sketch. The operation of a simple program using these principles is presented in detail along with an account of the complexities involved in applying the scheme to complex sketches. Methods of representing relationships to be looked for in a drawing are described and examples are provided of some descriptions which should prove useful in the next implementation. Two implementatons are described, one on a mini-computer and one on a large time sharing system. Included is a discussion of the requirements such a program makes on the programming environment and their implications for the future of inexpensive mini-computer oriented implementations. THESIS SUPERVISOR: Nicholas P. Negroponte TITLE: Associate Professor of Architecture"
N. Negroponte,f294b3912f7cb13ff6181128198c31226d80d05b,Recent advances in sketch recognition,AFIPS National Computer Conference,1973.0,43,"In a shocking and almost silly interview with Max Jacobson, Christopher Alexander recounted the following story.
 ""There was a conference which I was invited to a few months ago where computer graphics was being discussed as one item and I was arguing very strongly against computer graphics simply because of the frame of mind that you need to be in to create a good building. Are you at peace with yourself? Are you thinking about smell and touch, and what happens when people are walking about in a place? But particularly, are you at peace with yourself? All of that is completely disturbed by the pretentiousness, insistence and complicatedness of computer graphics and all the allied techniques. So my final objection to that and to other types of methodology is that they actually prevent you from being in the right state of mind to do the design, quite apart from the question of whether they help in a sort of technical sense, which, as I said, I don't think they do."""
F. Parke,63f24b857fad276c13bfe763401ec72f343de167,Computer generated animation of faces,ACM Annual Conference,1972.0,425,"This paper describes the representation, animation and data collection techniques that have been used to produce ""realistic"" computer generated half-tone animated sequences of a human face changing expression. It was determined that approximating the surface of a face with a polygonal skin containing approximately 250 polygons defined by about 400 vertices is sufficient to achieve a realistic face. Animation was accomplished using a cosine interpolation scheme to fill in the intermediate frames between expressions. This approach is good enough to produce realistic facial motion. The three-dimensional data used to describe the expressions of the face was obtained photogrammetrically using pairs of photographs."
"N. Burtnyk, M. Wein",48537c35744ad8595c35cdf5514c27b7264d4eec,Computer-Generated Key-Frame Animation,,1971.0,130,"Special animation languages have been developed for specifying an image sequence to be generated by a computer. Although this approach to computer animation has provided some form of organization and control of the specification of image sequences, the computer remains out of reach to most animators because of the communication difficulty. An animator's ideas involve mainly pictures and their motion. Thus it is appropriate that the communication of ideas between the animator and the computer should be largely through pictures. An interactive computer-controlled graphical system allows the animator to develop pictorial sequences directly on a cathode-ray tube display, without forcing the animator to become a computer programer. The implementation of computer-generated key-frame animation is based on techniques that have been developed for conventional cel animation. Key frames are created and stored on a suitable medium such as digital magnetic tape or disc. In addition to the picture, information about the kind of motion and the number of frames from the previous key frame is specified. During playback of this sequence, the in-between frames are computed by interpolating between key frames and are displayed at the cine rate on the cathode-ray display. Thus previewing is available in seconds."
Min Yuan,2cadf52b820d31debe565c15317d86c3fcd3a91e,Line Art Colorization with Concatenated Spatial Attention,,,0,"Line art plays a fundamental role in illustration and design, and allows for iteratively polishing designs. However, as they lack color, they can have issues in conveying final designs. In this work, we propose an interactive colorization approach based on a conditional generative adversarial network that takes both the line art and color hints as inputs to produce a high-quality colorized image. Our approach is based on a U-net architecture with a multi-discriminator framework. We propose a Concatenation and Spatial Attention module that is able to generate more consistent and higher quality of line art colorization from user given hints. We evaluate on a large-scale illustration dataset and comparison with existing approaches corroborate the effectiveness of our approach."
Lvmin Zhang,f43302cc6fb115c97add812082db8b77970b4ec6,User-Guided Line Art Flat Filling with Split Filling Mechanism,,,0,"Flat filling is a critical step in digital artistic content creation with the objective of filling line arts with flat colors. We present a deep learning framework for user-guided line art flat filling that can compute the “influence areas” of the user color scribbles, i.e., the areas where the user scribbles should propagate and influence. This framework explicitly controls such scribble influence areas for artists to manipulate the colors of image details and avoid color leakage/contamination between scribbles, and simultaneously, leverages data-driven color generation to facilitate content creation. This framework is based on a Split Filling Mechanism (SFM), which first splits the user scribbles into individual groups and then independently processes the colors and influence areas of each group with a Convolutional Neural Network (CNN). Learned from more than a million illustrations, the framework can estimate the scribble influence areas in a content-aware manner, and can smartly generate visually pleasing colors to assist the daily works of artists. We show that our proposed framework is easy to use, allowing even amateurs to obtain professional-quality results on a wide variety of line arts."
Lvmin Zhang,7de5f1aa200affde036a1bb041be026d1eb92577,Generating Manga from Illustrations via Mimicking Manga Creation Workflow,,,0,"We present a framework to generate manga from digital illustrations. In professional mange studios, the manga create workflow consists of three key steps: (1) Artists use line drawings to delineate the structural outlines in manga storyboards. (2) Artists apply several types of regular screentones to render the shading, occlusion, and object materials. (3) Artists selectively paste irregular screen textures onto the canvas to achieve various background layouts or special effects. Motivated by this workflow, we propose a data-driven framework to convert a digital illustration into three corresponding components: manga line drawing, regular screentone, and irregular screen texture. These components can be directly composed into manga images and can be further retouched for more plentiful manga creations. To this end, we create a large-scale dataset with these three components annotated by artists in a human-in-the-loop manner. We conduct both perceptual user study and qualitative evaluation of the generated manga, and observe that our generated image layers for these three components are practically usable in the daily works of manga artists. We provide 60 qualitative results and 15 additional comparisons in the supplementary material. We will make our presented manga dataset publicly available to assist related applications."
